
Capitalist

Realism

Is There No Alternative?

To my wife, Zöe, my parents, Bob and Linda, and the readers of my website


It’s easier to imagine the end of the world than the end of capitalism


In one of the key scenes in Alfonso Cuarón’s 2006 film Children of Men, Clive Owen’s character, Theo, visits a friend at Battersea Power Station, which is now some combination of government building and private collection. Cultural treasures – Michelangelo’s David, Picasso’s Guernica, Pink Floyd’s inflatable pig – are preserved in a building that is itself a refurbished heritage artifact. This is our only glimpse into the lives of the elite, holed up against the effects of a catastrophe which has caused mass sterility: no children have been born for a generation. Theo asks the question, ‘how all this can matter if there will be no-one to see it?’ The alibi can no longer be future generations, since there will be none. The response is nihilistic hedonism: ‘I try not to think about it’.

What is unique about the dystopia in Children of Men is that it is specific to late capitalism. This isn’t the familiar totalitarian scenario routinely trotted out in cinematic dystopias (see, for example, James McTeigue’s 2005 V for Vendetta). In the PD. James novel on which the film is based, democracy is suspended and the country is ruled over by a self-appointed Warden, but, wisely, the film downplays all this. For all that we know, the authoritarian measures that are everywhere in place could have been implemented within a political structure that remains, notionally, democratic. The War on Terror has prepared us for such a development: the normalization of crisis produces a situation in which the repealing of measures brought in to deal with an emergency becomes unimaginable (when will the war be over?)

Watching Children of Men, we are inevitably reminded of the phrase attributed to Fredric Jameson and Slavoj Žižek, that it is easier to imagine the end of the world than it is to imagine the end of capitalism. That slogan captures precisely what I mean by ‘capitalist realism’: the widespread sense that not only is capitalism the only viable political and economic system, but also that it is now impossible even to imagine a coherent alternative to it. Once, dystopian films and novels were exercises in such acts of imagination – the disasters they depicted acting as narrative pretext for the emergence of different ways of living. Not so in Children of Men. The world that it projects seems more like an extrapolation or exacerbation of ours than an alternative to it. In its world, as in ours, ultra-authoritarianism and Capital are by no means incompatible: internment camps and franchise coffee bars co-exist. In Children of Men, public space is abandoned, given over to uncollected garbage and stalking animals (one especially resonant scene takes place inside a derelict school, through which a deer runs). Neoliberals, the capitalist realists par excellence, have celebrated the destruction of public space but, contrary to their official hopes, there is no withering away of the state in Children of Men, only a stripping back of the state to its core military and police functions (I say ‘official’ hopes since neoliberalism surreptitiously relied on the state even while it has ideologically excoriated it. This was made spectacularly clear during the banking crisis of 2008, when, at the invitation of neoliberal ideologues, the state rushed in to shore up the banking system.)

The catastrophe in Children of Men is neither waiting down the road, nor has it already happened. Rather, it is being lived through. There is no punctual moment of disaster; the world doesn’t end with a bang, it winks out, unravels, gradually falls apart. What caused the catastrophe to occur, who knows; its cause lies long in the past, so absolutely detached from the present as to seem like the caprice of a malign being: a negative miracle, a malediction which no penitence can ameliorate. Such a blight can only be eased by an intervention that can no more be anticipated than was the onset of the curse in the first place. Action is pointless; only senseless hope makes sense. Superstition and religion, the first resorts of the helpless, proliferate.

But what of the catastrophe itself? It is evident that the theme of sterility must be read metaphorically, as the displacement of another kind of anxiety. I want to argue this anxiety cries out to be read in cultural terms, and the question the film poses is: how long can a culture persist without the new? What happens if the young are no longer capable of producing surprises?

Children of Men connects with the suspicion that the end has already come, the thought that it could well be the case that the future harbors only reiteration and re-permutation. Could it be that there are no breaks, no ‘shocks of the new’ to come? Such anxieties tend to result in a bi-polar oscillation: the ‘weak messianic’ hope that there must be something new on the way lapses into the morose conviction that nothing new can ever happen. The focus shifts from the Next Big Thing to the last big thing – how long ago did it happen and just how big was it?

T.S. Eliot looms in the background of Children of Men, which, after all, inherits the theme of sterility from The Waste Land. The film’s closing epigraph ‘shantih shantih shantih’ has more to do with Eliot’s fragmentary pieces than the Upanishads’ peace. Perhaps it is possible to see the concerns of another Eliot – the Eliot of ‘Tradition and the Individual Talent’ – ciphered in Children of Men. It was in this essay that Eliot, in anticipation of Harold Bloom, described the reciprocal relationship between the canonical and the new. The new defines itself in response to what is already established; at the same time, the established has to reconfigure itself in response to the new. Eliot’s claim was that the exhaustion of the future does not even leave us with the past. Tradition counts for nothing when it is no longer contested and modified. A culture that is merely preserved is no culture at all. The fate of Picasso’s Guernica in the film – once a howl of anguish and outrage against Fascist atrocities, now a wall-hanging – is exemplary. Like its Battersea hanging space in the film, the painting is accorded ‘iconic’ status only when it is deprived of any possible function or context. No cultural object can retain its power when there are no longer new eyes to see it.

We do not need to wait for Children of Men’s near-future to arrive to see this transformation of culture into museum pieces. The power of capitalist realism derives in part from the way that capitalism subsumes and consumes all of previous history: one effect of its ‘system of equivalence’ which can assign all cultural objects, whether they are religious iconography, pornography, or Das Kapital, a monetary value. Walk around the British Museum, where you see objects torn from their lifeworlds and assembled as if on the deck of some Predator spacecraft, and you have a powerful image of this process at work. In the conversion of practices and rituals into merely aesthetic objects, the beliefs of previous cultures are objectively ironized, transformed into artifacts. Capitalist realism is therefore not a particular type of realism; it is more like realism in itself. As Marx and Engels themselves observed in The Communist Manifesto,

Capital () has drowned the most heavenly ecstasies of religious fervor, of chivalrous enthusiasm, of philistine sentimentalism, in the icy water of egotistical calculation. It has resolved personal worth into exchange value, and in place of the numberless indefeasible chartered freedoms, has set up that single, unconscionable freedom — Free Trade. In one word, for exploitation, veiled by religious and political illusions, it has substituted naked, shameless, direct, brutal exploitation.

Capitalism is what is left when beliefs have collapsed at the level of ritual or symbolic elaboration, and all that is left is the consumer-spectator, trudging through the ruins and the relics.

Yet this turn from belief to aesthetics, from engagement to spectatorship, is held to be one of the virtues of capitalist realism. In claiming, as Badiou puts it, to have ‘delivered us from the “fatal abstractions” inspired by the “ideologies of the past”’, capitalist realism presents itself as a shield protecting us from the perils posed by belief itself. The attitude of ironic distance proper to postmodern capitalism is supposed to immunize us against the seductions of fanaticism. Lowering our expectations, we are told, is a small price to pay for being protected from terror and totalitarianism. ‘We live in a contradiction,’ Badiou has observed:

a brutal state of affairs, profoundly inegalitarian – where all existence is evaluated in terms of money alone – is presented to us as ideal. To justify their conservatism, the partisans of the established order cannot really call it ideal or wonderful. So instead, they have decided to say that all the rest is horrible. Sure, they say, we may not live in a condition of perfect Goodness. But we’re lucky that we don’t live in a condition of Evil. Our democracy is not perfect. But it’s better than the bloody dictatorships. Capitalism is unjust. But it’s not criminal like Stalinism. We let millions of Africans die of AIDS, but we don’t make racist nationalist declarations like Milosevic. We kill Iraqis with our airplanes, but we don’t cut their throats with machetes like they do in Rwanda, etc.

The ‘realism’ here is analogous to the deflationary perspective of a depressive who believes that any positive state, any hope, is a dangerous illusion.

In their account of capitalism, surely the most impressive since Marx’s, Deleuze and Guattari describe capitalism as a kind of dark potentiality which haunted all previous social systems. Capital, they argue, is the ‘unnamable Thing’, the abomination, which primitive and feudal societies ‘warded off in advance’. When it actually arrives, capitalism brings with it a massive desacralization of culture. It is a system which is no longer governed by any transcendent Law; on the contrary, it dismantles all such codes, only to re-install them on an ad hoc basis. The limits of capitalism are not fixed by fiat, but defined (and redefined) pragmatically and improvisationally. This makes capitalism very much like the Thing in John Carpenter’s film of the same name: a monstrous, infinitely plastic entity, capable of metabolizing and absorbing anything with which it comes into contact. Capital, Deleuze and Guattari says, is a ‘motley painting of everything that ever was’; a strange hybrid of the ultra-modern and the archaic. In the years since Deleuze and Guattari wrote the two volumes of their Capitalism And Schizophrenia, it has seemed as if the deterritorializing impulses of capitalism have been confined to finance, leaving culture presided over by the forces of reterritorialization.

This malaise, the feeling that there is nothing new, is itself nothing new of course. We find ourselves at the notorious ‘end of history’ trumpeted by Francis Fukuyama after the fall of the Berlin Wall. Fukuyama’s thesis that history has climaxed with liberal capitalism may have been widely derided, but it is accepted, even assumed, at the level of the cultural unconscious. It should be remembered, though, that even when Fukuyama advanced it, the idea that history had reached a ‘terminal beach’ was not merely triumphalist. Fukuyama warned that his radiant city would be haunted, but he thought its specters would be Nietzschean rather than Marxian. Some of Nietzsche’s most prescient pages are those in which he describes the ‘oversaturation of an age with history’. ‘It leads an age into a dangerous mood of irony in regard to itself, he wrote in Untimely Meditations, ‘and subsequently into the even more dangerous mood of cynicism’, in which ‘cosmopolitan fingering’, a detached spectatorialism, replaces engagement and involvement. This is the condition of Nietzsche’s Last Man, who has seen everything, but is decadently enfeebled precisely by this excess of (self) awareness.

Fukuyama’s position is in some ways a mirror image of Fredric Jameson’s. Jameson famously claimed that postmodernism is the ‘cultural logic of late capitalism’. He argued that the failure of the future was constitutive of a postmodern cultural scene which, as he correctly prophesied, would become dominated by pastiche and revivalism. Given that Jameson has made a convincing case for the relationship between postmodern culture and certain tendencies in consumer (or post-Fordist) capitalism, it could appear that there is no need for the concept of capitalist realism at all. In some ways, this is true. What I’m calling capitalist realism can be subsumed under the rubric of postmodernism as theorized by Jameson. Yet, despite Jameson’s heroic work of clarification, postmodernism remains a hugely contested term, its meanings, appropriately but unhelpfully, unsettled and multiple. More importantly, I would want to argue that some of the processes which Jameson described and analyzed have now become so aggravated and chronic that they have gone through a change in kind.

Ultimately, there are three reasons that I prefer the term capitalist realism to postmodernism. In the 1980s, when Jameson first advanced his thesis about postmodernism, there were still, in name at least, political alternatives to capitalism. What we are dealing with now, however, is a deeper, far more pervasive, sense of exhaustion, of cultural and political sterility. In the 80s, ‘Really Existing Socialism’ still persisted, albeit in its final phase of collapse. In Britain, the fault lines of class antagonism were fully exposed in an event like the Miners’ Strike of 1984-1985, and the defeat of the miners was an important moment in the development of capitalist realism, at least as significant in its symbolic dimension as in its practical effects. The closure of pits was defended precisely on the grounds that keeping them open was not ‘economically realistic’, and the miners were cast in the role of the last actors in a doomed proletarian romance. The 80s were the period when capitalist realism was fought for and established, when Margaret Thatcher’s doctrine that ‘there is no alternative’ – as succinct a slogan of capitalist realism as you could hope for – became a brutally self-fulfilling prophecy.

Secondly, postmodernism involved some relationship to modernism. Jameson’s work on postmodernism began with an interrogation of the idea, cherished by the likes of Adorno, that modernism possessed revolutionary potentials by virtue of its formal innovations alone. What Jameson saw happening instead was the incorporation of modernist motifs into popular culture (suddenly, for example, Surrealist techniques would appear in advertising). At the same time as particular modernist forms were absorbed and commodified, modernism’s credos – its supposed belief in elitism and its monological, top-down model of culture – were challenged and rejected in the name of ‘difference’, ‘diversity’ and ‘multiplicity’. Capitalist realism no longer stages this kind of confrontation with modernism. On the contrary, it takes the vanquishing of modernism for granted: modernism is now something that can periodically return, but only as a frozen aesthetic style, never as an ideal for living.

Thirdly, a whole generation has passed since the collapse of the Berlin Wall. In the 1960s and 1970s, capitalism had to face the problem of how to contain and absorb energies from outside. It now, in fact, has the opposite problem; having all-too successfully incorporated externality, how can it function without an outside it can colonize and appropriate? For most people under twenty in Europe and North America, the lack of alternatives to capitalism is no longer even an issue. Capitalism seamlessly occupies the horizons of the thinkable. Jameson used to report in horror about the ways that capitalism had seeped into the very unconscious; now, the fact that capitalism has colonized the dreaming life of the population is so taken for granted that it is no longer worthy of comment. It would be dangerous and misleading to imagine that the near past was some prelapsarian state rife with political potentials, so it’s as well to remember the role that commodification played in the production of culture throughout the twentieth century. Yet the old struggle between detournement and recuperation, between subversion and incorporation, seems to have been played out. What we are dealing with now is not the incorporation of materials that previously seemed to possess subversive potentials, but instead, their precorporation: the pre-emptive formatting and shaping of desires, aspirations and hopes by capitalist culture. Witness, for instance, the establishment of settled ‘alternative’ or ‘independent’ cultural zones, which endlessly repeat older gestures of rebellion and contestation as if for the first time. ‘Alternative’ and ‘independent’ don’t designate something outside mainstream culture; rather, they are styles, in fact the dominant styles, within the mainstream. No-one embodied (and struggled with) this deadlock more than Kurt Cobain and Nirvana. In his dreadful lassitude and objectless rage, Cobain seemed to give wearied voice to the despondency of the generation that had come after history, whose every move was anticipated, tracked, bought and sold before it had even happened. Cobain knew that he was just another piece of spectacle, that nothing runs better on MTV than a protest against MTV; knew that his every move was a cliché scripted in advance, knew that even realizing it is a cliché. The impasse that paralyzed Cobain is precisely the one that Jameson described: like postmodern culture in general, Cobain found himself in ‘a world in which stylistic innovation is no longer possible, where () all that is left is to imitate dead styles, to speak through the masks and with the voices of the styles in the imaginary museum’. Here, even success meant failure, since to succeed would only mean that you were the new meat on which the system could feed. But the high existential angst of Nirvana and Cobain belongs to an older moment; what succeeded them was a pastiche-rock which reproduced the forms of the past without anxiety.

Cobain’s death confirmed the defeat and incorporation of rock’s utopian and promethean ambitions. When he died, rock was already being eclipsed by hip hop, whose global success has presupposed just the kind of precorporation by capital which I alluded to above. For much hip hop, any ‘naïve’ hope that youth culture could change anything has been replaced by the hard-headed embracing of a brutally reductive version of ‘reality’. ‘In hip hop’, Simon Reynolds pointed out in a 1996 essay in The Wire magazine,

‘real’ has two meanings. First, it means authentic, uncompro-mised music that refuses to sell out to the music industry and soften its message for crossover. ‘Real’ also signifies that the music reflects a ‘reality’ constituted by late capitalist economic instability, institutionalized racism, and increased surveillance and harassment of youth by the police. ‘Real’ means the death of the social: it means corporations who respond to increased profits not by raising pay or improving benefits but by …. downsizing (the laying-off the permanent workforce in order to create a floating employment pool of part-time and freelance workers without benefits or job security).

In the end, it was precisely hip hop’s performance of this first version of the real – ‘the uncompromising’ – that enabled its easy absorption into the second, the reality of late capitalist economic instability, where such authenticity has proven highly marketable. Gangster rap neither merely reflects pre-existing social conditions, as many of its advocates claim, nor does it simply cause those conditions, as its critics argue – rather the circuit whereby hip hop and the late capitalist social field feed into each other is one of the means by which capitalist realism transforms itself into a kind of anti-mythical myth. The affinity between hip hop and gangster movies such as Scarface, The Godfather films, Reservoir Dogs, Goodfellas and Pulp Fiction arises from their common claim to have stripped the world of sentimental illusions and seen it for ‘what it really is’: a Hobbesian war of all against all, a system of perpetual exploitation and generalized criminality. In hip hop, Reynolds writes, ‘To “get real” is to confront a state-of-nature where dog eats dog, where you’re either a winner or a loser, and where most will be losers’.

The same neo-noir worldview can be found in the comic books of Frank Miller and in the novels of James Ellroy. There is a kind of machismo of demythologization in Miller and Ellroy’s works. They pose as unflinching observers who refuse to prettify the world so that it can be fitted into the supposedly simple ethical binaries of the superhero comic and the traditional crime novel. The ‘realism’ here is somehow underscored, rather than undercut, by their fixation on the luridly venal – even though the hyperbolic insistence on cruelty, betrayal and savagery in both writers quickly becomes pantomimic. ‘In his pitch blackness’, Mike Davis wrote of Ellroy in 1992, ‘there is no light left to cast shadows and evil becomes a forensic banality. The result feels very much like the actual moral texture of the Reagan-Bush era: a supersaturation of corruption that fails any longer to outrage or even interest’. Yet this very desensitization serves a function for capitalist realism: Davis hypothesized that ‘the role of L.A. noir’ may have been ‘to endorse the emergence of homo reaganus’.



What if you held a protest and everyone came?


In the cases of gangster rap and Ellroy, capitalist realism takes the form of a kind of super-identification with capital at its most pitilessly predatory, but this need not be the case. In fact, capitalist realism is very far from precluding a certain anti-capitalism. After all, and as Žižek has provocatively pointed out, anti-capitalism is widely disseminated in capitalism. Time after time, the villain in Hollywood films will turn out to be the ‘evil corporation’. Far from undermining capitalist realism, this gestural anti-capitalism actually reinforces it. Take Disney/ Pixar’s Wall-E (2008). The film shows an earth so despoiled that human beings are no longer capable of inhabiting it. We’re left in no doubt that consumer capitalism and corporations – or rather one mega-corporation, Buy n Large – is responsible for this depredation; and when we see eventually see the human beings in offworld exile, they are infantile and obese, interacting via screen interfaces, carried around in large motorized chairs, and supping indeterminate slop from cups. What we have here is a vision of control and communication much as Jean Baudrillard understood it, in which subjugation no longer takes the form of a subordination to an extrinsic spectacle, but rather invites us to interact and participate. It seems that the cinema audience is itself the object of this satire, which prompted some right wing observers to recoil in disgust, condemning Disney/Pixar for attacking its own audience. But this kind of irony feeds rather than challenges capitalist realism. A film like Wall-E exemplifies what Robert Pfaller has called ‘interpassivity’: the film performs our anti-capitalism for us, allowing us to continue to consume with impunity. The role of capitalist ideology is not to make an explicit case for something in the way that propaganda does, but to conceal the fact that the operations of capital do not depend on any sort of subjectively assumed belief. It is impossible to conceive of fascism or Stalinism without propaganda – but capitalism can proceed perfectly well, in some ways better, without anyone making a case for it. Žižek’s counsel here remains invaluable. ‘If the concept of ideology is the classic one in which the illusion is located in knowledge’, he argues,

then today’s society must appear post-ideological: the prevailing ideology is that of cynicism; people no longer believe in ideological truth; they do not take ideological propositions seriously. The fundamental level of ideology, however, is not of an illusion masking the real state of things but that of an (unconscious) fantasy structuring our social reality itself. And at this level, we are of course far from being a post-ideological society. Cynical distance is just one way … to blind ourselves to the structural power of ideological fantasy: even if we do not take things seriously, even if we keep an ironical distance, we are still doing them.

Capitalist ideology in general, Žižek maintains, consists precisely in the overvaluing of belief – in the sense of inner subjective attitude – at the expense of the beliefs we exhibit and externalize in our behavior. So long as we believe (in our hearts) that capitalism is bad, we are free to continue to participate in capitalist exchange. According to Žižek, capitalism in general relies on this structure of disavowal. We believe that money is only a meaningless token of no intrinsic worth, yet we act as if it has a holy value. Moreover, this behavior precisely depends upon the prior disavowal – we are able to fetishize money in our actions only because we have already taken an ironic distance towards money in our heads.

Corporate anti-capitalism wouldn’t matter if it could be differentiated from an authentic anti-capitalist movement. Yet, even before its momentum was stalled by the September 11th attacks on the World Trade Center, the so called anti-capitalist movement seemed also to have conceded too much to capitalist realism. Since it was unable to posit a coherent alternative political-economic model to capitalism, the suspicion was that the actual aim was not to replace capitalism but to mitigate its worst excesses; and, since the form of its activities tended to be the staging of protests rather than political organization, there was a sense that the anti-capitalism movement consisted of making a series of hysterical demands which it didn’t expect to be met. Protests have formed a kind of carnivalesque background noise to capitalist realism, and the anti-capitalist protests share rather too much with hyper-corporate events like 2005’s Live 8, with their exorbitant demands that politicians legislate away poverty.

Live 8 was a strange kind of protest; a protest that everyone could agree with: who is it who actually wants poverty? And it is not that Live 8 was a ‘degraded’ form of protest. On the contrary, it was in Live 8 that the logic of the protest was revealed in its purest form. The protest impulse of the 60s posited a malevolent Father, the harbinger of a reality principle that (supposedly) cruelly and arbitrarily denies the ‘right’ to total enjoyment. This Father has unlimited access to resources, but he selfishly – and senselessly – hoards them. Yet it is not capitalism but protest itself which depends upon this figuration of the Father; and one of the successes of the current global elite has been their avoidance of identification with the figure of the hoarding Father, even though the ‘reality’ they impose on the young is substantially harsher than the conditions they protested against in the 60s. Indeed, it was of course the global elite itself – in the form of entertainers such as Richard Curtis and Bono – which organized the Live 8 event. To reclaim a real political agency means first of all accepting our insertion at the level of desire in the remorseless meat-grinder of Capital. What is being disavowed in the abjection of evil and ignorance onto fantasmatic Others is our own complicity in planetary networks of oppression. What needs to be kept in mind is both that capitalism is a hyper-abstract impersonal structure and that it would be nothing without our co-operation. The most Gothic description of Capital is also the most accurate. Capital is an abstract parasite, an insatiable vampire and zombie-maker; but the living flesh it converts into dead labor is ours, and the zombies it makes are us. There is a sense in which it simply is the case that the political elite are our servants; the miserable service they provide from us is to launder our libidos, to obligingly re-present for us our disavowed desires as if they had nothing to do with us.

The ideological blackmail that has been in place since the original Live Aid concerts in 1985 has insisted that ‘caring individuals’ could end famine directly, without the need for any kind of political solution or systemic reorganization. It is necessary to act straight away, we were told; politics has to be suspended in the name of ethical immediacy. Bono’s Product Red brand wanted to dispense even with the philanthropic intermediary. ‘Philanthropy is like hippy music, holding hands’, Bono proclaimed. ‘Red is more like punk rock, hip hop, this should feel like hard commerce’. The point was not to offer an alternative to capitalism – on the contrary, Product Red’s ‘punk rock’ or ‘hip hop’ character consisted in its ‘realistic’ acceptance that capitalism is the only game in town. No, the aim was only to ensure that some of the proceeds of particular transactions went to good causes. The fantasy being that western consumerism, far from being intrinsically implicated in systemic global inequalities, could itself solve them. All we have to do is buy the right products.



Capitalism and the Real


‘Capitalist realism’ is not an original coinage. It was used as far back as the 1960s by a group of German Pop artists and by Michael Schudson in his 1984 book Advertising, The Uneasy Persuasion, both of whom were making parodic references to socialist realism. What is new about my use of the term is the more expansive – even exorbitant – meaning that I ascribe to it. Capitalist realism as I understand it cannot be confined to art or to the quasi-propagandistic way in which advertising functions. It is more like a pervasive atmosphere, conditioning not only the production of culture but also the regulation of work and education, and acting as a kind of invisible barrier constraining thought and action.

If capitalist realism is so seamless, and if current forms of resistance are so hopeless and impotent, where can an effective challenge come from? A moral critique of capitalism, emphasizing the ways in which it leads to suffering, only reinforces capitalist realism. Poverty, famine and war can be presented as an inevitable part of reality, while the hope that these forms of suffering could be eliminated easily painted as naive utopianism. Capitalist realism can only be threatened if it is shown to be in some way inconsistent or untenable; if, that is to say, capitalism’s ostensible ‘realism’ turns out to be nothing of the sort.

Needless to say, what counts as ‘realistic’, what seems possible at any point in the social field, is defined by a series of political determinations. An ideological position can never be really successful until it is naturalized, and it cannot be naturalized while it is still thought of as a value rather than a fact. Accordingly, neoliberalism has sought to eliminate the very category of value in the ethical sense. Over the past thirty years, capitalist realism has successfully installed a ‘business ontology’ in which it is simply obvious that everything in society, including healthcare and education, should be run as a business. As any number of radical theorists from Brecht through to Foucault and Badiou have maintained, emancipatory politics must always destroy the appearance of a ‘natural order’, must reveal what is presented as necessary and inevitable to be a mere contingency, just as it must make what was previously deemed to be impossible seem attainable. It is worth recalling that what is currently called realistic was itself once ‘impossible’: the slew of privatizations that took place since the 1980s would have been unthinkable only a decade earlier, and the current political-economic landscape (with unions in abeyance, utilities and railways denationalized) could scarcely have been imagined in 1975. Conversely, what was once eminently possible is now deemed unrealistic. ‘Modernization’, Badiou bitterly observes, ‘is the name for a strict and servile definition of the possible. These ‘reforms’ invariably aim at making impossible what used to be practicable (for the largest number), and making profitable (for the dominant oligarchy) what did not used to be so’.

At this point, it is perhaps worth introducing an elementary theoretical distinction from Lacanian psychoanalysis which Žižek has done so much to give contemporary currency: the difference between the Real and reality. As Alenka Zupancic explains, psychoanalysis’s positing of a reality principle invites us to be suspicious of any reality that presents itself as natural. ‘The reality principle’, Zupancic writes,

is not some kind of natural way associated with how things are ... The reality principle itself is ideologically mediated; one could even claim that it constitutes the highest form of ideology, the ideology that presents itself as empirical fact (or biological, economic...) necessity (and that we tend to perceive as non-ideological). It is precisely here that we should be most alert to the functioning of ideology.

For Lacan, the Real is what any ‘reality’ must suppress; indeed, reality constitutes itself through just this repression. The Real is an unrepresentable X, a traumatic void that can only be glimpsed in the fractures and inconsistencies in the field of apparent reality. So one strategy against capitalist realism could involve invoking the Real(s) underlying the reality that capitalism presents to us.

Environmental catastrophe is one such Real. At one level, to be sure, it might look as if Green issues are very far from being ‘unrepresentable voids’ for capitalist culture. Climate change and the threat of resource-depletion are not being repressed so much as incorporated into advertising and marketing. What this treatment of environmental catastrophe illustrates is the fantasy structure on which capitalist realism depends: a presupposition that resources are infinite, that the earth itself is merely a husk which capital can at a certain point slough off like a used skin, and that any problem can be solved by the market (In the end, Wall-E presents a version of this fantasy – the idea that the infinite expansion of capital is possible, that capital can proliferate without labor – on the off world ship, Axiom, all labor is performed by robots; that the burning up of Earth’s resources is only a temporary glitch, and that, after a suitable period of recovery, capital can terraform the planet and recolonize it). Yet environmental catastrophe features in late capitalist culture only as a kind of simulacra, its real implications for capitalism too traumatic to be assimilated into the system. The significance of Green critiques is that they suggest that, far from being the only viable political-economic system, capitalism is in fact primed to destroy the entire human environment. The relationship between capitalism and eco-disaster is neither coincidental nor accidental: capital’s ‘need of a constantly expanding market’, its ‘growth fetish’, mean that capitalism is by its very nature opposed to any notion of sustainability.

But Green issues are already a contested zone, already a site where politicization is being fought for. In what follows, I want to stress two other aporias in capitalist realism, which are not yet politicized to anything like the same degree. The first is mental health. Mental health, in fact, is a paradigm case of how capitalist realism operates. Capitalist realism insists on treating mental health as if it were a natural fact, like weather (but, then again, weather is no longer a natural fact so much as a political-economic effect). In the 1960s and 1970s, radical theory and politics (Laing, Foucault, Deleuze and Guattari, etc.) coalesced around extreme mental conditions such as schizophrenia, arguing, for instance, that madness was not a natural, but a political, category. But what is needed now is a politicization of much more common disorders. Indeed, it is their very commonness which is the issue: in Britain, depression is now the condition that is most treated by the NHS. In his book The Selfish Capitalist, Oliver James has convincingly posited a correlation between rising rates of mental distress and the neoliberal mode of capitalism practiced in countries like Britain, the USA and Australia. In line with James’s claims, I want to argue that it is necessary to reframe the growing problem of stress (and distress) in capitalist societies. Instead of treating it as incumbent on individuals to resolve their own psychological distress, instead, that is, of accepting the vast privatization of stress that has taken place over the last thirty years, we need to ask: how has it become acceptable that so many people, and especially so many young people, are ill? The ‘mental health plague’ in capitalist societies would suggest that, instead of being the only social system that works, capitalism is inherently dysfunctional, and that the cost of it appearing to work is very high.

The other phenomenon I want to highlight is bureaucracy. In making their case against socialism, neoliberal ideologues often excoriated the top-down bureaucracy which supposedly led to institutional sclerosis and inefficiency in command economies. With the triumph of neoliberalism, bureaucracy was supposed to have been made obsolete; a relic of an unlamented Stalinist past. Yet this is at odds with the experiences of most people working and living in late capitalism, for whom bureaucracy remains very much a part of everyday life. Instead of disappearing, bureaucracy has changed its form; and this new, decentralized, form has allowed it to proliferate. The persistence of bureaucracy in late capitalism does not in itself indicate that capitalism does not work – rather, what it suggests is that the way in which capitalism does actually work is very different from the picture presented by capitalist realism.

In part, I have chosen to focus on mental health problems and bureaucracy because they both feature heavily in an area of culture which has becoming increasingly dominated by the imperatives of capitalist realism: education. Through most of the current decade, I worked as a lecturer in a Further Education college, and in what follows, I will draw extensively on my experiences there. In Britain, Further Education colleges used to be places which students, often from working class backgrounds, were drawn to if they wanted an alternative to more formal state educational institutions. Ever since Further Education colleges were removed from local authority control in the early 1990s, they have become subject both to ‘market’ pressures and to government-imposed targets. They have been at the vanguard of changes that would be rolled out through the rest of the education system and public services – a kind of lab in which neoliberal ‘reforms’ of education have been trialed, and as such, they are the perfect place to begin an analysis of the effects of capitalist realism.


Reflexive impotence, immobilization and liberal communism


By contrast with their forebears in the 1960s and 1970s, British students today appear to be politically disengaged. While French students can still be found on the streets protesting against neoliberalism, British students, whose situation is incomparably worse, seem resigned to their fate. But this, I want to argue, is a matter not of apathy, nor of cynicism, but of reflexive impotence. They know things are bad, but more than that, they know they can’t do anything about it. But that ‘knowledge’, that reflexivity, is not a passive observation of an already existing state of affairs. It is a self-fulfilling prophecy.

Reflexive impotence amounts to an unstated worldview amongst the British young, and it has its correlate in widespread pathologies. Many of the teenagers I worked with had mental health problems or learning difficulties. Depression is endemic. It is the condition most dealt with by the National Health Service, and is afflicting people at increasingly younger ages. The number of students who have some variant of dyslexia is astonishing. It is not an exaggeration to say that being a teenager in late capitalist Britain is now close to being reclassified as a sickness. This pathologization already forecloses any possibility of politicization. By privatizing these problems – treating them as if they were caused only by chemical imbalances in the individual’s neurology and/or by their family background – any question of social systemic causation is ruled out.

Many of the teenage students I encountered seemed to be in a state of what I would call depressive hedonia. Depression is usually characterized as a state of anhedonia, but the condition I’m referring to is constituted not by an inability to get pleasure so much as it by an inability to do anything else except pursue pleasure. There is a sense that ‘something is missing’ – but no appreciation that this mysterious, missing enjoyment can only be accessed beyond the pleasure principle. In large part this is a consequence of students’ ambiguous structural position, stranded between their old role as subjects of disciplinary institutions and their new status as consumers of services. In his crucial essay ‘Postscript on Societies of Control’, Deleuze distinguishes between the disciplinary societies described by Foucault, which were organized around the enclosed spaces of the factory, the school and the prison, and the new control societies, in which all institutions are embedded in a dispersed corporation.

Deleuze is right to argue that Kafka is the prophet of distributed, cybernetic power that is typical of Control societies. In The Trial, Kafka importantly distinguishes between two types of acquittal available to the accused. Definite acquittal is no longer possible, if it ever was (‘we have only legendary accounts of ancient cases which () provide instances of acquittal’). The two remaining options, then, are (1) ‘Ostensible acquittal’, in which the accused is to all and intents and purposes acquitted, but may later, at some unspecified time, face the charges in full, or (2) ‘Indefinite postponement’, in which the accused engages in (what they hope is an infinitely) protracted process of legal wrangling, so that the dreaded ultimate judgment is unlikely to be forthcoming. Deleuze observes that the Control societies delineated by Kafka himself, but also by Foucault and Burroughs, operate using indefinite postponement: Education as a lifelong process... Training that persists for as long as your working life continues... Work you take home with you… Working from home, homing from work. A consequence of this ‘indefinite’ mode of power is that external surveillance is succeeded by internal policing. Control only works if you are complicit with it. Hence the Burroughs figure of the ‘Control Addict’: the one who is addicted to control, but also, inevitably, the one who has been taken over, possessed by Control.

Walk into almost any class at the college where I taught and you will immediately appreciate that you are in a post-disciplinary framework. Foucault painstakingly enumerated the way in which discipline was installed through the imposition of rigid body postures. During lessons at our college, however, students will be found slumped on desk, talking almost constantly, snacking incessantly (or even, on occasions, eating full meals). The old disciplinary segmentation of time is breaking down. The carceral regime of discipline is being eroded by the technologies of control, with their systems of perpetual consumption and continuous development.

The system by which the college is funded means that it literally cannot afford to exclude students, even if it wanted to. Resources are allocated to colleges on the basis of how successfully they meet targets on achievement (exam results), attendance and retention of students. This combination of market imperatives with bureaucratically-defined ‘targets’ is typical of the ‘market Stalinist’ initiatives which now regulate public services. The lack of an effective disciplinary system has not, to say the least, been compensated for by an increase in student self-motivation. Students are aware that if they don’t attend for weeks on end, and/or if they don’t produce any work, they will not face any meaningful sanction. They typically respond to this freedom not by pursuing projects but by falling into hedonic (or anhedonic) lassitude: the soft narcosis, the comfort food oblivion of Playstation, all-night TV and marijuana.

Ask students to read for more than a couple of sentences and many – and these are A-level students mind you – will protest that they can’t do it. The most frequent complaint teachers hear is that it’s boring. It is not so much the content of the written material that is at issue here; it is the act of reading itself that is deemed to be ‘boring’. What we are facing here is not just time–honored teenage torpor, but the mismatch between a post-literate ‘New Flesh’ that is ‘too wired to concentrate’ and the confining, concentrational logics of decaying disciplinary systems. To be bored simply means to be removed from the communicative sensation-stimulus matrix of texting, YouTube and fast food; to be denied, for a moment, the constant flow of sugary gratification on demand. Some students want Nietzsche in the same way that they want a hamburger; they fail to grasp – and the logic of the consumer system encourages this misapprehension – that the indigestibility, the difficulty is Nietzsche.

An illustration: I challenged one student about why he always wore headphones in class. He replied that it didn’t matter, because he wasn’t actually playing any music. In another lesson, he was playing music at very low volume through the headphones, without wearing them. When I asked him to switch it off, he replied that even he couldn’t hear it. Why wear the headphones without playing music or play music without wearing the headphones? Because the presence of the phones on the ears or the knowledge that the music is playing (even if he couldn’t hear it) was a reassurance that the matrix was still there, within reach. Besides, in a classic example of interpassivity, if the music was still playing, even if he couldn’t hear it, then the player could still enjoy it on his behalf. The use of headphones is significant here – pop is experienced not as something which could have impacts upon public space, but as a retreat into private ‘OedIpod’ consumer bliss, a walling up against the social.

The consequence of being hooked into the entertainment matrix is twitchy, agitated interpassivity, an inability to concentrate or focus. Students’ incapacity to connect current lack of focus with future failure, their inability to synthesize time into any coherent narrative, is symptomatic of more than mere demotivation. It is, in fact, eerily reminiscent of Jameson’s analysis in ‘Postmodernism and Consumer Society’. Jameson observed there that Lacan’s theory of schizophrenia offered a ‘suggestive aesthetic model’ for understanding the fragmenting of subjectivity in the face of the emerging entertainment-industrial complex. ‘With the breakdown of the signifying chain’, Jameson summarized, ‘the Lacanian schizophrenic is reduced to an experience of pure material signifiers, or, in other words, a series of pure and unrelated presents in time’. Jameson was writing in the late 1980s – i.e. the period in which most of my students were born. What we in the classroom are now facing is a generation born into that ahistorical, anti-mnemonic blip culture – a generation, that is to say, for whom time has always come ready-cut into digital micro-slices.

If the figure of discipline was the worker-prisoner, the figure of control is the debtor-addict. Cyberspatial capital operates by addicting its users; William Gibson recognized that in Neuromancer when he had Case and the other cyberspace cowboys feeling insects-under-the-skin strung out when they unplugged from the matrix (Case’s amphetamine habit is plainly the substitute for an addiction to a far more abstract speed). If, then, something like attention deficit hyperactivity disorder is a pathology, it is a pathology of late capitalism – a consequence of being wired into the entertainment-control circuits of hyperme-diated consumer culture. Similarly, what is called dyslexia may in many cases amount to a post-lexia. Teenagers process capital’s image-dense data very effectively without any need to read –slogan-recognition is sufficient to navigate the net-mobile-magazine informational plane. ‘Writing has never been capitalism’s thing. Capitalism is profoundly illiterate’, Deleuze and Guattari argued in Anti-Oedipus. ‘Electric language does not go by way of the voice or writing: data processing does without them both’. Hence the reason that many successful business people are dyslexic (but is their post-lexical efficiency a cause or effect of their success?)

Teachers are now put under intolerable pressure to mediate between the post-literate subjectivity of the late capitalist consumer and the demands of the disciplinary regime (to pass examinations etc). This is one way in which education, far from being in some ivory tower safely inured from the ‘real world’, is the engine room of the reproduction of social reality, directly confronting the inconsistencies of the capitalist social field. Teachers are caught between being facilitator-entertainers and disciplinarian-authoritarians. Teachers want to help students to pass the exams; they want us to be authority figures who tell them what to do. Teachers being interpellated by students as authority figures exacerbates the ‘boredom’ problem, since isn’t anything that comes from the place of authority a priori boring? Ironically, the role of disciplinarian is demanded of educators more than ever at precisely the time when disciplinary structures are breaking down in institutions. With families buckling under the pressure of a capitalism which requires both parents to work, teachers are now increasingly required to act as surrogate parents, instilling the most basic behavioral protocols in students and providing pastoral and emotional support for teenagers who are in some cases only minimally socialized.

It is worth stressing that none of the students I taught had any legal obligation to be at college. They could leave if they wanted to. But the lack of any meaningful employment opportunities, together with cynical encouragement from government means that college seems to be the easier, safer option. Deleuze says that Control societies are based on debt rather than enclosure; but there is a way in which the current education system both indebts and encloses students. Pay for your own exploitation, the logic insists – get into debt so you can get the same McJob you could have walked into if you’d left school at sixteen…

Jameson observed that ‘the breakdown of temporality suddenly releases the () present of time from all the activities and intentionalities that might focus it and make it a space of praxis’. But nostalgia for the context in which the old types of praxis operated is plainly useless. That is why French students don’t in the end constitute an alternative to British reflexive impotence. That the neoliberal Economist would deride French opposition to capitalism is hardly surprising, yet its mockery of French ‘immobilization’ had a point. ‘Certainly the students who kicked off the latest protests seemed to think they were re-enacting the events of May 1968 their parents sprang on Charles de Gaulle’, it wrote in its lead article of March 30, 2006.

They have borrowed its slogans (‘Beneath the cobblestones, the beach!’) and hijacked its symbols (the Sorbonne university). In this sense, the revolt appears to be the natural sequel to 2005 ()’s suburban riots, which prompted the government to impose a state of emergency. Then it was the jobless, ethnic underclass that rebelled against a system that excluded them. Yet the striking feature of the latest protest movement is that this time the rebellious forces are on the side of conservatism. Unlike the rioting youths in the banlieues, the objective of the students and public-sector trade unions is to prevent change, and to keep France the way it is.

It’s striking how the practice of many of the immobilizers is a kind of inversion of that of another group who also count themselves heirs of 68: the so called ‘liberal communists’ such as George Soros and Bill Gates who combine rapacious pursuit of profit with the rhetoric of ecological concern and social responsibility. Alongside their social concern, liberal communists believe that work practices should be (post) modernized, in line with the concept of ‘being smart’. As Žižek explains,

Being smart means being dynamic and nomadic, and against centralized bureaucracy; believing in dialogue and cooperation as against central authority; in flexibility as against routine; culture and knowledge as against industrial production; in spontaneous interaction and autopoiesis as against fixed hierarchy.

Taken together, the immobilizers, with their implicit concession that capitalism can only be resisted, never overcome, and the liberal communists, who maintain that the amoral excesses of capitalism must be offset by charity, give a sense of the way in which capitalist realism circumscribes current political possibilities. Whereas the immobilizers retain the form of 68-style protest but in the name of resistance to change, liberal communists energetically embrace newness. Žižek is right to argue that, far from constituting any kind of progressive corrective to official capitalist ideology, liberal communism constitutes the dominant ideology of capitalism now. ‘Flexibility’, ‘nomadism’ and ‘spontaneity’ are the very hallmarks of management in a post-Fordist, Control society. But the problem is that any opposition to flexibility and decentralization risks being self-defeating, since calls for inflexibility and centralization are, to say the least, not likely to be very galvanizing.

In any case, resistance to the ‘new’ is not a cause that the left can or should rally around. Capital thought very carefully about how to break labor; yet there has still not yet been enough thought about what tactics will work against capital in conditions of post-Fordism, and what new language can be innovated to deal with those conditions. It is important to contest capitalism’s appropriation of ‘the new’, but to reclaim the ‘new’ can’t be a matter of adapting to the conditions in which we find ourselves –we’ve done that rather too well, and ‘successful adaptation’ is the strategy of managerialism par excellence.

The persistent association of neoliberalism with the term ‘Restoration’, favored by both Badiou and David Harvey, is an important corrective to the association of capital with novelty. For Harvey and Badiou, neoliberal politics are not about the new, but a return of class power and privilege. ‘I ()n France,’ Badiou has said, ‘‘Restoration’ refers to the period of the return of the King, in 1815, after the Revolution and Napoleon. We are in such a period. Today we see liberal capitalism and its political system, parliamentarianism, as the only natural and acceptable solutions’. Harvey argues that neoliberalization is best conceived of as a ‘political project to re-establish the conditions for capital accumulation and to restore the power of economic elites’. Harvey demonstrates that, in an era popularly described as ‘post-political’, class war has continued to be fought, but only by one side: the wealthy. ‘After the implementation of neoliberal policies in the late 1970s,’ Harvey reveals,

the share of national income of the top 1 per cent of income earners soared, to reach 15 per cent ... by the end of the century. The top 0.1 per cent of income earners in the US increased their share of the national income from 2 per cent in 1978 to over 6 per cent by 1999, while the ratio of the median compensation of workers to the salaries of CEOs increased from just over 30 to 1 in 1970 to nearly 500 to 1 by 2000.... The US is not alone in this: the top 1 per cent of income earners in Britain have doubled their share of the national income from 6.5 per cent to 13 per cent since 1982.

As Harvey shows, neoliberals were more Leninist than the Leninists, using think-tanks as the intellectual vanguard to create the ideological climate in which capitalist realism could flourish.

The immobilization model – which amounts to a demand to retain the Fordist/disciplinary regime – could not work in Britain or the other countries in which neoliberalism has already taken a hold. Fordism has definitively collapsed in Britain, and with it the sites around which the old politics were organized. At the end of the control essay, Deleuze wonders what new forms an anti-control politics might take:

One of the most important questions will concern the ineptitude of the unions: tied to the whole of their history of struggle against the disciplines or within the spaces of enclosure, will they be able to adapt themselves or will they give way to new forms of resistance against the societies of control? Can we already grasp the rough outlines of the coming forms, capable of threatening the joys of marketing? Many young people strangely boast of being “motivated”; they re-request apprenticeships and permanent training. It’s up to them to discover what they’re being made to serve, just as their elders discovered, not without difficulty, the telos of the disciplines.

What must be discovered is a way out of the motivation/demotivation binary, so that disidentification from the control program registers as something other than dejected apathy. One strategy would be to shift the political terrain – to move away from the unions’ traditional focus on pay and onto forms of discontent specific to post-Fordism. Before we analyse that further, we must consider in more depth what post-Fordism actually is.



October 6, 1979: ‘Don’t let yourself get attached to anything’


‘A guy told me one time’, says organized crime boss Neil McCauley in Michael Mann’s 1995 film Heat, ’Don’t let yourself get attached to anything you are not willing to walk out on in 30 seconds flat if you feel the heat around the corner’. One of the easiest ways to grasp the differences between Fordism and post-Fordism is to compare Mann’s film with the gangster movies made by Francis Ford Coppola and Martin Scorsese between 1971 and 1990. In Heat, the scores are undertaken not by Families with links to the Old Country, but by rootless crews, in an LA of polished chrome and interchangeable designer kitchens, of featureless freeways and late-night diners. All the local color, the cuisine aromas, the cultural idiolects which the likes of The Godfather and Goodfellas depended upon have been painted over and re-fitted. Heat’s Los Angeles is a world without landmarks, a branded Sprawl, where markable territory has been replaced by endlessly repeating vistas of replicating franchises. The ghosts of Old Europe that stalked Scorsese and Coppola’s streets have been exorcised, buried with the ancient beefs, bad blood and burning vendettas somewhere beneath the multinational coffee shops. You can learn a great deal about the world of Heat from considering the name ‘Neil McCauley’. It is an anonymous name, a fake passport name, a name that is bereft of history (even as, ironically, it echoes the name of British historian, Lord McCaulay). Compare ‘Corleone’, and remember that the Godfather was named after a village. McCauley is perhaps the part that De Niro played that is closest to the actor’s own personality: a screen, a cipher, depthless, icily professional, stripped down to pure preparation, research, Method (‘I do what I do best’). McCauley is no mafia Boss, no puffed-up chief perched atop a baroque hierarchy governed by codes as solemn and mysterious as those of the Catholic Church and written in the blood of a thousand feuds. His Crew are professionals, hands-on entrepreneur-speculators, crime-technicians, whose credo is the exact opposite of Cosa Nostra family loyalty. Family ties are unsustainable in these conditions, as McCauley tells the Pacino character, the driven detective, Vincent Hanna. ‘Now, if you’re on me and you gotta move when I move, how do you expect to keep a marriage?’ Hanna is McCauley’s shadow, forced to assume his insubstantiality, his perpetual mobility. Like any group of shareholders, McCauley’s crew is held together by the prospect of future revenue; any other bonds are optional extras, almost certainly dangerous. Their arrangement is temporary, pragmatic and lateral – they know that they are interchangeable machine parts, that there are no guarantees, that nothing lasts. Compared to this, the goodfellas seem like sedentary sentimentalists, rooted in dying communities, doomed territories.

The ethos espoused by McCauley is the one which Richard Sennett examines in The Corrosion of Character: The Personal Consequences of Work in the New Capitalism, a landmark study of the affective changes that the post-Fordist reorganization of work has brought about. The slogan which sums up the new conditions is ‘no long term’. Where formerly workers could acquire a single set of skills and expect to progress upwards through a rigid organizational hierarchy, now they are required to periodically re-skill as they move from institution to institution, from role to role. As the organization of work is decentralized, with lateral networks replacing pyramidal hierarchies, a premium is put on ‘flexibility’. Echoing McCauley’s mockery of Hanna in Heat (‘How do you expect to keep a marriage?’), Sennett emphasizes the intolerable stresses that these conditions of permanent instability put on family life. The values that family life depends upon – obligation, trustworthiness, commitment – are precisely those which are held to be obsolete in the new capitalism. Yet, with the public sphere under attack and the safety nets that a ‘Nanny State’ used to provide being dismantled, the family becomes an increasingly important place of respite from the pressures of a world in which instability is a constant. The situation of the family in post-Fordist capitalism is contradictory, in precisely the way that traditional Marxism expected: capitalism requires the family (as an essential means of reproducing and caring for labor power; as a salve for the psychic wounds inflicted by anarchic social-economic conditions), even as it undermines it (denying parents time with children, putting intolerable stress on couples as they become the exclusive source of affective consolation for each other).

According to Marxist economist Christian Marazzi, the switch from Fordism to post-Fordism can be given a very specific date: October 6, 1979. It was on that date that the Federal Reserve increased interest rates by 20 points, preparing the way for the ‘supply-side economics’ that would constitute the ‘economic reality’ in which we are now enmeshed. The rise in interest rates not only contained inflation, it made possible a new organization of the means of production and distribution. The ‘rigidity’ of the Fordist production line gave way to a new ‘flexibility’, a word that will send chills of recognition down the spine of every worker today. This flexibility was defined by a deregulation of Capital and labor, with the workforce being casualized (with an increasing number of workers employed on a temporary basis), and outsourced.

Like Sennett, Marazzi recognizes that the new conditions both required and emerged from an increased cybernetization of the working environment. The Fordist factory was crudely divided into blue and white collar work, with the different types of labor physically delimited by the structure of the building itself. Laboring in noisy environments, watched over by managers and supervisors, workers had access to language only in their breaks, in the toilet, at the end of the working day, or when they were engaged in sabotage, because communication interrupted production. But in post-Fordism, when the assembly line becomes a ‘flux of information’, people work by communicating. As Norbert Wiener taught, communication and control entail one another.

Work and life become inseparable. Capital follows you when you dream. Time ceases to be linear, becomes chaotic, broken down into punctiform divisions. As production and distribution are restructured, so are nervous systems. To function effectively as a component of just-in-time production you must develop a capacity to respond to unforeseen events, you must learn to live in conditions of total instability, or ‘precarity’, as the ugly neologism has it. Periods of work alternate with periods of unemployment. Typically, you find yourself employed in a series of short-term jobs, unable to plan for the future.

Both Marazzi and Sennett point out that the disintegration of stable working patterns was in part driven by the desires of workers – it was they who, quite rightly, did not wish to work in the same factory for forty years. In many ways, the left has never recovered from being wrong-footed by Capital’s mobilization and metabolization of the desire for emancipation from Fordist routine. Especially in the UK, the traditional representatives of the working class – union and labor leaders – found Fordism rather too congenial; its stability of antagonism gave them a guaranteed role. But this meant that it was easy for the advocates of post-Fordist Capital to present themselves as the opponents of the status quo, bravely resisting an inertial organized labor ‘pointlessly’ invested in fruitless ideological antagonism which served the ends of union leaders and politicians, but did little to advance the hopes of the class they purportedly represented. Antagonism is not now located externally, in the face-off between class blocs, but internally, in the psychology of the worker, who, as a worker, is interested in old-style class conflict, but, as someone with a pension fund, is also interested in maximizing the yield from his or her investments. There is no longer an identifiable external enemy. The consequence is, Marazzi argues, that post-Fordist workers are like the Old Testament Jews after they left the ‘house of slavery’: liberated from a bondage to which they have no wish to return but also abandoned, stranded in the desert, confused about the way forward.

The psychological conflict raging within individuals cannot but have casualties. Marazzi is researching the link between the increase in bi-polar disorder and post-Fordism and, if, as Deleuze and Guattari argue, schizophrenia is the condition that marks the outer edges of capitalism, then bi-polar disorder is the mental illness proper to the ‘interior’ of capitalism. With its ceaseless boom and bust cycles, capitalism is itself fundamentally and irreducibly bi-polar, periodically lurching between hyped-up mania (the irrational exuberance of ‘bubble thinking’) and depressive come-down. (The term ‘economic depression’ is no accident, of course). To a degree unprecedented in any other social system, capitalism both feeds on and reproduces the moods of populations. Without delirium and confidence, capital could not function.

It seems that with post-Fordism, the ‘invisible plague’ of psychiatric and affective disorders that has spread, silently and stealthily, since around 1750 (i.e. the very onset of industrial capitalism) has reached a new level of acuteness. Here, Oliver James’s work is important. In The Selfish Capitalist, James points to significant rises in the rates of ‘mental distress’ over the last 25 years. ‘By most criteria’, James reports,

rates of distress almost doubled between people born in 1946 (aged thirty-six in 1982) and 1970 (aged thirty in 2000). For example, 16 per cent of thirty-six-year-old women in 1982 reported having ‘trouble with nerves, feeling low, depressed or sad’, whereas 29 per cent of thirty year-olds reported this in 2000 (for men it was 8 per cent in 1982, 13 per cent in 2000).

Another British study James cites compared levels of psychiatric morbidity (which includes neurotic symptoms, phobias and depression) in samples of people in 1977 and 1985. ‘Whereas 22 per cent of the 1977 sample reported psychiatric morbidity, this had risen to almost a third of the population (31 per cent) by 1986’. Since these rates are much higher in countries that have implemented what James calls ‘selfish’ capitalism than in other capitalist nations, James hypothesizes that it is selfish (i.e. neoliberalized) capitalist policies and culture that are to blame. Specifically, James points to the way in which selfish capitalism stokes up

both aspirations and the expectations that they can be fulfilled. ... In the entrepreneurial fantasy society, the delusion is fostered that anyone can be Alan Sugar or Bill Gates, never mind that the actual likelihood of this occurring has diminished since the 1970s – a person born in 1958 was more likely than one born in 1970 to achieve upward mobility through education, for example. The Selfish Capitalist toxins that are most poisonous to well-being are the systematic encouragement of the ideas that material affluence is they key to fulfillment, that only the affluent are winners and that access to the top is open to anyone willing to work hard enough, regardless of their familial, ethnic or social background – if you do not succeed, there is only one person to blame.

James’s conjectures about aspirations, expectations and fantasy fit with my own observations of what I have called ‘hedonic depression’ in British youth.

It is telling, in this context of rising rates of mental illness, that New Labour committed itself, early in its third term in government, to removing people from Incapacity Benefit, implying that many, if not most, claimants are malingerers. In contrast with this assumption, it doesn’t seem unreasonable to infer that most of the people claiming Incapacity Benefit – and there are well in excess of two million of them – are casualties of Capital. A significant proportion of claimants, for instance, are people psychologically damaged as a consequence of the capitalist realist insistence that industries such as mining are no longer economically viable. (Even considered in brute economic terms, though, the arguments about ‘viability’ seem rather less than convincing, especially once you factor in the cost to taxpayers of incapacity and other benefits.) Many have simply buckled under the terrifyingly unstable conditions of post-Fordism.

The current ruling ontology denies any possibility of a social causation of mental illness. The chemico-biologization of mental illness is of course strictly commensurate with its de-politicization. Considering mental illness an individual chemico-biological problem has enormous benefits for capitalism. First, it reinforces Capital’s drive towards atomistic individualization (you are sick because of your brain chemistry). Second, it provides an enormously lucrative market in which multinational pharmaceutical companies can peddle their pharmaceuticals (we can cure you with our SSRIs). It goes without saying that all mental illnesses are neurologically instantiated, but this says nothing about their causation. If it is true, for instance, that depression is constituted by low serotonin levels, what still needs to be explained is why particular individuals have low levels of serotonin. This requires a social and political explanation; and the task of repoliticizing mental illness is an urgent one if the left wants to challenge capitalist realism.

It does not seem fanciful to see parallels between the rising incidence of mental distress and new patterns of assessing workers’ performance. We will now take a closer look at this ‘new bureaucracy’.



All that is solid melts into PR: Market Stalinism and bureaucratic anti-production


Mike Judge’s unjustly undercelebrated film Office Space (1999) is as acute an account of the 90s/00s workplace as Schrader’s Blue Collar (1978) was of 70s labor relations. Instead of the confrontation between trade union officials and management in a factory, Judge’s film shows a corporation sclerotized by administrative ‘anti-production’: workers receive multiple memos from different managers saying the exact same thing. Naturally, the memo concerns a bureaucratic practice: it aims to induce compliance with a new procedure of putting ‘cover sheets’ on reports. In keeping with the ‘being smart’ ethos, the management style in Office Space is a mixture of shirtsleeves-informality and quiet authoritarianism. Judge shows this same managerialism presides in the corporate coffee chains where the office workers go to relax. Here, staff are required to decorate their uniforms with ‘seven pieces of flair’, (i.e. badges or other personal tokens) to express their ‘individuality and creativity’: a handy illustration of the way in which ‘creativity’ and ‘self-expression’ have become intrinsic to labor in Control societies; which, as Paolo Virno, Yann Moulier Boutang and others have pointed out, now makes affective, as well as productive demands, on workers. Furthermore, the attempt to crudely quantify these affective contributions also tells us a great deal about the new arrangements. The flair example also points to another phenomenon: hidden expectations behind official standards. Joanna, a waitress at the coffee chain, wears exactly seven pieces of flair, but it is made clear to her that, even though seven is officially enough, it is actually inadequate – the manager asks if she wants to look the sort of person ‘who only does the bare minimum.’

‘You know what, Stan, if you want me to wear 37 pieces of flair,’ Joanna complains, ‘why don’t you just make the minimum 37 pieces of flair?’

‘Well,’ the manager replies, ‘I thought I remembered you saying that you wanted to express yourself.’ Enough is no longer enough. This syndrome will be familiar to many workers who may find that a ‘satisfactory’ grading in a performance evaluation is no longer satisfactory. In many educational institutions, for instance, if after a classroom observation a teacher is graded as ‘satisfactory’, they will be required to undertake training prior to a reassessment.

Initially, it might appear to be a mystery that bureaucratic measures should have intensified under neoliberal governments that have presented themselves as anti-bureaucratic and anti-Stalinist. Yet new kinds of bureaucracy – ‘aims and objectives’, ‘outcomes’, ‘mission statements’ – have proliferated, even as neoliberal rhetoric about the end of top-down, centralized control has gained pre-eminence. It might seem that bureaucracy is a kind of return of the repressed, ironically re-emerging at the heart of a system which has professed to destroy it. But the resurgence of bureaucracy in neoliberalism is more than an atavism or an anomaly.

As I have already indicated, there is no contradiction between ‘being smart’ and the increase of administration and regulation: they are two sides of labor in Control societies. Richard Sennett has argued that the flattening of pyramidal hierarchies has actually led to more surveillance of workers. ‘One of the claims made for the new organization of work is that it decentralizes power, that is, gives people in the lower ranks of organization more control over their own activities’, Sennett writes. ‘Certainly this claim is false in terms of the techniques employed for taking apart the old bureaucratic behemoths. The new information systems provide a comprehensive picture of the organization to top managers in ways which give individuals anywhere in the network little room to hide’. But it isn’t only that information technology has granted managers more access to data; it is that the data itself has proliferated. Much of this ‘information’ is provided by workers themselves. Massimo De Angelis and David Harvie describe some of the bureaucratic measures with which a lecturer must comply when putting together a module for an undergraduate degree in British universities. ‘For each module’, De Angelis and Harvie write,

the ‘module leader’ (ML, i.e., lecturer) must complete various paperwork, in particular a ‘module specification’ (at the module’s start) which lists the module’s ‘aims and objectives’, ILOs, ‘modes and methods of assessment’, amongst other information; and a ‘module review’ document (at the end of the module), in which the ML reports their own assessment of the module’s strengths and weaknesses and their suggested changes for the following year; a summary of student feedback; and average marks and their dispersion.

This is only the beginning, however. For the degree program as a whole, academics must prepare a ‘program specification’, as well as producing ‘annual program reports’, which record student performance according to ‘progression rates’, ‘withdrawal rates’, location and spread of marks. All students’ marks have to be graded against a ‘matrix’. This auto-surveillance is complemented by assessments carried out by external authorities. The marking of student assignments is monitored by ‘external examiners’ who are supposed to maintain consistency of standards across the university sector. Lecturers have to be observed by their peers, while departments are subject to periodic three or four day inspections by the Quality Assurance Agency for Higher Education (QAA). If they are ‘research active’, lecturers must submit their ‘best four publications’ every four or five years to be graded by panel as part of the Research Assessment Exercise (replaced in 2008 by the equally controversial Research Excellence Framework). De Angelis and Harvie are clear that these are only very sketchy accounts of only some of the bureaucratic tasks that academics have to perform, all of which have funding implications for institutions. This battery of bureaucratic procedures is by no means confined to universities, nor to education: other public services, such as the National Health Service and the police force, find themselves enmeshed in similar bureaucratic metastases.

This is in part a consequence of the inherent resistance of certain processes and services to marketization. (The supposed marketization of education, for instance, rests on a confused and underdeveloped analogy: are students the consumers of the service or its product?) The idealized market was supposed to deliver ‘friction free’ exchanges, in which the desires of consumers would be met directly, without the need for intervention or mediation by regulatory agencies. Yet the drive to assess the performance of workers and to measure forms of labor which, by their nature, are resistant to quantification, has inevitably required additional layers of management and bureaucracy. What we have is not a direct comparison of workers’ performance or output, but a comparison between the audited representation of that performance and output. Inevitably, a short-circuiting occurs, and work becomes geared towards the generation and massaging of representations rather than to the official goals of the work itself. Indeed, an anthropological study of local government in Britain argues that ‘More effort goes into ensuring that a local authority’s services are represented correctly than goes into actually improving those services’. This reversal of priorities is one of the hallmarks of a system which can be characterized without hyperbole as ‘market Stalinism’. What late capitalism repeats from Stalinism is just this valuing of symbols of achievement over actual achievement. As Marshall Berman explained, describing Stalin’s White Sea Canal project of 1931-33:

Stalin seems to have been so intent on creating a highly visible symbol of development that he pushed and squeezed the project in ways that only retarded the development of the project. Thus the workers and the engineers were never allowed the time, money or equipment necessary to build a canal that would be deep enough and safe enough to carry twentieth-century cargoes; consequently, the canal has never played any significant role in Soviet commerce or industry. All the canal could support, apparently, were tourist steamers, which in the 1930s were abundantly stocked with Soviet and foreign writers who obligingly proclaimed the glories of the work. The canal was a triumph of publicity; but if half the care that went into the public relations campaign had been devoted to the work itself, there would have been far fewer victims and far more real developments – and the project would have been a genuine tragedy, rather than a brutal farce in which real people were killed by pseudo-events.

In a strange compulsion to repeat, the ostensibly anti-Stalinist neoliberal New Labour government has shown the same tendency to implement initiatives in which real world effects matter only insofar as they register at the level of (PR) appearance. The notorious ‘targets’ which the New Labour government was so enthusiastic in imposing are a case in point. In a process that repeats itself with iron predictability everywhere that they are installed, targets quickly cease to be a way of measuring performance and become ends in themselves. Anxiety about falling standards in school examinations is now a regular feature of the summertime in Britain. Yet if students are less skilled and knowledgeable than their predecessors, this is due not to a decline in the quality of examinations per se, but to the fact that all of the teaching is geared towards passing the exams. Narrowly focused ‘exam drill’ replaces a wider engagement with subjects. Similarly, hospitals perform many routine procedures instead of a few serious, urgent operations, because this allows them to hit the targets they are assessed on (operating rates, success rates and reduction in waiting time) more effectively.

It would be a mistake to regard this market Stalinism as some deviation from the ‘true spirit’ of capitalism. On the contrary, it would be better to say that an essential dimension of Stalinism was inhibited by its association with a social project like socialism and can only emerge in a late capitalist culture in which images acquire an autonomous force. The way value is generated on the stock exchange depends of course less on what a company ‘really does’, and more on perceptions of, and beliefs about, its (future) performance. In capitalism, that is to say, all that is solid melts into PR, and late capitalism is defined at least as much by this ubiquitous tendency towards PR-production as it is by the imposition of market mechanisms.

Here, Žižek’s elaboration of Lacan’s concept of the ‘big Other’ is crucial. The big Other is the collective fiction, the symbolic structure, presupposed by any social field. The big Other can never be encountered in itself; instead, we only ever confront its stand-ins. These representatives are by no means always leaders. In the example of the White Sea Canal above, for instance, it wasn’t Stalin himself who was the representative of the big Other so much as the Soviet and foreign writers who had to be persuaded of the glories of the project. One important dimension of the big Other is that it does not know everything. It is this constitutive ignorance of the big Other that allows public relations to function. Indeed, the big Other could be defined as the consumer of PR and propaganda, the virtual figure which is required to believe even when no individual can. To use one of Žižek’s examples: who was it, for instance, who didn’t know that Really Existing Socialism (RES) was shabby and corrupt? Not any of the people, who were all too aware of its shortcomings; nor any of the government administrators, who couldn’t but know. No, it was the big Other who was the one deemed not to know – who wasn’t allowed to know – the quotidian reality of RES. Yet the distinction between what the big Other knows, i.e. what is officially accepted, and what is widely known and experienced by actual individuals, is very far from being ‘merely’ emptily formal; it is the discrepancy between the two that allows ‘ordinary’ social reality to function. When the illusion that the big Other did not know can no longer be maintained, the incorporeal fabric holding the social system together disintegrates. This is why Khrushchev’s speech in 1965, in which he ‘admitted’ the failings of the Soviet state, was so momentous. It is not as if anyone in the party was unaware of the atrocities and corruption carried out in its name, but Khrushchev’s announcement made it impossible to believe any more that the big Other was ignorant of them.

So much for Really Existing Socialism – but what of Really Existing Capitalism? One way to understand the ‘realism’ of capitalist realism is in terms of the claim to have given up belief in the big Other. Postmodernism can be construed as the name for the complex of crises that the decline in the belief in the big Other has triggered, as Lyotard’s famous formulation of the postmodern condition – ‘incredulity towards metanarratives’ –suggests. Jameson, of course, would argue that the ‘incredulity towards metanarratives’ is one expression of the ‘cultural logic of late capitalism’, a consequence of the switch into the post-Fordist mode of capital accumulation. Nick Land gives one of the most euphoric accounts of the ‘postmodern meltdown of culture into the economy’. In Land’s work, a cybernetically upgraded invisible hand is progressively eliminating centralized state power. Land’s 90s texts synthesized cybernetics, complexity theory, cyberpunk fiction and neoliberalism to construct a vision of capital planetary artificial intelligence: a vast, supple, endlessly fissile system which renders human will obsolete. In his manifesto for nonlinear, decentered Capital, ‘Meltdown’, Land invokes a ‘massively distributed matrix-networked tendency oriented to disabling ROM command-control programs sustaining all macro- and micro-governmental entities, globally concentrating themselves as the Human Security System’. This is capitalism as a shattering Real, in which (viral, digital) signals circulate on self-sustaining networks which bypass the Symbolic, and therefore do not require the big Other as guarantor. It is Deleuze and Guattari’s Capital as ‘Unnamable Thing’, but without the forces of reterritorialization and anti-production which they argued were constitutive of capitalism. One of the problems of Land’s position is also what is most interesting about it: precisely that it posits a ‘pure’ capitalism, a capitalism which is only inhibited and blocked by extrinsic, rather than internal, elements (according to Land’s logic, these elements are atavisms that will eventually be consumed and metabolized by Capital). Yet capitalism cannot be ‘purified’ in this way; strip away the forces of anti-production and capitalism disappears with them. Similarly, there is no progressive tendency towards an ‘unsheathing’ of capitalism, no gradual unmasking of Capital as it ‘really’ is: rapacious, indifferent, inhuman. On the contrary, the essential role of the ‘incorporeal transformations’ effectuated by PR, branding and advertising in capitalism suggests that, in order to operate effectively, capitalism’s rapacity depends upon various forms of sheathing. Really Existing Capitalism is marked by the same division which characterized Really Existing Socialism, between, on the one hand, an official culture in which capitalist enterprises are presented as socially responsible and caring, and, on the other, a widespread awareness that companies are actually corrupt, ruthless, etc. In other words, capitalist postmodernity is not quite as incredulous as it would appear to be, as the jeweler Gerald Ratner famously found to his cost. Ratner precisely tried to circumvent the Symbolic and ‘tell it how it is’, describing the inexpensive jewelry his shops sold as ‘crap’ in an after-dinner speech. But the consequence of Ratner making this judgment official were immediate, and serious - £500m was wiped off the value of the company and he lost his job. Customers might previously have known that the jewelry Ratners sold was poor quality, but the big Other didn’t know; as soon as it did, Ratners collapsed.

Vernacular postmodernism has dealt with the ‘crisis of symbolic efficiency’ in a far less intense way than Nick Land, through metafictional anxieties about the function of the author, and in television programs or films which expose the mechanisms of their own productions and reflexively incorporate discussions of their own status as commodities. But postmod-ernism’s supposed gestures of demystification do not evince sophistication so much as a certain naivety, a conviction that there were others, in the past, who really believed in the Symbolic. In fact, of course, ‘symbolic efficiency’ was achieved precisely by maintaining a clear distinction between a material-empirical causality, and another, incorporeal causality proper to the Symbolic. Žižek gives the example of a judge: ‘I know very well that things are the way I see them, that this person is a corrupted weakling, but I nonetheless treat him respectfully, since he wears the insignia of a judge, so that when he speaks, it is the Law itself which speaks through him’. However, postmodernism’s

cynical reduction to reality ... falls short: when a judge speaks, there is in a way more truth in his words (the words of the Institution of law) than in the direct reality of the person of judge if one limits oneself to what one sees, one simply misses the point. Lacan aims at this paradox with his ‘les non-dupes errent’: those who do not allow themselves to be caught in the symbolic deception/fiction, who continue to believe their eyes, are the ones who err most. A cynic who ‘believes only his eyes’ misses the efficiency of the symbolic fiction, and how it structures our experience of reality.

Much of Baudrillard’s work was a commentary on this same effect: the way in which the abolition of the Symbolic led not to a direct encounter with the Real, but to a kind of hemorrhaging of the Real. For Baudrillard, phenomena such as fly on the wall documentaries and political opinion polls – both of which claimed to present reality in an unmediated way – would always pose an insoluble dilemma. Did the presence of the cameras affect the behavior of those being filmed? Would the publication of poll results affect the future behavior of voters? Such questions were undecidable, and therefore ‘reality’ would always be elusive: at the very moment when it seemed that it was being grasped in the raw, reality transformed into what Baudrillard, in a much misunderstood neologism, called ‘hyperreality’. Uncannily echoing Baudrillard’s fixations, the most successful reality television programs ended up fusing fly on the wall documentary elements with interactive polling. In effect, there are two levels of ‘reality’ in these shows: the unscripted behavior of the ‘real life’ participants onscreen, and the unpredictable responses of the audience at home, which in turn affect the behavior of the onscreen participants. Yet reality TV is continually haunted by questions about fiction and illusion: are the participants acting, suppressing certain aspects of their personality in order to appear more appealing to us, the audience? And have the audience’s votes been accurately registered, or is there some kind of a fix? The slogan that the Big Brother TV show uses – ‘You decide’ – captures perfectly the mode of control by feedback that, according to Baudrillard, has replaced old centralized forms of power. We ourselves occupy the empty seat of power, phoning and clicking in our responses. TV’s Big Brother had superseded Orwell’s Big Brother. We the audience are not subjected to a power that comes from outside; rather, we are integrated into a control circuit that has our desires and preferences as its only mandate – but those desires and preferences are returned to us, no longer as ours, but as the desires of the big Other. Clearly, these circuits are not confined to television: cybernetic feedback systems (focus groups, demographic surveys) are now integral to the delivery of all ‘services’, including education and government.

This returns us to the issue of post-Fordist bureaucracy. There is of course a close relationship between bureaucracy – the discourse of officialdom – and the big Other. Witness two of Žižek’s own examples of the big Other at work: a low-level official who, having not been informed of a promotion, says ‘Sorry, I have not yet been properly informed about this new measure, so I can’t help you...’; a woman who believed that she was suffering bad luck because of the number of her house, who could not be satisfied by simply repainting a different number herself , because ‘it has to be done properly, by the responsible state institution...’ We are all familiar with bureaucratic libido, with the enjoyment that certain officials derive from this position of disavowed responsibility (‘it’s not me, I’m afraid, it’s the regulations’). The frustration of dealing with bureaucrats often arises because they themselves can make no decisions; rather, they are permitted only to refer to decisions that have always-already been made (by the big Other). Kafka was the greatest writer on bureaucracy because he saw that this structure of disavowal was inherent to bureaucracy. The quest to reach the ultimate authority who will finally resolve K’s official status can never end, because the big Other cannot be encountered in itself: there are only officials, more or less hostile, engaged in acts of interpretation about what the big Other’s intentions. And these acts of interpretation, these deferrals of responsibility, are all that the big Other is.

If Kafka is valuable as a commentator on totalitarianism, it is by revealing that there was a dimension of totalitarianism which cannot be understood on the model of despotic command. Kafka’s purgatorial vision of a bureaucratic labyrinth without end chimes with Žižek’s claim that the Soviet system was an ‘empire of signs’, in which even the Nomenklatura themselves –including Stalin and Molotov – were engaged in interpreting a complex series of social semiotic signals. No-one knew what was required; instead, individuals could only guess what particular gestures or directives meant. What happens in late capitalism, when there is no possibility of appealing, even in principle, to a final authority which can offer the definitive official version, is a massive intensification of that ambiguity. As an example of this syndrome, let us turn once more to Further Education. At a meeting between Trade Union officials, college Principals and Members of Parliament, the Learning and Skills Council (LSC), the quango at the heart of the FE funding labyrinth, came in for particular attack. Neither the teachers, nor the Principals, nor the MPs could determine how particular directives had generated themselves, since they are not there in government policy itself. The answer was that the LSC ‘interpreted’ the instructions issued by the Department for Education and Skills. These interpretations then achieve the strange autonomy peculiar to bureaucracy. On the one hand, bureaucratic procedures float freely, independent of any external authority; but that very autonomy means that they assume a heavy implacability, a resistance to any amendment or questioning.

The proliferation of auditing culture in post Fordism indicates that the demise of the big Other has been exaggerated. Auditing can perhaps best be conceived of as fusion of PR and bureaucracy, because the bureaucratic data is usually intended to fulfill a promotional role: in the case of education, for example, exam results or research ratings augment (or diminish) the prestige of particular institutions. The frustration for the teacher is that it seems as if their work is increasingly aimed at impressing the big Other which is collating and consuming this ‘data’. ‘Data’ has been put in inverted commas here, because much of the so-called information has little meaning or application outside the parameters of the audit: as Eeva Berglund puts it, ‘the information that audit creates does have consequences even though it is so shorn of local detail, so abstract, as to be misleading or meaningless - except, that is, by the aesthetic criteria of audit itself.

New bureaucracy takes the form not of a specific, delimited function performed by particular workers but invades all areas of work, with the result that – as Kafka prophesied – workers become their own auditors, forced to assess their own performance. Take, for example, the ‘new system’ that OFSTED (Office for Standards in Education) uses to inspect Further Education colleges. Under the old system, a college would have a ‘heavy’ inspection once every four years or so, i.e. one involving many lesson observations and a large number of inspectors present in the college. Under the new, ‘improved’ system, if a college can demonstrate that its internal assessment systems are effective, it will only have to undergo a ‘light’ inspection. But the downside of this ‘light’ inspection is obvious – surveillance and monitoring are outsourced from OFSTED to the college and ultimately to lecturers themselves, and become a permanent feature of the college structure (and of the psychology of individual lecturers). The difference between the old/heavy and new/light inspection system corresponds precisely to Kafka’s distinction between ostensible acquittal and indefinite postponement, outlined above. With ostensible acquittal, you petition the lower court judges until they grant you a non-binding reprieve. You are then free from the court, until the time when your case is re-opened. Indefinite postponement, meanwhile, keeps your case at the lowest level of the court, but at the cost of an anxiety that has never ends. (The changes in OFSTED inspections are mirrored by in the change from the Research Assessment Exercise to the Research Excellence Framework in higher education: periodic assessment will be superseded by a permanent and ubiquitous measurement which cannot help but generate the same perpetual anxiety.)

In any case, it is not as if the ‘light’ inspection is in any sense preferable for staff than the heavy one. The inspectors are in the college for the same amount of time as they were under the old system. The fact that there are fewer of them does nothing to alleviate the stress of the inspection, which has far more to do with the extra bureaucratic window-dressing one has to do in anticipation of a possible observation than it has to do with any actual observation itself. The inspection, that is to say, corresponds precisely to Foucault’s account of the virtual nature of surveillance in Discipline And Punish. Foucault famously observes there that there is no need for the place of surveillance to actually be occupied. The effect of not knowing whether you will be observed or not produces an introjection of the surveillance apparatus. You constantly act as if you are always about to be observed. Yet, in the case of school and university inspections, what you will be graded on is not primarily your abilities as a teacher so much as your diligence as a bureaucrat. There are other bizarre effects. Since OFSTED is now observing the college’s self-assessment systems, there is an implicit incentive for the college to grade itself and its teaching lower than it actually deserves. The result is a kind of postmodern capitalist version of Maoist confessionalism, in which workers are required to engage in constant symbolic self-denigration. At one point, when our line manager was extolling the virtues of the new, light inspection system, he told us that the problem with our departmental log-books was that they were not sufficiently self-critical. But don’t worry, he urged, any self-criticisms we make are purely symbolic, and will never be acted upon; as if performing self-flagellation as part of a purely formal exercise in cynical bureaucratic compliance were any less demoralizing.

In the post-Fordist classroom, the reflexive impotence of the students is mirrored by reflexive impotence of the teachers. De Angelis and Harvie report that

practices and requirements of standardisation and surveillance obviously impose a huge burden of work on academics and few are happy about it. There have been a number of responses. Managers have frequently suggested there is no alternative (TINA) and have perhaps suggested that what we need to do is ‘work smarter, not harder’. This seductive slogan, introduced to dampen staff resistance to further change which in their (our) experience has a devastating effects on working conditions, attempts to couple the need for ‘change’ (restructuring and innovation) in order to meet the budget pressure and increase ‘competitiveness’, with staff’s resistance not only to worsening of their condition of work, but also to the educational and academic ‘meaninglessness’ of the ‘changes’.

The invocation of the idea that ‘there is no alternative’, and the recommendation to ‘work smarter, not harder’, shows how capitalist realism sets the tone for labor disputes in post-Fordism. Ending the inspection regime, one lecturer sardonically remarked, seems more impossible than ending slavery was. Such fatalism can only be challenged if a new (collective) political subject emerges.



‘...if you can watch the overlap of one reality with another’: capitalist realism as dreamwork and memory disorder


‘Being realistic’ may once have meant coming to terms with of a reality experienced as solid and immovable. Capitalist realism, however, entails subordinating oneself to a reality that is infinitely plastic, capable of reconfiguring itself at any moment. We are confronted with what Jameson, in his essay ‘The Antimonies Of The Postmodern’, calls ‘a purely fungible present in which space and psyches alike can be processed and remade at will’. The ‘reality’ here is akin to the multiplicity of options available on a digital document, where no decision is final, revisions are always possible, and any previous moment can be recalled at any time. The middle manager I referred to above turned adaptation to this ‘fungible’ reality it into a fine art. He asserted with full confidence a story about the college and its future one day – what the implications of the inspection were likely to be; what senior management was thinking; then literally the next day would happily propound a story that directly contradicted what he previously said. There was never a question of his repudiating the previous story; it was as if he, only dimly remembered there ever being another story. This, I suppose, is ‘good management’. It is, also, perhaps the only way to stay healthy amidst capitalism’s perpetual instability. On the face of it, this manager is a model of beaming mental health, his whole being radiating a hail-fellow-well-met bonhomie. Such cheerfulness can only be maintained if one has a near-total absence of any critical reflexivity and a capacity, as he had, to cynically comply with every directive from bureaucratic authority. The cynicism of the compliance is essential, of course; the preservation of his 60s liberal self-image depended upon his ‘not really believing’ in the auditing processes he so assiduously enforced. What this disavowal depends upon is the distinction between inner subjective attitude and outward behavior I discussed above: in terms of his inner subjective attitude, the manager is hostile, even contemptuous, towards, the bureaucratic procedures he supervises; but in terms of his outward behavior, he is perfectly compliant. Yet it is precisely workers’ subjective disinvestment from auditing tasks which enables them to continue to perform labor that is pointless and demoralizing.

The manager’s capacity to smoothly migrate from one reality to another reminded me of nothing so much as Ursula Le Guin’s The Lathe of Heaven. It is a novel about George Orr, a man whose dreams literally come true. In time-honored fairy tale fashion, however, the acts of wish fulfillment quickly become traumatic and catastrophic. When, for instance, Orr is induced by his therapist, Dr Haber, into dreaming that the problem of overpopulation is solved, he wakes to find himself in a world in which billions have been wiped out by a plague; a plague that, as Jameson put it in his discussion of the novel, was ‘a hitherto nonexistent event which rapidly finds its place in our chronological memory of the recent past’. Much of the power of the novel consists in its rendering of these retrospective confabulations, whose mechanics are at once so familiar – because we perform them every night when we dream – and so odd. How could it ever be possible for us to believe successive or even co-extensive stories that so obviously contradict one another? Yet we know from Kant, Nietzsche and psychoanalysis that waking, as much as dreaming, experience, depends upon just such screening narratives. If the Real is unbearable, any reality we construct must be a tissue of inconsistencies. What differentiates Kant, Nietzsche and Freud from the tiresome cliché that ‘life is but a dream’ is the sense that the confabulations we live are consensual. The idea that the world we experience is a solipsistic delusion projected from the interior of our mind consoles rather than disturbs us, since it conforms with our infantile fantasies of omnipotence; but the thought that our so-called interiority owe its existence to a fictionalized consensus will always carry an uncanny charge. This extra level of uncanniness is registered in The Lathe of Heaven when Le Guin has Orr’s reality-warping dreams witnessed by others – the therapist, Haber, who seeks to manipulate and control Orr’s ability, and the lawyer, Heather Lelache. What, then, is it like to live through someone else’s dream coming true?

Haber () could not go on talking. He felt it: the shift, the arrival, the change.

The woman felt it too. She looked frightened. Holding the brass necklace up close to her throat like a talisman, she was staring in dismay, shock, terror, out of the window at the view.

... () What would it do to the woman? Would she understand, would she go mad, what would she do? Would she keep both memories, as he did, the true one and the new one, the old one and the true one?

Does she ‘go crazy’? No, not at all: after a few moments of bewildered fugue, Heather Lelache accepts the ‘new’ world as the ‘true’ world, editing out the point of suture. This strategy – of accepting the incommensurable and the senseless without question – has always been the exemplary technique of sanity as such, but it has a special role to play in late capitalism, that ‘motley painting of everything that ever was’, whose dreaming up and junking of social fictions is nearly as rapid as its production and disposal of commodities.

In these conditions of ontological precarity, forgetting becomes an adaptive strategy. Take the example of Gordon Brown, whose expedient reinvention of his political identity involved an attempt to induce a collective forgetting. In an article in International Socialism, John Newsinger remembers how

Brown told the Confederation of British Industry conference that ‘business is in my blood’. His mother had been a company director and ‘I was brought up in an atmosphere where I knew exactly what was happening as far as business was concerned’. He was, indeed he had always been, one of them. The only problem is that it was not true. As his mother subsequently admitted, she would never have called herself ‘a business woman’: she had only ever done some ‘light administrative duties’ for ‘a small family firm’ and had given up the job when she married, three years before young Gordon was even born. While there have been Labor politicians who have tried to invent working class backgrounds for themselves before, Brown is the first to try and invent a capitalist background.

Newsinger contrasts Brown with his rival and predecessor as British prime minister, Tony Blair, a very different case. While Blair – who presented the strange spectacle of a postmodern messianism – never had any beliefs that he had to recant on, Brown’s move from Presbyterian socialist to New Labour supremo was a long, arduous and painful process of repudiation and denial. ‘Whereas, for Blair, the embrace of neoliberalism involved no great personal struggle because he had no previous beliefs to dispose of, Newsinger writes, ‘for Brown it involved a deliberate decision to change sides. The effort, one suspects, damaged his personality’. Blair was the Last Man by nature and inclination; Brown has become the Last Man, the dwarf at the End of History, by force of will.

Blair was the man without a chest, the outsider the party needed in order to get into power, his joker hysterical face salesman-smooth; Brown’s implausible act of self-reinvention is what the party itself had to go through, his fake-smile grimace the objective correlative of Labour’s real state now that it has completely capitulated to capitalist realism: gutted, and gutless, its insides replaced by simulacra which once looked lustrous but now possess all the allure of decade-old computer technology.

In conditions where realities and identities are upgraded like software, it is not surprising that memory disorders should have become the focus of cultural anxiety – see, for instance, the Bourne films, Memento, Eternal Sunshine Of the Spotless Mind. In the Bourne films, Jason Bourne’s quest to regain his identity goes alongside a continual flight from any settled sense of self. ‘Try to understand me... ,’ says Bourne in the original novel by Robert Ludlum,

I have to know certain things ... enough to make a decision... but maybe not everything. A part of me has to be able to walk away, disappear. I have to be able to say to myself, what was isn’t any longer, and there’s a possibility that it never was because I have no memory of it. What a person can’t remember didn’t exist.... for him.

In the films, Bourne’s transnational nomadism is rendered in an ultra-fast cutting style which functions as a kind of anti-memory, pitching the viewer into the vertiginous ‘continuous present’ which Jameson argues is characteristic of postmodern temporality. The complex plotting of Ludlum’s novels is transformed into a series of evanescent event-ciphers and action set pieces which barely cohere into an intelligible narrative. Bereft of personal history, Bourne lacks narrative memory, but retains what we might call formal memory: a memory – of techniques, practices, actions – that is literally embodied in a series of physical reflexes and tics. Here, Bourne’s damaged memory echoes the postmodern nostalgia mode as described by Fredric Jameson, in which contemporary or even futuristic reference at the level of content obscure a reliance on established or antiquated models at the level of form. On the one hand, this is a culture that privileges only the present and the immediate – the extirpation of the long term extends backwards as well as forwards in time (for example, media stories monopolize attention for a week or so then are instantly forgotten); on the other hand, it is a culture that is excessively nostalgic, given over to retrospection, incapable of generating any authentic novelty. It may be that Jameson’s identification and analysis of this temporal antimony is his most important contribution to our understanding of postmodern/post-Fordist culture. ‘T ()he paradox from which we must set forth,’ he argues in ‘Antimonies Of The Postmodern’,

is the equivalence between an unparalleled rate of change on all the levels of social life and an unparalleled standardization of everything – feelings along with consumer goods, language along with built space – that would seem incompatible with such mutability... What then dawns is the realization that no society has ever been as standardized as this one, and that the stream of human, social and historical temporality has never flowed quite so homogenously. ... What we now begin to feel, therefore – and what begins to emerge as some deeper and more fundamental constitution of postmodernity itself, at least in its temporal dimension – is henceforth, where everything now submits to the perpetual change of fashion and media image, that nothing can change any longer.

No doubt this is another example of the struggle between the forces of deterritorialization and reterritorialization which Deleuze and Guattari argue is constitutive of capitalism as such. It wouldn’t be surprising if profound social and economic instability resulted in a craving for familiar cultural forms, to which we return in the same way that Bourne reverts to his core reflexes. The memory disorder that is the correlative of this situation is the condition which afflicts Leonard in Memento, theoretically pure anterograde amnesia. Here, memories prior to the onset of the condition are left intact, but sufferers are unable to transfer new memories into long term memory; the new therefore looms up as hostile, fleeting, un-navigable, and the sufferer is drawn back to the security of the old. The inability to make new memories: a succinct formulation of the postmodern impasse....

If memory disorder provides a compelling analogy for the glitches in capitalist realism, the model for its smooth functioning would be dreamwork. When we are dreaming, we forget, but immediately forget that we have done so; since the gaps and lacunae in our memories are Photoshopped out, they do not trouble or torment us. What dreamwork does is to produce a confabulated consistency which covers over anomalies and contradictions, and it is this which Wendy Brown picked up on when she argued that it was precisely dreamwork which provided the best model for understanding contemporary forms of power. In her essay ‘American Nightmare: Neoconservatism, Neoliberalism, and De-democratization’, Brown unpicked the alliance between neoconservatism and neoliberalism which constituted the American version of capitalist realism up until 2008. Brown shows that neoliberalism and neoconservatism operated from premises which are not only inconsistent, but directly contradictory. ‘How’, Brown asks,

does a rationality that is expressly amoral at the level of both ends and means (neoliberalism) intersect with one that is expressly moral and regulatory (neoconservatism)? How does a project that empties the world of meaning, that cheapens and deracinates life and openly exploits desire, intersect one centered on fixing and enforcing meanings, conserving certain ways of life, and repressing and regulating desire? How does support for governance modeled on the firm and a normative social fabric of self-interest marry or jostle against support for governance modeled on church authority and a normative social fabric of self-sacrifice and long-term filial loyalty, the very fabric shredded by unbridled capitalism?

But incoherence at the level of what Brown calls ‘political rationality’ does nothing to prevent symbiosis at the level of political subjectivity, and, although they proceeded from very different guiding assumptions, Brown argues that neoliberalism and neoconservatism worked together to undermine the public sphere and democracy, producing a governed citizen who looks to find solutions in products, not political processes. As Brown claims,

the choosing subject and the governed subject are far from opposites ... Frankfurt school intellectuals and, before them, Plato theorized the open compatibility between individual choice and political domination, and depicted democratic subjects who are available to political tyranny or authoritarianism precisely because they are absorbed in a province of choice and need-satisfaction that they mistake for freedom.

Extrapolating a little from Brown’s arguments, we might hypothesize that what held the bizarre synthesis of neoconservatism and neoliberalism together was their shared objects of abomination: the so called Nanny State and its dependents. Despite evincing an anti-statist rhetoric, neoliberalism is in practice not opposed to the state per se – as the bank bail-outs of 2008 demonstrated – but rather to particular uses of state funds; meanwhile, neoconservatism’s strong state was confined to military and police functions, and defined itself against a welfare state held to undermine individual moral responsibility.


‘There’s no central exchange’


Although excoriated by both neoliberalism and neoconserva-tivism, the concept of the Nanny State continues to haunt capitalist realism. The specter of big government plays an essential libidinal function for capitalist realism. It is there to be blamed precisely for its failure to act as a centralizing power, the anger directed at it much like the fury Thomas Hardy supposedly spat at God for not existing. ‘Time and again’, James Meek observed in an LRB piece on water privatization in Britain, ‘Conservative and Labor governments have discovered that when they give powers to private companies, and those private companies screw up, voters blame the government for giving the powers away, rather than the companies for misusing them’. Meek was visiting Tewkesbury, one of the British towns that was the victim of serious flooding in 2007, a year after the disaster. On the face of it, the flooding and the consequent failure of services was the fault of privatized water companies and house builders, yet Meek found that this was not the way that most of the local residents saw it. ‘In Tewkesbury’, Meeks wrote,

in general there is more hostility towards the government, the council and the Environment Agency for not stopping house builders than there is towards house builders for building houses, or buyers for buying them. When insurers raise their premiums, more blame is directed at the government for not spending enough on flood defences than at insurers for raising the premiums, or at people who choose to live in a flood-prone valley but don’t like paying extra for it.

This syndrome was repeated on a much grander scale with a disaster of a different kind –the bank crisis of 2008. The media focus was on the excesses of individual bankers and on the government’s handling of the crisis, not on the systemic causes of the crisis. I don’t for a moment want to excuse New Labour for its part in such disasters, but it has to be recognized that focus on government, like the focus on immoral individuals, is an act of deflection. Scapegoating an impotent government (running around to clean up the messes made by its business friends) arises from bad faith, from a continuing hostility to the Nanny State that nevertheless goes alongside a refusal to accept the consequences of the sidelining of government in global capitalism – a sign, perhaps, that, at the level of the political unconscious, it is impossible to accept that there are no overall controllers, that the closest thing we have to ruling powers now are nebulous, unaccountable interests exercising corporate irresponsibility. A case of fetishist disavowal, perhaps – ‘we know perfectly well that the government is not pulling the strings, but nevertheless...’ The disavowal happens in part because the centerlessness of global capitalism is radically unthinkable. Although people are interpellated now as consumers – and, as Wendy Brown and others have pointed out, government itself is presented as a kind of commodity or service – they still cannot help but think of themselves as (if they were) citizens.

The closest that most of us come to a direct experience of the centerlessness of capitalism is an encounter with the call center. As a consumer in late capitalism, you increasingly exist in two, distinct realities: the one in which the services are provided without hitch, and another reality entirely, the crazed Kafkaesque labyrinth of call centers, a world without memory, where cause and effect connect together in mysterious, unfathomable ways, where it is a miracle that anything ever happens, and you lose hope of ever passing back over to the other side, where things seem to function smoothly. What exemplifies the failure of the neoliberal world to live up to its own PR better than the call center? Even so, the universality of bad experiences with call centers does nothing to unsettle the operating assumption that capitalism is inherently efficient, as if the problems with call centers weren’t the systemic consequences of a logic of Capital which means organizations are so fixated on making profits that they can’t actually sell you anything.

The call center experience distils the political phenomenology of late capitalism: the boredom and frustration punctuated by cheerily piped PR, the repeating of the same dreary details many times to different poorly trained and badly informed operatives, the building rage that must remain impotent because it can have no legitimate object, since – as is very quickly clear to the caller –there is no-one who knows, and no-one who could do anything even if they could. Anger can only be a matter of venting; it is aggression in a vacuum, directed at someone who is a fellow victim of the system but with whom there is no possibility of communality. Just as the anger has no proper object, it will have no effect. In this experience of a system that is unresponsive, impersonal, centerless, abstract and fragmentary, you are as close as you can be to confronting the artificial stupidity of Capital in itself.

Call center angst is one more illustration of the way that Kafka is poorly understood as exclusively a writer on totalitarianism; a decentralized, market Stalinist bureaucracy is far more Kafkaesque than one in which there is a central authority. Read, for instance, the bleak farce of K’s encounter with the telephone system in the Castle, and it is hard not to see it as uncannily prophetic of the call center experience.

There’s no fixed exchange with the Castle, no central exchange which transmits our calls further. When anybody calls up the Castle from here the instruments in all the subordinate departments ring, or rather they would ring if practically all the departments – I know this for a certainty – didn’t leave their receivers off. Now and then, however, a fatigued official may feel the need of a little distraction, especially in the evenings and at night and may hang the receiver on. Then we get an answer, but of course an answer that’s a practical joke. And that’s very understandable too. For who would take the responsibility of interrupting, in the middle of the night, the extremely important work that goes on furiously the whole time, with a message about his own private troubles? I can’t comprehend how even a stranger can imagine that when he calls up Sordini, for example, it’s Sordini that answers.

K’s response anticipates the bewildered frustration of the individual in the call center labyrinth. Although many of the conversations with call center operatives appear Dadaistically nonsensical, they cannot be treated as such, cannot be dismissed as being of no significance.

‘I didn’t know it was like that, certainly,’ said K. ‘I couldn’t know of all these peculiarities, but I didn’t put much confidence in those telephone conversations and I was always aware that the only things of any importance were those that happened in the Castle itself.’

‘No,’ said the Superintendent, holding firmly onto the word, ‘these telephone replies from the Castle certainly have a meaning, why shouldn’t they? How could a message given by an official from the Castle not be important?’

The supreme genius of Kafka was to have explored the negative atheology proper to Capital: the centre is missing, but we cannot stop searching for it or positing it. It is not that there is nothing there – it is that what is there is not capable of exercising responsibility.

This problem is addressed from another angle in a paper by Campbell Jones entitled ‘The Subject Supposed To Recycle’. In posing the question, ‘who is the subject supposed to recycle?’ Jones denaturalizes an imperative that is now so taken for granted that resisting it seems senseless, never mind unethical. Everyone is supposed to recycle; no-one, whatever their political persuasion, ought to resist this injunction. The demand that we recycle is precisely posited as a pre- or post-ideological imperative; in other words, it is positioned in precisely the space where ideology always does its work. But the subject supposed to recycle, Jones argued, presupposed the structure not supposed to recycle: in making recycling the responsibility of ‘everyone’, structure contracts out its responsibility to consumers, by itself receding into invisibility. Now, when the appeal to individual ethical responsibility has never been more clamorous – in her book Frames Of War, Judith Butler uses the term ‘responsibi-lization’ to refer to this phenomenon – it is necessary to wager instead on structure at its most totalizing. Instead of saying that everyone – i.e. every one – is responsible for climate change, we all have to do our bit, it would be better to say that no-one is, and that’s the very problem. The cause of eco-catastrophe is an impersonal structure which, even though it is capable of producing all manner of effects, is precisely not a subject capable of exercising responsibility. The required subject – a collective subject - does not exist, yet the crisis, like all the other global crises we’re now facing, demands that it be constructed. Yet the appeal to ethical immediacy that has been in place in British political culture since at least 1985 – when the consensual sentimentality of Live Aid replaced the antagonism of the Miners Strike – permanently defers the emergence of such a subject.

Similar issues are touched on in a paper by Armin Beverungen on Alan Pakula’s 1974 film The Parallax View, which sees The Parallax View as providing a kind of diagram of the way in which a certain model of (business) ethics goes wrong. The problem is that the model of individual responsibility assumed by most versions of ethics have little purchase on the behavior of Capital or corporations. The Parallax View is in a sense a meta-conspiracy film: a film not only about conspiracies but about the impotence of attempts to uncover them; or, much worse than that, about the way in which particular kinds of investigation feed the very conspiracies they intend to uncover. It is not only that the Warren Beatty character is framed/killed for the crime he is investigating, neatly eliminating him and undermining his investigations with one pull of a corporate assassins trigger; it’s that, as Jameson noted in his commentary on the film in The Geopolitical Aesthetic, his very tenacity, quasi-sociopathic individualism, make him eminently frameable.

The terrifying climactic moment of The Parallax View – when the silhouette of Beatty’s anonymous assassin appears against migraine-white space – for me now rhymes with the open door at the end of a very different film, Peter Weir’s The Truman Show. But where the door in the horizon opening onto black space at the end of Weir’s film connotes a break in a universe of total determinism, the nothingness on which existentialist freedom depends, The Parallax View’s ‘final open door ... opens onto a world conspiratorially organized and controlled as far as the eye can see’ (Jameson). This anonymous figure with a rifle in a doorway is the closest we get to seeing the conspiracy (as) itself. The conspiracy in The Parallax View never gives any account of itself. It is never focalised through a single malign individual. Although presumably corporate, the interests and motives of the conspiracy in The Parallax View are never articulated (perhaps not even to or by those actually involved in it). Who knows what the Parallax Corporation really wants? It is itself situated in the parallax between politics and economy. Is it a commercial front for political interests, or is the whole machinery of government a front for it? It’s not clear if the Corporation really exists – more than that, it is not clear if its aim is to pretend that it doesn’t exist, or to pretend that it does.

There are certainly conspiracies in capitalism, but the problem is that they are themselves only possible because of deeper level structures that allow them to function. Does anyone really think, for instance, that things would improve if we replaced the whole managerial and banking class with a whole new set of (‘better’) people? Surely, on the contrary, it is evident that the vices are engendered by the structure, and that while the structure remains, the vices will reproduce themselves. The strength of Pakula’s film is precisely to invoke the shadowy, centerless impersonality proper to a corporate conspiracy. As Jameson observes, what Pakula captures so well in The Parallax View is a particular kind of corporate affective tonality:

For the agents of conspiracy, Sorge conern () is a matter of smiling confidence, and the preoccupation is not personal but corporate, concern for the vitality of the network or the institution, a disembodied distraction or inattentiveness engaging the absent space of the collective organization itself without the clumsy conjectures that sap the energies of the victims. These people know, and are therefore able to invest their presence as characters in an intense yet complacent attention whose centre of gravity is elsewhere: a rapt intentness which is at the same time disinterest. Yet this very different type of concern, equally depersonalised, carries its own specific anxiety with it, as it were unconsciously and corporately, without any consequences for the individual villains.

... without any consequences for the individual villains... How that phrase resonates just now – after the deaths of Jean Charles De Menezes and Ian Tomlinson and after the banking fiasco. And what Jameson is describing here is the mortifying cocoon of corporate structure – which deadens as it protects, which hollows out, absents, the manager, ensures that their attention is always displaced, ensures that they cannot listen. The delusion that many who enter into management with high hopes is precisely that they, the individual, can change things, that they will not repeat what their managers had done, that things will be different this time; but watch someone step up into management and it’s usually not very long before the grey petrification of power starts to subsume them. It is here that structure is palpable – you can practically see it taking people over, hear its deadened/ deadening judgements speaking through them.

For this reason, it is a mistake to rush to impose the individual ethical responsibility that the corporate structure deflects. This is the temptation of the ethical which, as Žižek has argued, the capitalist system is using in order to protect itself in the wake of the credit crisis – the blame will be put on supposedly pathological individuals, those ‘abusing the system’, rather than on the system itself. But the evasion is actually a two step procedure – since structure will often be invoked (either implicitly or openly) precisely at the point when there is the possibility of individuals who belong to the corporate structure being punished. At this point, suddenly, the causes of abuse or atrocity are so systemic, so diffuse, that no individual can be held responsible. This was what happened with the Hillsborough football disaster, the Jean Charles De Menezes farce and so many other cases. But this impasse – it is only individuals that can be held ethically responsible for actions, and yet the cause of these abuses and errors is corporate, systemic – is not only a dissimulation: it precisely indicates what is lacking in capitalism. What agencies are capable of regulating and controlling impersonal structures? How is it possible to chastise a corporate structure? Yes, corporations can legally be treated as individuals – but the problem is that corporations, whilst certainly entities, are not like individual humans, and any analogy between punishing corporations and punishing individuals will therefore necessarily be poor. And it is not as if corporations are the deep-level agents behind everything; they are themselves constrained by/ expressions of the ultimate cause-that-is-not-a-subject: Capital.



Marxist Supernanny


Nothing could be a clearer illustration of what Žižek has identified as the failure of the Father function, the crisis of the paternal superego in late capitalism, than a typical edition of Supernanny. The program offers what amounts to a relentless, although of course implicit, attack on postmodernity’s permissive hedonism. Supernanny is a Spinozist insofar as, like Spinoza, she takes it for granted that children are in a state of abjection. They are unable to recognize their own interests, unable to apprehend either the causes of their actions or their (usually deleterious) effects. But the problems that Supernanny confronts do not arise from the actions or character of the children – who can only be expected to be idiotic hedonists – but with the parents. It is the parents’ following of the trajectory of the pleasure principle, the path of least resistance, that causes most of the misery in the families. In a pattern that quickly becomes familiar, the parents’ pursuit of the easy life leads them to accede to their children’s every demand, which become increasingly tyrannical.

Rather like many teachers or other workers in what used to be called ‘public service’, Supernanny has to sort out problems of socialization that the family can no longer resolve. A Marxist Supernanny would of course turn away from the troubleshooting of individual families to look at the structural causes which produce the same repeated effect.

The problem is that late capitalism insists and relies upon the very equation of desire with interests that parenting used to be based on rejecting. In a culture in which the ‘paternal’ concept of duty has been subsumed into the ‘maternal’ imperative to enjoy, it can seem that the parent is failing in their duty if they in any way impede their children’s absolute right to enjoyment. Partly this is an effect of the increasing requirement that both parents work; in these conditions, when the parent sees the child very little, the tendency will often be to refuse to occupy the ‘oppressive’ function of telling the child what to do. The parental disavowal of this role is doubled at the level of cultural production by the refusal of ‘gatekeepers’ to do anything but give audiences what they already (appear to) want. The concrete question is: if a return to the paternal superego – the stern father in the home, Reithian superciliousness in broadcasting – is neither possible nor desirable, then how are we to move beyond the culture of monotonous moribund conformity that results from a refusal to challenge or educate? A question as massive as this cannot of course be finally answered in a short book such as this, and what follows here will amount to a few starting points and suggestions. In brief, though, I believe that it is Spinoza who offers the best resources for thinking through what a ‘paternalism without the father’ might look like.

In Tarrying with the Negative, Žižek famously argues that a certain Spinozism is the ideology of late capitalism. Žižek believes that Spinoza’s rejection of deontology for an ethics based around the concept of health is allegedly flat with capitalism’s amoral affective engineering. The famous example here is Spinoza’s reading of the myth of the Fall and the foundation of Law. On Spinoza’s account, God does not condemn Adam for eating the apple because the action is wrong; he tells him that he should not consume the apple because it will poison him. For Žižek, this dramatizes the termination of the Father function. An act is wrong not because Daddy says so; Daddy only says it is ‘wrong’ because performing the act will be harmful to us. In Žižek’s view, Spinoza’s move both deprives the grounding of Law in a sadistic act of scission (the cruel cut of castration), at the same time as it denies the ungrounded positing of agency in an act of pure volition, in which the subject assumes responsibility for everything. In fact, Spinoza has immense resources for analyzing the affective regime of late capitalism, the video-drome-control apparatus described by Burroughs, Philip K. Dick and David Cronenberg in which agency is dissolved in a phantasmagoric haze of psychic and physical intoxicants. Like Burroughs, Spinoza shows that, far from being an aberrant condition, addiction is the standard state for human beings, who are habitually enslaved into reactive and repetitive behaviors by frozen images (of themselves and the world). Freedom, Spinoza shows, is something that can be achieved only when we can apprehend the real causes of our actions, when we can set aside the ‘sad passions’ that intoxicate and entrance us.

There’s no doubt that late capitalism certainly articulates many of its injunctions via an appeal to (a certain version of) health. The banning of smoking in public places, the relentless monstering of working class diet on programs like You Are What You Eat, do appear to indicate that we are already in the presence of a paternalism without the Father. It is not that smoking is ‘wrong’, it is that it will lead to our failing to lead long and enjoyable lives. But there are limits to this emphasis on good health: mental health and intellectual development barely feature at all, for instance. What we see instead is a reductive, hedonic model of health which is all about ‘feeling and looking good’. To tell people how to lose weight, or how to decorate their house, is acceptable; but to call for any kind of cultural improvement is to be oppressive and elitist. The alleged elitism and oppression cannot consist in the notion that a third party might know someone’s interest better than they know it themselves, since, presumably smokers are deemed either to be unaware of their interests or incapable of acting in accordance with them. No: the problem is that only certain types of interest are deemed relevant, since they reflect values that are held to be consensual. Losing weight, decorating your house and improving your appearance belong to the ‘consentimental’ regime.

In an excellent interview at the Register.com, the documentary film-maker Adam Curtis identifies the contours of this regime of affective management.

TV now tells you what to feel.

It doesn’t tell you what to think any more. From EastEnders to reality format shows, you’re on the emotional journey of people – and through the editing, it gently suggests to you what is the agreed form of feeling. “Hugs and Kisses”, I call it.

I nicked that off Mark Ravenhill who wrote a very good piece which said that if you analyse television now it’s a system of guidance – it tells you who is having the Bad Feelings and who is having the Good Feelings. And the person who is having the Bad Feelings is redeemed through a “hugs and kisses” moment at the end. It really is a system not of moral guidance, but of emotional guidance.

Morality has been replaced by feeling. In the ‘empire of the self everyone ‘feels the same’ without ever escaping a condition of solipsism. ‘What people suffer from,’ Curtis claims,

is being trapped within themselves - in a world of individualism everyone is trapped within their own feelings, trapped within their own imaginations. Our job as public service broadcasters is to take people beyond the limits of their own self, and until we do that we will carry on declining.

The BBC should realize that. I have an idealistic view, but if the BBC could do that, taking people beyond their own selves, it will renew itself in a way that jumps over the competition. The competition is obsessed by serving people in their little selves. And in a way, actually, Murdoch for all his power, is trapped by the self. That’s his job, to feed the self.

In the BBC, it’s the next step forward. It doesn’t mean we go back to the 1950s and tell people how to dress, what we do is say “we can free you from yourself” – and people would love it.

Curtis attacks the internet because, in his view, it facilitates communities of solipsists, interpassive networks of like-minds who confirm, rather than challenge, each others’ assumptions and prejudices. Instead of having to confront other points of view in a contested public space, these communities retreat into closed circuits. But, Curtis claims, the impact of internet lobbies on Old Media is disastrous, since, not only does its reactive pro-activity allow the media class to further abnegate its function to educate and lead, it also allows populist currents on both the left and the right to ‘bully’ media producers into turning out programming that is anodyne and mediocre.

Curtis’s critique has a point, but it misses important dimensions of what is happening on the net. Contrary to Curtis’s account of blogging, blogs can generate new discourse networks that have no correlate in the social field outside cyberspace. As Old Media increasingly becomes subsumed into PR and the consumer report replaces the critical essay, some zones of cyberspace offer resistance to a ‘critical compression’ that is elsewhere depressingly pervasive. Nevertheless, the interpassive simulation of participation in postmodern media, the network narcissism of MySpace and Facebook, has, in the main, generated content that is repetitive, parasitic and conformist. In a seeming irony, the media class’s refusal to be paternalistic has not produced a bottom-up culture of breathtaking diversity, but one that is increasingly infantilized. By contrast, it is paternalistic cultures that treat audiences as adults, assuming that they can cope with cultural products that are complex and intellectually demanding. The reason that focus groups and capitalist feedback systems fail, even when they generate commodities that are immensely popular, is that people do not know what they want. This is not only because people’s desire is already present but concealed from them (although this is often the case). Rather, the most powerful forms of desire are precisely cravings for the strange, the unexpected, the weird. These can only be supplied by artists and media professionals who are prepared to give people something different from that which already satisfies them; by those, that is to say, prepared to take a certain kind of risk. The Marxist Supernanny would not only be the one who laid down limitations, who acted in our own interests when we are incapable of recognizing them ourselves, but also the one prepared to take this kind of risk, to wager on the strange and our appetite for it. It is another irony that capitalism’s ‘society of risk’ is much less likely to take this kind of risk than was the supposedly stodgy, centralized culture of the postwar social consensus. It was the public service-oriented BBC and Channel 4 that perplexed and delighted me with the likes of Tinker, Tailor, Soldier Spy, Pinter plays and Tarkovsky seasons; it was this BBC that also funded the popular avant gardism of the BBC Radiophonic Workshop, which embedded sonic experimentalism into everyday life. Such innovations are unthinkable now that the public has been displaced by the consumer. The effect of permanent structural instability, the ‘cancellation of the long term’, is invariably stagnation and conservatism, not innovation. This is not a paradox. As Adam Curtis’s remarks above make clear, the affects that predominate in late capitalism are fear and cynicism. These emotions do not inspire bold thinking or entrepreneurial leaps, they breed conformity and the cult of the minimal variation, the turning out of products which very closely resemble those that are already successful. Meanwhile, films such as the aforementioned Tarkovsky’s Solaris and Stalker -plundered by Hollywood since as far back as Alien and Blade Runner – were produced in the ostensibly moribund conditions of the Brezhnevite Soviet state, meaning that the USSR acted as a cultural entrepreneur for Hollywood. Since it is now clear that a certain amount of stability is necessary for cultural vibrancy, the question to be asked is: how can this stability be provided, and by what agencies?

It’s well past time for the left to cease limiting its ambitions to the establishing of a big state. But being ‘at a distance from the state’ does not mean either abandoning the state or retreating into the private space of affects and diversity which Žižek rightly argues is the perfect complement to neoliberalism’s domination of the state. It means recognizing that the goal of a genuinely new left should be not be to take over the state but to subordinate the state to the general will. This involves, naturally, resuscitating the very concept of a general will, reviving – and modernizing – the idea of a public space that is not reducible to an aggregation of individuals and their interests. The ‘methodological individualism’ of the capitalist realist worldview presupposes the philosophy of Max Stirner as much as that of Adam Smith or Hayek in that it regards notions such as the public as ‘spooks’, phantom abstractions devoid of content. All that is real is the individual (and their families). The symptoms of the failures of this worldview are everywhere – in a disintegrated social sphere in which teenagers shooting each other has become commonplace, in which hospitals incubate aggressive superbugs – what is required is that effect be connected to structural cause. Against the postmodernist suspicion of grand narratives, we need to reassert that, far from being isolated, contingent problems, these are all the effects of a single systemic cause: Capital. We need to begin, as if for the first time, to develop strategies against a Capital which presents itself as ontologically, as well as geographically, ubiquitous.

Despite initial appearances (and hopes), capitalist realism was not undermined by the credit crisis of 2008. The speculations that capitalism might be on the verge of collapsing soon proved to be unfounded. It quickly became clear that, far from constituting the end of capitalism, the bank bail-outs were a massive re-assertion of the capitalist realist insistence that there is no alternative. Allowing the banking system to disintegrate was held to be unthinkable, and what ensued was a vast hemor-rhaging of public money into private hands. Nevertheless, what did happen in 2008 was the collapse of the framework which has provided ideological cover for capitalist accumulation since the 1970s. After the bank bail-outs neoliberalism has, in every sense, been discredited. That is not to say that neoliberalism has disappeared overnight; on the contrary, its assumptions continue to dominate political economy, but they do so now no longer as part of an ideological project that has a confident forward momentum, but as inertial, undead defaults. We can now see that, while neoliberalism was necessarily capitalist realist, capitalist realism need not be neoliberal. In order to save itself, capitalism could revert to a model of social democracy or to a Children of Men–like authoritarianism. Without a credible and coherent alternative to capitalism, capitalist realism will continue to rule the political-economic unconscious.

But even if it is now evident that the credit crisis will not lead to the end of capitalism all by itself, the crisis has led to the relaxing of a certain kind of mental paralysis. We are now in a political landscape littered with what Alex Williams called ‘ideological rubble’ – it is year zero again, and a space has been cleared for a new anti-capitalism to emerge which is not necessarily tied to the old language or traditions. One of the left’s vices is its endless rehearsal of historical debates, its tendency to keep going over Kronsdadt or the New Economic Policy rather than planning and organizing for a future that it really believes in. The failure of previous forms of anti-capitalist political organization should not be a cause for despair, but what needs to be left behind is a certain romantic attachment to the politics of failure, to the comfortable position of a defeated marginality. The credit crisis is an opportunity – but it needs to be treated as a tremendous speculative challenge, a spur for a renewal that is not a return. As Badiou has forcefully insisted, an effective anti-capitalism must be a rival to Capital, not a reaction to it; there can be no return to pre-capitalist territorialities. Anti-capitalism must oppose Capital’s globalism with its own, authentic, universality.

It is crucial that a genuinely revitalized left confidently occupy the new political terrain I have (very provisionally) sketched here. Nothing is inherently political; politicization requires a political agent which can transform the taken-for-granted into the up-for-grabs. If neoliberalism triumphed by incorporating the desires of the post 68 working class, a new left could begin by building on the desires which neoliberalism has generated but which it has been unable to satisfy. For example, the left should argue that it can deliver what neoliberalism signally failed to do: a massive reduction of bureaucracy. What is needed is a new struggle over work and who controls it; an assertion of worker autonomy (as opposed to control by management) together with a rejection of certain kinds of labor (such as the excessive auditing which has become so central feature of work in post-Fordism). This is a struggle that can be won – but only if a new political subject coalesces; it is an open question as to whether the old structures (such as the trade unions) will be capable of nurturing that subjectivity, or whether it will entail the formation of wholly new political organizations. New forms of industrial action need to be instituted against managerialism. For instance, in the case of teachers and lecturers, the tactic of strikes (or even of marking bans) should be abandoned, because they only hurt students and members (at the college where I used to work, one-day strikes were pretty much welcomed by management because they saved on the wage bill whilst causing negligible disruption to the college). What is needed is the strategic withdrawal of forms of labor which will only be noticed by management: all of the machineries of self-surveillance that have no effect whatsoever on the delivery of education, but which managerialism could not exist without. Instead of the gestural, spectacular politics around (noble) causes like Palestine, it’s time that teaching unions got far more immanent, and take the opportunity opened up by the crisis to begin to rid public services of business ontology. When even businesses can’t be run as businesses, why should public services?

We must convert widespread mental health problems from medicalized conditions into effective antagonisms. Affective disorders are forms of captured discontent; this disaffection can and must be channeled outwards, directed towards its real cause, Capital. Furthermore, the proliferation of certain kinds of mental illness in late capitalism makes the case for a new austerity, a case that is also made by the increasing urgency of dealing with environmental disaster. Nothing contradicts capitalism’s constitutive imperative towards growth more than the concept of rationing goods and resources. Yet it is becoming uncomfortably clear that consumer self-regulation and the market will not by themselves avert environmental catastrophe. There is a libidinal, as well as a practical case, to be made for this new ascesis. If, as Oliver James, Žižek and Supernanny have shown, unlimited license leads to misery and disaffection, then limitations placed on desire are likely to quicken, rather than deaden, it. In any case, rationing of some sort is inevitable. The issue is whether it will be collectively managed, or whether it will be imposed by authoritarian means when it is already too late. Quite what forms this collective management should take is, again, an open question, one that can only be resolved practically and experimentally.

The long, dark night of the end of history has to be grasped as an enormous opportunity. The very oppressive pervasiveness of capitalist realism means that even glimmers of alternative political and economic possibilities can have a disproportionately great effect. The tiniest event can tear a hole in the grey curtain of reaction which has marked the horizons of possibility under capitalist realism. From a situation in which nothing can happen, suddenly anything is possible again.

The Great Digital Swindle
Who dares dissent from the gospel according to Silicon Valley? There is – we are insistently told – no alternative to the invasion of capitalist cyberspace into all areas of consciousness and culture.  Anyone who expresses even the mildest scepticism about social media and smartphones is roundly denounced as nostalgic.  The old, desperate not to seem out of touch, rarely dare question the young’s compulsive attachment to their smartphones. Anti-capitalists join with
tycoons to celebrate the potentials of network society. In article after article, conference after conference, the “new” is routinely equated with “the digital”, to such an extent that is now difficult to remember a time when “technology” wasn’t a shorthand for communicative software.  When mobile phones entered the marketplace, they were the object of mockery: who could be so self-important as to believe that they needed to be contactable everywhere and anywhere? Now, everyone is required to act like some cross between a hustler always on the make and an addict jonesing for contact.

But how has this model of progress, in which history culminates in the glorious invention of iPhones and apps, become so uncontested? And, if we attend closely, isn’t there a desperate quality to all this cheerleading? Addicts always rationalise their compulsions, but the desperation here belongs to capital itself, which has thrown everything at the great digital swindle. Capital might still swagger like some data cowboy, but iPhones plus Victorian values can only be a steampunk throwback.  The return to centuries’ old forms of exploitation is obfuscated by the distracting urgencies of digital communication. 

What if Silicon Valley was not – as we are relentlessly hectored to believe – a stupendous success story but a massive monument to failure? In Defence of Serendipity encourages us to pose this counter-intuitive question. Sebastian Olma demonstrates that neoliberal capitalism has systematically destroyed the conditions which allowed Silicon Valley to emerge, at the very same time as it pimps 70s California as the definitive model for all cultural as well as business innovation. In Olma’s narrative, Steve Jobs and the other Californian oligarchs come to seem like the hapless figures from a fairy tale. They wished to totally transform the world, but instead they received unimaginable wealth. Their devices only led to more of the same: the ‘changeless change’ of a capitalism that endlessly crows about innovation in a manic attempt to cover over the glacial monotony of its homogeneity and repetitiveness.  The Silicon Valley princes provided capital with new tools of capture and captivation. More than that, they gave capital a new hymn sheet, a way to sell drudgery as creativity and hyper-exploitation as sharing, so that we are all expected to be “passionate” about our cyber-serfery.

It is by now screamingly clear that innovation does not spontaneously effloresce when capital dominates society and culture. Generalised insecurity leads to sterility and repetition, not surprise and innovation. The conditions in which the new can appear have to be produced and nurtured. This, Sebastian Olma demonstrates, is the real import of the concept of serendipity when it is properly understood. The irony of Silicon Valley is that its very hegemonic dominion has contributed to the disappearance of such conditions in the capitalist world. Silicon Valley emerged from the serendipitious synthesis of the counterculture and state-sponsored cybernetics, but neoliberal capital has destroyed the possibility of a counterculture even as it has annexed and subdued the state. In Defence of Serendipity shows that that the real future is building itself beyond the instrumentalising urgencies of business, in the spaces between a new bohemia and a revived public sphere.

The Weird And The Eerie





To Zöe, my constant source of support, and the reason there is something here rather than nothing.



INTRODUCTION





The Weird and the Eerie (Beyond the Unheimlich)

It is odd that it has taken me so long to really reckon with the weird and the eerie. For although the immediate origins of this book lay in fairly recent events, I have been fascinated and haunted by examples of the weird and the eerie for as long as I can remember. Yet I had not really identified the two modes, still less specified their defining features. No doubt this is partly because the major cultural examples of the weird and the eerie are to be found at the edges of genres such as horror and science fiction, and these genre associations have obscured what is specific to the weird and the eerie.

The weird came into focus for me around a decade ago, as the result of two symposia on the work of H.P. Lovecraft at Goldsmiths, University of London; while the eerie became the major subject of On Vanishing Land, the 2013 audio-essay I produced in collaboration with Justin Barton. Appropriately, the eerie crept up on Justin and me; it had not been our original focus, but by the end of the project we found that much of the music, film and fiction that had always haunted us possessed the quality of the eerie.

What the weird and the eerie have in common is a preoccupation with the strange. The strange — not the horrific. The allure that the weird and the eerie possess is not captured by the idea that we “enjoy what scares us”. It has, rather, to do with a fascination for the outside, for that which lies beyond standard perception, cognition and experience. This fascination usually involves a certain apprehension, perhaps even dread — but it would be wrong to say that the weird and the eerie are necessarily terrifying. I am not here claiming that the outside is always beneficent. There are more than enough terrors to be found there; but such terrors are not all there is to the outside.

Perhaps my delay in coming round to the weird and the eerie had to do with the spell cast by Freud’s concept of the unheimlich. As is well known, the unheimlich has been inadequately translated into English as the uncanny; the word which better captures Freud’s sense of the term is the “unhomely”. The unheimlich is often equated with the weird and the eerie — Freud’s own essay treats the terms as interchangeable. But the influence of Freud’s great essay has meant that the unheimlich has crowded out the other two modes.

The essay on the unheimlich has been highly influential on the study of horror and science fiction — perhaps, in the end, more because of Freud’s hesitations, conjectures and rejected theses than for the actual definition he provides. The examples of the unheimlich which Freud furnishes — doubles, mechanical entities that appear human, prostheses — call up a certain kind of disquiet. But Freud’s ultimate settling of the enigma of the unheimlich — his claim that it can be reduced to castration anxiety — is as disappointing as any mediocre genre detective’s rote solution to a mystery. What enduringly fascinates is the cluster of concepts that circulate in Freud’s essay, and the way in which they often recursively instantiate the very processes to which they refer. Repetition and doubling — themselves an uncanny pair which double and repeat each other — seem to be at the heart of every "uncanny" phenomena which Freud identifies.

There is certainly something that the weird, the eerie and the unheimlich share. They are all affects, but they are also modes: modes of film and fiction, modes of perception, ultimately, you might even say, modes of being. Even so, they are not quite genres.

Perhaps the most important difference between the unheimlich on the one hand and the weird and the eerie on the other is their treatment of the strange. Freud’s unheimlich is about the strange within the familiar, the strangely familiar, the familiar as strange — about the way in which the domestic world does not coincide with itself. All of the ambivalences of Freud’s psychoanalysis are caught up in this concept. Is it about making the familiar — and the familial — strange? Or is it about returning the strange to the familiar, the familial? Here we can appreciate the double move inherent to Freudian psychoanalysis: first of all, there is estrangement of many of the common notions about the family; but this is accompanied by a compensatory move, whereby the outside becomes legible in terms of a modernist family drama. Psychoanalysis itself is an unheimlich genre; it is haunted by an outside which it circles around but can never fully acknowledge or affirm. Many commentators have recognised that the essay on the unheimlich itself resembles a tale, with Freud in the role of the Jamesian unreliable narrator. If Freud is an unreliable narrator, why should we accept that his own tale should be classified in terms of the category that his essay proposes? What if, instead, the whole drama of the essay consisted in Freud’s attempts continually to contain the phenomena he explores within the remit of the unheimlich?

The folding of the weird and the eerie into the unheimlich is symptomatic of a secular retreat from the outside. The wider predilection for the unheimlich is commensurate with a compulsion towards a certain kind of critique, which operates by always processing the outside through the gaps and impasses of the inside. The weird and the eerie make the opposite move: they allow us to see the inside from the perspective of the outside. As we shall see, the weird is that which does not belong. The weird brings to the familiar something which ordinarily lies beyond it, and which cannot be reconciled with the “homely” (even as its negation). The form that is perhaps most appropriate to the weird is montage — the conjoining of two or more things which do not belong together. Hence the predilection within surrealism for the weird, which understood the unconscious as a montage-machine, a generator of weird juxtapositions. Hence also the reason that Jacques Lacan — rising to the challenge posed by surrealism and the rest of aesthetic modernism — could move towards a weird psychoanalysis, in which the death drive, dreams and the unconscious become untethered from any naturalisation or sense of homeliness.

At first glance, the eerie might seem to be closer to the unheimlich than to the weird. Yet, like the weird, the eerie is also fundamentally to do with the outside, and here we can understand the outside in a straightforwardly empirical as well as a more abstract transcendental sense. A sense of the eerie seldom clings to enclosed and inhabited domestic spaces; we find the eerie more readily in landscapes partially emptied of the human. What happened to produce these ruins, this disappearance? What kind of entity was involved? What kind of thing was it that emitted such an eerie cry? As we can see from these examples, the eerie is fundamentally tied up with questions of agency. What kind of agent is acting here? Is there an agent at all? These questions can be posed in a psychoanalytic register — if we are not who we think we are, what are we? — but they also apply to the forces governing capitalist society. Capital is at every level an eerie entity: conjured out of nothing, capital nevertheless exerts more influence than any allegedly substantial entity.

The metaphysical scandal of capital brings us to the broader question of the agency of the immaterial and the inanimate: the agency of minerals and landscape for authors like Nigel Kneale and Alan Garner, and the way that “we” “ourselves” are caught up in the rhythms, pulsions and patternings of non-human forces. There is no inside except as a folding of the outside; the mirror cracks, I am an other, and I always was. The shudder here is the shudder of the eerie, not of the unheimlich.

One extraordinary example of the displacement of the unheimlich by the eerie is D.M. Thomas’ novel The White Hotel. The novel first of all seems to be about a simulated case study of a fictional patient of Freud’s, “Anna G”. The poem by Anna G which begins the novel seems at first sight to be saturated with erotic hysteria, as Thomas’ Freud proposes in the Case History which he writes. Freud’s reading threatens to dissipate the oneiric atmosphere of Anna G’s poem, and also establish to a direction of explanation: from the present to the past, from the outside to the inside. Yet it turns out that the seeming eroticism is itself an obfuscation and a deflection from the poem’s most intense referent, which is to be found not in Anna G’s past, but in her future — her death at the massacre at Babi Yar in 1941. The problems of foresight and fate here bring us to the eerie in a disturbing form. Yet fate might be said to belong to the weird as well as the eerie. The soothsaying witches in Macbeth, after all, are known as the Weird Sisters, and one of the archaic meanings of “weird” is “fate”. The concept of fate is weird in that it implies twisted forms of time and causality that are alien to ordinary perception, but it is also eerie in that it raises questions about agency: who or what is the entity that has woven fate?

The eerie concerns the most fundamental metaphysical questions one could pose, questions to do with existence and non-existence: Why is there something here when there should be nothing? Why is there nothing here when there should be something? The unseeing eyes of the dead; the bewildered eyes of an amnesiac — these provoke a sense of the eerie, just as surely as an abandoned village or a stone circle do.

So far, we are still left with the impression that the weird and the eerie have primarily to do with what is distressing or terrifying. So let us end these preliminary remarks by pointing to examples of the weird and the eerie that produce a different set of affects. Modernist and experimental work often strikes us as weird when we first encounter it. The sense of wrongness associated with the weird — the conviction that this does not belong — is often a sign that we are in the presence of the new. The weird here is a signal that the concepts and frameworks which we have previously employed are now obsolete. If the encounter with the strange here is not straightforwardly pleasurable (the pleasurable would always refer to previous forms of satisfaction), it is not simply unpleasant either: there is an enjoyment in seeing the familiar and the conventional becoming outmoded — an enjoyment which, in its mixture of pleasure and pain, has something in common with what Lacan called jouissance.

The eerie also entails a disengagement from our current attachments. But, with the eerie, this disengagement does not usually have the quality of shock that is typically a feature of the weird. The serenity that is often associated with the eerie — think of the phrase eerie calm — has to do with detachment from the urgencies of the everyday. The perspective of the eerie can give us access to the forces which govern mundane reality but which are ordinarily obscured, just as it can give us access to spaces beyond mundane reality altogether. It is this release from the mundane, this escape from the confines of what is ordinarily taken for reality, which goes some way to account for the peculiar appeal that the eerie possesses.





THE WEIRD





The Out of Place and the Out of Time: Lovecraft and the Weird

What is the weird? When we say something is weird, what kind of feeling are we pointing to? I want to argue that the weird is a particular kind of perturbation. It involves a sensation of wrongness: a weird entity or object is so strange that it makes us feel that it should not exist, or at least it should not exist here. Yet if the entity or object is here, then the categories which we have up until now used to make sense of the world cannot be valid. The weird thing is not wrong, after all: it is our conceptions that must be inadequate.

Dictionary definitions are not always much help in defining the weird. Some refer immediately to the supernatural, but it is by no means clear that supernatural entities must be weird. In many ways, a natural phenomenon such as a black hole is more weird than a vampire. Certainly, when it comes to fiction, the very generic recognisability of creatures such as vampires and werewolves disqualifies them from provoking any sensation of weirdness. There is a pre-existing lore, a set of protocols for interpreting and placing the vampire and the werewolf. In any case, these creatures are merely empirically monstrous; their appearance recombines elements from the natural world as we already understand it. At the same time, the very fact that they are supernatural entities means that any strangeness they possess is now attributed to a realm beyond nature. Compare this to a black hole: the bizarre ways in which it bends space and time are completely outside our common experience, and yet a black hole belongs to the natural-material cosmos — a cosmos which must therefore be much stranger than our ordinary experience can comprehend.

It was this kind of intuition which inspired the weird fiction of H.P. Lovecraft. “Now all my tales are based on the fundamental premise that common human laws and interests and emotions have no validity or significance in the vast cosmosat-large,” Lovecraft wrote to the publisher of the magazine Weird Tales in 1927. “To achieve the essence of real externality, whether of time or space or dimension, one must forget that such things as organic life, good and evil, love and hate, and all such local attributes of a negligible and temporary race called mankind, have any existence at all.” It is this quality of “real externality” that is crucial to the weird.

Any discussion of weird fiction must begin with Lovecraft. In stories that were published in pulp magazines, Lovecraft practically invented the weird tale, developing a formula which can be differentiated from both fantasy and horror fiction. Lovecraft’s stories are obsessively fixated on the question of the outside: an outside that breaks through in encounters with anomalous entities from the deep past, in altered states of consciousness, in bizarre twists in the structure of time. The encounter with the outside often ends in breakdown and psychosis. Lovecraft’s stories frequently involve a catastrophic integration of the outside into an interior that is retrospectively revealed to be a delusive envelope, a sham. Take “The Shadow over Innsmouth”, in which it is ultimately revealed that the lead character is himself a Deep One, an aquatic alien entity. I am It — or better, I am They.

Although he is often classified as a writer of horror, Lovecraft’s work seldom evokes a feeling of horror. When Lovecraft sets out his motives for writing in his short essay “Notes on Writing Weird Fiction”, he does not immediately mention horror. He writes instead of “vague, elusive, fragmentary impressions of wonder, beauty, and adventurous expectancy.” The emphasis on horror, Lovecraft goes on to say, is a consequence of the stories’ encounter with the unknown.

Accordingly, it is not horror but fascination — albeit a fascination usually mixed with a certain trepidation — that is integral to Lovecraft’s rendition of the weird. But I would say this is also integral to the concept of the weird itself — the weird cannot only repel, it must also compel our attention. So if the element of fascination were entirely absent from a story, and if the story were merely horrible, it would no longer be weird. Fascination is the affect shared by Lovecraft’s characters and his readers. Fear or terror are not shared in the same way; Lovecraft’s characters are often terrified, but his readers seldom are.

Fascination in Lovecraft is a form of Lacanian jouissance: an enjoyment that entails the inextricability of pleasure and pain. Lovecraft’s texts fairly froth with jouissance. "Frothing", "foaming" and "teeming" are words which Lovecraft frequently uses, but they could apply equally well to the “obscene jelly” of jouissance. This is not to make the absurd claim that there is no negativity in Lovecraft — the loathing and abomination are hardly concealed — only that negativity does not have the last word. An excessive preoccupation with objects that are “officially” negative always indicates the work of jouissance — a mode of enjoyment which does not in any sense “redeem” negativity: it sublimates it. That is to say, it transforms an ordinary object causing displeasure into a Thing which is both terrible and alluring, which can no longer be libidinally classified as either positive or negative. The Thing overwhelms, it cannot be contained, but it fascinates.

It is fascination, above all else, that is the engine of fatality in Lovecraft’s fictions, fascination that draws his bookish characters towards the dissolution, disintegration or degeneration that we, the readers, always foresee. Once the reader has read one or two of Lovecraft’s stories, they know perfectly well what to expect in the others. In fact, it is hard to believe that even when a reader encounters a Lovecraft story for the first time that they will be very surprised by how the tale turns out. Therefore it follows that suspense — as much as horror — is not a defining feature of Lovecraft’s fiction.

This means that Lovecraft’s work does not fit the structuralist definition of fantasy offered by Tzvetan Todorov. According to that definition, the fantastic is constituted by a suspension between the uncanny (stories which ultimately resolve in a naturalistic way) and the marvellous (stories which resolve supernaturalistically). Although Lovecraft’s stories involve what he characterised in “Notes on Writing Weird Fiction” as “the illusion of some strange suspension or violation of the galling limitations of time, space, and natural law which forever imprison us and frustrate our curiosity about the infinite cosmic spaces beyond the radius of our sight and analysis”, there is never any suggestion of the involvement of supernatural beings. Human attempts to transform the alien entities into gods are clearly regarded by Lovecraft as vain acts of anthropomorphism, perhaps noble but ultimately absurd efforts to impose meaning and sense on to the “real externality” of a cosmos in which human concerns, perspectives and concepts have only a local reference.

In his book Lovecraft: A Study in the Fantastic, Maurice Lévy fitted Lovecraft into a “Fantastic tradition” which includes the Gothic novels, Poe, Hawthorne and Bierce. But Lovecraft’s emphasis on the materiality of the anomalous entities in his stories means that he is very different from the Gothic novelists and Poe. Even though what we might call ordinary naturalism — the standard, empirical world of common sense and Euclidean geometries — will be shredded by the end of each tale, it is replaced by a hypernaturalism — an expanded sense of what the material cosmos contains.

Lovecraft’s materialism is one reason that I think we should distinguish his fiction — and indeed the weird in general — from fantasy and the fantastic. (It should be noted that Lovecraft himself happily equates the weird and the fantastic in “Notes on Writing Weird Fiction”.) The fantastic is a rather capacious category, which can include much of science fiction and horror. It is not that this is inappropriate for Lovecraft’s work, but it does not point to what is unique in his method. Fantasy, however, denotes a more specific set of generic properties. Lord Dunsany, Lovecraft’s early inspiration, and Tolkien, are exemplary fantasy writers, and the contrast with them will allow us to grasp the difference from the weird. Fantasy is set in worlds that are entirely different from ours — Dunsany’s Pegāna, or Tolkien’s Middle Earth; or rather, these worlds are locationally and temporally distant from ours (too many fantasy worlds turn out to be all too similar, ontologically and politically, to ours). The weird, by contrast, is notable for the way in which it opens up an egress between this world and others. There are of course stories and series — such as C.S. Lewis’ Narnia books, Baum’s Oz, Stephen Donaldson’s Thomas Covenant trilogy — in which there is an egress between this world and another, yet there is no discernible charge of the weird. That is because the “this world” sections of these fictions serve, more or less, as prologues and epilogues to standard fantasy tales. Characters from this world go into another world, but that other world has no impact upon this one, beyond the effect it has on the minds of the returning characters. With Lovecraft, there is an interplay, an exchange, a confrontation and indeed a conflict between this world and others.

This accounts for the supreme significance of Lovecraft setting so many of his stories in New England. Lovecraft’s New England, Maurice Lévy writes, is a world whose “reality — physical, topographical, historical — should be emphasised. It is well known that the truly fantastic exists only where the impossible can make an irruption, through time and space, into an objectively familiar locale.” What I propose, then, is that in his break from the tendency to invent worlds as Dunsany had done, Lovecraft ceased to be a fantasy writer and became a writer of the weird. A first characteristic of the weird, at least in Lovecraft’s version of it, would be — to adapt Lévy’s phrase — a fiction in which, not the impossible but the outside “can make an irruption, through time and space, into an objectively familiar locale”. Worlds may be entirely foreign to ours, both in terms of location and even in terms of the physical laws which govern them, without being weird. It is the irruption into this world of something from outside which is the marker of the weird.

Here we can see why the weird entails a certain relationship to realism. Lovecraft himself often wrote disdainfully of realism. But if Lovecraft had entirely rejected realism, he would never have emerged from the fantasy realms of Dunsany and de la Mare. It would be closer to the mark to say that Lovecraft contained or localised realism. In the 1927 letter to the editor of Weird Tales, he makes this explicit:

Only the human scenes and characters must have human qualities. These must be handled with unsparing realism, (not catch-penny romanticism) but when we cross the line to the boundless and hideous unknown — the shadow-haunted Outside — we must remember to leave our humanity and terrestrialism at the threshold.

Lovecraft’s tales depend for their power on the difference between the terrestrial-empirical and the outside. That is one reason why they are so often written in the first person: if the outside gradually encroaches upon a human subject, its alien contours can be appreciated; whereas to attempt to capture “the boundless and hideous unknown” without any reference to the human world at all is to risk banality. Lovecraft needs the human world, for much the same reason that a painter of a vast edifice might insert a standard human figure standing before it: to provide a sense of scale.

A provisional definition of the weird might therefore take its cue from the slightly odd and ambiguous phrase “out of” that Lovecraft uses in the titles of two of his stories, “The Colour Out of Space” and “The Shadow Out of Time”. On the simplest level, “out of” evidently means “from”. Yet it is not possible — especially in the case of “The Shadow Out of Time” — to avoid the second meaning, the suggestion of something removed, cut out. The shadow is something cut out of time. This notion of things “cut out” of their proper place is one way in which Lovecraft has an affinity with modernist techniques of collage. Yet there is also a third meaning of “out of”: the beyond. The shadow out of time is, in part, a shadow of that which is beyond time as we ordinarily understand and experience it.

To possess a flavour of the beyond, to invoke the outside, Lovecraft’s work cannot rely on already-existing figures or lore. It depends crucially on the production of the new. As China Miéville put it in his introduction to At the Mountains of Madness: “Lovecraft resides radically outside any folk tradition: this is not the modernising of the familiar vampire or werewolf (or garuda or rusalka or any other such traditional bugbear). Lovecraft’s pantheon and bestiary are absolutely sui generis.” There is another, important, dimension of the newness of Lovecraft’s creations however: it is disclaimed and disguised by the author. As Miéville continues: “There is … () a paradox to be found in Lovecraft’s narrative. Though his concept of the monstrous and his approach to the fantastic are utterly new, he pretends that it is not.” When they confront the weird entities, Lovecraft’s characters find parallels in mythologies and lore which he had himself invented. Lovecraft’s retrospective projection of a newly minted mythos into the deep past gave rise to what Jason Colavito calls the “cult of alien gods” in writers such as Erich von Däniken and Graham Hancock. Lovecraft’s “retro-interring” of the new is also what places his weird fictions “out of” time — much as in the story “The Shadow Out of Time”, in which the main character Peaslee encounters texts written in his own hand amongst architectural relics.

China Miéville argues that it was the impact of the First World War which gave rise to Lovecraft’s new: the traumatic break from the past allowed the new to emerge. But it is perhaps also useful to think of Lovecraft’s work as being about trauma, in the sense that it concerns ruptures in the very fabric of experience itself. Remarks that Freud makes in “Beyond the Pleasure Principle” (“as a result of certain psychoanalytic discoveries, we are today in a position to embark on a discussion of the Kantian theorem that time and space are ‘necessary forms of thought’”) indicated that he believed that the unconscious operated beyond what Kant called the “transcendental” structures of time, space and causality which govern the perceptual-conscious system. One way of grasping the functions of the unconscious, and its break from the dominant models of time, space and causality, was through studying the mental lives of those suffering from trauma. Trauma can therefore be thought of as a kind of transcendental shock — a suggestive phrase in relation to Lovecraft’s work. The outside is not “empirically” exterior; it is transcendentally exterior, i.e. it is not just a matter of something being distant in space and time, but of something which is beyond our ordinary experience and conception of space and time itself. Throughout his work, Freud repeatedly stressed that the unconscious knows neither negation nor time. Hence the Escheresque image in Civilisation and its Discontents of the unconscious as a Rome “in which nothing that has once come into existence will have passed away and all the earlier phases of development continue to exist alongside the latest ones”. Freud’s weird geometries have clear parallels in Lovecraft’s fictions, with their repeated invocations of non-Euclidean spaces. Witness the description of “the geometry of the dream-place” in “Call of Cthulhu”: “abnormal, non-Euclidean, and loathsomely redolent of spheres and dimensions apart from ours”.

It is important not to surrender Lovecraft too quickly to a notion of the unrepresentable. Lovecraft is too often taken at his word when he calls his own entities “unnameable” or “indescribable”. As China Miéville points out, typically Lovecraft no sooner calls an entity “indescribable” than he begins to describe it, in very precise technical detail. (Nor, despite his predilection for using the term “unnameable” — mocked but also defended by Lovecraft himself in his own story “The Unnameable” — is Lovecraft shy of giving names to Things.) But this sequence has a third moment. After (1) the declaration of indescribability, and (2) the description, comes (3) the unvisualisable. For all their detail, or perhaps because of it, Lovecraft’s descriptions do not allow the reader to synthesise the logorrheic schizophony of adjectives into a mental image, prompting Graham Harman to compare the effect of such passages with Cubism, a parallel reinforced by the invocation of “clusters of cubes and planes” in “Dreams in the Witch House”. Cubist and futurist techniques and motifs feature in a number of Lovecraft’s stories, usually as (ostensible) objects of loathing. Even if he was hostile to it, Lovecraft recognised that modernist visual art could be repurposed as a resource for invoking the outside.

So far, my discussion of Lovecraft has concentrated on what happens within the stories themselves, but one of the most important weird effects Lovecraft produces happens between his texts. The systematisation of Lovecraft’s texts into a “mythos” might have been the work of his follower August Derleth, but the inter-relationship of the stories, the way in which they generate a consistent reality, is crucial to understanding what is singular about Lovecraft’s work. It might appear that the way that Lovecraft produces such consistency is not very different to the way in which Tolkien achieved a similar effect, but, once again, the relationship to this world is crucial. By setting his stories in New England rather than in some inviolate, far-distant realm, Lovecraft is able to tangle the hierarchical relationship between fiction and reality.

The interpolation into the stories of simulated scholarship alongside authentic history produces ontological anomalies similar to those created in the “postmodernist” fictions of Robbe-Grillet, Pynchon and Borges. By treating really existing phenomenon as if they had the same ontological status as his own inventions, Lovecraft de-realises the factual and real-ises the fictional. Graham Harman looks forward to a day when Lovecraft will have displaced Holderlin from his throne as philosophers’ most exalted object of literary study. Perhaps we can also anticipate a time when the pulp modernist Lovecraft displaces the postmodernist Borges as the pre-eminent fictional explorer of ontological conundra. Lovecraft instantiates what Borges only “fabulates”; no one would ever believe that Pierre Menard’s version of Don Quixote exists outside Borges’ story, whereas more than a few readers have contacted the British Library asking for a copy of the Necronomicon, the book of ancient lore which is frequently referred to in many of Lovecraft’s stories. Lovecraft generates a “reality-effect” by only ever showing us tiny fragments of the Necronomicon. It is the very fragmentary quality of his references to the abominable text that induce the belief in readers that it must be a real object. Imagine if Lovecraft had actually produced a full text of the Necronomicon; the book would seem far less real than it does when we only see citations. Lovecraft seemed to have understood the power of the citation, the way in which a text seems more real if it is cited than if it is encountered in the raw.

One effect of such ontological displacements is that Lovecraft ceases to have ultimate authority over his own texts. If the texts have achieved a certain autonomy from their author, then Lovecraft’s role as their ostensible creator becomes incidental. He becomes instead the inventor of entities, characters and formulae. What matters is the consistency of his fictional system — a consistency which invites collective participation by both readers and other authors alike. As is well known, not only Derleth but also Clark Ashton Smith, Robert E. Howard, Brian Lumley, Ramsey Campbell and many others have written tales of the Cthulhu mythos. By webbing his tales together, Lovecraft loses control of his creations to the emerging system, which has its own rules that acolytes can determine just as easily as he can.





The Weird Against the Worldly: H.G. Wells

I want now to approach the weird from a different angle, via a reading of H.G. Wells’ short story “The Door in the Wall”. I believe this story possesses a strong weird charge, even though it is very different from Lovecraft’s work.

The narrator is Redmond, and the story concerns his friend, the politician Lionel Wallace. Wallace tells Redmond of his childhood memory of seeing a green door in a wall somewhere in the streets of West Kensington in London. For some reason, he was attracted to opening the door. Initially, he was apprehensive, feeling it is “unwise or wrong” to go through the door, but “in a gust of emotion”, he overcomes these anxieties and runs through the Door in the Wall. The garden beyond the Door in the Wall has something of the feel of a surrealist painting by Delvaux or Ernst — there is an atmosphere of languid joy, while a diffuse sense of kindness seems to emanate from all of the people he meets there. There are anomalous things there — he sees a pair of panthers, and some kind of book in which the images “were not pictures but realities”. Whether this book is a magical object, an example of advanced technology, or the product of some kind of intoxicant is not clear. After a while, though, when he is looking through this book, he suddenly finds himself seeing “a long grey street in West Kensington, on that chill hour of afternoon before the lamps are lit, and I was there, a wretched little figure, weeping aloud”. However, for reasons that are not fully clear — why does he not immediately go through the Door in the Wall again? — he cannot return straight away. Once again consigned to the mundane world, he is overcome by a sense of “ungovernable grief”.

Wallace only sees the Door in the Wall a few years later, initially by accident. He “got entangled among some rather low-class streets on the other side of Campden Hill”, until he sees the long white wall and the door that leads into the garden. However, this time he does not go through. He feels he will be late for school, so he will return later, when he has more time. He makes the mistake of telling some school friends about the door and the garden. They force Wallace to take them there, but he cannot find it.

He sees the door again a couple of times in his youth — once when he is on the way to collect his scholarship for Oxford — but, again consumed by the urgencies of everyday life, he passes by without going through the door. In recent years, as he enters middle age, Wallace is once again haunted by the door, and fears that he may never see it again:

Years of hard work after that and never a sight of the door. It’s only recently it has come back to me. With it there has come a sense as though some thin tarnish had spread itself over my world. I began to think of it as a sorrowful and bitter thing that I should never see that door again. Perhaps I was suffering a little from overwork — perhaps it was what I’ve heard spoken of as the feeling of forty. I don’t know. But certainly the keen brightness that makes effort easy has gone out of things recently…

Yet he does see the door again — three times. But each time he passes it by — because he is embroiled in important political business; because he is en route to his father’s deathbed; because he is engaged in a conversation about his position. When Wallace recounts this to Redmond, he is racked with anguish about his failure to go through the door. It doesn’t surprise us to learn that the next thing Redmond hears of Wallace is that he is dead. His body is discovered “in a deep excavation near East Kensington Station”.

Why should “The Door in the Wall” be classified as a weird tale? The problem of worlds — of contact between incommensurable worlds — is clearly something that the story shares with Lovecraft, and this brings us once again to the heart of the weird. As we began to explore in the last chapter, weird fiction always presents us with a threshold between worlds. “The Door in the Wall”, evidently, centres on just such a threshold. Much of its power derives from the opposition between the mundanity of the London setting, with its quotidian details — “he recalls a number of mean, dirty shops, and particularly that of a plumber and decorator, with a dusty disorder of earthenware pipes, sheet lead ball taps, pattern books of wall paper, and tins of enamel” — and the world beyond the door.

Lovecraft’s stories are full of thresholds between worlds: often the egress will be a book (the dreaded Necronomicon), sometimes, as in the case of the Randolph Carter “Silver Key” stories, it is literally a portal. Gateways and portals routinely feature in the deeply Lovecraftian stories of the Marvel Comics character Doctor Strange. David Lynch’s film and television work is similarly fixated on doorways, curtains and gateways: as we shall see later, Inland Empire appears to be a “holey space” constructed out of thresholds between worlds, an ontological rabbit warren. Sometimes the threshold into another world may only be a matter of re-scaling: Richard Matheson’s The Incredible Shrinking Man demonstrates that your own living-room can be a space of weird wonder and dread if you become sufficiently small.

The centrality of doors, thresholds and portals means that the notion of the between is crucial to the weird. It is clear that if Wells’ story had taken place only in the garden behind the wall, then no weird charge would have been produced. (This is why a feeling of the weird attaches to the lamppost at the edge of Narnia in C.S. Lewis’ stories, but not to Narnia proper.) If the story were set entirely beyond the door, we would be in the realm of the fantasy genre. This mode of fantasy naturalises other worlds. But the weird de-naturalises all worlds, by exposing their instability, their openness to the outside.

One obvious point of departure from the formula of the Lovecraftian tale is the lack of any inhuman entities in “The Door in the Wall”. When Wallace passes through the door, he encounters strange beings, but they appear to be human. The feeling of the weird that the story gives rise to is not primarily produced by these languid, beneficent beings; and the weird does not require any of the “abominable monstrosities” which are so central to Lovecraft’s tales.

A second difference between Lovecraft and “The Door in the Wall” concerns the question of suspense. As we have seen, Lovecraft’s stories are rarely characterised by a feeling of suspense: we are not left wondering if the outside is real or not. At the end of “The Door in the Wall”, by contrast, Redmond finds his mind “darkened with questions and riddles”. He cannot dismiss the possibility that Wallace was suffering from an “unprecedented type of hallucination”. Wallace was either a madman or a “dreamer, a man of vision and the imagination”. “We see our world fair and common,” Redmond concludes, inconclusively, “the hoarding and the pit. By our daylight standard he walked out of security into darkness, danger and death. But did he see like that?”

This brings us to a third difference between Lovecraft and this story: the question of insanity. In Lovecraft’s tales, any insanity the characters experience is a consequence of the transcendental shock that the encounter with the outside produces; there is no question of the insanity causing characters to perceive the entities (whose status would then, evidently, be degraded; they would merely be products of a delirium). “The Door in the Wall” leaves open the question of psychosis: it is possible — though Redmond doubts it, it is not his “profoundest belief” — that Wallace is mad, or is deluded, or has confabulated the whole experience from garbled childhood memories (which, to use a distinction from Freud’s essay on “Screen Memory” would then be memories of childhood, not memories from childhood). Wallace himself suspects that he may have augmented a childhood memory — re-dreamed it — to the point of completely distorting it.

But perhaps the most decisive difference between “The Door in the Wall” and Lovecraft consists in the quality of longing that is central to Wells’ story. In Lovecraft, the positive lure of the outside has to be repressed and inverted, transformed into loathing and dread. But the appeal of the world beyond the door shines through “The Door in the Wall”. The key opposition structuring the story is not naturalism versus the supernatural — there is little to suggest that the world behind the wall is supernatural, though it is certainly “enchanted” — it is the opposition between the quotidian and the numinous. Wallace’s description of an “indescribable quality of translucent unreality, different () from the common things of experience that hung about it all” recalls Rudolf Otto’s characterisation of the numinous in The Idea of the Holy. Yet, for both Wallace and Otto, an “indescribable quality of translucent unreality” accompanies encounters with that which is more real than “the common things of experience”. The Real does not feel real; it involves a heightening of sensation, exceeds the parameters of ordinary experience, but to Wallace “at least the Door in the Wall was a real door leading through a real wall to immortal realities.”

Michel Houellebecq entitled his book on Lovecraft Against the World, Against Life, but it might be that Lovecraft’s real antipathy was to the worldly, to the mean confines of the mundane, which his tales endlessly explode. The attack on the deficiencies of the worldly is surely one of the driving imperatives of “The Door in the Wall”. “Oh! the wretchedness of that return!” Wallace complains, when he finds himself back in “this grey world again”. Wallace feels that he is depressed because he has yielded to the temptations of the worldly.

When Wallace describes his grief, he seems to be a plaything of the psychoanalytic death drive. “The fact is — it isn’t a case of ghosts or apparitions — but — it’s an odd thing to tell of, — I am haunted. I am haunted by something — that rather takes the light out of things, that fills me with longings…” Reflecting on Wallace’s first encounter with the door, Redmond pictures “the figure of that little boy, drawn and repelled” (emphasis added). Freud describes the death drive in terms of just this ambivalent attraction towards what is unpleasurable. It is Lacan and his followers who have drawn out the strange geometries of the death drive, the way in which desire perpetuates itself by always missing its official object of satisfaction — just as Wallace repeatedly fails to go through the door, even though this is apparently his deepest desire. The pull exerted by the door and the garden deprives all of his worldly satisfactions and achievements of their flavour:

Now that I have the clue to it, the thing seems written visibly in his face. I have a photograph in which that look of detachment has been caught and intensified. It reminds me of what a woman once said of him — a woman who had loved him greatly. ‘Suddenly,’ she said, ‘the interest goes out of him. He forgets you. He doesn’t care a rap for you — under his very nose…’

The door was always a threshold leading beyond the pleasure principle, and into the weird.





“Body a tentacle mess”: The Grotesque and The Weird: The Fall

The word grotesque derives from a type of Roman ornamental design first discovered in the fifteenth century, during the excavation of Titus’s baths. Named after the ‘grottoes’ in which they were found, the new forms consisted of human and animal shapes intermingled with foliage, flowers, and fruits in fantastic designs which bore no relationship to the logical categories of classical art. For a contemporary account of these forms we can turn to the Latin writer Vitruvius. Vitruvius was an official charged with the rebuilding of Rome under Augustus, to whom his treatise On Architecture is addressed. Not surprisingly, it bears down hard on the “improper taste” for the grotesque: “Such things neither are, nor can be, nor have been,” says the author in his description of the mixed human, animal, and vegetable forms: “For how can a reed actually sustain a roof, or a candelabrum the ornament of a gable? Or a soft and slender stalk, a seated statue? Or how can flowers and half-statues rise alternately from roots and stalks? Yet when people view these falsehoods, they approve rather than condemn, failing to consider whether any of them can really occur or not.”

— PATRICK PARRINDER, James Joyce



If Wells’ story is an example of a melancholic weird, then we can appreciate another dimension of the weird by thinking about the relationship between the weird and the grotesque. Like the weird, the grotesque evokes something which is out of place. The response to the apparition of a grotesque object will involve laughter as much as revulsion, and, in his study of the grotesque, Philip Thomson argued that the grotesque was often characterised by the co-presence of the laughable and that which is not compatible with the laughable. This capacity to excite laughter means that the grotesque is perhaps best understood as a particular form of the weird. It is difficult to conceive of a grotesque object that cannot also be apprehended as weird, but there are weird phenomena which do not induce laughter — Lovecraft’s stories, for example, the only humour in which is accidental.

The confluence of the weird and the grotesque is no better exemplified than in the work of the post-punk group The Fall. The Fall’s work — particularly in their period between 1980-82 — is steeped in references to the grotesque and the weird. The group’s methodology at this time is vividly captured in the cover image for the 1980 single, “City Hobgoblins”, in which we see an urban scene invaded by “emigres from old green glades”; a leering, malevolent cobold looms over a dilapidated tenement. But rather than being smoothly integrated into the photographed scene, the crudely rendered hobgoblin has been etched onto the background. This is a war of worlds, an ontological struggle, a struggle over the means of representation. From the point of view of the official bourgeois culture and its categories, a group like The Fall — working class and experimental, popular and modernist — could not and should not exist, and The Fall are remarkable for the way in which they draw out a cultural politics of the weird and the grotesque. The Fall produced what could be called a popular modernist weird, wherein the weird shapes the form as well as the content of the work. The weird tale enters into becoming with the weirdness of modernism — its unfamiliarity, its combination of elements previously held to be incommensurable, its compression, its challenges to standard models of legibility — and with all the difficulties and compulsions of post-punk sound.

Much of this comes together, albeit in an oblique and enigmatic way, on The Fall’s 1980 album Grotesque (After the Gramme). Otherwise incomprehensible references to “huckleberry masks”, “a man with butterflies on his face”, “ostrich headdress” and “light blue plant-heads” begin to make sense when you recognise that, in Parrinder’s description quoted above, the grotesque originally referred to “human and animal shapes intermingled with foliage, flowers, and fruits in fantastic designs which bore no relationship to the logical categories of classical art”.

The songs on Grotesque are tales, but tales half-told. The words are fragmentary, as if they have come to us via an unreliable transmission that keeps cutting out. Viewpoints are garbled; ontological distinctions between author, text and character are confused and fractured. It is impossible to definitively sort out the narrator’s words from direct speech. The tracks are palimpsests, badly recorded in a deliberate refusal of the “coffee table” aesthetic that the group’s leader Mark E. Smith derides on the cryptic sleeve notes. The process of recording is not airbrushed out but foregrounded, surface hiss and illegible cassette noise brandished like improvised stitching on some Hammer Frankenstein monster. The track “Impression of J Temperance” was typical, a story in the Lovecraft style in which a dog breeder’s “hideous replica”, (“brown sockets... purple eyes … fed with rubbish from disposal barges…”) stalks Manchester. This is a weird tale, but one subjected to modernist techniques of compression and collage. The result is so elliptical that it is as if the text — part-obliterated by silt, mildew and algae — has been fished out of the Manchester ship canal which Steve Hanley’s bass sounds like it is dredging.

There is certainly laughter here, a renegade form of parody and mockery that one hesitates to label satire, especially given the pallid and toothless form that satire has assumed in British culture in recent times. With The Fall, however, it is as if satire is returned to its origins in the grotesque. The Fall’s laughter does not issue from the commonsensical mainstream but from a psychotic outside. This is satire in the oneiric mode of Gillray, in which invective and lampoonery becomes delirial, a (psycho)tropological spewing of associations and animosities, the true object of which is not any failing of probity but the delusion that human dignity is possible. It is not surprising to find Smith alluding to Jarry’s Ubu Roi in a barely audible line in “City Hobgoblins”: “Ubu le Roi is a home hobgoblin.” For Jarry, as for Smith, the incoherence and incompleteness of the obscene and the absurd were to be opposed to the false symmetries of good sense. We could go so far as to say that it is the human condition to be grotesque, since the human animal is the one that does not fit in, the freak of nature who has no place in the natural order and is capable of re-combining nature’s products into hideous new forms.

The sound on Grotesque is a seemingly impossible combination of the shambolic and the disciplined, the cerebral-literary and the idiotic-physical. The album is structured around the opposition between the quotidian and the weird-grotesque. It seems as if the whole record has been constructed as a response to a hypothetical conjecture. What if rock and roll had emerged from the industrial heartlands of England rather than the Mississippi Delta? The rockabilly on “Container Drivers” or “Fiery Jack” is slowed by meat pies and gravy, its dreams of escape fatally poisoned by pints of bitter and cups of greasy-spoon tea. It is rock and roll as working men’s club cabaret, performed by a failed Gene Vincent imitator in Prestwich. The what if? speculations fail. Rock and roll needed the endless open highways; it could never have begun in England’s snarled-up ring roads and claustrophobic conurbations. It is on the track “The N.W.R.A.” (“The North Will Rise Again”) that the conflict between the claustrophobic mundaneness of England and the grotesque-weird is most explicitly played out. All of the album’s themes coalesce in this track, a tale of cultural political intrigue that plays like some improbable mulching of T.S. Eliot, Wyndham Lewis, H.G. Wells, Philip K. Dick, Lovecraft and le Carré. It is the story of Roman Totale, a psychic and former cabaret performer whose body is covered in tentacles. It is often said that Roman Totale is one of Smith’s “alter-egos”; in fact, Smith is in the same relationship to Totale as Lovecraft was to someone like Randolph Carter. Totale is a character rather than a persona. Needless to say, he in no way resembles a “well-rounded” character so much as a carrier of mythos, an inter-textual linkage between Pulp fragments:

So R. Totale dwells underground / Away from sickly grind / With ostrich head-dress / Face a mess, covered in feathers / Orange-red with blue-black lines / That draped down to his chest / Body a tentacle mess / And light blue plant-heads.

The form of “The N.W.R.A.” is as alien to organic wholeness as is Totale’s abominable tentacular body. It is a grotesque concoction, a collage of pieces that do not belong together. The model is the novella rather than the tale and the story is told episodically, from multiple points of view, using a heteroglossic riot of styles and tones: comic, journalistic, satirical, novelistic, it is like Lovecraft’s “Call of Cthulhu” re-written by the Joyce of Ulysses and compressed into ten minutes. From what we can glean, Totale is at the centre of a plot — infiltrated and betrayed from the start — which aims at restoring the North to glory, perhaps to its Victorian moment of economic and industrial supremacy; perhaps to some more ancient pre-eminence, perhaps to a greatness that will eclipse anything that has come before. More than a matter of regional railing against the capital, in Smith’s vision the North comes to stand for everything suppressed by urbane good taste: the esoteric, the anomalous, the vulgar sublime, that is to say, the weird and the grotesque itself. Totale, festooned in the incongruous Grotesque costume of “ostrich head-dress”, “feathers/ orange-red with blue-black lines” and “light blue plant-heads”, is the would-be Faery King of this weird revolt who ends up its maimed Fisher King, abandoned like a pulp modernist Miss Havisham amongst the relics of a carnival that will never happen, a drooling totem of a defeated tilt at social realism, the visionary leader reduced, as the psychotropics fade and the fervour cools, to being a washed-up cabaret artiste once again.

Smith returns to the weird tale form on The Fall’s 1982 album Hex Enduction Hour, another record which is saturated with references to the weird. In the track “Jawbone and the Air Rifle”, a poacher accidentally causes damage to a tomb, unearthing a jawbone which “carries the germ of a curse / Of the Broken Brothers Pentacle Church”. The song is a tissue of allusions to texts such as M.R. James’ tales “A Warning to the Curious” and “Oh, Whistle, and I’ll Come to You, My Lad”, to Lovecraft’s “The Shadow over Innsmouth”, to Hammer Horror, and to The Wicker Man — culminating in a psychedelic/psychotic breakdown, complete with a torch-wielding mob of villagers:

He sees jawbones on the street / advertisements become carnivores / and roadworkers turn into jawbones / and he has visions of islands, heavily covered in slime. / The villagers dance round pre-fabs / and laugh through twisted mouths.

“Jawbone and the Air Rifle” resembles nothing so much as a routine by the British comedy group the League of Gentlemen. The League of Gentlemen’s febrile carnival — with its multiple references to weird tales, and its frequent conjunctions of the laughable with that which is not laughable — is a much more worthy successor to The Fall than most of the musical groups who have attempted to reckon with their influence.

The track “Iceland”, meanwhile, recorded in a lava-lined studio in Reykjavik, is an encounter with the fading myths of North European culture in the frozen territory from which they originated. Here, the grotesque laughter is gone. The song, hypnotic and undulating, meditative and mournful, recalls the bone-white steppes of Nico’s The Marble Index in its arctic atmospherics. A keening wind (on a cassette recording made by Smith) whips through the track as Smith invites us to “cast the runes against your own soul”, another M.R. James reference, this time to his story, “Casting the Runes”. “Iceland” is a Twilight of the Idols for the retreating hobgoblins, cobolds and trolls of Europe’s receding weird culture, a lament for the monstrosities and myths whose dying breaths it captures on tape:

Witness the last of the god men

A Memorex for the Krakens





Caught in the Coils of Ouroboros: Tim Powers

Templeton sits immobile in his attic room, immersed in the deceptively erratic ticking of his old nautical clock, lost in meditation upon JC Chapman’s hermetic engraving. It now seems that this complex image, long accepted as a portrait of Kant, constitutes a disturbing monogram of his own chronological predicament. As if in mockery of stable framing, the picture is surrounded by strange-loop coilings of Ouroboros, the cosmic snake, who traces a figure of eight — and of moebian eternity — by endlessly swallowing itself.

— CCRU, “The Templeton Episode”

One is … () tempted to see in the ‘time paradox’ of science-fiction novels a kind of ‘apparition in the Real’ of the elementary structure of the symbolic process, the so-called internal, internally inverted eight: a circular movement, a kind of snare where we can progress only in such a manner that we ‘overtake’ ourselves in the transference, to find ourselves later at a point which we have already been. The paradox consists in the fact that this superfluous detour, this supplementary snare of understanding ourselves (‘voyage into the future’) and then reversing the time direction (‘voyage into the past’) is not just a subjective illusion/perception of an objective process taking place in so-called reality independent of these illusions. The supplementary snare is, rather, an internal condition, an internal constituent of the so-called ‘objective’ process itself: only through this additional detour does the past itself, the ‘objective’ state of things, become retroactively what it always was.

— SLAVOJ ŽIŽEK, The Sublime Object of Ideology



Is there not an intrinsically weird dimension to the time travel story? By its very nature, the time travel story, after all, combines entities and objects that do not belong together. Here the threshold between worlds is the apparatus that allows travel between different time periods — which may be a time machine, or which could actually be a kind of time-crossing door or gate — and the weird effect typically manifests as a sense of anachronism. But another weird effect is triggered when the time travel story involves time paradox(es). The time travel paradox plunges us into the structures that Douglas Hofstadter calls “strange loops” or “tangled hierarchies”, in which the orderly distinction between cause and effect is fatally disrupted.

The Anubis Gates by Tim Powers is a fabulously inventive take on the time travel paradox story, on the model of Robert Heinlein’s “All You Zombies” and “By His Bootstraps”. But perhaps the predecessor to which The Anubis Gates is closest is Michael Moorcock’s 1969 novella Behold the Man, in which Karl Glogauer time-travels back two thousand years from the 1960s and ends up re-creating — or living for the first time — the life of Christ, including his crucifixion.

The Anubis Gates is in effect an extended weird tale. Although it is stuffed full of references to sorcery, bodily transformation and anomalous entities, the main source of the novel’s weird charge is the twisting of time into an infernal loop. In The Anubis Gates, the academic Brendan Doyle is lured into a time-travel experiment by the eccentric plutocrat Clarence Darrow. Darrow is dying, and, whilst undertaking the prodigious and apparently deranged research he has pursued in a desperate bid to prolong his life, he comes upon the story of “Dog-Face Joe” amongst the folklore of early-nineteenth-century London. By a process of diligent scholarship and daring supposition, Darrow determines that Joe was a magician capable of transferring his consciousness from body to body, but whose body-stealing had an unfortunate side-effect: almost immediately as Joe enters it, the purloined body grows profuse, simian-like hair, so that its new owner is forced to discard it very soon after switching into it. For obvious reasons, Darrow wants to acquire the secret of this profane transmigration, and he seems to have the means to make contact with the body-switching magician since his research has uncovered “gaps” in the river of time, gates through which it is possible to pass into the past. Doyle’s role is to act as a kind of literary tour guide for the ultra-wealthy time travellers Darrow has assembled, attracted by the possibility of seeing a lecture by Coleridge, and whose million dollar fee will finance the trip.

Very soon after arriving in the nineteenth century, Doyle is abducted into a rhizomic under-London that is part Oliver Twist, part Burroughs’ The Western Lands (if you will permit the anachronism — The Western Lands was actually published after The Anubis Gates). Powers’ phantasmagoric London — the apocalyptic vividness of whose rendering led John Clute to describe The Anubis Gates as “Babylon-on-Thames punk” — is the site of a war between the forces of Egyptian polytheistic sorcery and the grey positivism of British empiricism, involving romanys, magical duplicates, poets, beggars, costermongers, male impersonators...

After a while, Doyle comes, reluctantly, to accept his Fate — which in literary-generic terms is to be propelled, by means of SF, into the nineteenth-century picaresque — and more or less gives up any hope of returning home. He resigns himself to make the best of his nineteenth-century life and decides that his most realistic hope of an escape from beggary is to make contact with William Ashbless, the minor poet in whose works he has specialist knowledge.

Doyle goes to the Jamaica Coffee House on the morning in which, according to Ashbless’ biographer, the American poet will write his epic poem, “The Twelve Hours of the Night”. The appointed time arrives, but there is no sign of Ashbless. While he waits, at first agitated and then deflated, Doyle idly transcribes “The Twelve Hours of the Night” from memory.

He is soon caught up in more intrigue and, for a while, forgets about Ashbless. In a moment that is more eerie than weird, Doyle hears, or fancies he hears, someone whistling The Beatles’ “Yesterday”. It is only after he catches the refrain being whistled again a day or so later that he is able to confirm that there are indeed a group of twentieth-century temporal emigres living in this nineteenth-century London. They turn out to be Darrow’s people, given the task of helping in the search for Dog-Face Joe. Doyle meets with one of them, his former student, Benner, who by now is a paranoid and grizzled wreck, convinced that Darrow is out to kill him. He and Doyle agree to meet again a few days later, but when they do, Doyle finds his former friend’s behaviour is even odder than before. Doyle discovers the reason for this too late. Benner’s body has been acquired by Dog-Face Joe. This becomes clear to Doyle only when he finds himself in Benner’s body, after it has been discarded by Joe.

Everything is now in place for the revelation that shocks Doyle but which is, by now, no surprise at all for the reader: Doyle is Ashbless. Or rather: there is no Ashbless (except for Doyle). Doyle only begins to process the full implications of this when he contemplates the peculiar (a)temporal status of the “Twelve Hours of the Night” manuscript:

It hadn’t … () come to too much of a surprise to him when he’d realised, after writing down the first few lines of ‘The Twelve Hours of the Night’, that while his casual scrawl had remained recognisably his own, his new left-handedness made his formal handwriting different — though by no means unfamiliar: for it was identical to William Ashbless’. And now that he’d written the poem out completely he was certain that if a photographic slide of the copy that in 1983 would reside in the British Museum, they would line up perfectly, with every comma and i-dot of his version perfectly covering those of the original manuscript.

Original manuscript? He thought with a mixture of awe and unease. This stack of papers here is the original manuscript… it’s just newer now than it was when I saw it in 1976. Hah! I wouldn’t have been so impressed to see it then if I’d known I had made or would make those pen scratches. I wonder when, where and how it’ll pick up the grease marks I remember seeing on the early pages.

Suddenly a thought struck him. My God, he thought, then if I stay and live out my life as Ashbless — which the universe pretty clearly means me to do — then nobody wrote Ashbless’ poems. I’ll copy out his poems from memory, having read them in the 1932 Collected Poems, and my copies will be set in type for the magazines, and they’ll use tear sheets from the magazines to create the Collected Poems! They’re a closed loop, uncreated! … I’m just the… Messenger and caretaker.



Like his unhappier time-displaced fellow, Jack Torrance in The Shining, Doyle has always been the caretaker. The mise-enabyme here produces a charge of the weird, both because of the scandal of an uncreated thing, and because of the twisted causality that has allowed such a thing to exist. (Perhaps all paradoxes have a touch of the weird about them?)

The Ashbless Enigma that Doyle encounters is comically deflated once he realises that — at some level — the solution is only him. “I wouldn’t have been so impressed to see it then if I’d known I had made or would make those pen scratches.” But the deflation is immediately followed by a profound dread and awe (the poems are uncreated!) that far exceeds his original fascination with the poet.

Once Doyle realises that he is destined to be Ashbless, which is to say, that he always-already was Ashbless, he is faced with a dilemma: does he act in accordance with what he characterises as the will of the universe (it is the “universe” that “wants” him to live in Ashbless’ shoes), or not? The problem that Doyle faces is that the determinism is much more invariant than a will, even a will that belongs to “the universe”. It is impossible for him to process that everything he will do as Ashbless has already happened. The barrier that means that this cannot be faced is transcendental: subjectivity as such presupposes the illusion that things could be different. To be a subject is to be unable to think of oneself as anything but free — even if you know that you are not. What sustains Doyle’s presupposition is the apparently spontaneously emerging hypothesis of an “alternative past”: in order to hold open the possibility that things might go against the already-recorded Ashbless biography, Doyle is forced to consider the possibility that he has somehow crossed into a “different past” to the one he has seen documented. But the full paradox is that it is only Doyle’s positing of such an “alternative past” that ensures that he acts in accordance with what has already happened. Ashbless becomes the hero he already was, the restorer of an order that was never threatened. Everything is at it always was; only now, as Doyle and the reader know, something weird has happened.





Simulations and Unworlding: Rainer Werner Fassbinder and Philip K. Dick

There is another type of weird effect that is generated by strange loops. The strange loops here involve not just tangles in cause and effect of the type we discussed in the last chapter in reference to the time loop story, but confusions of ontological level. Brian McHale devotes much of his Postmodernist Fiction to analyzing these confusions. What should be at an ontologically “inferior” level suddenly appears one level up (characters from a simulated world suddenly appear in the world generating the simulation); or what should be at an ontologically “superior” level appears one level down (authors interact with their characters). Escher’s images exemplify the paradoxical spaces of this strange loop. There is a definite weirdness in this Escher-effect, which, after all, is fundamentally about a sense of wrongness: levels are tangled, things are not where they are supposed to be.

Although McHale does refer to Dick, to whom we shall turn in a moment, many of the texts that he discusses render this confusion of worlds in a literary-metafictional register. I want to discuss now two texts which — on the edge of the science fiction genre — deal with the question of simulated or embedded worlds in a way that emphasises weirdness.

Let’s turn first to Welt am Draht (World on a Wire), a two-part production made for the Westdeutscher Rundfunk public service television channel in 1973. It was an adaptation of Daniel F. Galouye’s science fiction novel Simulacron-3 by none other than Rainer Werner Fassbinder.

One of the opening scenes centres on a mirror: a small hand-mirror that the obviously disturbed head of the Simulacron project, Professor Vollmer, frantically waves in the face of his colleagues, saying, “You are only the image that others have of you.” The project has created a computer-generated world, populated by “identity units” who believe themselves to be real people. Vollmer dies, and is replaced by the programmer Stiller, who soon becomes obsessed with the enigma that drove Vollmer into madness — that their “real world” is also a simulation, engineered by a “realer” world above.

The ambient social scene in the film seems to confirm Vollmer’s idea that we are what we are perceived to be. There is barely a scene that doesn’t feature a reflective surface, and some of the most memorable shots show reflections of reflections, infinite regresses of simulacra. The background figures in crowd scenes have a curiously agog immobility, as if they are spectators at a stageplay. One early scene is like an extrapolation from a Bryan Ferry album sleeve of the early 1970s: in an atmosphere of louche decadence, the business and cultural elite linger like models or gawp like voyeurs as they stand around a swimming pool, its reflected light playing on the then-futuristic interiors.

Much like Tarkovsky’s take on SF in Solaris and Stalker (which we shall discuss later), it is Fassbinder’s deviation from certain science fictional conventions that gives World on a Wire a special charge — especially in the wake of Star Wars and The Matrix. While both those films were defined by their special effects, there are no visual effects to speak of in World on a Wire. The most conspicuous “effect” is the startling Radiophonic Workshop-like squiggles and spurts of electronic music, which break into Fassbinder’s stylised naturalism like a crack in reality itself.

In World on a Wire, the strange loop is created by “Einstein”, the identity unit in Simulacron that those in The Institute for Cybernetics and Future Science use to communicate directly with in the simulated world. In order to perform this liaising function, Einstein naturally has to be aware that he is a simulation. But this knowledge inevitably produces the desire to climb up to the “real” world — a desire, it is implied, that can never be satisfied.

The ontological terror on which World on a Wire turns — is our own world a simulation? — is now very familiar, via the many Philip K. Dick adaptations and their imitators. But, despite not actually being an adaptation of Dick’s fiction, World on a Wire has more in common with the wry mordancy of Dick’s work than many official Dick adaptations, not least in the way that it shows each of its three nested worlds as being equally drab. We actually see very little of the world “below” (the world inside the Simulacron) and almost nothing of the world “above” (the world one level up from what we first took to be reality). The world below we see only in snatched glimpses of hotel lobbies and inside a lorry-driver’s cab. But it is the revelation — or non-revelation — of the world above at the climax of the film that is most startling. Instead of some Gnostic transfiguration, we find ourselves in what looks like a meeting room in some ultra-banal office block. At first, the electronic blinds are down, momentarily holding open the possibility that there will be some marvellous — or at least strange — world to be seen once they are up. But when they do eventually rise, we see only the same grey skies and cityscape. Stiller — whose name now assumes a special significance — has attained his official goal (climbing up to the “world above”), but he has not “moved”. The Zenonian condition remains in the form of an ontological anxiety that in a pre-echo of the torment that destroys Mal in Inception follows the weird topologies of drive: once Stiller’s faith in his initial lifeworld is shattered, there is no possibility of fully believing in any reality.

The differences between the three worlds is not accessible at the level of experience (of either the characters or the audience), and it as if Fassbinder produces in World on a Wire something that perfectly fits Darko Suvin’s famous definition of science fiction as the art of “cognitive estrangement”. Stiller’s mounting awareness of the simulated nature of the world that everyone around him takes for reality forces a cognitive estrangement so intense that it constitutes a psychotic break. The content of his experience is the same in every respect; but, because it is now classified as a simulation, it is psychotically transformed. But, as is so often in the fiction of Dick, the position of the psychotic is also the position of truth.

“Cognitive estrangement” here takes the form of an unworlding, an abyssal falling away of any sense that there is any “fundamental” level which could operate as a foundation or a touchstone, securing and authenticating what is ultimately real. The film generates what you might call a cognitive weird, in that the weird here is not directly seen or experienced; it is a cognitive effect, produced by depriving the film’s formal realism of any feeling of reality.


Philip K. Dick’s Time Out of Joint, published in 1959, performs a similar estrangement of realism, as well as presenting another version of unworlding. The novel is remarkable, in fact, for the painstaking way in which Dick constructs a “realistic” small town America. Two years after the first Disneyland park opened — Dick would become a frequent visitor to the park in LA — the novel treats literary realism as a kind of Disneyfication. In a classic moment of Dick ontological vertigo, the novel’s painstakingly described small town is revealed, in the end, to be an intricate system of pasteboard frontages, hypnotic suggestions and negative hallucinations (we shall return to the question of negative hallucinations later). The pay-off can just as easily be read in terms of critical metafiction as science fiction, for what is any setting in realist fiction if not the same kind of system? How is any “reality effect” achieved except by authors using the literary equivalent of these simulatory techniques? In Time Out of Joint, the machinery of realism becomes, then, re-described as a set of special effects.

In the novel, the feeling of the weird is not generated by a collision of worlds, but by the passage out of a “realistic” world into an “unworld”. After it is downgraded to a simulation, the realistic world is not so much invaded as erased. In the novel, the whole small town scenario is constructed as a ruse, a comfortable setting in which the protagonist can undertake high pressure military work for the government while thinking that he is doing a trivial newspaper contest. Yet it is clear that the science fictional elements were for Dick the pretext that allowed him to write successfully in a naturalistic way about Fifties America. They were the enframing devices that enabled Time Out of Joint to succeed where Dick’s purely realist fiction failed.

In Postmodernism, or the Cultural Logic of Late Capitalism, Jameson captures the peculiar ache of nostalgia that Time Out of Joint engenders, a nostalgia for the present, which Dick achieves by constellating stereotypical images of the decade he was writing at the end of:

President Eisenhower’s stroke; Main Street, U.S.A.; Marilyn Monroe; a world of neighbours and PTAs; small retail stores (the produce trucked in from outside); favourite television programmes; mild flirtations with the housewife next door; game shows and contests; sputniks directly revolving over-head, mere blinking lights in the firmament, hard to distinguish from airliners or flying saucers.

(Monroe actually features as one of the anomalies that leads to the unraveling of the simulated small town, for she has not been incorporated into the reconstructed 1950s world, and appears to the main character only when he discovers some rotting magazines, relics of our Fifties, in a waste ground “outside the city limits”.)

What is remarkable is the way in which Dick was capable, in 1959, of already identifying those stereotypical features of the American Fifties which would come to define the decade in retrospect. It is not Dick’s skill in projecting into the future that is to be admired — the novel’s 1997 is confected out of generic SF tropes, far less convincing than the ostensibly fake Fifties world it embeds — but rather his capacity to imagine how the future would see the Fifties. It is the Fifties already envisaged as a themepark: an anticipated reconstruction. Dick’s simulated small town is not en-kitsched as Disney’s memories of his early twentieth century were, but precisely given what Jameson calls the “cabbage stink” of naturalism:

The misery of happiness, … () of Marcuse’s false happiness, the gratifications of the new car, the TV dinner and your favourite programme on the sofa — which are now themselves secretly a misery, an unhappiness that doesn’t know its name, that has no way of telling itself apart from genuine satisfaction and fulfilment since it has presumably never encountered this last.

In this lukewarm world, ambient discontent hides in plain view, a hazy malaise given off by the refrigerators, television sets and other consumer durables. The vividness and plausibility of this miserable world — with misery itself contributing to the world’s plausibility — somehow becomes all the more intense when its status is downgraded to that of a constructed simulation. The world is a simulation but it still feels real.

Some of the most powerful passages in Dick’s work are those in which there is an ontological interregnum: a traumatic unworlding is not yet given a narrative motivation; an unresolved space that awaits reincorporation into another symbolic regime. In Time Out of Joint, the interregnum takes the form of an extraordinary scene in which the seemingly dull objects of quotidian naturalism — the gas station and the motel — act almost like a negative version of the lamppost at the edge of the Narnian forest. Unlike Lewis’ lamppost, these objects do not mark the threshold of a new world; they constitute instead staging posts on the way towards a desert of the Real, a void beyond any constituted world. When the edge-oftown gas stations come into focus, the background furniture of literary realism suddenly looms into the foreground, and there is a moment of object-epiphany, in which peripheral vision-familiarity transforms into something alien:

The houses became fewer. The truck passed gas stations, tawdry cafes, ice cream stands and motels. The dreary parade of motels ... as if, Ragle thought, we had already gone a thousand miles and were just now entering a strange town. Nothing is so alien, so bleak and unfriendly, as the strip of gas stations — cut-rate gas stations — and motels at the edge of your own city. You fail to recognise it. And, at the same time, you have to grasp it to your bosom. Not just for one night, but for as long as you intend to live where you live. But we don’t intend to live here any more. We’re leaving. For good.

It’s a scene in which Edward Hopper seems to devolve into Beckett, as the natural(ist) landscape gives way to an emptied-out monotony, a minimal, quasi-abstract space that is de-peopled but still industrialised and commercialised: “A last intersection, a minor road serving industries that had been zoned out of the city proper. The railroad tracks... he noticed an infinitely long freight train at rest. The suspended drums of chemicals on towers over factories.” It is as if Dick is slowly clearing away the fixtures and fittings of literary realism in order to prepare the way for the unworlding which he had described a few pages earlier:

Hollow outward form instead of substance; the sun not actually shining, the day not actually warm at all but cold, grey and quietly raining, raining, the god-awful ash filtering down on everything. No grass except charred stumps, broken off. Pools of contaminated water... The skeleton of life, white brittle scarecrow support in the shape of a cross. Grinning. Space instead of eyes. The whole world … () can be seen through. I am on the inside looking out. Peeking through a crack and seeing — emptiness. Looking into its eyes.





Curtains and Holes: David Lynch

David Lynch’s two latest films — Mulholland Drive and Inland Empire — present a kind of acute, compacted weirdness. While often perplexing, Lynch’s earlier work, including the film Blue Velvet (1986) and the television series Twin Peaks (1990-91, with a third series currently in production), presented what at first glance could appear to be a superficial coherence. Both the film and the TV series were — at least initially — constructed around the opposition between an idealised-stereotypical small-town America (not dissimilar from the one depicted in Dick’s Time Out of Joint) and various other- or under-worlds (criminal, occult). The division between worlds was often marked by one of Lynch’s frequently recurring visual motifs: curtains. Curtains both conceal and reveal (and, not accidentally, one of the things that they conceal and reveal is the cinema screen itself). They do not only mark a threshold; they constitute one: an egress to the outside.

In Mulholland Drive, released in 2001, the stability of the opposition which had structured Blue Velvet and Twin Peaks begins to collapse. No doubt this is partly because of the shift away from the small-town setting, and the new focus on LA. Lynch’s customary preoccupation with dreams and the oneiric is now refracted and redoubled by the mediated and manufactured dreams of the Dream Factory, Hollywood. The Hollywood setting proliferates embedded worlds — filmswithin-films (and possibly films-within-films-within-films), screen tests, performed roles, fantasies. Each embedding contains the possibility of a dis-embedding, as something that was at a supposedly inferior ontological level threatens to climb up out of its subordinated position and claim equal status with the level above: figments from dreams cross over into waking life; screen tests appear at least as convincing as the exchanges in the supposedly real-world scenes that surround them. In Mulholland Drive, however — rendered in the onscreen title as Mulholland Dr, with its suggestion of Mulholland Dream — the overwhelming tendency appears to move in the opposite direction: it is not so much that dreams become taken for reality, as that any apparent reality subsides into a dream. But whose dream is it anyway?

The “standard” interpretation of Mulholland Drive claims that its first half is the fantasy/dream of failed two-bit actress Diane Selwyn (Naomi Watts), whose actual life is allegedly depicted, in all its quotidian squalor, in the second half of the film. In the first part of the film, Betty assists an amnesiac brunette (Laura Haring) — the victim of a failed murder plot — to recover her identity. The brunette assumes the name “Rita”, after Rita Hayworth, a name she sees on a film poster, and she and Betty become lovers. In the second part of the film, “Rita” is now Camilla, a successful actress, and the object of bitter jealousy from the failed and jaded Diane, who lives in a miserable apartment in Hollywood. Diane hires a hitman to kill Camilla, before apparently committing suicide. According to the standard interpretation, aspiring actress Betty — who arrives in Hollywood seemingly not only from a small town but from the past (she has just won a jitterbugging competition!) — is Selwyn’s idealised image of herself. The opposition between the idealised place and the underworld(s) that structured Blue Velvet and Twin Peaks has now become an opposition between two personae: naïve small-town Betty versus hard-bitten LA-resident Diane.

In an online review, “Double Dreams in Hollywood”, Timothy Takemoto pointed out that one problem with the standard interpretation is that the second part of the film is, in its own way, as dream-like and as saturated in melodramatic tropes, as the first. “What is some woman in a run-down apartment in Hollywood doing having an affair with a movie star, that is about to get married to a famous director? Where does she get the money to pay for a hitman?” Takemoto’s view is that both the first and second part of the film are dreams. Diane is not the dreamer; the “real dreamer is elsewhere”, and Betty/Diane and Rita/Camilla are all fragments of this (unseen) dreamer’s disintegrated psyche.

Whether or not this view is correct, I think that Takemoto is right to argue that there are two scenes in Mulholland Drive which merit particular attention: the scene about dreams in the diner, and the scene in Club Silencio (perhaps the most powerful sequence in the entire film). In the diner scene, a man called Dan is talking to someone who appears to be a psychiatrist about a dream he has had twice. The dream is set in the very diner in which they are currently sitting (Winkie’s, on Sunset Boulevard). In the dream, Dan is terrified by a figure with a blackened, scarred face, who lurks in a hinterland space behind the diner. In a bid to defeat the power of the dream, the two men walk out to the back of the diner — where the scarred figure is waiting, and Dan collapses, perhaps in a faint, perhaps dead.

The paradoxically entrancing Club Silencio scene acts as a gateway between the two sections of the film. With its red curtains, Club Silencio is evidently a threshold space. Betty and Rita enter the club, but they do not properly emerge from it; they are afterwards replaced/displaced by Diane and Camilla. I described the scene as paradoxically entrancing because it is ostensibly demystifying. Like some cinematic equivalent of Magritte’s This Is Not a Pipe, the Club Silencio performance tells us that what we are witnessing is an illusion, whilst at the same time showing that we will be unable to treat it as such. The host of Club Silencio, a kind of magician-compere figure, repeatedly tells the audience (those in Club Silencio, as well as those watching Mulholland Drive), “There is no band. It is all recorded. It is all a tape. It is an illusion.” A man emerges from behind the red curtains, appearing to play a muted trumpet; he takes the trumpet away from his mouth, but the music continues. When the singer Rebekah Del Rio appears to deliver an emotionally wracked version of Roy Orbison’s version of “Crying”, we are seduced by the power of her performance. So when Del Rio collapses but the music plays on, we cannot help but be shocked. Something in us compels us to treat the performance as if it were genuine.

There is of course nothing less mendacious, less dissimulatory, in cinema’s history of illusion than the scene in Club Silencio. What we are seeing and hearing — the film itself — is indeed a recording and nothing but. On the most banal level, this is the material infrastructure which the “magic of cinema” must conceal. Yet the scene haunts for reasons other than this. It points to the automatisms at work in our subjectivity: insofar as we cannot help but be drawn into Silencio’s illusions (which are also the illusions of cinema), we are like the very recordings by which we are seduced. Yet these illusions are something more than mere deceptions. Like the scene with Dan in the diner, the Club Silencio scene reminds us that dreams and “illusions” are conduits to a Real that cannot ordinarily be confronted. Dreams are not only spaces of solipsistic interiority: they are also a terrain in which the “red curtains” to the outside can open up.

Ultimately, Mulholland Drive is perhaps best read as something which cannot be made to add up. That is not to say that the film should just be considered fair game for any possible interpretation. Rather, it is to say that any attempt finally to tie up the film’s convolutions and impasses will only dissipate its strangeness, its formal weirdness. The weirdness here is generated in part by the way that the film feels like a “wrong” version of a recognisable Hollywood film-type. Roger Ebert remarked that “there is no solution. There may not even be a mystery.” It could be that Mulholland Drive is the illusion of a mystery: we are compelled to treat it as a solvable enigma, to overlook its “wrongness”, its intractability, in the same way that, in Club Silencio, we are compelled to overlook the illusory nature of the performances.

In Lynch’s 2006 film, Inland Empire, it is as if the kind of slippages, incoherencies and conundrums we saw in Mulholland Drive are pushed much further, to the point where there is no longer even the prospect of tractability. For all its many film references, Inland Empire does not even seem to resemble any Hollywood template. If the weird is fundamentally about thresholds, then Inland Empire is a film that seems to be primarily composed of gateways. The best readings of Inland Empire have rightly stressed the film’s labyrinthine, rabbit-warren anarchitecture. Yet the space involved is ontological, rather than merely physical. Each corridor in the film — and there are many of Lynch’s signature corridors in Inland Empire — is potentially the threshold to another world. Yet no character — the word seems absurdly inappropriate when applied to Inland Empire’s fleeting figures, figments and fragments — can cross into these other worlds without themselves changing their nature. In Inland Empire, you are whatever world you find yourself in.

The dominant motif in the film is another kind of threshold: the hole. A hole cigarette-burned into silk; a hole in the vagina wall leading to the intestine; a hole punctured into the stomach by a screwdriver; rabbit holes; holes in memory; holes in narrative; holes as positive nullity, gaps but also tunnels, the connectors in a hellish rhizome in which any part can potentially collapse into any other. The cigarette burn hole could serve as a metonym for the film’s entire psychotic geography. The hole in silk is an image of the camera and its double the spectating eye, whose gaze in Inland Empire is always voyeuristic and partial.

With Inland Empire, world-haemorrhaging has become so acute that we can no longer talk about tangled hierarchies but a terrain subject to chronic ontological subsidence. The film appears at first to be about an actress, Nikki Grace (Laura Dern) who is to play a character, Sue, in a film called On High in Blue Tomorrows. But there is no stability to these personae, nor to the hierarchy which would treat Sue as “less real” than Nikki. By the end, Sue appears to have subsumed Nikki, and seems not to be inside in any film that would be called On High in Blue Tomorrows. “Reflexivity without subjectivity”, that perfect description of the unconscious, is a phrase that is exceptionally apt for Inland Empire’s convolutions and involutions. Nikki Grace and the gaggle of other personae which Dern plays/Grace hosts (or fragments into) are like de-psychologised avatars: holes that we cannot help treating as mysteries, even though it is clear (to us, if not to them) that there is no hope of any solution.

“Something got out from inside the story”, we are told of the Polish movie which Nikki Grace’s film-within-a-film is remaking. In Inland Empire — which often seems like a series of dream sequences floating free of any grounding reality, a dreaming without a dreamer (as all dreams really are, since the unconscious is not a subject) — no frame is secure, all attempts at embedding fail. The temptation to resolve the film’s conundrums psychologically (i.e. to attribute the anomalies to phantasms issuing from the deranged mind of one or more of the characters) is no doubt great, but should be resisted if we are to remain true to what is singular about the film. Instead of looking inside (the characters) for some final key to the film, we must attend to the strange folds, burrows and passageways of Inland Empire’s weird architecture, in which no interior space is ever secure for long, and gateways to the outside can open up practically anywhere.





THE EERIE





Approaching the Eerie

What is the eerie, exactly? And why is it important to think about it? As with the weird, the eerie is worth reckoning with in its own right as a particular kind of aesthetic experience. Although this experience is certainly triggered by particular cultural forms, it does not originate in them. You could say rather that certain tales, certain novels, certain films, evoke the feeling of the eerie, but this sensation is not a literary or a filmic invention. As with the weird, we can and often do encounter the sensation of the eerie “in the raw”, without the need for specific forms of cultural mediation. For instance, there is no doubt that the sensation of the eerie clings to certain kinds of physical spaces and landscapes.

The feeling of the eerie is very different from that of the weird. The simplest way to get to this difference is by thinking about the (highly metaphysically freighted) opposition — perhaps it is the most fundamental opposition of all — between presence and absence. As we have seen, the weird is constituted by a presence — the presence of that which does not belong. In some cases of the weird (those with which Lovecraft was obsessed) the weird is marked by an exorbitant presence, a teeming which exceeds our capacity to represent it. The eerie, by contrast, is constituted by a failure of absence or by a failure of presence. The sensation of the eerie occurs either when there is something present where there should be nothing, or is there is nothing present when there should be something.

We can grasp these two modes quickly by means of examples. The notion of an “eerie cry” — often cited in dictionary definitions of the eerie — is an example of the first mode of the eerie (the failure of absence). A bird’s cry is eerie if there is a feeling that there is something more in (or behind) the cry than a mere animal reflex or biological mechanism — that there is some kind of intent at work, a form of intent that we do not usually associate with a bird. Clearly, there is something in common between this and the feeling of “something which does not belong” that we have said constitutes the weird. But the eerie necessarily involves forms of speculation and suspense that are not an essential feature of the weird. Is there something anomalous about this bird’s cry? What exactly is strange about it? Is, perhaps, the bird possessed — and if it is, by what kind of entity? Such speculations are intrinsic to the eerie, and once the questions and enigmas are resolved, the eerie immediately dissipates. The eerie concerns the unknown; when knowledge is achieved, the eerie disappears. It must be stressed at this point that not all mysteries generate the eerie. There must be also be a sense of alterity, a feeling that the enigma might involve forms of knowledge, subjectivity and sensation that lie beyond common experience.

An example of the second mode of the eerie (the failure of presence) is the feeling of the eerie that pertains to ruins or to other abandoned structures. Post-apocalyptic science fiction, whilst not in itself necessarily an eerie genre, is nevertheless full of eerie scenes. Yet the sense of the eerie is limited in these cases, because we are an offered an explanation of why these cities have been depopulated. Compare this with the case of the abandoned ship the Marie Celeste. Because the mystery of the ship — what happened to the crew? What made them leave? Where did they go? — has never been resolved, nor is ever likely to be, the case of the Marie Celeste is saturated in a sense of the eerie. The enigma here, evidently, turns on two questions — what happened and why? But structures whose meaning and purpose we cannot parse pose a different kind of enigma. Faced with the stone circle at Stonehenge, or with the statues on Easter Island, we are confronted with a different set of questions. The problem here is not why the people who created these structures disappeared — there is no mystery here — but the nature of what disappeared. What kinds of being created these structures? How were they similar to us, and how were they different? What kind of symbolic order did these beings belong to, and what role did the monuments they constructed play in it? For the symbolic structures which made sense of the monuments have rotted away, and in a sense what we witness here is the unintelligibility and the inscrutability of the Real itself. Confronted with Easter Island or Stonehenge, it is hard not to speculate about what the relics of our culture will look like when the semiotic systems in which they are currently embedded have fallen away. We are compelled to imagine our own world as a set of eerie traces. Such speculations no doubt account for the eeriness that attaches to the justly famous final image of the original 1968 version of Planet of the Apes: the remains of the Statue of Liberty, which are as illegible from the perspective of the film’s post-apocalyptic and indeed post-human far future as Stonehenge is to us now. The examples of Stonehenge and Easter Island make us realise that there is an irreducibly eerie dimension to certain archaeological and historical practices. Particularly when dealing with the remote past, archaeologists and historians form hypotheses, but the culture to which they refer and which would vindicate their speculations can never (again) be present.

Behind all of the manifestations of the eerie, the central enigma at its core is the problem of agency. In the case of the failure of absence, the question concerns the existence of agency as such. Is there a deliberative agent here at all? Are we being watched by an entity that has not yet revealed itself? In the case of the failure of presence, the question concerns the particular nature of the agent at work. We know that Stonehenge has been erected, so the questions of whether there was an agent behind its construction or not does not arise; what we have to reckon with are the traces of a departed agent whose purposes are unknown.

We are now in a position to answer the question of why it is important to think about the eerie. Since the eerie turns crucially on the problem of agency, it is about the forces that govern our lives and the world. It should be especially clear to those of us in a globally tele-connected capitalist world that those forces are not fully available to our sensory apprehension. A force like capital does not exist in any substantial sense, yet it is capable of producing practically any kind of effect. At another level, had not Freud long ago shown that the forces that govern our psyche can be conceived of as failures of presence — is not the unconscious itself not just such a failure of presence? — and failures of absence (the various drives or compulsions that intercede where our free will should be)?





Something Where There Should Be Nothing: Nothing Where There Should Be Something: Daphne du Maurier and Christopher Priest

Let’s now test out these preliminary observations in relation to two writers who have rightly been closely associated with the eerie: Daphne du Maurier and Christopher Priest. Du Maurier’s eerie tales often revolve around the influence of entities or objects that should not possess reflective agency: animals, telepathic forces, fate itself. The eerie effect in some of Priest’s novels, meanwhile, depends upon gaps in memory, gaps that fatally undermine the characters’ sense of their own identity.

Du Maurier’s well-known tale “The Birds” (1952) is an almost generic case of the eerie. As I mentioned above, dictionaries frequently cite an animal’s “eerie cry” when they are giving examples of the eerie. “The Birds” builds upon the feeling that is triggered when we hear such cries — the suspicion that an entity to which we do not normally ascribe it possesses a deliberative agency. In du Maurier’s tale, the birds cease to be part of the natural background and assert an agency of their own, but the nature of this agency remains mysterious. Instead of co-existing with human beings, the birds collaborate with one another to launch a murderous attack on the human population. This collaboration amongst different bird species is one of the first signs that something unprecedentedly strange is happening: “The birds were circling still above the fields. Mostly herring gull, but the black-backed gull amongst them. Usually they kept apart. Now they were united. Some bond had brought them together.”

For those familiar with Hitchcock’s film adaptation, reading du Maurier’s original story will come as something of a surprise. (Du Maurier reputedly hated Hitchcock’s film.) Instead of a sunlit Californian setting, we find ourselves in a grey and tempestuous Cornwall, still in the grip of postwar austerity. Instead of a flirting couple in the early days of romance, we find a family — the Hockens — defending their home against the birds’ attack. In some ways, “The Birds”, with its focus on a retreat into a boarded-up house besieged by anomalous entities, reads like an anticipation of George Romero’s Night of the Living Dead (1968). The story sees the characters pitched out of a pastoral communal life into the kind of survivalist atomisation that Romero will depict.

The story’s unsettling power depends on two levels of threat: the first, of course, is the brute physical terror of the birds’ attack. But it is the second level that takes us into the eerie. As the story develops, we see residual wartime certainties and authority structures disintegrate. What the birds threaten is the very structures of explanation that had previously made sense of the world. Initially, the preferred account of the birds’ behaviour is the weather. As the attacks intensify, other narratives emerge: the farmer for whom Hocken works says that the idea is circulating in town that the Russians poisoned the birds. (This turn to the readymade explanations of Cold War paranoia makes a certain sense, when we remember that the birds have set aside their differences in order to develop a kind of species consciousness, analogous to class consciousness.) BBC radio broadcasts assume a crucial role in the story. Initially, the broadcasts are the trusted voice of authority: when the BBC announces that the birds are amassing everywhere, the anomalous situation achieves a kind of official validation. At this point, the BBC is synonymous with an authority structure that it is assumed will “do something” to repel the birds’ attack. But, as the broadcasts become increasingly infrequent, it becomes clear that there is no more a strategy to deal with the birds than there is an adequate explanation of their behaviour. By the end, the BBC is no longer broadcasting at all, and its silence means that we are definitively in the space of the eerie. There will be no explanation, for the characters or for the readers. Nor will there be any reprieve: at the end of the story, the birds’ siege shows no signs of concluding.

In another of du Maurier’s well-known short stories, “Don’t Look Now” (1971), the “something where there should be nothing”, the forces that lie beyond ordinary modes of explanation, are extrasensory perception and fate. The story is about the way in which the misrecognition and disavowal of the power of foresight ends up contributing to the very event that was foreseen happening.

John and Laura are a married couple visiting Venice as part of their grieving process for their young daughter, who has recently died of an illness. While sitting in a restaurant, they meet a strange pair of sisters, who say that they can see the daughter sitting between the grieving couple, laughing. Laura is delighted, and becomes fixated on the sisters; John is skeptical and hostile, certain that the sisters are exploiting his wife’s grief. Soon afterwards, the couple learn that their son at school in England is ill, and it is decided that Laura will return home to be with him. When John is walking around the city, he thinks he sees Laura with the two sisters on a vaporetto. In a panic, he goes to the police, sure that the sisters have abducted Laura. Yet John learns that Laura returned as planned; a humiliated John has to explain to the police that he was mistaken, and to apologise to the sisters. After he has taken the sisters home, he sees what he thinks is a young child being pursued by a man. Venice is being menaced by a serial killer, and John fears that the child will be its next victim. But what he thought was a child turns out to be murderous dwarf — presumably the serial killer — who kills John. As he dies, John only now realises that his seeing the sisters with Laura was a case of foresight, a glimpse into the near future when the three would be together at his own funeral:

And he saw the vaporetto with Laura and the two sisters steaming down the Grand Canal, not today, not tomorrow, but the day after that and he knew why they were together and for what sad purpose they had come. The creature was gibbering in its corner. The hammering and the voices and the barking dog grew fainter, and ‘Oh God,’ he thought, ‘What a bloody silly way to die…’

In some ways, the structure that emerges here is similar to the time loop that we discussed earlier, but the loop here is less tight, and the register is eerie rather than weird, because the emphasis is on an obscured agent: fate itself. Fate here is certainly terrifying, but, as John realises in his dying moments, the patterns it weaves exhibit a certain artistry that in the end is ironic, and perhaps even macabrely comic, as well as harrowing. One irony is that, precisely because it is not recognised as such, John’s foresight does not allow fate’s patterns to be foreseen. John shares the disavowal of his own powers of extrasensory perception with another male fatally defined by self-blinding, The Shining’s Jack Torrance, who we shall discuss in a later chapter. As with Jack Torrance, extrasensory perception compromises John’s masculine sense of self-determination; like Jack, John’s underestimating of the forces that threaten this — ultimately illusory — self-possession feed into the power of those very forces, which in the end leads to his destruction.

Nic Roeg’s film adaptation (1973) (of which, this time, du Maurier approved) is an exercise in the poetics of fate. Here as in so many of his films, Roeg works with parallels, pre-figurations and echoes, inviting us to see time as a rhyming structure. The redness of the stain on a slide that John is studying rhymes with the redness of the raincoat his daughter is wearing when she dies; but his daughter’s death is not so much a completed catastrophe as the opening moment in a grim poetic pattern that will only be closed with John’s death, at the hands of the dwarf wearing a near-identical red raincoat. As Roeg heightens our sensitivity to these rhymes, he suggests the eerie contours of fateful forces that will never fully come into view. Repetitions of colour are supplemented by sonic doublings. In keeping with the story, Roeg’s rendering of Venice is intensely eerie, and much of this has to do with the use of sound. Roeg took advantage of the way in which Venice acts as a sound maze, its architecture generating “schizophonic” effects by separating sounds from their sources, producing a duplicitous sonic space. John and Laura often lose their way, returning inadvertently to places they had just left, retracing their steps and doubling back, wandering around a city that is a dubious labyrinth, and the fragmented image of a fate that can only be recognised too late.

If these two works by du Maurier are about an agency that should not be there — the collective cunning of birds; the poetic weaving of fate — then Christopher Priest’s novels The Affirmation (1981) and The Glamour (1984) are organised around absences, gaps where agency should be. The two lead characters are defined by gaps in the stories that they can tell about themselves, and one effect of Priest’s work (like that of Alan Garner, to which we shall turn later) is to make us appreciate the eerie power of stories.

The Affirmation appears at first to be the story of a young man, Peter Sinclair, who has had a breakdown after a relationship has collapsed and he has lost his job. A meeting with an older acquaintance leads to Sinclair taking up an offer to live in the older man’s second home, a rundown cottage in rural Herefordshire, in exchange for decorating and renovating the property. While he is at the cottage, Sinclair starts writing what he comes to think of as an autobiographical work, a piece of writing that will finally explain his own life to him. We do not at first see this text — perhaps we never see it — only Sinclair’s alternately euphoric and tortured thoughts about it. Sinclair admits that he has begun to embellish and indeed wholly alter elements of the narrative — changing relatively trivial details such as the names of places and characters, but also personality traits and key events, rationalizing that these amendments mean that the novel will have fidelity to a “higher truth”. This is what many novelists would claim, and Priest is no doubt having a self-mocking joke at his own expense here.

When we eventually see it, Sinclair’s “autobiographical” text appears to be nothing of the sort: it looks like a work of extravagant fantasy (indeed it appears to belong almost to the fantasy genre). Actually, we are never certain that what we are reading is Sinclair’s autobiographical manuscript; in at least one version of what happens, the treasured manuscript which Sinclair carries around with him is nothing more than a sheaf of empty papers. But in the manuscript that we read, Sinclair becomes the winner of a special lottery, run on a place called Collago, an island that is part of a “Dream Archipelago” — a vast island group that, as its name suggests, appears to be at least as much a state of mind as a geographical location. The lottery allows winners to undergo a process called “athanasia”, which will give them a limited kind of immortality — their bodies will be cleansed of any morbidities and will be immune from contracting any future illnesses, but they may still die as a result of accidents. However, the athanasia process involves them losing their memory entirely. Their personalities will be rebuilt on the basis of a detailed questionnaire which they complete before the athanasia operation. However, Sinclair insists that those conducting his rehabilitation use his own autobiographical text instead (which cannot now, evidently, be quite the same text as the one we are reading: it must exist one level “down” from this narrative about the archipelago and the lottery).

In the remainder of The Affirmation, the relationship between the narrative lines set in real world locations and those which take place in the Dream Archipelago becomes increasingly tangled. It appears that Sinclair — or some part of Sinclair — is proliferating fractured narratives in order to deflect from the trauma of his role in the suicide of his lover, Gracia.

An episode from Sinclair’s childhood provides what might be the key to the whole novel. He recalls an incident where, after an accident, he retrospectively lost any memory of the previous three days:

During these three days, I must have been alert, conscious and self-aware, feeling the continuity of memory, sure of my identity and existence. An event that followed them, though, eradicated them, just as one day death would erase all memory. It was my first experience of a kind of death and, since then, although unconsciousness itself was not to be feared, I saw memory as the key to sentience. I existed as long as I remembered.

The irony is that the Sinclair of the Dream Archipelago undergoes the “death” of amnesia in order to achieve immortality. And if Sinclair exists “as long as he remembers”, the problem is that the different versions of Sinclair do not remember: the “this-world” Sinclair because his consciousness has fragmented under pressure from Gracia’s suicide; the Dream Archipelago Sinclair because he has submitted to the athanasia process.

What is eerie here is the agency of the unconscious itself. The Affirmation can be read as an extended reflection on the conundrum of how it is possible to conceal something from ourselves, how a single entity can be simultaneously the one who is hiding something and the one from whom the thing is hidden. This can only happen because the unity and transparency which we ordinarily ascribe to our minds are illusory. Gaps and inconsistencies are constitutive of what we are. What covers over these lacunae are stories — which therefore possess their own agency. Memory is already a story, and when there are gaps in memory, new stories must be confabulated to fill in the holes. But who is the author of these stories? The answer is that there is not so much an author as a confabulatory process without any “one” behind it. This process isn’t a pathological deviation from the norm, but the way in which identity ordinarily functions. However, this functioning is usually obscured, and only comes into view when something goes wrong — when the stories fail, and the question about the machinery that produces them becomes unavoidable.

Priest’s novel The Glamour returns to many of these preoccupations, particularly the problems of amnesia and confabulation. Richard Grey is a cameraman who has lost his memory as a result of being caught in a terrorist bomb blast. He is recovering in a hospital in Devon, when he is visited by a woman, Susan Kewley, who claims to have been his girlfriend. Like The Affirmation, the novel turns on the relationship between gaps and stories, with memory understood as a particular kind of story, susceptible to manipulation and reconstruction. For instance, one of the doctors working on Grey’s rehabilitation refers to the condition of “hysterical paramnesia”, in which patients confabulate a whole “remembered” world on the basis of a few fragments.

The novel offers alternate versions of how Richard and Susan met. In the first version, the one that Richard initially believes, and which he seems to have recovered via hypnosis, the couple met while on holiday in France. Their developing relationship was overshadowed by the presence of Susan’s manipulative lover, Niall, with whom she wants to break off, but who has a sinister hold over her. Yet Susan utterly rejects this account, claiming that she has never been to France, and that their affair — again with Niall always in the background — actually took place in London. There is something intensely eerie about the retrospective downgrading of the episodes in France. To the reader — and presumably to Grey — the events in France have a vividness which makes them “feel” at least as real, if not more real, than the episodes in London narrated by Kewley. (This is something like a reverse of the effect of what happens in The Affirmation: the Dream Archipelago scenes appear at first to be a fantasy or a fiction-within-a-fiction, ontologically inferior to the episodes which happen in the real-world locations, but they attain a vividness which exceeds that of the more “realistic” sections of the novel.) If the French story was not real, we are confronted, as in The Affirmation, with the question of the agent that produced it. At the climax of The Glamour, we seem to receive an answer to this question: in a metafictional twist, Niall claims to be the narrator of the whole novel, and it is Niall who has “fed” Richard his false memories of the France trip. If the overwhelming effect of this revelation is to somewhat dissipate the sense of the eerie that the novel has built up — we now seem to know the precise nature of the agent which has produced all these stories — we are still left with the problem of the scope of Niall’s influence: how much of what we have read is Niall’s contrivance, how much belongs to what Niall still calls Richard’s “real life”, and to what extent can Niall’s fictions be separated from this “real life”? If Richard has a “real life” beyond Niall, this implies that Niall is “only” the narrator, someone who is telling Richard’s story, not his author-creator — despite Niall’s claim that “I have made you, Grey.”

The metafictional struggle between Niall and Richard can be read as part of the novel’s core preoccupation with the question of invisibility. If Niall is the narrator, he is a “level up” from the characters he is narrating, and therefore not fully visible to them (they can interact with Niall the character, but not with Niall the narrator). But the novel is about invisibility in a seemingly more straightforward way. Niall, Susan and to some extent Richard himself apparently have “the glamour”. Glamour, the novel explains, is an old Scottish word, and

i ()n the original sense a glamour was a spell, an enchantment. A young man in love would approach the wisest old woman in his village and pay her for a charm of invisibility to be placed on his beloved, so that she could no longer be coveted by the other young men. Once she had been glammered, or made glamorous, she was free from prying eyes.

The novel is ambivalent about how this disappearance is produced — is it an induced failure to see? Do some people simply escape notice, and forever fall into the background? Or is it some form of sorcery which allows Niall and the others not be seen (but would this ultimately be any different from an induced failure to see in any case)?

Disappearance, alongside amnesia, is a clear case of “nothing where there should be something”. But the two cases are very different. Whereas amnesia generates a gap that is perceived and felt — a gap that demands filling by a story; disappearance is a gap which conceals itself. It is an example of negative hallucination, a concept which is introduced into the novel when, while under hypnotic suggestion, Grey is induced not to see a woman who is in the same room as him. Negative hallucination is a phenomenon that is in many ways more interesting — and more eerie — than “positive” hallucination. Not seeing what is there is both stranger and more commonplace than seeing what is not there. Failure to see, the involuntary process of overlooking material which contradicts — or simply does not fit in with — the dominant stories which we tell ourselves is part of the ongoing “editing process” through which what we experience as identity is produced. In negative hallucination, objects and entities are typically registered but not seen. If, say, someone is induced into not seeing a box lying on the floor, they will nevertheless swerve to avoid the box when they walk across the room, and what is more they will produce a rationale, a little story, explaining why they have done so. It was Freud who introduced the concept of negative hallucination, and, as with confabulation, the phenomenon illuminates the eerie qualities of the unconscious, its negative production. The unconscious, something which is itself a gap, an invisibility, is also the producer of gaps which are not seen.





On Vanishing Land: M.R. James and Eno

As I mentioned in the introduction to this book, my thoughts on the eerie emerged from a collaborative project that I worked on with Justin Barton, On Vanishing Land. The eventual form that project took was a forty-five-minute audio-essay, but its origins came in a walk that we took in Suffolk, in the east of England, going from the coastal town of Felixstowe inland to Woodbridge. We were supposed to be scouting locations for another project, but the landscape demanded to be engaged with on its own terms. The symbolic markers of the beginning and ending of the journey were Felixstowe container port — an “unvisited vastness”, as Justin put it in the script for On Vanishing Land — and Sutton Hoo, the world-famous site of an Anglo-Saxon ship burial.

The port and the burial ground offer two different versions of the eerie. The container port looms over the declining seaside town, the port’s cranes towering above the Victorian resort like H.G. Wells’ Martian Tripods. Approached from the countryside, from Trimley marshes, the cranes preside over the rural scene like gleaming cybernetic dinosaurs erupting out of a Constable landscape. Viewed in this way, the port appears almost as a weird phenomenon, an alien and incommensurable eruption in the “natural” scene. Ultimately, however, it is the feeling of the eerie that is dominant. There’s an eerie sense of silence about the port that has nothing to do with actual noise levels. The port is full of the inorganic clangs and clanks that issue from ships as they are loaded and unloaded; what’s missing, at least for the spectator watching the port from a vantage point outside, are any traces of language and sociability. Watching the container lorries and the ships do their work, or surveying the containers themselves, the metal boxes racked up like a materialised version of the bar charts in Gibson’s cyberspace, their names ringing with a certain transnational, blank, Ballardian poetry — Maersk Sealand, Hanjin, K-line — one seldom has any sense of human presence. The humans remain out of sight, in cabs, in cranes, in offices. I’m reminded instead of the mute alien efficiency of the pod distribution site in Philip Kaufman’s 1978 version of Invasion of the Body Snatchers. The contrast between the container port, in which humans are invisible connectors between automated systems, and the clamour of the old London docks, which the port of Felixstowe effectively replaced, tells us a great deal about the shifts of capital and labour in the last forty years. The port is a sign of the triumph of finance capital; it is part of the heavy material infrastructure that facilitates the illusion of a “dematerialised” capitalism. It is the eerie underside of contemporary capital’s mundane gloss.

Sutton Hoo, meanwhile, is eerie in at least two different senses. Firstly, it constitutes a gap in knowledge. The beliefs and rituals of the Anglo-Saxon society that constructed the artefacts and buried the ship are only partly understood. (The ship itself and the artefacts it contains — including some incredibly intricate jewellery — was long ago moved to the British Museum. Replicas now stand in the Visitor Centre at Sutton Hoo.) Secondly, Sutton Hoo — a burial mound, standing above the town of Woodbridge — is an eerie site in its own right: desolate, atmospheric, solitary.

Another way of marking the beginning and ending of our journey into the eerie is by thinking about two figures: M.R. James and Brian Eno. James set one of his most famous ghost stories, “Oh, Whistle, and I’ll Come to You, My Lad” (1904), in a thinly fictionalised Felixstowe, while Eno’s 1982 album, Ambient 4: On Land, is in part an engagement with Suffolk coastal territory. James approached the Suffolk landscape as a holidaying antiquarian, visiting from Cambridge. Eno, meanwhile, came to the terrain as a returning Suffolk-born native (he was born in Woodbridge), reconstructing in sound the “places, times, climates and moods” of landscapes he had walked through as a child.

“Oh, Whistle, and I’ll Come to You, My Lad” concerns Parkins, a Cambridge scholar who has travelled up to East Anglia for a walking holiday. It is set in Burnstow, a transparent code for Felixstowe. Parkins is a close double of James himself: James was a Cambridge antiquarian who was a frequent visitor to Suffolk. The contrast between the urban world which Parkin has left behind and the empty heathland over which he wanders is also a contrast between enlightenment knowledge and ancient lore, and Parkins’ estrangement consists in large part in his finding the modes of scholarly explanation which work so well in Cambridge libraries suddenly having no purchase on what he encounters in the Suffolk landscape.

In “Oh, Whistle, and I’ll Come to You, My Lad” and “A Warning to the Curious” (1925), James discovers a template that later writers such as H.P. Lovecraft, Alan Garner, Nigel Kneale and David Rudkin will work from. The two stories turn on the unearthing of old objects — a bronze whistle and an ancient crown — which carry ancient threats. But when the BBC adapted these stories, the films became as much about the East Anglian landscape — “bleak and solemn”, as James described it in “A Warning to the Curious” — as they did about the demonic creatures called up by the inorganic artefacts.

Jonathan Miller didn’t use Felixstowe as a location in his 1968 adaptation of “Oh, Whistle, and I’ll Come to You, My Lad”, but the legendary Suffolk town of Dunwich and the tiny village of Waxham in Norfolk. The crucial scene in which Parkin (slightly renamed in the adaptation) comes upon the whistle whilst wandering among the gravestones on a crumbling cliff-side were recognisably filmed in Dunwich — a place, which as James’ namesake Henry noted while on a walking tour of Suffolk, consists now almost entirely of absence. Dunwich, once a thriving sea port, was nearly destroyed at a stroke by a storm in 1328; most of what remained was gradually claimed by the sea, so that today only a few houses and a single church are still standing, themselves threatened by the slowly voracious ocean.

Waxham is also a place governed by absence. With its few cottages and dilapidated church, it feels like the skeleton of a village. But Miller didn’t use any of the village’s few landmarks, concentrating instead on the semi-abstract terrain of the beach. The largely featureless beach at Waxham is an excellent version of the landscape as described by James: “a long stretch of shore-shingle edged by sand, and intersected at short intervals with black groynes running down to the water”, a “bleak stage” on which “no actor was visible”, and defined by “the absence of any landmark”.

In Miller’s version, Parkin, played by a splendid Michael Hordern, is a crumbling logical positivist, his mind eroding as surely as the threatened East Anglian coastline, only far more quickly. Hordern, who was never better, conveys Parkin’s withdrawal, his gestures and expressions suggesting conversational gambits and anecdotes that work far better when rehearsed in the theatre of his mind than they ever would in any inter-personal context. This is a man more at home with books than people. In the manner of A.J. Ayer, Hordern’s Parkin is wont to dismiss the concept of life after death as devoid of meaning. Yet the stridency of his philosophical position is belied by the unsteadiness of his mumbling exposition. At one level, the empty dunes and solitary heathland become an objective correlative for Parkin’s increasingly solipsistic mental state. Yet the beach is also the zone where Parkin encounters the outside, the alien forces that fatally disrupt his interiority.

There is a strong affinity between Miller’s television adaptation of “Oh, Whistle, and I’ll Come to You, My Lad” and Eno’s On Land: both in effect are meditations on the eerie as it manifested in the East Anglian terrain. With its lingering concentration on the landscape, its brooding silences, and its long scenes devoid of much action, it was as if Miller produced something like the television equivalent of the ambient music that Eno would later invent. With On Land, Eno wrote in his sleevenotes for the album, “the landscape has ceased to be a backdrop for something else to happen in front of; instead, everything that happens is a part of the landscape. There is no longer a sharp distinction between foreground and background.” The eeriness of Miller’s film comes from the way it treats the landscape as an agent in its own right. The film captures a seductive slowness proper to the nearly-deserted heaths and beaches, sublime in their sombre desolation. Parkin underestimates the powers of this archaic and arcane terrain at his peril.

For James, who was both a horror writer and a conservative Christian, the fascination for the outside is always fateful, as the title of “A Warning to the Curious” made clear. But On Land is more open to the idea of an outside that need not be threatening or destructive. With its gentle, eddying movements, its bubblings and babblings, its susurrating suggestions of nonorganic sentience, On Land calls up a dreaming landscape teeming with detail. Eno’s biographer David Sheppard wrote that, for all its invocations of Eno’s childhood, the atmosphere of On Land “was less one of sentimental yearning and more one of introverted, sensual intoxication.” Certainly, On Land is sensually intoxicating, but “introverted” seems an odd word for a record that seems so lacking in psychological interiority. There is no doubt a sense of solitude, a withdrawal from the hubbub of banal sociality in On Land but this emerges as a precondition for openness to the outside, where the outside designates, at one level, a radically depastoralised nature, and, at the outer limits, a different, heightened encounter with the Real.

Eno recounts in those same sleevenotes that part of the inspiration for On Land lay in his ambition to produce an “aural counterpart” to Fellini’s Amarcord (1973). The shift into sound opens up the eerie. There is an intrinsically eerie dimension to acousmatic sound — sound that is detached from a visible source — and one of the most unsettling tracks on On Land is “Shadow”, which features a quietly distressing whimper that could be a human voice, an animal sobbing, or an aural hallucination produced by the movement of wind. This suggests the work of some hostile agent, but part of what makes On Land remarkable is the way that it is open to the possibility of an eerie that is not containable by the horror or ghost story genres: an outside that — pulsing beyond the confines of the mundane — is achingly alluring even as it is disconcertingly alien. For James, the outside is always coded as hostile and demonic. When he read his ghost stories to his Cambridge audience at Christmas, the glimpses of exteriority they offered no doubt brought a thrill to his listeners, but they also came with a firm warning: venture outside this cloistered world at your peril. Yet the world that James — a Victorian figure in the twentieth century — sought to defend had in many ways already vanished, or was on the brink of vanishing. The Bath Hotel in Felixstowe — where James habitually stayed, the model for the hotel in “Oh, Whistle, and I’ll Come to You, My Lad” — was burned down by suffragettes in 1914. Ultimately, I want to emphasise the dimensions of the eerie that James foreclosed, but for the moment, let’s consider two writers who follow James into exploring the malign version of the eerie: Nigel Kneale and Alan Garner.





Eerie Thanatos: Nigel Kneale and Alan Garner

Pulp-horror, archaic science fiction and the darker aspects of folklore share a preoccupation with exhumation of or confrontation with ancient super-weapons categorised as Inorganic Demons or xenolithic artifacts. These relics or artifacts are generally depicted in the shape of objects made of inorganic materials (stone, metal, bones, souls, ashes, etc.). Autonomous, sentient and independent of human will, their existence is characterised by their forsaken status, their immemorial slumber and their provocatively exquisite forms. … () Inorganic demons are parasitic by nature, they … () generate their effects out of the human host, whether as an individual, an ethnicity, a society or an entire civilisation.

— REZA NEGARESTANI, Cyclonopedia: Complicity with Anonymous Materials




Reza Negarestani could be describing here the structure that James uses in “Oh, Whistle, and I’ll Come to You, My Lad” and “A Warning to the Curious”: but this pattern is also used by two of James’ successors, Nigel Kneale and Alan Garner. In some of their most important works, Kneale and Garner show disinterred “inorganic demons”/artefacts operating as fatalistic engines, drawing characters into deadly compulsions. Both Kneale and Garner explore the contours of what you might call an eerie Thanatos — a transpersonal (and transtemporal) death drive, in which the “psychological” emerges as the product of forces from the outside.

Quatermass’ Thanatos

The television series Nigel Kneale is most famous for writing are typically described as operating on the interstices between genres (especially horror and science fiction). But I would argue that what is most characteristic of Kneale’s best work is its sense of the eerie. Unlike M.R. James, Kneale does not take the supernatural on its own terms. In fact, Kneale’s standard move — made most obviously in Quatermass and the Pit — is to offer a scientific remotivation of what had previously been taken to be supernatural. What in one register can be apprehended as a “demon” appears in another register as a particular kind of material agent. It’s true, Kneale agrees, that science since the Enlightenment has maintained there is no supplementary spiritual substance, but the material world in which we live is more profoundly alien and strange than we had previously imagined; and rather than insisting upon the pre-eminence of the human subject who is alleged to be the privileged bearer of reason, Kneale shows that an enquiry into the nature of what the world is like is also inevitably an unraveling of what human beings had taken them themselves to be.

At the heart of Kneale’s work is the question of agency and intent. According to some philosophers, it is the capacity for intentionality which definitively separates human beings from the natural world. Intentionality includes intent as we ordinarily understand it, but really refers to the capacity to feel a certain way about things. Rivers may possess agency — they affect changes — but they do not care about what they do; they do not have any sort of attitude towards the world. Kneale’s most famous creation, the scientist Bernard Quatermass, could be said to belong to a trajectory of Radical Enlightenment thinking which is troubled by this distinction. Radical Enlightenment thinkers such as Spinoza, Darwin, and Freud continually pose the question: to what extent can the concept of intentionality be applied to human beings, never mind to the natural world? The question is posed in part because of the thoroughgoing naturalisation that Radical Enlightenment thought has insisted upon: if human beings fully belong to the so-called natural world, then on what grounds can a special case be made for them? The conclusions that Radical Enlightenment thinking draws are the exact opposite of the claims for which so-called new materialists such as Jane Bennett have argued. New materialists such as Bennett accept that the distinction between human beings and the natural world is no longer tenable, but they construe this to mean that many of the features previously ascribed only to human beings are actually distributed throughout nature. Radical Enlightenment goes in the opposite direction, by questioning whether there is any such thing as intentionality at all; and if there is, could human beings be said to possess it? The answer is complex: there may be something like intentionality at work in human beings, but it does not correspond with what human beings, in their casual phenomenal self-reflections, think of as their personality, conscious intentions or feelings.

Here is where Kneale comes in. Quatermass discovers the mechanical-automatic-alien basis of what has been taken to be human. What emerges as the eventual object of Quatermass’ research is what Freud, in “Beyond The Pleasure Principle” (1920), calls Thanatos. By striking contrast with the new materialist idea of “vibrant matter”, which suggests that all matter is to some extent alive, the conjecture implied by Freud’s positing of Thanatos is that nothing is alive: life is a region of death. Freud’s later invocation of a dualistic struggle between Thanatos and Eros can be read as a retreat from the forbidding monism of “Beyond The Pleasure Principle”, which argues that all life is merely a route to death. What is called organic life is actually a kind of folding of the inorganic.

But the inorganic is not the passive, inert counterpart to an allegedly self-propelling life; on the contrary, it possesses its own agency. There is a death drive, which in its most radical formulation is not a drive towards death, but a drive of death. The inorganic is the impersonal pilot of everything, including that which seems to be personal and organic. Seen from the perspective of Thanatos, we ourselves become an exemplary case of the eerie: there is an agency at work in us (the unconscious, the death drive), but it is not where or what we expected it to be.

But this is not the whole story. The point here is not that we are the blind slaves of the death drive, but, if we are not, it is because of an equally impersonal process: science, which consists in part of discovering and analysing the very processes that Freud calls Thanatos. The figure of the Radical Enlightenment scientist, then, is someone who understands the Thanatoidal nature of their own impulses, but who — precisely because they understand this — offers some possibility of escape from them. I will now explore this by considering two of Kneale’s celebrated works — Quatermass and the Pit (195859) and The Stone Tape (1972), and one of his lesser regarded series — the final installment of the Quatermass series, Quatermass, from 1979.

Quatermass and the Pit is about an excavation in the fictional London tube station of Hobbs End. Workers uncover what turns out to be a Martian spaceship filled with the corpses of repulsive quasi-insect beings. Aliens, we think. Yet the genius of Kneale’s script is that the Martians turn out not to be aliens — in the sense of being “different from us” — at all. Fleeing the destruction of their own planet, the Martians had, five million years previously, interbred with proto-human hominids in order to perpetuate their species.

So the distinction between alien and human is fatally unsettled. As the Quatermass sequence progresses, the alien has become increasingly intimate: In the first installment, The Quatermass Experiment — the aliens are out in space; in the second, Quatermass II (a kind of British equivalent of Invasion of the Body Snatchers) — the aliens are already amongst us; and in the third, Quatermass and the Pit — we are the aliens.

When, at the end of the film, Quatermass makes a stand against the Martians and earnestly hopes that Earth does not become “the Martians’ second dead planet”, this could look like a retreat from the film’s pitiless message — that we ourselves are Martian. Yet even if Kneale has already deconstructed the opposition between Eros and Thanatos, human and Martian — unravel the human, and you discover that it is only a fold within the body of an organic Thanatos — he is still entitled to place hope in the science that has discovered this.

A darker version of the origin of humanity story told in Kubrick’s 2001: A Space Odyssey (to which we will return in a later chapter), Quatermass and the Pit also shares much with J.G. Ballard’s The Drowned World (1962): most importantly the theme of what Greil Marcus in Lipstick Traces calls “phylogenetic memory”. In Quatermass and the Pit, the memory is a “literal” memory, a deeply submerged but still accessible mental trace (triggered, in the film, by the unearthing of the spaceship); in The Drowned World, the “memories” are encoded in the physical form of the human being itself, Ballard’s “spinal landscapes”. Quatermass and the Pit is archaeological; The Drowned World is geological. But in both human nervous systems and memory are conceived of as inorganic recordings — relics of traumatic events that humans must either decode or repeat.

Kneale foregrounded this theme of recording in The Stone Tape. Here, a group of scientists take up residence in a new research facility. It quickly becomes apparent that the building is haunted: one of their number, a female computer programmer, is particularly “sensitive” to the ghost (a servant girl from the nineteenth century who died in a mysterious fall). Inevitably, the scientists go from sceptical dismissal to a manic need to explain and map the phenomenon without much of a pause for breath.

Kneale’s thesis is that hauntings and ghosts are particularly intense phenomena that are literally recorded by matter, by the stone of the room. (Hence the “stone tape” of the title.) What the scientists had been looking for, apparently coincidentally, was a new, more compact and durable recording medium. But what the haunting phenomenon offers is the possibility not only of a new recording medium, but of a new player: the human nervous system itself. In their moment of exultant bliss (before the inevitably bleak denouement), the scientists laugh and joke about the prospect of a totally wireless communication system: transmissions beamed directly into your head (like William Gibson’s cyberspace, but without even the ‘trodes).

But the scientists’ obsessive activity ends up wiping the tape — or at least wiping away the thing last recorded onto it. Something else, something more ancient, stirs beneath, terrifying the female computer programmer into literally falling into the footsteps of the nineteenth-century girl, plunging to her death in a state of total terror. So what Kneale implies in the end is the breakdown of the distinction between the player and what is being played. To begin with, it seems that the ghostly screams are passive and inert, as incapable of exerting agency as the dry rot that afflicts the haunted room; yet in the end, it is the human beings who are revealed to be caught in a terrible compulsion to repeat. It is as if the room — the site, it is eventually implied, of some unimaginably ancient place of sacrifice — solicits the scientists into precipitating yet another death, into playing out the same old sequence once again. The human players are themselves part of an aeons-old pattern of senseless repetition. Eerie Thanatos, again…

Thanatos looms large in the final, under-rated, Quatermass serial. Kneale saw this as a requiem for the Sixties: a dark parable about the thanatropic drives which youth messianism could nurture. In place of the hippie dream of a renewed Earth, his trance-intoxicated post-punk proto-crusties — the Planet People — long for an escape into another world, another solar system. Quatermass’ landscape was projected directly out of the anxieties of the 1970s: the choking ecosphere, the fuel shortages, the power-cuts, the disintegration of the social contract into a Hobbesian war of all-against-all — it was Sixties utopianism in ruins.

Those barricaded streets, the roving armed street gangs (inspired by Baader Meinhof and the Red and Angry Brigades) could equally well have walked off a Killing Joke record cover or from a Conservative party election broadcast. Such was the way in which imaginaries and impulses — reactionary, neoarchaic, revolutionary — became collapsed into one another (collapsed like the abandoned vehicles from which the geriatric colony in the serial construct their bolthole rhizome) in 1979.

If you want to think of analogues for the 1979 Quatermass, look to some of the major post-punk records of that year — Tubeway Army’s Replicas, Joy Division’s Unknown Pleasures — rather than to the cinematic blockbusters (Star Wars and Close Encounters of the Third Kind (both 1977)) to which it was inevitably, and unfavourably, compared at the time. That said, the early, obsessive scenes of Close Encounters of the Third Kind could almost be Knealeian — but all of that is dissipated at the end by the Jarre-like lightshow and the appearance ofthe rather cute aliens. What disappears is nothing less than the eerie itself, as the early automatism of the main characters, and many of the questions about the aliens (indeed, the question of whether there are aliens at all) gives way to what has since become standard in blockbuster science fiction: the compulsory spectacle of conspicuously expensive FX.

What Close Encounters of the Third Kind has in common with Quatermass is its vision of human populations entranced into unconscious complicity with the alien powers. But Quatermass is consummately able to resist the temptation to which Spielberg must succumb — that of anthropomorphizing the aliens. The purposes of the aliens in Quatermass remain unfathomably opaque, like their physical forms. Anything we “learn” about them is conjecture, inference, speculation. They are, in every sense, lightyears away from us.

Kneale’s great themes — the intimacy of the alien; the lust for annihilation in organic beings — this time emerge in an analysis of youth millenarianism. His rendition of youth culture is, predictably, more to do with Jeff Nuttall’s Bomb Culture (1968) than it is Age-of-Aquarius utopian. The urge to herd together into crowds is interpreted symptomatically as the following of a programme seeded deep into the unconscious of the young.

Kneale’s usual cybergothic methodology — disinterring the present in the relics of the Deep Past — this time focuses on Neolithic stone circles. Quatermass hypothesises that the megalithic sites are trauma records, the stones arranged as commemorations of mass exterminations: the Earth’s scar tissue. (The parallel between astro-apocalyptic events and stone circles had actually been made three years earlier, in ITV’s memorably eerie children’s programme from 1976, Children of the Stones.)

The stone circles were the sites of what Quatermass ominously refers to as previous “harvestings” of the human race. Who can say what the species reaping humanity is like and what their motivations are? A lust for protein? Energy vampirism? Quatermass can only guess. Here, Kneale draws upon the eerie affect which stone circles typically produce. As I noted above, stone circles confront us with a symbolic structure that has entirely rotted away, so that the deep past of humanity is revealed to be in effect an illegible alien civilisation, its rituals and modes of subjectivity unknown to us.

Kneale was disappointed with the casting of John Mills, which was forced on him by the Euston production company that insisted on a big-name star; he preferred André Morell and Andrew Keir (who had played the scientist in, respectively, the TV and the film versions of Quatermass and the Pit). He supposedly found Mills insufficiently heroic, scarcely recognisable as the same figure Morell and Keir had portrayed.

Yet Mills’ quiet anger, his compassion and disgust for humanity, his slighted but enduring dignity, make him what could be the definitive Quatermass. Mills brings a terrible authority to the cosmic Spinozism of the show’s ethical payoff. When the young astronomer Joe Kapp — just thawing from the shock of losing his entire family — talks of “evil”, Quatermass corrects him: “Maybe evil is always someone else’s good. Perhaps it’s a cosmic law.”

The Mythic Time of Red Shift

It is said that Alan Garner’s extraordinary novel Red Shift (1973) was triggered by the author seeing a piece of graffiti at a railway station which read “not really now not any more”. There is something so eerie, so cryptic, so suggestive about that phrase, especially when written as an anonymous graffito. What did the nameless author of this vagabond poetry mean by it, and what did it mean to them? What event — was it a personal crisis, a cultural event, a mystical revelation of some kind? — prompted them to write it? And did anyone else but Garner ever witness the phrase graffitied onto the railway station wall? Or was it only Garner who saw it? Not that I am suggesting he imagined it — but the phrase so perfectly captures the temporal vortices in Garner’s work that it seems as if it could have been a special message meant only for him. Perhaps it was, whatever the “intentions” of the graffiti writer happened to be.

If the most famous anonymous source in the world is to be believed, the words “not really now not any more” were scrawled in lipstick, beneath two lovers’ names that had been chalked onto the wall. In which case, the explanation for the phrase seems — on the face of it — to be somewhat prosaic. Someone — one of the two lovers, or one of their friends, enemies or rivals, or a stranger — was making a comment — sarcastic, melancholic, angry? — about the status of the lovers’ relationship. A phrase that is not quite banal, but which is certainly transparent, conversational — “not really now not any more” — acquires a poetic opacity by virtue of the omission of a comma. Yet, even that apparently deflationary explanation cannot conjure away the eeriness of the phrase: “not really now not any more”. To say there was something fated about Garner’s encounter with this graffiti is to redouble the phrase’s intrinsic, indelible eeriness. For what does the phrase point to if not a fatal temporality? No now, not any more, not really. Does this mean that the present has eroded, disappeared — no now any more? Are we in the time of the always-already, where the future has been written; in which case it is not the future, not really?

But we are getting ahead of ourselves. What, exactly, happens in Red Shift? The “novel” — a label which scarcely seems adequate for a text whose cryptic density makes it resemble a prose poem — juxtaposes three time periods: Roman Britain, the English Civil War and the then-present day.

The contemporary episode centres on the tormented, asphyxiatingly intense relationship between Tom and Jan. Their entanglement has a blocked, frustrated quality seemingly from the start. External obstacles — the hostility of Tom’s parents to the relationship; the physical distance between the couple, now that Jan has moved to London — are doubled by internal obstacles, most powerfully and distressingly those generated by Tom’s obsessive jealousy and possessiveness, which becomes malevolent — even deadly — after he discovers that Jan had an affair with an older man. It is Tom’s very desire to possess Jan, to claim ownership over her very being, which ultimately drives Jan away. This quickly becomes more self-destructive to Tom than it is destructive of Jan, as Jan increasingly asserts her autonomy and ultimately ends the relationship.

The Civil War episode involves a young epileptic, Thomas Rowley, and his wife Margery, who live in the Cheshire village of Barthomley. He and the other villagers are barricaded up in the church behind defences they have improvised to repel Royalist troops, when Rowley has a fit and accidentally fires a musket, causing the Royalists to brutally attack. The women are raped, and all the men bar Rowley are killed. But Rowley and his wife are helped to safety by one of the most savage of the Royalist soldiers, Thomas Venables, who is also Margery’s former lover.

The Roman occupation episode focuses on Macey, one of a number of Roman soldiers from the destroyed Ninth Legion. The childlike Macey befriends a Celtic priestess that the soldiers have raped and captured. Ultimately, the priestess kills the soldiers by poisoning their bread, and escapes with Macey.

The relationship amongst these periods is enigmatic, if not outright unintelligible. What all three episodes have in common — besides certain differently repeating traumatic elements — is an inorganic object: a Neolithic votive axe, which assumes symbolic significance for all three of the couples. This axe serves many functions — it seems to mark, at one and the same “time”, continuity and simultaneity, as well as operating as a kind of trigger (causing, for instance, Rowley and Macey to fit).

What Red Shift discloses is not, evidently, a linear temporality, in which the different historical episodes simply succeed one another. Nor does it present the episodes in a relation of sheer juxtaposition — in which no causal connection at all is asserted amongst the different episodes, and they are offered to us as merely sharing some similarities. Nor do we have the idea — familiar from science fiction or fantasy conventions — of a causality operating “backwards” and “forwards” through time, so that past, present and future have influence upon one another. This latter possibility is the closest to what Red Shift seems to be doing, but the novel’s scrambling of time is so complete that we are not left with any secure sense of “past”, “present” and “future” at all: not really now any more. Is there, then, no now because the past has consumed the present, reduced it to a series of compulsive repetitions, and what seemed to be new, what seemed to be now, is only the playing out of some out-of-time pattern? This formulation, perhaps, is closest to the cold fatality that seems to (un)ravel in Red Shift: Yet if different historical moments are in some sense synchronous, would this not mean, not that there was no now, but that it is all now?

A whole other level of eerie repetition comes into focus when we consider Red Shift in its relationship both to Garner’s other novels and to the work of other writers. The novel is a kind of repetition-without-origin. It can be read as an extension and intensification of the model established by Garner’s own earlier novels, Elidor (1965) and The Owl Service (1967). In his 1975 lecture “Inner Time”, Garner explained that his novels could all be seen as an “expression” of a particular myth, so that his Elidor was an “expression” of the ballad of “Childe Rowland and Burd Ellen”, while The Owl Service was an “expression” of the myth of Lleu, Blodeuedd and Gronw, from the Welsh myth-system the Mabinogion. For Red Shift, the source material was the ballad of Tam Lin. With each successive novel, the relationship between Garner’s fiction and the myth which is “expressed” becomes more oblique, to the degree that, by the time of Red Shift, as Charles Butler notes in an important essay on the novel, “Alan Garner’s Red Shift and the Shifting Ballad of ‘Tam Lin’”, many were wont to dismiss the connection with the Tam Lin myth as fanciful or strained. Butler summarises the Tam Lin myth — or perhaps it would be better referred to as a series or complex of myths — as follows:

The ballad of ‘Tam Lin’ exists in numerous versions. There are nine in Child’s English and Scottish Popular Ballads alone, and that is certainly not an exhaustive collection. Many of the differences between versions are quite significant, as we shall see, but the narrative can be broadly summarised thus: a young woman called Janet (in some versions Margaret) goes to Carterhaugh (or Kertonha, Chaster’s Wood, Chester Wood, etc.) against the injunction of her parents, who fear she will lose her virginity to Tam Lin, a fairy youth who haunts the place. There she plucks a flower and thus summons Tam Lin himself. He challenges her presence, but she replies defiantly that Carterhaugh is her own property and that she has as much right as he to be there. On her return home, it becomes apparent that she is pregnant. Her family (variously her mother, sister, brother, or a family retainer) is shocked. She asserts that Tam Lin is the child’s father and returns to Carterhaugh, either to find Tam Lin or else (in some versions) to find a herb to cause an abortion. Tam Lin appears and explains that he is not a fairy at all but a young man of human blood who was stolen away by the Fairy Queen when he was a boy. Although his life with the fairies is pleasant, every seven years on Halloween the fairies must pay a ‘tithe to hell’, and this year he is likely to be the victim. If Janet wishes to save him (and therefore give her baby a father), she must execute a complex procedure that involves pulling Tam Lin from his horse as he rides past with the fairy troop, holding fast to him while he undergoes a series of frightening transformations, and finally covering his naked body with her green mantle. She achieves all this and thus wins Tam Lin from the Fairy Queen, who is bitter at her loss.



Butler convincingly argues that, despite the lack of many explicit references to Tam Lin, there are many intricate echoes of the myth(s) in Red Shift. The most obvious — and most superficial — mirroring is in the names of some of the characters — Tom/Thomas and Jan/Margery as variations on Tam and Janet/Margaret — but the deeper resonances are at the level of themes: the idea of possession (which instead of taking a supernatural form manifests itself in epileptic seizures, traumatic voidings of personal identity that are — for that very reason — also ecstasies); and the notion of “holding on” (Margery and the priestess saving Thomas/Macey). More broadly, Tom and Jan are pitched out of linear time into a mythic time; or, rather, the illusion of linearity is shattered by the eerie repetitions and simultaneities of a mythic time. This is essentially what happens to the three central characters in The Owl Service, who become engaged in a kind of deadly erotic struggle, as they assume the roles of the mythic figures Lleu, Blodeuedd and Gronw. It is as if the combination of adolescent erotic energy with an inorganic artefact (in this case a tea set decorated with an owl motifs) produces a trigger for a repeating of the ancient legend. It is not clear that “repeating” is the right word here, though. It might be better to say that the myth has been re-instantiated, with the myth being understood as a kind of structure that can be implemented whenever the conditions are right. But the myth doesn’t repeat so much as it abducts individuals out of linear time and into its “own” time, in which each iteration of the myth is in some sense always the first time. Here the myth would be something like the fatal compulsive pattern into which the scientists in The Stone Tape fall.

With Red Shift, Garner in effect transforms what he had narrated in The Owl Service into something that is performed. The reader is abducted into mythic time, as Garner’s use of compression and ellipsis puts linear time and narration under so much stress that they all but disappear. The impression we form is that it is not that linear time perception or experience has been corrupted by trauma; it is that time “itself” has been traumatised — so that we come to comprehend “history” not as a random sequence of events, but as a series of traumatic clusters. This broken time, this sense of history as a malign repetition, is “experienced” by the three major male characters (Tom/Thomas/Macey) as seizure and breakdown; I have placed “experienced” in inverted commas here because the kind of voiding interruption of subjectivity that the three characters undergo seems to obliterate the very conditions that allows experience to happen. For this reason, I think Butler moves too quickly when he argues that the “three men become, in effect, a single supra-historical personality, all of whose experiences are contemporaneous”. You could equally well argue the reverse — that rather than the three men in some sense becoming the “same” individual, what they all lack is any coherent or unitary sense of selfhood. Equally, you could say that rather than sharing the “same” moment, Macey, Tom and Thomas subsist in a broken time — a time from which sameness, unity and presence have been subtracted.

Like Kneale, then, Garner’s work endlessly worries away at the question of agency and intent. Free will is missing, or at least radically compromised. Human freedom is very different to “free will”, and can only be asserted if it reckons with agencies that belong primarily instead to (unconscious, mythic) structures that draw power from the people that they abduct into themselves. Landscape — the landscapes of Cheshire in many of his novels, including Red Shift, and the landscape of north Wales in The Owl Service — are a crucial element of these mythic structures. Repeatedly throughout his fiction, Garner points to the eerie power of landscape, reminding us of the ways in which physical spaces condition perception, and of the ways in which particular terrains are stained by traumatic events. The mythic, as Garner understands it, is something more than the merely fictional, just as it cannot be reduced to the fantasmatic. Rather, the mythic is part of the virtual infrastructure which makes human life as such possible. It is not the case that first of all there are human beings, and the mythic arrives afterwards, as a kind of cultural carapace added to a biological core. Humans are from the start — or from before the start, before the birth of the individual — enmeshed in mythic structures. Needless to say, the family itself is just such a mythic structure. Louis Althusser, emphasizing the way in which the human being is never merely a biological creature, refers to the virtual cultural infrastructure as ideology, and argues that it is not possible to live outside it. We could just as easily shift to the register Justin Barton uses, however, and talk of dreamings and stories. Garner’s fictions exceed the limitations of both naïve realism and fantasy by virtue of their complex reflections on the power — the eerie power — of dreamings and stories.





Inside Out: Outside In: Margaret Atwood and Jonathan Glazer

Woman sawn apart in a wooden crate, wearing a bathing suit, smiling, a trick done with mirrors, I read it in a comic book: only with me there had been an accident and I came apart. The other half, the one locked away, was the only one that could live; I was the wrong half, detached, terminal. I was nothing but a head, or no, something minor like a thumb; numb.

Pleasure and pain are side by side they said but most of the brain is neutral: nerveless, like fat. I rehearsed emotions, naming them: joy, peace, guilt, release, love and hate, react, relate; what to feel was like what to wear, you watched the others and memorised it. But the only thing there was the fear I wasn’t alive: a negative, the difference between the shadow of a pin and what it’s like when you stick it in your arm, in school caged in the desk I used to do that, with pen-nibs and compass points too, instruments of knowledge, English and Geometry; they’ve discovered rats prefer any sensation to none. The insides of my arms were stippled with tiny wounds, like an addict’s. They slipped the needle into the arm and I was falling down, it was like sinking from one level of darkness to a deeper, deepest; when I rose up through the anesthetic, pale green and then daylight, I could remember nothing.

I didn’t feel awful; I realised I didn’t feel much of anything. I hadn’t for a long time. Perhaps I’d been like that all my life, just as some babies are born deaf or without a sense of touch; but if that was true I wouldn’t have noticed the absence. At some point my neck must have closed over, pond freezing or a wound, shutting me into a head ...

— Surfacing, Margaret Atwood



Margaret Atwood’s 1972 novel Surfacing and Jonathan Glazer’s 2013 film Under the Skin offer complementary cases of the eerie. In Surfacing, we move from a position ambiguously “inside” to one outside; in Under the Skin the inside is apprehended from outside. The two lead characters’ problematic relationship to what Lacan called the Symbolic order (the structure through which cultural meaning is assigned, and which, Lacan said, is secured by the name of the father) is underscored by the fact that neither is named. The narrator of Surfacing comes to feel as if she is an alien who has been play-acting the role of a woman; the lead character in Under the Skin is an actual alien, who seeks to simulate human behaviour.

Surfacing turns on the enigma of a missing father. The narrator has returned to her childhood home in Quebec to look for her father, who has disappeared in the Canadian wilderness. The question what happened? hangs over the novel, and the ultimate lack of resolution to the mystery — not only is the father never found, but the narrator herself becomes lost, unmoored, operating without co-ordinates — means that the eerie atmosphere is never dissipated. As with Garner, in Surfacing there is a tremendous sensitivity to the power of terrain — not now the British countryside, with its vastly overdetermined history of civil war, atrocity and struggle, but the depopulated space of the Canadian bush, with its promises and threats, its openness and its terrifying emptiness. It is not the spectres of history which haunt Surfacing, but the spaces outside or at the edges of the human itself. It seems, so far as we can make out, that the father has fallen prey to a fatal fascination with the wilderness, its animals and associated lore. When the narrator enters his cabin, she finds that her father has filled his papers with images of strange human-animal creatures: signs of madness, or preparations for a shamanic passage out of what passes for modern civilisation? As the anti-psychiatric rhetoric of the time might have had it, is there actually a difference between these two possibilities? Does not any real rejection of civilisation not entail a move into schizophrenia — a shift into an outside that cannot be commensurated with dominant forms of subjectivity, thinking, sensation?

In some respects, Surfacing could be seen as registering the bitter awakening after the militant euphoria of the Sixties; Atwood’s famously cold prose freezing over the Sixties’ heated loins, and drawing, from the semi-desolation of the Canadian bush, a new landscape as alluring and forbidding as any in literature. A conservative reading suggests itself — what surfaces here, it might seem, are the consequences that Sixties permissiveness imagined it had dispensed with. The repressed — which in this sense would mean the agencies of repression themselves — returns in the spectral form of the unnamed narrator’s aborted child, encountered in a dark lake space where excrement and jellyfish-like foetal scrapings float, the abjected and the aborted commingling in a sewer of the Symbolic. Far from enabling her to “regain” some “wholeness”, the reintegration of this lost object destroys the fragile collage of screen memories and fantasies the narrator’s unconscious has artfully constructed, projecting her from the frozen poise of dysphoria into psychosis — which, in the conservative reading, would constitute a proper punishment for her licentiousness.

There’s a great deal at stake in resisting this conservative reading, and the concept of the eerie can help us in this task. Atwood’s narrator increasingly finds that there is no place for her. She lacks the capacity to feel that is supposedly constitutive of “ordinary” subjectivity. She is outside herself; a mystery to herself, a kind of reflexive gap in the dominant structure: an eerie enigma. The point is not then to too-quickly resolve this enigma, but to keep faith with the questions that it poses.

The narrator experiences the counterculture as little more than a sham, its libertarian rhetoric not only serving as a legitimation of familiar male privilege but offering new rationales for exploitation and subjugation. By 1972, the counterculture’s dreams of overthrowing and replacing dominant structures have devolved into a series of empty gestures, a congealed rhetoric. If Surfacing rejects the facile gestures of an exhausted counterculture, there is no question of its endorsing the (apparently) safe and settled world which the counterculture repudiated. That world of supposedly organic solidity — her parents’ world, where people have children who grow like flowers in their back garden, the narrator imagines — is gone, Atwood’s narrator notes, with an edge of wistfulness that nevertheless stops somewhat short of nostalgic longing. The question that Surfacing poses, and leaves hanging, is how to mobilise her discontent rather than treat it as a pathology that requires a cure — either by successful reintegration into the Symbolic/civilisation or by some purifying journey out beyond the Symbolic into a pre-linguistic Nature. How, in other words, is it possible to keep faith with, rather than remedy, the narrator’s affective dyslexia?

In some respects, Surfacing belongs to the same moment as such texts as Luce Irigaray’s Speculum: Of the Other Woman, and Gilles Deleuze and Felix Guattari’s Anti-Oedipus. These works attempt to rise to the challenge of treating discontent, abjection and psychopathology as traces of an as yet unimaginable outside rather than as symptoms of maladjustment. At her moment of schizophrenic break-rapture, the narrator’s vision resembles the “nonorganic life” and “becoming-animal” Deleuze and Guattari will describe in A Thousand Plateaus: “they think I should be filled with death, I should be in mourning. But nothing has died, everything is alive, everything is waiting to become alive.” Yet this febrile delirium is more in tune with what Ben Woodard has termed “dark vitalism” than with Deleuze, and what flows and stalks in the body-without-organs zone of animal- and water-becomings is something like Woodard’s sinister “creep of life”: “I hear breathing, withheld, observant, not in the house but all around it.” The place beyond the mortifications of the Symbolic is not only the space of an obscene, non-linguistic “life”, but also where everything deadened and dead goes, once it has been expelled from civilisation. “This is where I threw the dead things...” Beyond the living death of the Symbolic is the kingdom of the dead: “It was below me, drifting towards me from the furthest level where there was no life, a dark oval trailing limbs. It was blurred but it had eyes, they were open, it was something I knew about, a dead thing, it was dead.”

Surfacing can be situated as part of another fin-de-Sixties/ early-Seventies moment: the post-psychedelic oceanic. Atwood’s lake, viscous with blood and other bodily fluids, has something in common with the “bitches brew” that Miles Davis plunges into in 1969, emerging, catatonic, only six years later; it approaches the deep sea terrains John Martyn sounds out on Solid Air and One World:

Pale green, then darkness, layer after layer, deeper than before, seabottom: the water seemed to have thickened, in it pinprick lights flicked and darted, red and blue, yellow and white, and I saw that they were fish, the chasm-dwellers, fins lined with phosphorescent sparks, teeth neon. It was wonderful that I was down so far...

But these spaces of dissolved identity are not approached from the angle of a now tortured, now lulled male on a vacation from the Symbolic, but from the perspective of someone who was never fully integrated into the Symbolic in the first place.

Surfacing, like Atwood’s later Oryx and Crake, is a kind of rewriting of Freud’s Civilisation and its Discontents — the text with which all that early Seventies radical theory had to wrestle, and reckon. Just as at the end of Oryx and Crake, Surfacing concludes with a moment of suspension, with the narrator, like Oryx’s Snowman, poised between the schizophrenic space beyond the Symbolic and some return to civilisation. Perhaps what is most prescient about Surfacing is its acceptance that civilisation/the big Other/language cannot in the end be overcome by means of libido, madness or mysticism alone — yet, despite all this, Surfacing does not recommend an acquiescence in the reality principle. “For us, it’s necessary, the intercession of words”, the narrator concedes — but who is this “us”? It seems at first to encompass only the narrator and the lover with which she may be about to be reconciled. Then we might be tempted to read the “us” as humanity in general, and the novel would be ending with a fairly cheap reconciliation between civilisation and one who was discontented with it. Yet it’s more interesting to think of the “us” as indicating those, like the narrator, who do not properly belong to humanity at all — what kind of language, what kind of civilisation, would these discontents make?


Under the Skin probes some of the same areas, but from a different direction. The film could be a case study in how to produce the eerie out of unpromising resources. Its source material, the novel by Michael Faber, is effective enough, but it doesn’t possess much of an eerie charge. Or, rather, the way the narrative develops progressively eliminates any trace of the eerie until it disappears entirely. The novel soon becomes recognisable as a literary-science fictional satire on meat-eating and the meat industry, with the inconsistencies in human carnivore ethics exposed and mocked when human beings become the prey of alien meat-traders. It is a fable complete with talking animals (although of course the point of the satirical-fabular reversal is that, from the alien perspective, it is the humans who are “talking animals”, who must have their tongues removed when they are forced into captivity).

The film is a very different beast. Effectively, it is extrapolated from the early part of the novel — alone in a car, driving along the A-roads of Scotland, a young woman, or what appears to be a young woman, stalks men. In the novel, we soon learn that the “young woman” is Isserley, a surgically-altered extraterrestrial in the employ of an interplanetary luxury meat business. The men she lures into her car and sedates have been targeted because they look like prime cuts.

The film denies us any of this information (in fact, it’s far from clear that the film retains any of these narrative commitments; we never learn if the lead character is called Isserley, or if she works for a meat corporation). Crudely, we could say that the quickest way to produce a sense of the eerie is to restrict information in this way. But, as I argued above, not any mystery whatsoever will be eerie; there must be a sense of alterity, and this sense of alterity is something that Glazer adds to Faber’s source material. There is a curious quality to these additions, of course, because what is added, effectively, are gaps in the viewer’s knowledge. The tendency in Faber’s novel is to eliminate the alienness of the extraterrestrials, to make an equivalence between them and us — under the skin, we are the same (something reinforced by Faber’s having the aliens calling themselves “humans”). By contrast, the film not only emphasises the differences between the aliens and homo sapiens, it also denudes human culture of its casual familiarity, showing the taken-for-granted from an undetermined yet exterior perspective.

In terms of its generation of a sense of the eerie, the film is at an advantage over the novel because it is not required to give the lead character (played by Scarlett Johansson) any interior life. This means that it is not only the nature of her interior life that is left open: so is the very question of whether she has anything like “interior life” in any recognisable sense. The Johansson character is seen only from the outside (just as, reciprocally, her illegible behaviour and motives, her lack of “ordinary” emotional responses, give us an outsider perspective on the social world through which she moves as a predator). Her dialogue is bare, functional — perhaps limited by her competence with language and accent (as the film begins, we hear her learn to pronounce a series of words in an English accent). In any case, she speaks only enough to draw men into her vehicle — and this, in a passing mordant commentary on a certain kind of male sexuality, does not usually entail much talking. She is never required to give any but the most minimal account of herself, and almost everything she says is in any case a deception. She never gives voice to any feelings. When she liaises with another alien, they do not speak. Do they have their own language — or is language something that they merely acquire in order to trick humans? Do they have feelings in the same sense that we think we do? The film tells us practically nothing about what these creatures are, or what they want — or indeed, if what drives them can be construed as “desire” at all.

Perhaps Glazer’s most significant additions are the scenes in which the human prey is captured. In the novel, the capture is a simple matter of the men being drugged in their seats. The capture in the film takes place in some undetermined interzone, a semi-abstract space, in which the men, as they approach the half-clothed Johansson character, find themselves slowly sucked into cloying black ooze. Are these scenes — glacially oneiric, darkly psychedelic — a representation of the intoxicated men’s state of mind as they slip into some state of half-death? Or is this an actual interspace, with the black ooze an example of alien technology? Or could it be, as one commentator has suggested, that this is what sex feels like to the alien? The film provides us with no answers, and further scenes only add to the nightmare opacity. We see some of the captured men, now entirely submerged in the ooze, barely conscious and bloated (perhaps in a reference to the fattening of the human prey that happens in the novel). As they pathetically reach out for each other, one of the bodies is subjected to a horrible sucking and sluicing action. There is a cut to an image of what looks like rushing blood, as if the body has been liquidised. It could be that this is a semi-abstract image of the meat processing described in the novel; or it could be suggestive of some other (barely imaginable) mode of energy transfer.

These fragments — so many eerie ellipses — make the extraterrestrials, if that is what they are, as alien as anything we have seen in cinema. But the scenes of the Johansson character in her van, picking up men on lonely side-roads and in crowded clubs, or sizing up potential victims on crowded streets in Glasgow, generate something like a reverse eerie effect. Here, contemporary capitalist culture is estranged, seen through an outsider’s eye. The Johansson character’s tonal flatness makes her look from the outside as the narrator of Surfacing describes her own inner state — numb, detached. Yet this seeming numbness may of course be a whole different affective comportment; or it could suggest a type of being that has no capacity for what we understand as emotions. It could be, after all, that these kinds of creatures have more in common with insects than with human beings.

There is a kind of affinity between Johansson’s flatness and the naturalistic style in which much of the film is shot. She is the figure through whom the film is focalised — the audience’s point of identification — but since there is precious little with which we can identify, she functions as a kind of analogue of the camera itself. In the improvised scenes with passersby and non-actors in particular, we are invited to experience human behaviours, interactions and culture without the associations that we habitually bring to them, and without the forms of mediations that usually intercede in mainstream cinema. Since the scenes are stripped of much of their standard generic, narrative and emotional furniture, the naturalism becomes denaturalizing, as the camera effectively simulates the gaze of an alien anthropologist.

As the film goes on, the Johansson character shifts from being a predator into becoming an increasingly vulnerable figure. Not accidentally, this coincides with her becoming more immersed in human culture, as she engages in what might be an attempt to understand human affection and relationships. There is a disturbing sex scene, in which she passively and seemingly uncomprehendingly submits to her male partner, and afterwards examines herself with a flashlight, as if she has been badly wounded. Human sex becomes estranged, the object of panicked alien attention. The unnerving qualities of this scene are retrospectively intensified when, in another contrast with the novel, we learn that the alien’s human body is a kind of prosthesis. We discover this only in the distressing climactic scene, when a passerby attempts to rape her. As he attacks her, part of the prosthetic body comes away, leaving a gaping hole in her back, like a rip in a dress. The alien then casts aside the destroyed human prosthesis, and another figure — a smooth black humanoid form, lacking many defining features — emerges from inside the wreckage. We see the exposed alien body now studying the Scarlett Johansson face as if it is a latex mask — an echo of an earlier remarkable scene in which Johansson examines her own naked body in a mirror in a strangely dispassionate but appreciative way. It is now clear that the mirror scene redoubles the “ordinary” self-objectification that happens when we look in the mirror: the alien is not looking at herself, but at the human body she is wearing.

But this disjuncture between alien subject and human body-object only brings to the fore the fantasmatic structures that underlie “ordinary” human subjectivity. The climactic image of this almost featureless figure throwing aside its human form corresponds to a certain persistent fantasy of the relationship of subject to body. This fantasy was codified by Descartes into the philosophical doctrine known as substance dualism (the belief that mind and body are radically different kinds of things). According to Lacan, however, Descartes’ error was more than a simple philosophical mistake, since a certain kind of dualism is embedded in the structure of language, particularly the language of the subject. The I which speaks and the I which is spoken of are structurally different. The I which speaks possesses no positive predicates, it is something like the speaking position as such, while determinate features (height, age, weight, etc.) can only be attributed to the I which is spoken of. The featureless figure in those final scenes of Under the Skin, then, is something like a physicalisation of this soul-subject, this I which speaks: lacking in positive physical predicates, it dwells somehow “inside” the body, but it is ultimately detachable from this body-housing. The film’s final contribution, then, is to remind us of the sense of eeriness intrinsic to our unstable accounts of subject and object, mind and body.

The eeriness of the relationship between body and mind was the subject of Andy de Emmony’s 2010 BBC adaptation of M.R. James’ “Oh, Whistle, and I’ll Come to You, My Lad”, which was discussed in an earlier chapter. In this radically reworked version of the story, Parkin is tormented by the dementia that has reduced his wife to a catatonic shell: “a body that has outlasted the existence of the personality: more horrifying than any spook or ghoul”. “There is nothing inside us”, the Parkin in this version mordantly declares. “There are no ghosts in these machines. Man is matter, and matter rots.” Yet Parkin’s own statement establishes that there are ghosts in the machine, that a certain kind of spectrality is intrinsic to the speaking subject. After all, who is it who can talk of having no inside, of man being rotting matter? Not any substantial subject perhaps, but the subject who speaks, the subject, that is to say, composed out of the undead, discorporate stuff of language. In the very act of announcing its own nullity, the subject does not so much engage in performative contradiction, but points to an ineradicable dualism that results from subjectivity itself. The condition of materialists such as Parkin (our condition in other words) is of knowing that all subjectivity is reducible to matter, that no subjectivity can survive the death of the body, but of nevertheless being unable to experience oneself as mere matter. Once the body is recognised as the substrate-precondition of experience, then one is immediately compelled to accept this phenomenological dualism, precisely because experience and its substrate can be separated. There are ghosts in the machine, and we are they, and they are we.





Alien Traces: Stanley Kubrick, Andrei Tarkovsky, Christopher Nolan

Under the Skin presents us with one version of an eerie encounter with the alien: the alien-among-us. (Nic Roeg’s The Man Who Fell to Earth (1976) is another take on this kind of encounter, and David Bowie’s Newton is a cinematic ancestor of sorts to Johansson’s alien, even though Newton’s homesick exile exudes a romantic pathos that is absent from Under the Skin’s more opaque and unreadable extra-terrestrial.) I touched upon another version of the alien-eerie when I discussed the final Quatermass serial earlier. In this version, the alien is not encountered directly; its physical form, as well as its ontological and metaphysical features, is never disclosed, and the alien is perceptible only by its effects, its traces. We must now examine this kind of encounter with the alien in its own right.

A consideration of outer space quickly engenders a sense of the eerie because of the questions about agency that contemplating it cannot but pose. Is there anything out there at all — and if there are agents, what is their nature? It is therefore surprising that the eerie is disappointingly absent from so much science fiction.

Stanley Kubrick’s 2001: A Space Odyssey is perhaps the most famous example of a science fiction film which bucks this trend, resisting the positivistic pressure to bring the aliens out into the open. The enigma of alien agency is posed by the film’s totem, the monolith, which is something like the paradigm case of an eerie object. (Throughout the film, the feeling of the eerie is reinforced by the association of the monolith with Ligeti’s music, with its sense of awe and alterity.) The monolith’s “unnatural” qualities — its rectilinearity, its flatness, its opaque gloss — force the inference that it must have been produced by a higher intelligence of some kind. The logic here resembles a secular version of the so-called argument from design, which maintained that the functionality, purposiveness and systematicity of many aspects of the natural world compel us to posit a supernatural designer. There is little trace of the theological in Kubrick’s handling of these themes, and no attempt to positively characterise what kind of entity might have produced the monolith. The nature of the intelligence which has intervened in human history, and the purposes of this intervention, remain undisclosed. The film leaves us only some quite minimal resources on the basis of which we might speculate. In addition to the monoliths themselves, there is the simulated hotel room — unnerving in its very banality — in which, at the end of the film, astronaut David Bowman is prepared for his ambivalent transformation into the so-called Star Child. The hotel room might suggest that the intelligence wants Bowman to feel at home, though even if this is the case, its ultimate motives remain obscure: is it care for this human creature, so far from anything familiar, that motivates the construction of this dwelling place, or have these inscrutable intelligences calculated that this would be a better space in which to experimentally observe him?

(The scenes involving the sentient computer HAL, which maintains the systems on the Discovery One spacecraft, pose questions about agency on a smaller scale. HAL does not have a body, even if it has an organ — a red light-sensor — and a voice that is preternaturally calm. It certainly has agency, however, and the nature and scope of that agency — what drives HAL to rebel against the Discovery’s crew — becomes the crucial mystery in this section of the film. In the scenes where we see Bowman slowly, remorselessly dismantle HAL, and we hear HAL begin to audibly mentally deteriorate, we are confronted with the eerie disjunction between consciousness and the material hardware that makes consciousness possible.)


Kubrick’s other major contribution to the cinema of the eerie is another “meta-generic” intervention, The Shining. The genre here is horror or the ghost story, so we understand that the undisclosed beings here are spectres rather than aliens (although it is perfectly possible that they are in fact some kind of alien intelligence). In the shift from science fiction to horror, there is also an implied shift from the suggestion that the eerie forces at work in the film are benign, or at least neutral — as we are likely to conclude with 2001 — to the hypothesis that the presiding entities are malign. Malignancy and benignancy are of course relative to the interests and perspectives of particular entities, as Nietzsche’s parable of the eagles and the lambs reminds us. For the lambs, Nietzsche tells us, the eagles are evil; the lambs imagine that the birds of prey hate them. In fact, there is no question of the eagles hating the lambs — actually, their attitude towards the lambs is closer to affection, even love: after all, the lambs are very tasty. What Nietzsche renders in a comic mode, The Shining poses as an eerie enigma, which remains unresolved, in the film, just as it was in the novel.

The Overlook Hotel in The Shining is a massive version of the room in The Stone Tape: a kind of recording system in which the violence, atrocity and misery that has happened in the building is stored up and played back by the sensitive psychic apparatuses of those — like Jack Torrance and his son Danny — who have the ability to telepathically “shine”. Increasingly, Jack is drawn out of the present — which he shares with his wife Wendy and with Danny — into an aeonic time in which various historic moments are conflated and compressed. (This time of schizo-simultaneity is perhaps somewhat akin to the time in which Tom, in Garner’s Red Shift, finds himself.) But the suggestion is that the apparitions which alternately seduce and menace Jack are creatures like himself, hapless individuals who have been drawn into the Overlook’s fatal influence. What remains undisclosed is the nature of the forces that actually control the hotel. Jack probes this in a scene with the spectral barman, Lloyd:

Lloyd: No charge to you, Mr Torrance.

Jack: No charge?

Lloyd: Your money is no good here. Orders from the house.

Jack: Orders from the house?

Lloyd: Drink up, Mr Torrance.

Jack: I’m the kind of man who likes to know who’s buying their drinks, Lloyd.

Lloyd: It’s not a matter that concerns you, Mr Torrance. At least not at this point.



Who or what is the “house”, and what does it want? Jack asks no further questions, and the film — like the novel — offers no definitive answers. We never see the Overlook’s real management. In the novel, the Overlook’s reveling entities keep repeating the injunction “Unmask!” (a reference to one of the novel’s major intertexts, Poe’s “Masque of the Red Death”). But neither in the novel, nor in the film, do the creatures that have seized hold of the hotel ever fully reveal themselves. It is not so much that they do not show their faces as they do not seem to have faces to show. The image in the novel that seems to come closest to defining their most fundamental form is the swarming, teeming multiplicity of a wasps’ nest. As Roger Luckhurst suggested in his recent book on The Shining, the wasps’ nest image is missing from the film, but was perhaps translated into sound via the inclusion of the micropolyphonic buzzing of Ligeti’s Lontano.

But what do these creatures want? We can only conclude that they are beings which must feed on human misery. This would make them appear “evil” from a certain point of view — but this is essentially the perspective of Nietzsche’s lambs. After all, most human beings are hardly in a position to judge other entities on the basis of what they feed on.

Another eerie dimension of The Shining is opened up by the fateful powers of the Overlook Hotel. Jack is told that he “has always been the caretaker” of the hotel. In one sense, this points to the “aeonic” time of the hotel itself, the time beyond linear clock-time into which Jack increasingly finds himself drawn. But it could also refer to the chains of influence and causation that led Jack to taking on the position of the caretaker at the Overlook: his own abuse at the hands of his father, his failure as a writer, his alcoholism, his drunken injuring of Danny… how far back does the hotel’s influence go?


Andrei Tarkovsky’s two great films from the 1970s — Solaris (1972) and Stalker (1979) — are extended engagements with the alien-eerie. In both cases, Tarkovsky’s versions went against the grain of the source material from which they were adapted: Stanislaw Lem’s Solaris (1961) and Boris and Arkady Strugatsky’s Roadside Picnic (1971). What Tarkovsky subtracts from the novels are their satirical, ironic and absurdist elements, in favour of his habitual focus on questions of faith and redemption. But he retains the novels’ core preoccupations of encounters with the unknown.

Solaris concerns a so-called sentient ocean planet. Tarkovsky downplays the science of “Solaristics”, which plays a large part in Lem’s novel: the vast range of speculations and hypotheses that have been advanced about the planet. Instead, he concentrates on the impact of the planet on psychologist Kris Kelvin. When Kelvin arrives on the space station orbiting Solaris, he finds that his friend Dr Gibarian is dead, and the two remaining onboard scientists are furtive, spending most of their time skulking in their own quarters. He quickly learns the reason for their withdrawal, when a simulacrum of his late wife Hari, who had committed suicide a few years previously, appears, in a state of great confusion, not remembering anything and not knowing where she is. The scientists have come to call these apparitions “visitors”, and each has his own to come to reckon with — messages of a sort sent by Solaris, their purpose and intention unknown. In panic and disgust, Kelvin forces “Hari” into a space capsule, which he sends off into the cosmos. However, Hari — or rather another version of Hari — returns. In one of the most unsettling scenes in the film, we see that “Hari” has no zip on her dress. Why not? Because the planet has constructed “Hari” on the basis of Kelvin’s memories, and the memory of that dress (hazy and incomplete in the way that memories are) did not include a zip.

What does Solaris want? Does it want anything, or are its communications better thought of as automatic emissions of some kind? What is the purpose of the visitors that it sends? You could almost see the planet as a combination of externalised unconscious and psychoanalyst, which keeps sending the scientists undischarged traumatic material with which to deal. Or is the planet granting what it “thinks” are the wishes of the humans, grotesquely “misunderstanding” the nature of grief, almost as if it is an infant gifted with great powers? The film turns on the eerie impasse that arises when mismatching modes of intelligence, cognition and communication confront one another — or, it would be better to say, fail to confront one another. The sublime alterity of the Solaris ocean is one of cinema’s great images of the unknown.

In Tarkovsky’s Stalker, the alien trace is the Zone, a space in which physical laws do not seem to apply in the same way as they do in the outside world. The fairy tale theme of granting wishes, implicit in Solaris, becomes the major preoccupation of Stalker, which centres on the idea that there is a “Room” somewhere in the Zone which can make the deepest desires of those who enter it come true. The “stalker” is a kind of self-taught expert on the Zone who guides those who want to explore this treacherous and wondrous space. In the Strugatskys’ original novel, the stalkers were part of a criminal network dedicated to extracting artefacts from the Zone. In Tarkovsky’s film, the stalker remains a renegade figure — some of the early scenes show him leading his charges past fences, military checkpoints and gun emplacements — but his motives now are spiritual rather than materialistic. The stalker, with his respect for the Zone’s mystery, his sensitivity to its dangers and its volatility, wants others to be transformed by contact with its marvels. However, the two generically-titled figures who join him on this trip — “Writer” and “Scientist” — prove too cynical and untrusting to explore the Zone in that spirit, to the stalker’s bitter disappointment. It is not only reaching the Room that is perilous — the Room has its own dangers. We learn that another stalker, Porcupine, had gone to the Room after leading his brother to his death. But instead of returning his brother to him, the Room gave him money. In offering to grant them their deepest wishes, the Room presents a judgement on their being.

Stalker is remarkable for the way in which it constructs an eerie space without the use of any special effects. Tarkovsky used an extraordinarily atmospheric location in Estonia: an overgrown space, in which human detritus (abandoned factories, tank traps, pillboxes) is overcome by resurgent foliage, in which subterranean tunnels and derelict warehouses are recruited into a dream geography, an anomalous terrain full of traps that appear to be metaphysical and existential more than they are direct physical threats. Nothing is uniform here: time, as well as space, can curve and fold in unpredictable ways. The audience comes to appreciate the quality of this terrain not so much through what it actually sees, but from what it intuits via the artistry of the stalker. Cautious, always alert to potential dangers, drawing on his past knowledge but aware of the way in which the Zone’s mutability so often renders previous experience obsolete, the stalker invokes a space bristling with unseen menace and promise. Humble in the face of the unknown, yet dedicated to exploring the outside, the stalker offers a kind of ethics of the eerie.

For Tarkovsky, the Zone is approached largely as a space in which faith is tested. He avoids the idea, mooted in the title of the Strugatskys’ novel, that the Zone could be nothing more than an accident. Instead of being a miraculous sign of some kind of providence, the Strugatskys suggest, the Zone and all its “magical” properties, could be no more than the trash unintentionally left behind after the alien equivalent of a roadside picnic. Here, the eerie becomes an absurdist joke.


The question of providence is central to Christopher Nolan’s Interstellar (2014), a film that offers a welcome return to some of the terrain staked out by Kubrick and Tarkovsky in a twenty-first century cinema landscape that has so far had little space for the eerie. The film depends upon the providential intervention of a group of seemingly beneficent beings — referred to as “They”— who appear to be aiding humanity in its escape from a dying planet. Initially, “They” produce a wormhole, which makes travel into another galaxy feasible. By the end of the film, we learn that “They” are not aliens as such; rather, they are future humans who have evolved to access a “fifth dimension” which allows them to step outside the fourth dimension, time. But the alterity of “They” is not compromised by the revelation that they are future humans, because the nature of these humans is not disclosed. Inevitably, they must be vastly different from us — the future is an alien country. We apprehend this future species only by some of its traces — the construction of the wormhole and of the mysterious five-dimensional “Tesseract”, in which time is laid out as if it were space, and which Cooper enters at the climax of the film.

The providential intervention is thus revealed as a time loop, in which future humans act on the past to produce the conditions for their own survival. Within this time loop, there are other time anomalies — most notably, the anomaly in which Cooper, the astronaut who leads the ultimately successful space mission, “haunts” his daughter, Murph. In the five-dimensional Tesseract, Cooper desperately contacts Murph, in an attempt to get his past self to stay at home rather than beginning the mission that means he will miss most of his daughter’s life. There’s something strangely futile about this time anomaly. If Cooper was successful in persuading his past self to stay, then the mission would not have got off the ground (or at least he could not have led it); but the very fact that he is in the Tesseract and able to communicate with Murph in the past, means that he must have failed, in that he has ended up leading the mission.

The mission that Cooper leads is an attempt to flee an earth that is literally blighted — crops will not grow, the population is declining fast, it will not be very long before earth is no longer habitable at all for human beings. Cooper is recruited to work for a NASA that has now become an undercover organisation, operating in secrecy. NASA’s leader, John Brand, has apparently come up with two plans to save the human population: Plan A is to launch a centrifuge into space to form a space station; Plan B is to populate one of three potentially habitable planets, accessible through the wormhole near Saturn. These three planets were discovered on a mission a decade earlier. Actually, twelve ships were sent out, but only the three piloted by the astronauts Miller, Mann and Edmunds sent back a signal indicating that they had reached a viable planet.

The film turns on the contrast between a vision of an indifferent universe and one shaped by a kind of material providence (material in the sense that it involves human-technological, rather than supernatural, agency). Some of the most powerful scenes in the film — those on “Miller’s Planet” — show the sublime bleakness of an indifferent nature. This ocean planet, its surface entirely covered by water, is something like the insensate twin of Solaris. While Solaris prompts unanswerable speculations — what purposes and desires does the planet harbour? — Miller’s Planet presents the mute determinism of a world devoid of intent. The tsunamis and stillnesses of the planet’s endless oceans are so many actions without purpose, the product of causes without reasons. The very absence of a purposive agent provokes a feeling of the eerie (how can there be nothing here?). The term “indifferent” is perhaps ultimately inadequate, since it suggests an intentional capacity that is not being used. Mute nature, you could say, is not even indifferent: it lacks even the capacity for indifference. Even so, it is something like the degree-zero of agency, if agency is defined simply as the capacity to make things happen. Miller’s Planet is full of cause and effect; what it lacks is any designing or purposive intelligence.

The desperate scenes on the planet — the crew’s realisation that the planet is a kind of ocean of sterility, incapable of supporting life; their mistaking of a tsunami for mountains; their struggle to avoid being crushed under the monstrous wave — are given added force by the fact that they are aware that — because of the distorting effects of a nearby black hole — each hour on the planet is equivalent to seven years of earth time. We know that this is especially painful for Cooper because of his desire to return to his children. When Cooper returns to the ship, he learns there has been a miscalculation — in fact, twenty-three earth years have passed while they have been on Miller’s Planet. In a wrenching scene, Cooper watches his children’s lives pass into adulthood over the course of a few short minutes, as he watches the messages they have sent to the ship over the course of two decades.

Love — particularly love between parents and children — is a major theme of the film. The love between Cooper and his daughter, Murph, is what ultimately allows Brand’s Plan A to work — this connection between the two of them is what enables Cooper, when he is in the Tesseract, to send Murph the data she needs to solve the equation on which the plan depends. Although the love between the two is the central affective thread in the film, it is tragically thwarted. The two are only re-united on Murph’s deathbed. Because of the effects of relativity, Cooper looks much the same as he did when he left earth; Murph is by now an elderly woman, her life over, and Cooper has missed most of it.

During a scene onboard Endurance earlier in the film, Amelia Brand (John’s daughter) makes a case for love as a force from a “higher dimension”:

Cooper: You’re a scientist, Brand.

Brand: So listen to me when I say that love isn’t something that we invented. It’s... observable, powerful. It has to mean something.

Cooper: Love has meaning, yes. Social utility, social bonding, child rearing...

Brand: We love people who have died. Where’s the social utility in that?

Cooper: None.

Brand: Maybe it means something more — something we can’t yet understand. Maybe it’s some evidence, some artifact of a higher dimension that we can’t consciously perceive.

I’m drawn across the universe to someone I haven’t seen in a decade, who I know is probably dead. Love is the one thing we’re capable of perceiving that transcends dimensions of time and space.



Amelia Brand’s declaration about love is far from disinterested. She makes it when the crew is about to decide whether to travel to Mann’s planet or Edmunds’ planet. Brand wants to go to Edmunds’ planet, but her choice is driven by the fact that Edmunds was her lover. Hence her motive for believing that love is a mysterious force, with its own occult powers and capacities. Yet it turns out, in the end, that she is correct, at least about Edmunds’ planet. It is the only viable environment: as we have seen, Miller’s planet is a desolate ocean, while Mann’s is an icy wasteland.

The immediate temptation here is to dismiss this as nothing more than kitsch sentimentality. Part of the power of Interstellar, however, comes from its readiness to risk appearing naive, as well as emotionally and conceptually excessive. And what the film opens up here is the possibility of an eerie love. Love moves from being on the side of the seemingly (over)familiar to the side of the unknown. On Brand’s account, love is unknown but something that can be investigated and quantified: it becomes an eerie agent.





“…The Eeriness Remains”: Joan Lindsay

They see the walls of the gymnasium fading into an exquisite transparency, the ceiling opening up like a flower into the brilliant sky above Hanging Rock. The shadow of the Rock is flowing, luminous as water, across the shimmering plains and they are at the picnic, sitting on the warm dry grass under the gum trees…

— Joan Lindsay, Picnic at Hanging Rock



The last word must go to Joan Lindsay’s 1967 novel, Picnic at Hanging Rock. Not only because Picnic at Hanging Rock is practically a textbook example of an eerie novel — it includes disappearances, amnesia, a geological anomaly, an intensely atmospheric terrain — but also because Lindsay’s rendition of the eerie has a positivity, a languorous and delirious allure, that is absent or suppressed in so many other eerie texts. Lindsay is the opposite case to M.R. James. Where James, as we saw, always codes the outside as dangerous and deadly, Picnic at Hanging Rock invokes an outside that certainly invokes awe and peril, but which also involves a passage beyond the petty repressions and mean confines of common experience into a heightened atmosphere of oneiric lucidity.

Picnic at Hanging Rock shows that sometimes a disappearance can be more haunting than an apparition. You could say that, in Picnic at Hanging Rock, nothing happens. Nothing happens, not in the sense that there are no events — although the novel is about an unresolved enigma. No: nothing happens, in the sense that an absence erupts into empirical reality: the novel is about the gap that is opened up and the perturbations it produces.

The disappearance at the heart of the novel happens on a Valentine’s Day picnic at Hanging Rock, in Victoria, Australia. Hanging Rock broods over the novel like one of Oscar Dominguez or Max Ernst’s decalcomania spinal landscapes; it is a geological relic from deep time, a time that preceded the arrival of human beings by many millennia. It can only be seen in fragments, its labyrinthine spaces as intensively treacherous as those of another alien picnic site, Tarkovsky’s Zone. By the end, it seems that certain of the Rock’s terrains — psychic as much as physical spaces — are only navigable by the attaining of a delirium state. This calm delirium is the dominant mood in Peter Weir’s faithful 1975 film adaptation, where time (and narrative) are held in an aching suspension, and a dreamy fatalism dominates.

The picnic is a day-trip organised for the students of Apple-yard College, a private boarding school for girls. The College, an attempt to simulate a small part of Victorian England in conditions that could hardly be more different from Britain, squats in the surrounding landscape like some Magritte non-sequitur. In the contrast between the Rock and the elegantly stifling absurdity of the College’s clothes and rituals, we are made aware of the inherent surrealism of the colonial project:

Insulated from natural contacts with earth, air and sunlight, by corsets pressing on their solar plexuses, by voluminous petticoats, cotton stockings and kid boots, the drowsy wellfed girls lounging in the shade were no more a part of their environment than figures in a photograph album, arbitrarily posed against a backcloth of cork rocks and cardboard trees.

During the course of the picnic, four of the students — Miranda, Edith, Marion and Irma — and the College’s mathematics teacher, Greta McCraw, decide to climb the Rock. The trip up the Rock seems at first to be nothing out of the ordinary — there is idle chatter, gossip, some discussion of the vast age of the Rock. Initially, only a curious statement by Marion breaks with the mood. “Whatever can those people be doing down there like a lot of ants? A surprising number of people are without purpose. Although it’s probable that they are performing some necessary function unknown to themselves.” It is as if Marion is already detached from the world below, as if she has already crossed a threshold. It is after the four see a monolith — “a single outcrop of pock-marked stone, something like a monstrous egg perched above a precipitous drop the plain” — that the atmosphere decisively shifts. All four are immediately overcome by lassitude, and fall into a deep sleep. The focus now moves to Edith’s point of view. She awakes in a panic, demanding to return home. But the others seem now to all have passed over into some altered (trance) state:

‘Miranda,’ Edith said again. ‘I feel perfectly awful! When are we going home?’ Miranda was looking at her so strangely, almost as if she wasn’t seeing her. When Edith repeated the question more loudly, she simply turned her back and began walking away up the rise, the other two following a little way behind. Well, hardly walking — sliding over the stones on their bare feet as if they were walking on a drawing-room carpet.

Miranda, Marion and Irma slip away, disappearing out of sight behind the monolith. Edith flees down the rock, screaming. By the time she returns to the picnic, “crying and laughing, and with her dress torn to ribbons”, she is unable to give any indication of where she parted company from the other students. The Rock is searched, but neither the three students nor Miss McCraw are found. (A few days later, Edith claims to remember seeing Miss McCraw on the rock, inexplicably stripped down to her underwear.) Initial searches in subsequent days yield nothing. However, a few days later, Irma is discovered at the Rock, her clothes torn and her corset missing. Suffering from amnesia, she is unable to offer any explanation of what happened on the rock. In the rest of the novel, we learn nothing more about what happened. At the end, with the College collapsed because of the scandal associated with the events at Hanging Rock, the disappearances remain unexplained.

Alongside — and I think contributing to — the novel’s feeling of eeriness is its capacity to generate “reality-effects”. Although the novel was entirely fictionalised, it was widely, though mistakenly, believed to be based on a true story. Lindsay invited this reception: she wrote the novel as if it were a factual account, using real locations (including Hanging Rock itself, an actual geological formation). The novel’s trick involved re-telling a classic Faery story — young women abducted into another world — using the conventions of realism. One of these conventions was giving the event a precise date. According to the novel, the three women disappeared on February 14th, 1900. 1900, significantly, is the year which Freud wanted The Interpretation of Dreams dated (this dating is, famously, fictional: Freud’s text was actually published in 1899, but he wanted it to bear a more epochal date). But Picnic at Hanging Rock is not set in our 1900, in which February 14th fell on a Wednesday, not a Saturday.

Above all else, though, the illusion of factuality is produced by the lack of any solution to the mystery. The story about the painters Zeuxis and Parrhasios, referred to by Lacan, offers a parable. Zeuxius painted a bunch of grapes so convincing that birds attempted to eat them. Parrhasios, meanwhile, painted a curtain, which Zeuxius asked him to pull aside to reveal what he had painted. The lack of explanation makes Picnic at Hanging Rock into an analogue of Parhassios’ painting. It became a veil, an enigma whose very irresolution produced the illusion that there must be something behind the curtain.

The novel seems to justify the idea that a sense of the eerie is created and sustained simply by withholding information. In the case of Picnic at Hanging Rock, this literally happened: the form in which the novel was published was the result of an act of excision. In her original manuscript, Lindsay provided a solution of sorts to the enigma, in a concluding chapter that her publishers encouraged her to remove from the published version of the novel. This “Chapter Eighteen” was published separately, as The Secret of Hanging Rock.

There is no doubt that the original Chapter Eighteen would have somewhat undermined the novel’s “reality-effect”. The excised chapter is marked by a clear change in tone. The suggestiveness that has characterised the earlier parts of the novel — the hints of an outside, of something beyond the ordinary world — gives way to what is by now quite clearly an account of an anomalous experience. The chapter begins at more or less the point that Edith runs away. Miranda, Marion and Irma feel that they are being “pulled from the inside” by the monolith. They fall asleep, and when they awake it is with a heightened, hallucinogenic sensitivity to their surroundings. An older woman appears, in her underclothes — it seems to be Greta McCraw, but she is not named as such in the novel, nor is she recognised by the other characters. When the older woman faints, Miranda loosens her corset. This prompts Marion to suggest that they all “get out of these absurd garments” — so the three students remove their corsets and throw them from the Rock. In what is perhaps the most arresting image in Chapter Eighteen, the corsets do not immediately fall to the ground, but float in mid-air at the side of the Rock. Has time stopped? Certainly, we are beyond clock-time now: perhaps in dream-time. (In her essay “A Commentary on Chapter Eighteen” — included in The Secret of Hanging Rock — Yvonne Rousseau points to a pun — a dreamwork-compression — involved in the image of the corsets hanging in the air, arising from the fact that the alternative name for “corset” is “stay’”) A “hole in space” appears: “About the size of a fully rounded summer moon, coming and going. She saw it as painters and sculptors saw a hole, as a thing in itself, giving shape and significance to other shapes. As a presence, not an absence …” After this hole fades, they see a snake crawl into a small hole. The older woman says that she will follow it; somehow, she transforms into a crab and passes into the tiny space. After a signal, Marion follows (there is no mention of any animal-becoming here, nor any account of how she is able to fit her body into the hole). When it is Miranda’s turn to cross over, a frightened Irma begs her not to go, but Miranda does not understand her fear and reluctance, and she too passes into the hole. Irma is left on her own, waiting. After an indeterminate period of time, a boulder rolls over the hole. The final image in the chapter is of Irma — presumably now aware that she will not be able to make the crossing — desperately tearing at the boulder.

The published version of the novel — the one without Chapter Eighteen — not only leaves the enigma without solution; it also leaves open the question of the novel’s genre (does it belong to literary realism? To murder-mystery? To fantasy? To science fiction?). The inclusion of Chapter Eighteen would not have settled the question of genre, but it would have eliminated certain possibilities. It would not now seem possible to, say, read the novel as a murder-mystery. But Chapter Eighteen produces as many enigmas as it solves. What is the status of the experiences on the Rock? Are they to be taken literally, such that, for example, Greta McCraw actually turns into a crab? Are they to be understood as a consequence of some state of intoxication? (If this is the case, then the events could still be recuperated for a realist reading of sorts.) The suggestion that the women have passed through a gateway to the outside invites us to read Picnic at Hanging Rock as a weird tale, and the inclusion of Chapter Eighteen pushes the novel into some space between the weird and the eerie. What is certain is that Chapter Eighteen does not offer any simple kind of solution to the puzzles the novel poses. As Yvonne Rousseau put it, “Joan Lindsay’s original intention is finally disclosed — but her intention was not to dissolve the mystery. The Picnic geography is clarified, but the eeriness remains.”

The eeriness is partly a question of the affective atmosphere that hangs over the experiences on the Rock. Justin Barton has called this atmosphere “solar trance”, and it is manifested in a kind of positive fatalism. Initially, this fatalism registers as a seeming lack (there is nothing where there should be something). As they fall under the thrall of the Rock, the characters seem to be denuded of their passions. Yet these passions, which very much include fear, are attachments to the everyday world. It is Irma’s fear, her inability to let go of these everyday attachments (Lindsay’s final description of Irma refers to her skill at embroidery), which ultimately prevents her from making the crossing. She is unable to see through what was promised in the act of the casting aside of the corsets. Marion and Miranda, however, are fully prepared to take the step into the unknown. They are possessed by the eerie calm that settles whenever familiar passions can be overcome. They have disappeared, and their disappearances will leave haunting gaps, eerie intimations of the outside.

GHOSTS OF MY LIFE



For my wife, Zöe and my son, George


Acknowledgements


Many of the ideas in Ghosts Of My Life were first auditioned on my blog, k-punk. I’m grateful to the k-punk readers who responded to the ideas there and helped them to propagate. I’m also grateful to the publishers who kindly allowed me to reprint material in Ghosts, in particular Rob Winter at Sight & Sound and Tony Herrington at The Wire. Some of the pieces that originally appeared elsewhere have been altered for inclusion here. Needless to say, all responsibility for the edits in Ghosts lies with me.

If I were to list everyone who inspired or supported the writing of Ghosts Of My Life, the book would never get started, so I will concentrate only on those who worked closely on the manuscript. Thanks, therefore, to Tariq Goddard for his patience, Liam Sprod and Alex Niven for their attentive copy-editing and proofreading, Laura Oldfield Ford for allowing me to use her drawings to illustrate the text, Chris Heppell for the cover photograph, and Rob White for his customarily insightful and incisive comments.





Lately I’ve been feeling like Guy Pearce in

Memento

-Drake





00: LOST FUTURES





‘The Slow Cancellation of the Future’


‘There’s no time here, not any more’

The final image of the British television series Sapphire and Steel seemed designed to haunt the adolescent mind. The two lead characters, played by Joanna Lumley and David McCallum, find themselves in what seems to be a 1940s roadside café. The radio is playing a simulation of Glenn Miller-style smooth Big Band jazz. Another couple, a man and a woman dressed in 1940s clothes, are sitting at an adjacent table. The woman rises, saying: ‘This is the trap. This is nowhere, and it’s forever.’ She and her companion then disappear, leaving spectral outlines, then nothingness. Sapphire and Steel panic. They rifle through the few objects in the café, looking for something they can use to escape. There is nothing, and when they pull back the curtains, there is only a black starry void beyond the window. The café, it seems, is some kind of capsule floating in deep space.

Watching this extraordinary final sequence now, the juxtaposition of the café with the cosmos is likely to put in mind some combination of Edward Hopper and René Magritte. Neither of those references were available to me at the time; in fact, when I later encountered Hopper and Magritte, I no doubt thought of Sapphire and Steel. It was August 1982 and I had just turned 15 years old. It would be more than 20 years later before I would see these images again. By then, thanks to VHS, DVD and YouTube, it seemed that practically everything was available for re-watching. In conditions of digital recall, loss is itself lost.

The passage of 30 years has only made the series appear even stranger than it did at the time. This was science fiction with none of the traditional trappings of the genre, no spaceships, no ray guns, no anthropomorphic foes: only the unraveling fabric of the corridor of time, along which malevolent entities would crawl, exploiting and expanding gaps and fissures in temporal continuity. All we knew about Sapphire and Steel was that they were ‘detectives’ of a peculiar kind, probably not human, sent from a mysterious ‘agency’ to repair these breaks in time. ‘The basis of Sapphire and Steel,’ the series’s creator P. J. Hammond explained, ‘came from my desire to write a detective story, into which I wanted to incorporate Time. I’ve always been interested in Time, particularly the ideas of J. B. Priestley and H. G. Wells, but I wanted to take a different approach to the subject. So instead of having them go backwards and forwards in Time, it was about Time breaking in, and having set the precedent I realised the potential that it offered with two people whose job it was to stop the break-ins.’ (Steve O’Brien, ‘The Story Behind Sapphire & Steel’, The Fan Can, http://www.thefancan.com/fancandy/features/tvfeatures/steel.html)

Hammond had previously worked as a writer on police dramas such as The Gentle Touch and Hunter’s Walk and on children’s fantasy shows like Ace of Wands and Dramarama. With Sapphire and Steel, he attained a kind of auteurship that he would never manage to repeat. The conditions for this kind of visionary public broadcasting would disappear during the 1980s, as the British media became taken over by what another television auteur, Dennis Potter, would call the ‘occupying powers’ of neoliberalism. The result of that occupation is that it is now hard to believe that such a programme could ever have been transmitted on prime-time television, still less on what was then Britain’s sole commercial network, ITV. There were only three television channels in Britain then: BBC1, BBC2 and ITV; Channel 4 would make its first broadcast only a few months later.

By comparison with the expectations created by Star Wars, Sapphire and Steel came off as very cheap and cheerful. Even in 1982, the chroma-key special effects looked unconvincing. The fact that the stage sets were minimal, and the cast small (most of the ‘assignments’ only featured Lumley and McCallum and a couple of others), gave the impression of a theatre production. Yet there was none of the homeliness of kitchen sink naturalism; Sapphire and Steel had more in common with the enigmatic oppressiveness of Harold Pinter, whose plays were frequently broadcast on BBC television during the 1970s.

A number of things about the series are particularly striking from the perspective of the 21st century. The first is its absolute refusal to ‘meet the audience halfway’ in the way that we’ve come to expect. This is partly a conceptual matter: Sapphire and Steel was cryptic, its stories and its world never fully disclosed, still less explained. The series was much closer to something like the BBC’s adaptation of John Le Carré’s Smiley novels – Tinker Tailor Soldier Spy had been broadcast in 1979; its sequel Smiley’s People would begin transmission a month after Sapphire and Steel ended – than it was to Star Wars. It was also a question of emotional tenor: the series and its two lead characters are lacking in the warmth and wisecracking humour that is now so much a taken-for-granted feature of entertainment media. McCallum’s Steel had a technician’s indifference towards the lives in which he became reluctantly enmeshed; although he never loses his sense of duty, he is testy and impatient, frequently exasperated by the way humans ‘clutter their lives’. If Lumley’s Sapphire appeared more sympathetic, there was always the suspicion that her apparent affection towards humans was something like an owner’s benign fascination for her pets. The emotional austerity that had characterised the series from the start assumes a more explicitly pessimistic quality in this final assignment. The Le Carré parallels are reinforced by the strong suspicion that, just as in Tinker Tailor Soldier Spy, the lead characters have been betrayed by their own side.

Then there was Cyril Ornadel’s incidental music. As Nick Edwards explained in a 2009 blog post, this was ‘a ()rranged for a small ensemble of musicians (predominantly woodwind) with liberal use of electronic treatments (ring modulation, echo/delay) to intensify the drama and suggestion of horror, Ornadel’s cues are far more powerfully chilling and evocative than anything you’re likely hear in the mainstream media today.’ (‘Sapphire and Steel’, gutterbreakz.blogspot.co.uk/2009/05/sapphire-steel.html)

One aim of Sapphire and Steel was to transpose ghost stories out of the Victorian context and into contemporary places, the still inhabited or the recently abandoned. In the final assignment, Sapphire and Steel arrive at a small service station. Corporate logos – Access, 7 Up, Castrol GTX, LV – are pasted on the windows and the walls of the garage and the adjoining café. This ‘halfway place’ is a prototype version of what the anthropologist Marc Augé will call in a 1995 book of the same title, ‘non-places’ – the generic zones of transit (retail parks, airports) which will come to increasingly dominate the spaces of late capitalism. In truth, the modest service station in Sapphire and Steel is quaintly idiosyncratic compared to the cloned generic monoliths which will proliferate besides motorways over the coming 30 years.

The problem that Sapphire and Steel have come to solve is, as ever, to do with time. At the service station, there is temporal bleed-through from earlier periods: images and figures from 1925 and 1948 keep appearing, so that, as Sapphire and Steel’s colleague Silver puts it ‘time just got mixed, jumbled up, together, making no sort of sense’. Anachronism, the slippage of discrete time periods into one another, was throughout the series the major symptom of time breaking down. In one of the earlier assignments, Steel complains that these temporal anomalies are triggered by human beings’ predilection for the mixing of artefacts from different eras. In this final assignment, the anachronism has led to stasis: time has stopped. The service station is in ‘a pocket, a vacuum’. There’s ‘still traffic, but it’s not going anywhere’: the sound of cars is locked into a looped drone. Silver says, ‘there is no time here, not any more’. It’s as if the whole scenario is a literalisation of the lines in Pinter’s No Man’s Land: ‘No man’s land, which never moves, which never changes, which never grows older, which remains forever icy and silent.’ Hammond said that he had not necessarily intended the series to end there. He had thought that it would be rested, to return at some point in the future. There would be no return – at least, not on network television. In 2004, Sapphire and Steel would come back for a series of audio adventures; though Hammond, McCallum and Lumley were not involved, and by then the audience was not the television-viewing public, but the kind of special interest niche easily catered for in digital culture. Eternally suspended, never to be freed, their plight – and indeed their provenance – never to be fully explained, Sapphire and Steel’s internment in this café from nowhere is prophetic for a general condition: in which life continues, but time has somehow stopped.


The slow cancellation of the future

It is the contention of this book that 21st-century culture is marked by the same anachronism and inertia which afflicted Sapphire and Steel in their final adventure. But this stasis has been buried, interred behind a superficial frenzy of ‘newness’, of perpetual movement. The ‘jumbling up of time’, the montaging of earlier eras, has ceased to be worthy of comment; it is now so prevalent that is no longer even noticed.

In his book After The Future, Franco ‘Bifo’ Berardi refers to the ‘the slow cancellation of the future that () got underway in the 1970s and 1980s.’ ‘But when I say “future”’, he elaborates,


I am not referring to the direction of time. I am thinking, rather, of the psychological perception, which emerged in the cultural situation of progressive modernity, the cultural expectations that were fabricated during the long period of modern civilization, reaching a peak after the Second World War. These expectations were shaped in the conceptual frameworks of an ever progressing development, albeit through different methodologies: the Hegel-Marxist mythology of Aufhebung and founding of the new totality of Communism; the bourgeois mythology of a linear development of welfare and democracy; the technocratic mythology of the all-encom-passing power of scientific knowledge; and so on.

My generation grew up at the peak of this mythological temporalization, and it is very difficult, maybe impossible, to get rid of it, and look at reality without this kind of temporal lens. I’ll never be able to live in accordance with the new reality, no matter how evident, unmistakable, or even dazzling its social planetary trends. (After The Future, AK Books, 2011, pp18-19)


Bifo is a generation older than me, but he and I are on the same side of a temporal split here. I, too, will never be able to adjust to the paradoxes of this new situation. The immediate temptation here is to fit what I’m saying into a wearily familiar narrative: it is a matter of the old failing to come to terms with the new, saying it was better in their day. Yet it is just this picture – with its assumption that the young are automatically at the leading edge of cultural change – that is now out of date.

Rather than the old recoiling from the ‘new’ in fear and incomprehension, those whose expectations were formed in an earlier era are more likely to be startled by the sheer persistence of recognisable forms. Nowhere is this clearer than in popular music culture. It was through the mutations of popular music that many of those of us who grew up in the 1960s, 70s and 80s learned to measure the passage of cultural time. But faced with 21st-century music, it is the very sense of future shock which has disappeared. This is quickly established by performing a simple thought experiment. Imagine any record released in the past couple of years being beamed back in time to, say, 1995 and played on the radio. It’s hard to think that it will produce any jolt in the listeners. On the contrary, what would be likely to shock our 1995 audience would be the very recognisability of the sounds: would music really have changed so little in the next 17 years? Contrast this with the rapid turnover of styles between the 1960s and the 90s: play a jungle record from 1993 to someone in 1989 and it would have sounded like something so new that it would have challenged them to rethink what music was, or could be. While 20th-century experimental culture was seized by a recombinatorial delirium, which made it feel as if newness was infinitely available, the 21st century is oppressed by a crushing sense of finitude and exhaustion. It doesn’t feel like the future. Or, alternatively, it doesn’t feel as if the 21st century has started yet. We remain trapped in the 20th century, just as Sapphire and Steel were incarcerated in their roadside café.

The slow cancellation of the future has been accompanied by a deflation of expectations. There can be few who believe that in the coming year a record as great as, say, the Stooges’ Funhouse or Sly Stone’s There’s a Riot Goin’ On will be released. Still less do we expect the kind of ruptures brought about by The Beatles or disco. The feeling of belatedness, of living after the gold rush, is as omnipresent as it is disavowed. Compare the fallow terrain of the current moment with the fecundity of previous periods and you will quickly be accused of ‘nostalgia’. But the reliance of current artists on styles that were established long ago suggests that the current moment is in the grip of a formal nostalgia, of which more shortly.

It is not that nothing happened in the period when the slow cancellation of the future set in. On the contrary, those 30 years have been a time of massive, traumatic change. In the UK, the election of Margaret Thatcher had brought to an end the uneasy compromises of the so-called postwar social consensus. Thatcher’s neoliberal programme in politics was reinforced by a transnational restructuring of the capitalist economy. The shift into so-called Post-Fordism – with globalisation, ubiquitous computerisation and the casualisation of labour – resulted in a complete transformation in the way that work and leisure were organised. In the last 10 to 15 years, meanwhile, the internet and mobile telecommunications technology have altered the texture of everyday experience beyond all recognition. Yet, perhaps because of all this, there’s an increasing sense that culture has lost the ability to grasp and articulate the present. Or it could be that, in one very important sense, there is no present to grasp and articulate any more.

Consider the fate of the concept of ‘futuristic’ music. The ‘futuristic’ in music has long since ceased to refer to any future that we expect to be different; it has become an established style, much like a particular typographical font. Invited to think of the futuristic, we will still come up with something like the music of Kraftwerk, even though this is now as antique as Glenn Miller’s big band jazz was when the German group began experimenting with synthesizers in the early 1970s.

Where is the 21st-century equivalent of Kraftwerk? If Kraftwerk’s music came out of a casual intolerance of the already-established, then the present moment is marked by its extraordinary accommodation towards the past. More than that, the very distinction between past and present is breaking down. In 1981, the 1960s seemed much further away than they do today. Since then, cultural time has folded back on itself, and the impression of linear development has given way to a strange simultaneity.

Two examples will suffice to introduce this peculiar temporality. When I first saw the video for the Arctic Monkeys’ 2005 single ‘I Bet You Look Good on the Dancefloor’, I genuinely believed that it was some lost artifact from circa 1980. Everything in the video – the lighting, the haircuts, the clothes – had been assembled to give the impression that this was a performance on BBC2’s ‘serious rock show’ The Old Grey Whistle Test. Furthermore, there was no discordance between the look and the sound. At least to a casual listen, this could quite easily have been a postpunk group from the early 1980s. Certainly, if one performs a version of the thought experiment I described above, it’s easy to imagine ‘I Bet You Look Good On The Dancefloor’ being broadcast on The Old Grey Whistle Test in 1980, and producing no sense of disorientation in the audience. Like me, they might have imagined that the references to ‘1984’ in the lyrics referred to the future.

There ought to be something astonishing about this. Count back 25 years from 1980, and you are at the beginning of rock and roll. A record that sounded like Buddy Holly or Elvis in 1980 would have sounded out of time. Of course, such records were released in 1980, but they were marketed as retro. If the Arctic Monkeys weren’t positioned as a ‘retro’ group, it is partly because, by 2005, there was no ‘now’ with which to contrast their retrospection. In the 1990s, it was possible to hold something like Britpop revivalism to account by comparing it to the experimentalism happening on the UK dance underground or in US R&B. By 2005, the rates of innovation in both these areas had enormously slackened. UK dance music remains much more vibrant than rock, but the changes that happen there are tiny, incremental, and detectable largely only by initiates – there is none of the dislocation of sensation that you heard in the shift from Rave to Jungle and from Jungle to Garage in the 1990s. As I write this, one of the dominant sounds in pop (the globalised club music that has supplanted R&B) resembles nothing more than Eurotrance, a particularly bland European 1990s cocktail made from some of the most flavourless components of House and Techno.

Second example. I first heard Amy Winehouse’s version of ‘Valerie’ while walking through a shopping mall, perhaps the perfect venue for consuming it. Up until then, I had believed that ‘Valerie’ was first recorded by indie plodders the Zutons. But, for a moment, the record’s antiqued 1960s soul sound and the vocal (which on a casual listen I didn’t at first recognise as Winehouse) made me temporarily revise this belief: surely the Zutons’ version of the track was a cover of this apparently ‘older’ track, which I had not heard until now? Naturally, it didn’t take me long to realise that the ‘60s soul sound’ was actually a simulation; this was indeed a cover of the Zutons’ track, done in the souped-up retro style in which the record’s producer, Mark Ronson, has specialised.

Ronson’s productions might have been designed to illustrate what Fredric Jameson called the ‘nostalgia mode’. Jameson identifies this tendency in his remarkably prescient writings on postmodernism, beginning in the 1980s. What makes ‘Valerie’ and the Arctic Monkeys typical of postmodern retro is the way in which they perform anachronism. While they are sufficiently ‘historical’–sounding to pass on first listen as belonging to the period which they ape – there is something not quite right about them. Discrepancies in texture – the results of modern studio and recording techniques – mean that they belong neither to the present nor to the past but to some implied ‘timeless’ era, an eternal 1960s or an eternal 80s. The ‘classic’ sound, its elements now serenely liberated from the pressures of historical becoming, can now be periodically buffed up by new technology.

It is important to be clear about what Jameson means by the ‘nostalgia mode’. He is not referring to psychological nostalgia – indeed, the nostalgia mode as Jameson theorises it might be said to preclude psychological nostalgia, since it arises only when a coherent sense of historical time breaks down. The kind of figure capable of exhibiting and expressing a yearning for the past belongs, actually, to a paradigmatically modernist moment – think, for instance, of Proust’s and Joyce’s ingenious exercises in recovering lost time. Jameson’s nostalgia mode is better understood in terms of a formal attachment to the techniques and formulas of the past, a consequence of a retreat from the modernist challenge of innovating cultural forms adequate to contemporary experience. Jameson’s example is Lawrence Kasdan’s now half-forgotten film Body Heat (1981), which, although it was officially set in the 1980s, feels as if it belongs to the 30s. ‘Body Heat is technically not a nostalgia film,’ Jameson writes,


since it takes place in a contemporary setting, in a little Florida village near Miami. On the other hand, this technical contemporaneity is most ambiguous indeed…Technically,…its objects (its cars, for instance) are 1980s products, but everything in the film conspires to blur that immediate contemporary reference and to make it possible to receive this too as nostalgia work – as a narrative set in some indefinable nostalgic past, an eternal 1930s, say, beyond history. It seems to me exceedingly symptomatic to find the very style of nostalgia films invading and colonizing even those movies today which have contemporary settings, as though, for some reason, we were unable today to focus our own present, as though we had become incapable of achieving aesthetic representations of our own current experience. But if that is so, then it is a terrible indictment of consumer capitalism itself – or, at the very least, an alarming and pathological symptom of a society that has become incapable of dealing with time and history. (‘Postmodernism and Consumer Society’ in The Cultural Turn: Selected Writings on the Postmodern, 1983-1998, Verso, 1998, pp9-10.)


What blocks Body Heat from being a period piece or a nostalgia picture in any straightforward way is its disavowal of any explicit reference to the past. The result is anachronism, and the paradox is that this ‘blurring of official contemporaneity’, this ‘waning of historicity’ is increasingly typical of our experience of cultural products. Another of Jameson’s examples of the nostalgia mode is Star Wars:


one of the most important cultural experiences of the generations that grew up from the 1930s to the 1950s was the Saturday afternoon series of the Buck Rogers type – alien villains, true American heroes, heroines in distress, the death ray or the doomsday box, and the cliff-hanger at the end whose miraculous solution was to be witnessed next Saturday afternoon. Star Wars reinvents this experience in the form of a pastiche; there is no point to a parody of such series, since they are long extinct. Far from being a pointless satire of such dead forms, Star Wars satisfies a deep (might I even say repressed?) longing to experience them again: it is a complex object in which on some first level children and adolescents can take the adventures straight, while the adult public is able to gratify a deeper and more properly nostalgic desire to return to that older period and to live its strange old aesthetic artefacts through once again. (‘Postmodernism and Consumer Society’, p8)


There is no nostalgia for a historical period here (or if there is, it is only indirect): the longing of which Jameson writes is a yearning for a form. Star Wars is a particularly resonant example of postmodern anachronism, because of the way it used technology to obfuscate its archaic form. Belying its origins in these fusty adventure series forms, Star Wars could appear new because its then unprecedented special effects relied upon the latest technology. If, in a paradigmatically modernist way, Kraftwerk used technology to allow new forms to emerge, the nostalgia mode subordinated technology to the task of refurbishing the old. The effect was to disguise the disappearance of the future as its opposite.

The future didn’t disappear overnight. Berardi’s phrase ‘the slow cancellation of the future’ is so apt because it captures the gradual yet relentless way in which the future has been eroded over the last 30 years. If the late 1970s and early 80s were the moment when the current crisis of cultural temporality could first be felt, it was only during the first decade of the 21st century that what Simon Reynolds calls ‘dyschronia’ has become endemic. This dyschronia, this temporal disjuncture, ought to feel uncanny, yet the predominance of what Reynolds calls ‘retro-mania’ means that it has lost any unheimlich charge: anachronism is now taken for granted. Jameson’s postmodernism – with its tendencies towards retrospection and pastiche – has been naturalised. Take someone like the stupendously successful Adele: although her music is not marketed as retro, there is nothing that marks out her records as belonging to the 21st century either. Like so much contemporary cultural production, Adele’s recordings are saturated with a vague but persistent feeling of the past without recalling any specific historical moment.

Jameson equates the postmodern ‘waning of historicity’ with the ‘cultural logic of late capitalism’, but he says little about why the two are synonymous. Why did the arrival of neoliberal, post-Fordist capitalism lead to a culture of retrospection and pastiche? Perhaps we can venture a couple of provisional conjectures here. The first concerns consumption. Could it be that neoliberal capitalism’s destruction of solidarity and security brought about a compensatory hungering for the well-established and the familiar? Paul Virilio has written of a ‘polar inertia’ that is a kind of effect of and counterweight to the massive speeding up of communication. Virilio’s example is Howard Hughes, living in one hotel room for 15 years, endlessly rewatching Ice Station Zebra. Hughes, once a pioneer in aeronautics, became an early explorer of the existential terrain that cyberspace will open up, where it is no longer necessary to physically move in order to access the whole history of culture. Or, as Berardi has argued, the intensity and precariousness of late capitalist work culture leaves people in a state where they are simultaneously exhausted and overstimulated. The combination of precarious work and digital communications leads to a besieging of attention. In this insomniac, inundated state, Berardi claims, culture becomes de-eroticised. The art of seduction takes too much time, and, according to Berardi, something like Viagra answers not to a biological but to a cultural deficit: desperately short of time, energy and attention, we demand quick fixes. Like another of Berardi’s examples, pornography, retro offers the quick and easy promise of a minimal variation on an already familiar satisfaction.

The other explanation for the link between late capitalism and retrospection centres on production. Despite all its rhetoric of novelty and innovation, neoliberal capitalism has gradually but systematically deprived artists of the resources necessary to produce the new. In the UK, the postwar welfare state and higher education maintenance grants constituted an indirect source of funding for most of the experiments in popular culture between the 1960s and the 80s. The subsequent ideological and practical attack on public services meant that one of the spaces where artists could be sheltered from the pressure to produce something that was immediately successful was severely circumscribed. As public service broadcasting became ‘marketised’, there was an increased tendency to turn out cultural productions that resembled what was already successful. The result of all of this is that the social time available for withdrawing from work and immersing oneself in cultural production drastically declined. If there’s one factor above all else which contributes to cultural conservatism, it is the vast inflation in the cost of rent and mortgages. It’s no accident that the efflorescence of cultural invention in London and New York in the late 1970s and early 80s (in the punk and postpunk scenes) coincided with the availability of squatted and cheap property in those cities. Since then, the decline of social housing, the attacks on squatting, and the delirious rise in property prices have meant that the amount of time and energy available for cultural production has massively diminished. But perhaps it was only with the arrival of digital communicative capitalism that this reached terminal crisis point. Naturally, the besieging of attention described by Berardi applies to producers as much as consumers. Producing the new depends upon certain kinds of withdrawal – from, for instance, sociality as much as from pre-existing cultural forms – but the currently dominant form of socially networked cyberspace, with its endless opportunities for micro-contact and its deluge of YouTube links, has made withdrawal more difficult than ever before. Or, as Simon Reynolds so pithily put it, in recent years, everyday life has sped up, but culture has slowed down.

No matter what the causes for this temporal pathology are, it is clear that no area of Western culture is immune from them. The former redoubts of futurism, such as electronic music, no longer offer escape from formal nostalgia. Music culture is in many ways paradigmatic of the fate of culture under post-Fordist capitalism. At the level of form, music is locked into pastiche and repetition. But its infrastructure has been subject to massive, unpredictable change: the old paradigms of consumption, retail and distribution are disintegrating, with downloading eclipsing the physical object, record shops closing and cover art disappearing.


Why hauntology?

What has the concept of hauntology to do with all this? It was in fact with some reluctance that hauntology started to be applied to the electronic music of the middle of the last decade. I’d generally found Jacques Derrida, the inventor of the term, a frustrating thinker. As soon as it was established in certain areas of the academy, deconstruction, the philosophical project which Derrida founded, installed itself as a pious cult of indeterminacy, which at its worst made a lawyerly virtue of avoiding any definitive claim. Deconstruction was a kind of pathology of scepticism, which induced hedging, infirmity of purpose and compulsory doubt in its followers. It elevated particular modes of academic practice – Heidegger’s priestly opacity, literary theory’s emphasis on the ultimate instability of any interpretation – into quasi-theological imperatives. Derrida’s circumlocutions seemed like a disintensifying influence.

It’s by no means irrelevant to point out here that my first encounter with Derrida took place in what is now a vanished milieu. It came in the pages of the New Musical Express in the 1980s, where Derrida’s name would be mentioned by the most exciting writers. (And, actually, part of my frustration with Derrida’s work came out of disappointment. The enthusiasm of NME writers like Ian Penman and Mark Sinker for Derrida, and the formal and conceptual inventiveness it seemed to provoke in their writing, created expectations which Derrida’s own work couldn’t meet when I eventually came to read it.) It’s hard to believe this now but, along with public service broadcasting, the NME constituted a kind of supplementary-informal education system, in which theory acquired a strange, lustrous glamour. I had also seen Derrida in Ken McMullen’s film Ghost Dance, shown late at night on Channel 4 in the early days of the network, at a time before we had a VCR, when I had to resort to washing my face with cold water to try to keep myself awake.

Derrida coined the term ‘hauntology’ in his Specters of Marx: The State of the Debt, the Work of Mourning and the New International. ‘To haunt does not mean to be present, and it is necessary to introduce haunting into the very construction of a concept,’ he wrote. (Jacques Derrida, Specters of Marx: The State of the Debt, the Work of Mourning and the New International, Routledge, 1994, p202) Hauntology was this concept, or puncept. The pun was on the philosophical concept of ontology, the philosophical study of what can be said to exist. Hauntology was the successor to previous concepts of Derrida’s such as the trace and différance; like those earlier terms, it referred to the way in which nothing enjoys a purely positive existence. Everything that exists is possible only on the basis of a whole series of absences, which precede and surround it, allowing it to possess such consistency and intelligibility that it does. In the famous example, any particular linguistic term gains its meaning not from its own positive qualities but from its difference from other terms. Hence Derrida’s ingenious deconstructions of the ‘metaphysics of presence’ and ‘phonocentrism’, which expose the way in which particular dominant forms of thought had (incoherently) privileged the voice over writing.

But hauntology explicitly brings into play the question of time in a way that had not quite been the case with the trace or différance. One of the repeated phrases in Specters of Marx is from Hamlet, ‘the time is out of joint’ and in his recent Radical Atheism: Derrida and the Time of Life, Martin Hägglund argues that it is possible to see all of Derrida’s work in relation to this concept of broken time. ‘Derrida’s aim,’ Hägglund argues, ‘is to formulate a general ‘hauntology’ (hantologie), in contrast to the traditional ‘ontology’ that thinks being in terms of self-identical presence. What is important about the figure of the specter, then, is that it cannot be fully present: it has no being in itself but marks a relation to what is no longer or not yet’ (Radical Atheism: Derrida and the Time of Life, Stanford University Press, 2008, p82)

Is hauntology, then, some attempt to revive the supernatural, or is it just a figure of speech? The way out of this unhelpful opposition is to think of hauntology as the agency of the virtual, with the spectre understood not as anything supernatural, but as that which acts without (physically) existing. The great thinkers of modernity, Freud as well as Marx, had discovered different modes of this spectral causality. The late capitalist world, governed by the abstractions of finance, is very clearly a world in which virtualities are effective, and perhaps the most ominous ‘spectre of Marx’ is capital itself. But as Derrida underlines in his interviews in the Ghost Dance film, psychoanalysis is also a ‘science of ghosts’, a study of how reverberant events in the psyche become revenants.

Referring back to Hägglund’s distinction between the no longer and the not yet, we can provisionally distinguish two directions in hauntology. The first refers to that which is (in actuality is) no longer, but which remains effective as a virtuality (the traumatic ‘compulsion to repeat’, a fatal pattern). The second sense of hauntology refers to that which (in actuality) has not yet happened, but which is already effective in the virtual (an attractor, an anticipation shaping current behaviour). The ‘spectre of communism’ that Marx and Engels had warned of in the first lines of the Communist Manifesto was just this kind of ghost: a virtuality whose threatened coming was already playing a part in undermining the present state of things.

In addition to being another moment in Derrida’s own philosophical project of deconstruction, Specters of Marx was also a specific engagement with the immediate historical context provided by the disintegration of the Soviet empire. Or rather, it was an engagement with the alleged disappearance of history trumpeted by Francis Fukuyama in his The End of History and the Last Man. What would happen now that actually existing socialism had collapsed, and capitalism could assume full spectrum dominance, its claims to global dominion were thwarted not any longer by the existence of a whole other bloc, but by small islands of resistance such as Cuba and North Korea? The era of what I have called ‘capitalist realism’ – the widespread belief that there is no alternative to capitalism – has been haunted not by the apparition of the spectre of communism, but by its disappearance. As Derrida wrote:


There is today in the world a dominant discourse…This dominating discourse often has the manic, jubilatory, and incantatory form that Freud assigned to the so-called triumphant phase of mourning work. The incantation repeats and ritualizes itself, it holds forth and holds to formulas, like any animistic magic. To the rhythm of a cadenced march, it proclaims: Marx is dead, communism is dead, very dead, and along with it its hopes, its discourse, its theories, and its practices. It says: long live capitalism, long live the market, here’s to the survival of economic and political liberalism! (Specters of Marx, p64)


Specters of Marx was also a series of speculations about the media (or post-media) technologies that capital had installed on its now global territory. In this sense, hauntology was by no means something rarefied; it was endemic in the time of ‘techno-tele-discursivity, techno-tele-iconicity’ ‘simulacra’ and ‘synthetic images’. This discussion of the ‘tele-’ shows that hauntology concerns a crisis of space as well as time. As theorists such as Virilio and Jean Baudrillard had long acknowledged – and Specters of Marx can also be read as Derrida settling his account with these thinkers – ‘tele-technologies’ collapse both space and time. Events that are spatially distant become available to an audience instantaneously. Neither Baudrillard nor Derrida would live to see the full effects – no doubt I should say the full effects so far – of the ‘tele-technology’ that has most radically contracted space and time, cyberspace. But here we have a first reason why the concept of hauntology should have become attached to popular culture in the first decade of the 21st century. For it was at this moment when cyberspace enjoyed unprecedented dominion over the reception, distribution and consumption of culture – especially music culture.

When it was applied to music culture – in my own writing, and in that of other critics such as Simon Reynolds and Joseph Stannard – hauntology first of all named a confluence of artists. The word confluence is crucial here. For these artists – William Basinski, the Ghost Box label, The Caretaker, Burial, Mordant Music, Philip Jeck, amongst others – had converged on a certain terrain without actually influencing one another. What they shared was not a sound so much as a sensibility, an existential orientation. The artists that came to be labelled hauntological were suffused with an overwhelming melancholy; and they were preoccupied with the way in which technology materialised memory – hence a fascination with television, vinyl records, audiotape, and with the sounds of these technologies breaking down. This fixation on materialised memory led to what is perhaps the principal sonic signature of hauntology: the use of crackle, the surface noise made by vinyl. Crackle makes us aware that we are listening to a time that is out of joint; it won’t allow us to fall into the illusion of presence. It reverses the normal order of listening according to which, as Ian Penman put it, we are habituated to the ‘re’ of recording being repressed. We aren’t only made aware that the sounds we are hearing are recorded, we are also made conscious of the playback systems we use to access the recordings. And hovering behind much sonic hauntology is the difference between analogue and digital: so many hauntological tracks have been about revisiting the physicality of analogue media in the era of digital ether. MP3 files remain material, of course, but their materiality is occulted from us, by contrast with the tactile materiality of vinyl records and even compact discs.

No doubt a yearning for this older regime of materiality plays a part in the melancholia that saturates hauntological music. As to the deeper causes of this melancholia, we need look no further than the title of Leyland Kirby’s album: Sadly, The Future Is No Longer What It Was. In hauntological music there is an implicit acknowledgement that the hopes created by postwar electronica or by the euphoric dance music of the 1990s have evaporated – not only has the future not arrived, it no longer seems possible. Yet at the same time, the music constitutes a refusal to give up on the desire for the future. This refusal gives the melancholia a political dimension, because it amounts to a failure to accommodate to the closed horizons of capitalist realism.


Not giving up the ghost

In Freud’s terms, both mourning and melancholia are about loss. But whereas mourning is the slow, painful withdrawal of libido from the lost object, in melancholia, libido remains attached to what has disappeared. For mourning to properly begin, Derrida says in Specters of Marx, the dead must be conjured away: ‘the conjuration has to make sure that the dead will not come back: quick, do whatever is needed to keep the cadaver localised, in a safe place, decomposing right where it was inhumed, or even embalmed as they liked to do in Moscow’ (Specters of Marx, p120) But there are those who refuse to allow the body to be interred, just as there is a danger of (over)killing something to such an extent that it becomes a spectre, a pure virtuality. ‘Capitalist societies,’ Derrida writes, ‘can always heave a sigh of relief and say to themselves: communism is finished, but it did not take place, it was only a ghost. They do no more than disavow the undeniable itself: a ghost never dies, it remains always to come and to come-back.’ (Specters of Marx, p123)

Haunting, then, can be construed as a failed mourning. It is about refusing to give up the ghost or – and this can sometimes amount to the same thing – the refusal of the ghost to give up on us. The spectre will not allow us to settle into/ for the mediocre satisfactions one can glean in a world governed by capitalist realism.

What’s at stake in 21st century hauntology is not the disappearance of a particular object. What has vanished is a tendency, a virtual trajectory. One name for this tendency is popular modernism. The cultural ecology that I referred to above – the music press and the more challenging parts of public service broadcasting – were part of a UK popular modernism, as were postpunk, brutalist architecture, Penguin paperbacks and the BBC Radiophonic Workshop. In popular modernism, the elitist project of modernism was retrospectively vindicated. At the same time, popular culture definitively established that it did not have to be populist. Particular modernist techniques were not only disseminated but collectively reworked and extended, just as the modernist task of producing forms which were adequate to the present moment was taken up and renewed. Which is to say that, although of course I didn’t realise it at the time, the culture which shaped most of my early expectations was essentially popular modernist, and the writing that has been collected in Ghosts Of My Life is about coming to terms with the disappearance of the conditions which allowed it to exist.

It’s worth pausing a moment here to distinguish the haunto-logical melancholia I’m talking about from two other kinds of melancholia. The first is what Wendy Brown calls ‘left melancholy’. On the face of it, what I’ve said risks being heard as a kind of leftist melancholic resignation: although they weren’t perfect, the institutions of social democracy were much better than anything we can hope for now, perhaps the best we can ever hope for…In her essay ‘Resisting Left Melancholy’, Brown attacks ‘a Left that operates without either a deep and radical critique of the status quo or a compelling alternative to the existing order of things. But perhaps even more troubling, it is a Left that has become more attached to its impossibility than to its potential fruitfulness, a Left that is most at home dwelling not in hopefulness but in its own marginality and failure, a Left that is thus caught in a structure of melancholic attachment to a certain strain of its own dead past, whose spirit is ghostly, whose structure of desire is backward looking and punishing.’ (Wendy Brown, ‘Resisting Left Melancholy’, boundary 2 26:3, 1999, p26). Yet much of what makes the melancholy Brown analyses so pernicious is its disavowed quality. Brown’s left melancholic is a depressive who believes he is realistic; someone who no longer has any expectation that his desire for radical transformation could be achieved, but who doesn’t recognise that he has given up. In her discussion of Brown’s essay in The Communist Horizon, Jodi Dean refers to Lacan’s formula: ‘the only thing one can be guilty of is giving ground relative to one’s desire’ and the shift that Brown describes – from a left that confidently assumed the future belonged to it, to a left that makes a virtue of its own incapacity to act – seems to exemplify the transition from desire (which in Lacanian terms is the desire to desire) to drive (an enjoyment through failure). The kind of melancholia I’m talking about, by contrast, consists not in giving up on desire but in refusing to yield. It consists, that is to say, in a refusal to adjust to what current conditions call ‘reality’ – even if the cost of that refusal is that you feel like an outcast in your own time…

The second kind of melancholia that hauntological melancholia must be distinguished from is what Paul Gilroy calls ‘postcolonial melancholia’. Gilroy defines this melancholia in terms of an avoidance; it is about evading ‘the painful obligations to work through the grim details of imperial and colonial history and to transform paralyzing guilt into a more productive shame that would be conducive to the building of a multicultural nationality that is no longer phobic about the prospect of exposure to either strangers or otherness.’ (Paul Gilroy, Postcolonial Melancholia, Columbia University Press, 2005, p99) It comes out of a ‘loss of a fantasy of omnipotence’. Like Brown’s left melancholy, then, postcolonial melancholia is a disavowed form of melancholia: its ‘signature combination’, Gilroy writes, is that of ‘manic elation with misery, self-loathing, and ambivalence.’ (Postcolonial Melancholia, p104) The postcolonial melancholic doesn’t (just) refuse to accept change; at some level, he refuses to accept that change has happened at all. He incoherently holds on to the fantasy of omnipotence by experiencing change only as decline and failure, for which, naturally, the immigrant other must be blamed (the incoherence here is obvious: if the postcolonial melancholic were really omnipotent, how could he be harmed by the immigrant?). At first sight, it might be possible to see hauntological melancholia as a variant of postcolonial melancholia: another example of white boy whingeing over lost privileges…Yet this would be to grasp what has been lost only in the terms of the worst kind of resentment ressentiment, or in terms of what Alex Williams has called negative solidarity, in which we are invited to celebrate, not an increase in liberation, but the fact that another group has now been immiserated; and this is especially sad when the group in question was predominantly working class.


Nostalgia compared to what?

This raises the question of nostalgia again: is hauntology, as many of its critics have maintained, simply a name for nostalgia? Is it about pining for social democracy and its institutions? Given the ubiquity of the formal nostalgia I described above, the question has to be, nostalgia compared to what? It seems strange to have to argue that comparing the present unfavourably with the past is not automatically nostalgic in any culpable way, but such is the power of the dehistoricising pressures of populism and PR that the claim has to be explicitly made. PR and populism propagate the relativistic illusion that intensity and innovation are equally distributed throughout all cultural periods. It is the tendency to falsely overestimate the past that makes nostalgia egregious: but, one of the lessons of Andy Beckett’s history of Britain in the 1970s, When The Lights Went Out is that, in many ways, we falsely underestimate a period like the 70s – Beckett in effect shows that capitalist realism was built on a myth-monstering of the decade. Conversely, we are induced by ubiquitous PR into falsely overestimating the present, and those who can’t remember the past are condemned to have it resold to them forever.

If the 1970s were in many respects better than neoliberalism wants us to remember them, we must also recognise the extent to which the capitalist dystopia of 21st-century culture is not something that was simply imposed on us – it was built out of our captured desires. ‘Almost everything I was afraid of happening over the past 30 years has happened,’ Jeremy Gilbert has observed. ‘Everything my political mentors warned might happen, since I was a boy growing up on a poor council estate (that’s a housing project, if you’re American) in the North of England in the early 80s, or a high–school student reading denunciations of Thatcherism in the left press a few years later, has turned out just as badly as they said it would. And yet I don’t wish I was living 40 years ago. The point seems to be: this is the world we were all afraid of; but it’s also sort of the world we wanted.’ (Jeremy Gilbert, ‘Moving on from the Market Society: Culture (and Cultural Studies) in a Post-Democratic Age’, http://www.opendemocracy.net/ourkingdom/jeremy-gilbert/moving-on-from-market-society-culture-and-cultural-studies-in-post-democra) But we shouldn’t have to choose between, say, the internet and social security. One way of thinking about hauntology is that its lost futures do not force such false choices; instead, what haunts is the spectre of a world in which all the marvels of communicative technology could be combined with a sense of solidarity much stronger than anything social democracy could muster.

Popular modernism was by no means a completed project, some pristine zenith that needed no further improvement. In the 1970s, certainly, culture was opened up to working-class inventiveness in a way that is now scarcely imaginable to us; but this was also a time when casual racism, sexism and homophobia were routine features of the mainstream. Needless to say, the struggles against racism and (hetero)sexism have not in the meantime been won, but they have made significant hegemonic advances, even as neoliberalism has corroded the social democratic infrastructure which allowed increased working class participation in cultural production. The disarticulation of class from race, gender and sexuality has in fact been central to the success of the neoliberal project – making it seem, grotesquely, as if neoliberalism were in some way a precondition of the gains made in anti-racist, anti-sexist and anti-heterosexist struggles.

What is being longed for in hauntology is not a particular period, but the resumption of the processes of democratisation and pluralism for which Gilroy calls. Perhaps it’s useful to remind ourselves here that social democracy has only become a resolved totality in retrospect; at the time, it was a compromise formation, which those on the left saw as a temporary bridgehead from which further gains could be won. What should haunt us is not the no longer of actually existing social democracy, but the not yet of the futures that popular modernism trained us to expect, but which never materialised. These spectres – the spectres of lost futures – reproach the formal nostalgia of the capitalist realist world.

Music culture was central to the projection of the futures which have been lost. The term music culture is crucial here, because it is the culture constellated around music (fashion, discourse, cover art) that has been as important as the music itself in conjuring seductively unfamiliar worlds. The destranging of music culture in the 21st century – the ghastly return of industry moguls and boys next door to mainstream pop; the premium put on ‘reality’ in popular entertainment; the increased tendency of those in music culture to dress and look like digitally and surgically enhanced versions of regular folk; the emphasis placed on gymnastic emoting in singing – has played a major role in conditioning us to accept consumer capitalism’s model of ordinariness. Michael Hardt and Antonio Negri are right when they say that the revolutionary take on race, gender and sexuality struggles goes far beyond the demand that different identities be recognised. Ultimately, it is about the dismantling of identity. The ‘revolutionary process of the abolition of identity, we should keep in mind, is monstrous, violent, and traumatic. Don’t try to save yourself—in fact, your self has, to be sacrificed! This does not mean that liberation casts us into an indifferent sea with no objects of identification, but rather the existing identities will no longer serve as anchors.’ (Michael Hardt and Antonio Negri, Commonwealth, Harvard University Press, 2011, p339) While Hardt and Negri are correct to warn of the traumatic dimensions of this transformation, as they are also aware, it also has its joyful aspects. Throughout the 20th century, music culture was a probe that played a major role in preparing the population to enjoy a future that was no longer white, male or heterosexual, a future in which the relinquishing of identities that were in any case poor fictions would be a blessed relief. In the 21st century, by contrast – and the fusion of pop with reality TV is absolutely indicative of this – popular music culture has been reduced to being a mirror held up to late capitalist subjectivity.

By now, it should already be very clear that there are different senses of the word hauntology at play in Ghosts Of My Life. There is the specific sense in which it has been applied to music culture, and a more general sense, where it refers to persistences, repetitions, prefigurations. There are also more or less benign versions of hauntology. Ghosts Of My Life will move amongst these different uses of the term.

The book is about the ghosts of my life, so there is necessarily a personal dimension to what follows. Yet my take on the old phrase ‘the personal is political’ has been to look for the (cultural, structural, political) conditions of subjectivity. The most productive way of reading the ‘personal is political’ is to interpret it as saying: the personal is impersonal. It’s miserable for anyone at all to be themselves (still more, to be forced to sell themselves). Culture, and the analysis of culture, is valuable insofar as it allows an escape from ourselves.

Such insights have been hard won. Depression is the most malign spectre that has dogged my life – and I use the term depression to distinguish the dreary solipsism of the condition from the more lyrical (and collective) desolations of haunto-logical melancholia. I started blogging in 2003 whilst still in such a state of depression that I found everyday life scarcely bearable. Some of these writings were part of the working through of the condition, and it’s no accident that my (so far successful) escape from depression coincided with a certain externalisation of negativity: the problem wasn’t (just) me but the culture around me. It’s clear to me that now the period from roughly 2003 to the present will be recognised – not in the far distant future, but very soon – as the worst period for (popular) culture since the 1950s. To say that the culture was desolate is not to say that there weren’t traces of other possibilities. Ghosts Of My Life is an attempt to engage with some of these traces.





Ghosts Of My Life: Goldie, Japan, Tricky


It must have been 1994 when I first saw Rufige Kru’s ‘Ghosts Of My Life’ on the shelves of a high street record store. The four-track EP had been released in 1993, but this was a time – before internet hype and online discographies – when the traces of the underground took longer to surface. The EP was a prime example of darkside Jungle. Jungle was a moment in what Simon Reynolds would come to call the ‘hardcore continuum’: the series of mutations on the British dance music underground triggered by the introduction of the breakbeat into Rave, passing from hardcore Rave into Jungle, Speed Garage, 2-step.

I’ll always prefer the name Jungle to the more pallid and misleading term drum and bass, because much of the allure of the genre came from the fact that no drums or bass guitar were played. Instead of simulating the already-existing qualities of ‘real’ instruments, digital technology was exploited to produce sounds that had no pre-existing correlates. The function of timestretching – which allowed the time signature of a sound to be changed, without its pitch being altered – transformed sampled breakbeats into rhythms that no human could play. Producers would also use the strange metallic excrescence that was produced when samples were slowed down and the software had to fill in the gaps. The result was an abstract rush that made chemicals all but redundant: accelerating our metabolisms, heightening our expectations, reconstructing our nervous systems.

It is also worth holding onto the name Jungle because it evokes a terrain: the urban Jungle, or rather the underside of a metropolis that was just in the process of being digitalised. It has sometimes seemed as if the use of the word ‘urban’ is a polite synonym for ‘black’ music. Yet it’s possible to hear ‘urban’, not as some disavowal of race, but as an invocation of the powers of cosmopolitan conviviality. At the same time, however, Jungle was by no means an unequivocal celebration of the urban. If Jungle celebrated anything, it was the lure of the dark. Jungle liberated the suppressed libido in the dystopian impulse, releasing and amplifying the jouissance that comes from anticipating the annihilation of all current certainties. As Kodwo Eshun argued, in Jungle there was a libidinisation of anxiety itself, a transformation of fight and flight impulses into enjoyment.

This was deeply ambivalent: at one level, what we were hearing here was a kind of sonic fictional intensification and extrapolation of the neoliberal world’s destruction of solidarity and security. Nostalgia for the familiarity of smalltown life was rejected in Jungle, but its digital city was devoid of the comfort of strangers: no-one could be trusted here. Jungle took many of its cues from the Hobbesian scenarios of 1980s films such as Blade Runner, Terminator and Predator 2. It’s no accident that all three of these films are about hunting. Jungle’s world was one in which entities – human as well as nonhuman – stalked each other for sport as well as for sustenance. Yet darkside Jungle was about the thrill of the chased, about the videogame euphoria–anxiety of eluding ruthless predators, as much as it was about the exhilaration of running prey to ground.

At another level, darkside Jungle projected the very future that capital can only disavow. Capital can never openly admit that it is a system based on inhuman rapacity; the Terminator can never remove its human mask. Jungle not only ripped the mask off, it actively identified with the inorganic circuitry beneath: hence the android/ death’s head that Rufige Kru used as their logo. The paradoxical identification with death, and the equation of death with the inhuman future was more than a cheap nihilist gesture. At a certain point, the unrelieved negativity of the dystopian drive trips over into a perversely utopian gesture, and annihilation becomes the condition of the radically new.

I was a postgraduate student in 1994, and I didn’t have either the nerve or the money to hang around specialist record shops to pick up all the latest releases. So I would access Jungle tracks in much the same fitful way that I had followed American comics in the 70s. I would pick them up where and when I could, usually on CD compilations issued long after their dubplate freshness had cooled. For the most part, it was impossible to impose any narrative on Jungle’s relentless flow. Fittingly for a sound that was so depersonalised and dehumanised, the names of the acts tended to be cryptic cyberpunk tags, disconnected from any biography or place. Jungle was best enjoyed as an anonymous electro-libidinal current that seemed to pass through producers, as a series of affects and FX that were de-linked from authors. It sounded like some audio unlife form, a ferocious, feral artificial intelligence that had been unwittingly called up in the studio, the breakbeats like genetically-augmented hounds straining to be free of the leash.

Rufige Kru were one of the few Jungle acts about which I knew a little. Because of Simon Reynolds’ evangelical pieces on Jungle in the now long-defunct Melody Maker, I was aware that Rufige Kru was one of the aliases used by Goldie, who, almost uniquely in the anonymity of the Jungle scene, was already becoming a recognisable face. If there was to be a face for this faceless music, then Goldie – a mixed race former graffiti artist with gold teeth – was a strong candidate. Goldie was formed by hip-hop culture, but irrevocably altered by Rave’s collective delirium. His career became a parable for a whole series of impasses. The temptation for any producer emerging from the scenius of the hardcore continuum was always to renounce the essentially collective nature of the conditions of production. It was a temptation that Goldie was unable to resist, but, tellingly, his records declined the very moment he stopped using impersonal, collective names for his projects, and started releasing them under the (albeit assumed) name Goldie. His first album, Timeless, smoothed out the anorganic angles of Jungle with the use of analogue instruments and an alarming jazz-funk tastefulness. Goldie became a minor celebrity, took a part in the BBC soap opera EastEnders, and only in 2008 released the kind of album that Rufige Kru should have put out 15 years before. The lesson was clear: urban British artists can only be successful if they depart from the scenius, if they leave behind the collective.

The first records Goldie and his collaborators released under the names Rufige Kru and Metalheads were still high on Rave’s carny buzz. 1992’s ‘Terminator’ was the most epochal: jittery with excitable rave stabs, its phased and timestretched beats suggested aberrant, impossible geometries, while its vocal samples – from Linda Hamilton in Terminator – talked of time paradoxes and fatal strategies. The record sounded like a commentary on itself: as if the temporal anomalies that Hamilton described – ‘you’re talking about things that I haven’t done yet in the past tense’ – were made physical in the vertiginously imploding sound.

As Rufige Kru progressed their sound became sleeker. Where the early records put one in mind of an assemblage of dismembered organs that had been crudely stitched together, the later releases more closely resembled mutants that had been genetically engineered. The unruly and volatile Rave elements had gradually drained away, to be replaced by textures that were starker, moodier. The titles – ‘Dark Rider’, ‘Fury’, ‘Manslaughter’ – told their own story. As you listened, you felt like you were being pursued through a near-future brutalist arcade. Vocal samples were cut back, and became more subdued and ominous. ‘Manslaughter’ features one of the most electrifying lines from Blade Runner’s rogue replicant Roy Batty: ‘If only you could see what I’ve seen, through your eyes’ – the perfect slogan for Jungle’s new mutants, engineered by street science to have heightened senses but a shorter life span.

I bought any Rufige Kru record that I came upon, but ‘Ghosts Of My Life’ brought a special tingle of intrigue because of its title, with its suggestion of Japan’s 1981 art pop masterpiece, ‘Ghosts’. When I played the ‘Ghosts Of My Life’ 12’, I quickly realised with a shiver of exhilaration that the pitched down voice repeating the title phrase did indeed belong to Japan’s David Sylvian. But this wasn’t the only trace of ‘Ghosts’. After some atonal washes and twitchy breakbeats, the track lurched to a sudden halt, and – in a moment that still takes my breath away when I listen to it now – a brief snatch of the spidery, abstract electronics instantly recognizable from the Japan record leapt into the chasm, before being immediately consumed by viscous bass ooze and the synthetic screeches that were the sonic signatures of darkside Jungle.

Time had folded in on itself. One of my earliest pop fixations had returned, vindicated, in an unexpected context. Early 80s New Romantic synthpop, reviled and ridiculed in Britain, but revered in the dance music scenes of Detroit, New York and Chicago, was finally coming home to roost in the UK underground. Kodwo Eshun, then at work on his More Brilliant than the Sun: Adventures in Sonic Fiction, would argue that synthpop played the same founding role for Techno, hip-hop and Jungle as delta blues did for rock, and it was as if a disavowed part of myself – a ghost from another part of my life – was being recovered, although in a permanently altered form.


‘Just when I think I’m winning’

In 1982, I taped ‘Ghosts’ from the radio and chain-listened to it: pressing play, rewinding the cassette, repeating. ‘Ghosts’ is a record which, even now, compels you to keep replaying it. Partly, that’s because of the way the record teems with detail: you never feel you’ve fully grasped it all.

Nothing else that Japan recorded was like ‘Ghosts’. It as an anomaly, not only because of its seeming confessionalism, exceptional in the work of a group which favoured aesthetic poses over emotional expression, but also because of its arrangement, its texture. Elsewhere on Tin Drum – the 1981 album from which ‘Ghosts’ came – Japan had developed a plastic ethno-funk, where electronics flitted through the elasticated rhythmic architecture created by the bass and drums. On ‘Ghosts’, however, there are no drums and no bassline. There is only percussion that sounds like metallic vertebrae being gently struck, and a suite of sounds so austerely synthetic that they could have come from Stockhausen.

‘Ghosts’ begins with chimes that make you feel like you are inside some metallic clock. The air is charged, an electrical field through which unintelligible radio-wave chitterings pass. At the same time, the track is pervaded by an immense stillness, a poise. Watch the group’s extraordinary live performance of ‘Ghosts’ on the Old Grey Whistle Test. They look as if they are tending their instruments rather than playing them.

Only Sylvian appears animated, and then it’s only his face, half-hidden by the heavy fringe, that moves. The mannered angst of his vocal sits oddly with the electronic austerity of the music. Its sense of enervated foreboding is broken by the only trace of melodrama in the song – the synth stabs which, simulating the kind of strings you’d hear on a movie thriller-score, cue in the chorus. ‘Just when I think I’m win-ning/ when I’ve broken every door/ the ghosts of my life/ blow wild-er/ than the win-d’…

What, exactly, are the ghosts that haunt Sylvian? The song derives much of its potency from declining to answer, from its lack of specificity: we can fill in the blanks with our own spectres. What’s clear is that it isn’t external contingencies which ruin his wellbeing. Something from his past – something he wants to have left behind – keeps returning. He can’t leave it behind because he carries it with him. Is he anticipating the destruction of his happiness, or has the destruction already happened? The present tense – or rather the hesitation between past and present tense – creates an ambiguity, suggesting a fatalistic eternity, a compulsion to repeat – a compulsion that might be a self-fulfilling prophecy. The ghosts return because he fears they will…

It’s hard not to hear ‘Ghosts’ as a reflection of sorts on Japan’s career up to that point. The group was the culmination of a certain English take on art pop that began with Bowie and Roxy in the early 70s. They came from Beckenham, Catford, Lewisham the unglamorous conurbation where Kent joins South London – the same suburban hinterland from which David Bowie, Billy Idol and Siouxsie Sioux had come. As with most English art pop, Japan found their environment only a negative inspiration, something to escape from. ‘There was a conscious drive away from everything that childhood represented,’ Sylvian has remarked. Pop was the portal out of the prosaic. Music was only part of it. Art pop was a finishing school for working class autodidacts, where, by following up the clues left behind by earlier pioneers – the allusions secreted in lyrics, in track titles or in interview references – you could learn about things that weren’t on the formal curriculum for working class youth: fine art, European cinema, avant-garde literature…Changing your name was the first step, and Sylvian had traded his given name (Batt) for one that referred to Sylvain Sylvain from the New York Dolls, the group whose style Japan had begun by imitating.

By the time of ‘Ghosts’, all of the ersatz Amerikan swagger of this Dolls phase is long forgotten, and Sylvian has long since perfected his plastic mass-produced copy of Bryan Ferry. In his analysis of Bryan Ferry’s voice, Ian Penman argues that its peculiar quality came from an only partly successful attempt to get his Geordie accent to forge a classic, timeless Englishness. Sylvian’s singing voice is the faking of a fake. The almost whinnying quality of Ferry’s angst is retained, but transposed into a pure styling devoid of emotional content. It is culture(d), not natural at all; prissy, ultra-affected, and, for that very reason, strangely lacking in affect. It couldn’t contrast more with Sylvian’s speaking voice at the time – awkward, tentative, strongly bearing all the traces of class and South London which his singing voice had sought to remove. ‘Sons of pioneers/ are hungry men.’

‘Ghosts’ was paralysed by very English anxieties: you could imagine Pip from Great Expectations singing it. In England, working class escape is always haunted by the possibility that you will be found out, that your roots are showing. You won’t know some crucial rule of etiquette that you should. You will pronounce something wrongly – mispronunciation is a constant source of anxiety for the autodidact, because books don’t necessarily tell you how to say words. Is ‘Ghosts’ the moment when art pop confronts this fear – that class will out, that one’s background can never be transcended, that the rude spectres of Lewisham will return no matter how far East you travel?

Japan had pursued art pop into a sheer superficiality, which exceeded even their inspirations in its depthless aestheticism. Tin Drum, the 1981 album from which ‘Ghosts’ came, was art pop as Barthes pop, a conspicuous playing with signs for their own seductive sake. The album cover immediately drew you into their heavily confected world: Sylvian, his heavily sprayed, peroxided fringe falling artfully over his Trevor Horn specs, sits in a simulation of a simple Chinese dwelling, chopsticks in hand, as a Mao poster peels from the wall behind him. Everything is posed, every Sign selected with a fetishistic fastidiousness. Check the way his eyeshadow gives his eyelids an almost opiated heaviness – but, at the same time, everything is so painfully fragile; his face a Noh-mask, anemically ultra-white, his body posture ragdoll drained. Here he is, one of the last glam princes, and perhaps the most magnificent – his face and body rare and delicate works of art, not extrinsic to, or lesser than, the music, but forming an integral component of the overall concept. All – social, political, cultural – meaning seems to be drained from these references. When Sylvian sings ‘Red Army needs you’ on the closing track, ‘Cantonese Boy’, it is in the same spirit of semiotic orientalism: the Chinese and Japanese Empires of signs are reduced to images, exploited and coveted for their frission.

By the time of Tin Drum, Japan have perfected their transition from New York Dolls-trash-hounds to gentlemen connoisseurs, from working class Beckenham youth into cosmopolitan men about town. (Or they’ve achieved as much as is possible: ‘Ghosts’ suggests that the transition will never be so successful as to eliminate anxiety: the more you’ve disguised your background, the more it will hurt when it is exposed.) Tin Drum’s superficiality is the superficiality of the (glossy) photograph, the group’s detachment that of the photographer. Images are decontextualised, then re-assembled to form an ‘Oriental’ panorama that is strangely abstract: a Far East as surrealist novelist Raymond Roussel might have reimagined it. Like Ferry, Sylvian remains Subject as well as Object: not only the frozen Image, but also he who assembles images, not in any pathological, Peeping Tom sense, but in a coolly detached way. The detachment, naturally, is a performance, concealing anxiety even as it sublimates it. The words are little labyrinths, enigmas with no possible solution – the appearance of enigmas, perhaps – false-fronted follies decorated with Chinese and Japanese motifs.

Sylvian’s voice belongs to this masquerade. Even on ‘Ghosts’, Sylvian’s voice does not ask to be taken at face value. It is not a voice that reveals, or even pretends to reveal, it is a voice to hide behind, just like the make-up, the conspicuously-worn sino-signs. It’s not only the fixation on geography that makes Sylvian seem like a tourist, an outside observer even in his own ‘inner’ life. His voice seems to come entirely from his head, barely from his body at all.

And after this? Japan would fall apart, while Duran Duran were already more than half way towards taking a lumpen version of Japan’s schtick into superstardom. For Sylvian, there was a pursuit of ‘authenticity’, which was connoted by two things: the turn away from rhythm and the embracing of ‘real’ instruments. The wiping away of the cosmetics, the quest for Meaning, the discovery of a Real Self. Yet, until 2003’s Blemish, Sylvian’s solo records seemed as if they were straining towards an emotional authenticity that his voice could never quite deliver, only now they lacked the alibi of aestheticism.

Tin Drum was Japan’s final studio album, but it was also one of the last moments in English art pop. One future had quietly died, but others would surface.


‘Your eyes resemble mine…’

A fragment of Japan’s ‘Ghosts’ washed up 14 years later, on Tricky’s first single, ‘Aftermath’. Here it wasn’t sampled, but cited, by Tricky’s mentor, fellow Bristolian Mark Stewart. In the background of the track’s loping-shanty rhythms, you can hear Stewart speak-sing the lines ‘just when I thought I was winning, just when I thought I could not be stopped…‘ The use of the Japan reference and the presence of Stewart – a major figure in Bristol postpunk since his time with The Pop Group in the 1970s – were already powerful clues that Tricky’s positioning as a ‘trip-hop’ artist was reductive and misleading. Too often, the label trip-hop would be applied to what was in effect a black music with the ‘blackness’ muted or excised (hip-hop without rap). The ‘trip’ in Tricky’s music had less to do with psychedelics and more to do with the fuggy indolence of marijuana. But Tricky pursued ganja inertia well beyond stoner lassitude into a visionary condition, in which rap’s aggression and braggadocio weren’t so much removed as refracted in the heat haze of a dreamy, hydroponic humidity.

On the face of it, Tricky’s ra(s)p could be heard as the British answer to hip-hop, but, on a more subterranean level, what he was also taking up and renewing were strands in postpunk and art pop. Tricky counts postpunk acts like Blondie, The Banshees, The Cure (‘the last great pop band, I think’, he says) as his precursors. It’s not as simple as opposing this lineage to the soul, funk and dub references which were so obvious in Tricky’s earliest music. Postpunk and art pop had already drawn substantially upon funk and dub. ‘I grew up in a white ghetto,’ Tricky said when I interviewed him in 2008. ‘My Dad’s Jamaican, my grandmother is white. When I was growing up, till I was about 16, everything was normal. When I moved to an ethnic ghetto, I had friends there and my friends would say, “Why do you hang out with those skinhead guys, the white guys?” and my skinhead friends were like, “Why you hanging out with those black guys?” I couldn’t get it, I couldn’t understand it. I could always go to both worlds, I could go to a reggae club and then a white club and not even notice it because my family is all different colours, different shades. So at Christmas, you got a white person, black person, African looking person, Asian looking person…we didn’t notice it, my family are colour blind. But all of a sudden things started moving around, learning bad habits, people whispering to you, like, “Why you hanging around with those white guys?” These are kids I grew up with since five years old, the guys I grew up with saying “why you hanging out with those black guys?” Then I see The Specials on TV, these white and black guys getting together.’

Tricky appeared at the very moment when the reactionary pantomime of Britpop – a rock which had whitewashed out contemporary black influences – was moving towards dominance. The phony face-off between Blur and Oasis which preoccupied the media was a distraction from the real fault lines in British music culture at the time. The conflict that really mattered was between a music which acknowledged and accelerated what was new in the 90s – technology, cultural pluralism, genre innovations – and a music which took refuge in a monocultural version of Britishness: a swaggering white boy rock built almost entirely out of forms that were established in the 1960s and 1970s. This was a music designed to reassure anxious white males at a moment when all of the certainties they had previously counted on – in work, sexual relations, ethnic identity – were coming under pressure. As we now know, Britpop would win the struggle. Tricky would slink away to become the herald of a future for British music that never materialised. (A rapprochement of sorts between Tricky and Britpop was – thank-fully – missed. Blur’s Damon Albarn was supposed to guest on the album Tricky recorded under the name Nearly God – alongside The Specials’ Terry Hall, amongst many others – but the track that the pair recorded together was removed from the album before it was released.)

When Maxinquaye was released in 1995, Tricky was immediately anointed as the voice of a mute, depoliticised generation, the wounded prophet who absorbed and transmitted a decade’s psychic pollution. The extent of this adulation can be gauged by the origin of the name Nearly God: a German journalist had asked him ‘what’s it like to be God? Well, nearly God?’ Instead of taking up his assigned role as the imp of the perverse in 90s mainstream pop, though, Tricky sidled off into the sidelines, a half-forgotten figure. So much so, that when he appeared as a guest at Beyoncé’s 2011 Glastonbury performance, it provoked a gasp of shock – as if, for a moment, we’d stumbled into some alternative reality where Tricky was where he deserved to be, a glamorous gargoyle on the edifice of 21st century pop. All-too-symbolically, however, Tricky’s microphone didn’t seem to be switched on, and he could barely be heard.

‘On Maxinquaye,’ Ian Penman wrote in his landmark March 1995 essay for The Wire magazine, ‘Tricky sounds like ghosts from another solar system’. The spectrality of Tricky’s music, the way it refused to step up or represent, the way it slurred between lucidity and inarticulacy, made for a sharp contrast with the multicoloured brashness of what Penman called ‘the Face- cover/Talkin Loud/Jazzie B nexus of groovy One World vibery’. What’s so significant about the version of multiculturalism that Tricky and Goldie proffered was its refusal of earnestness and worthiness. Theirs was not a music that petitioned for inclusion in any kind of ordinariness. Instead, it revelled in its otherworld- liness, its science-fictional glamour. Like art pop’s first pioneer, Bowie, it was about identification with the alien, where the alien stood in for the technologically new and the cognitively strange – and ultimately for forms of social relations that were as yet only faintly imaginable. Bowie was by no means the first to make this identification: loving the alien was a gesture that self-mytholo-gizing black magi – Kodwo Eshun’s ‘sonic fictional’ canon of Lee Perry, George Clinton, Sun Ra – had made long before Bowie first did it. Identifying with the alien – not so much speaking for the alien as letting the alien speak through you – was what gave 20th century popular music much of its political charge. Identification with the alien meant the possibility of an escape from identity, into other subjectivities, other worlds.

There was also identification with the android. ‘Aftermath’ includes a sample of dialogue from Blade Runner: ‘I’ll tell you about my mother’, the anti-Oedipal taunt that the replicant Leon throws at his interrogator-tormentor before killing him. ‘Is it merely coincidence that the Sylvian quote and the Blade Runner lift converge in the same song?’, Penman asks.


‘Ghosts’…Replicants? Electricity has made us all angels. Technology (from psycho-analysis to surveillance) has made us all ghosts. The replicant (‘YOUR EYES RESEMBLE MINE…‘) is a speaking void. The scary thing about ‘Aftermath’ is that it suggests that nowadays WE ALL ARE. Speaking voids, made up only of scraps and citations… contaminated by other people’s memories…adrift…


When I met Tricky in 2008, he referred unbidden to the line from ‘Aftermath’ that Penman picks up on here. ’My first lyric ever on a song was ‘your eyes resemble mine, you’ll see as no others can’. I never had any kids then, so what am I talking about? Who am I talking about? My daughter () Maisie wasn’t born. My mother used to write poetry but in her time she couldn’t have done anything with that, there wasn’t any opportunity. It’s almost like she killed herself to give me the opportunity, my lyrics, I can never understand why I write as a female; I think I’ve got my Mum’s talent, I’m her vehicle. So I need a woman to sing that.’

Hauntology, then, telepathy, the persistence of the no longer…You don’t have to believe in the supernatural to recognise that the family is a haunted structure, an Overlook Hotel full of presentiments and uncanny repetitions, something that speaks ahead of us, instead of us…From the start – like all of us – Tricky was haunted, and the crepitational-texture of 21st century hauntology was already being auditioned on Tricky’s earliest recordings. When I first heard Burial a decade later, I would immediately reach for Tricky’s first album Maxinquaye as a point of comparison. It wasn’t only the use of vinyl crackle, so much a signature of both Maxinquaye and Burial, that suggested the affinity. It was also the prevailing mood, the way suffocating sadness and mumbling melancholy bled into lovelorn eroticism and dreamspeech. Both records feel like emotional states transformed into landscapes, but where Burial’s music conjures urban scenes under Blade Runner perma-drizzle, Maxinquaye feels as if it is taking place in a desert as delirial and Daliesque as the initiatory space that the characters pass through in Nic Roeg’s Walkabout: the land is scorched, cracked and barren, but there are occasional bursts of verdant lushness (on the queasily erotic ‘Abbaon Fat Tracks’, for instance, we could have strayed into the ruined pastoral of Talk Talk’s Spirit of Eden).

‘Your eyes resemble mine…’ From the very beginning, speaking in his dead mother’s voice, a semi-benign Norman Bates, Tricky was conscious of his (dis)possession by female spectres. With his predilection for cosmetics and cross-dressing, he looked like one of the last vestiges of the glam impulse in British pop: his gender ambivalence a welcome antidote to Britpop’s lumpen laddishness. It’s clear that gender indeterminacy is no pantomime mummery for him, but something that goes right to the core of his music. Saying that Tricky ‘writes from a female point of view’ fails to capture the uncanniness of what he does, since he also induces women to sing from what seems to be a male perspective. ‘I like putting women in a male role, to have the woman play the strength and the man be the weak. I was brought up, one of my uncles was in jail for 30 years and the other for 15 years. I didn’t see my dad, I was brought up by my grandmother and my auntie so I’ve seen my grandmother fight in the street. I’ve seen my auntie and my grandmother have fistfights, I’ve seen my grandmother grab my auntie’s arm and close it in the door and break her arm fighting over meat. So I see women as tough. They fed me, they clothed me, my grandmother taught me to steal, my auntie taught me to fight, she sent me to boxing when I was 15. If men go to war, you stand in one field, I stand in another, we shoot each other, but what’s the hardest is when you are at home and you gotta listen to kids cry and you gotta feed ‘em. That’s tough, I’ve seen no men around, I’ve seen my uncle go jail for seven years, then ten years, my other uncle; my Dad never rang. Women keep it together, keep the food on the table, defend us, defend the children, like if anyone fucked with us they would be down the school. I’ve never seen men do that for me, I’ve never seen men there for me like that. All I know is women.’

Gender doesn’t dissolve here into some bland unisex mush; instead it resolves into an unstable space in which subjectivity is continually sliding from male to female voice. It is an art of splitting which is also an art of doubling. Through the women who sing for/as him, Tricky becomes less than one, a split subject that can never be restored to wholeness. Yet their voicing of his incompleteness also makes him more than one, a double in search of a lost other half it will never recover. Either way, what Tricky unsettles – both as a vocalist and as a writer/ producer who coaxes singing from an Other – is the idea of the voice as a rock solid guarantor of presence and identity. His own weakened, recessed voice, all those croaks, mumbles and murmurs, has always suggested a presence that was barely there, something supplementary rather than centred. But the main – usually female – voice on his songs also sounds absented and abstracted. What the voices of his female singers – flat, drained, destitute of ordinary affective cadences – most resemble is the sound of a medium, a voice being spoken by something else.

‘So this is the aftermath…’ It is not that Tricky possesses female singers; more that he induces them into sharing his trance states. The words that come to him from a lost female source are returned to a female mouth. ‘I’m already on the other side’, as Martina Topley-Bird sang on ‘I Be The Prophet’ from the Nearly God LP. Tricky’s upbringing was particularly gothic. ‘My grandmother used to keep me at home because my stepgrandfather used to be out working, and she used to watch all these black and white horror movies, vampire movies, and it was like growing up in a movie. She used to sit me in the middle of the floor, cause she lost my mum, her daughter. She’d be playing Billie Holiday, smoking a cigarette and would say things like “you look like your Mum,” watching me. I was always my Mum’s ghost. I grew up in a dreamlike state. One time I’ve seen a suicide off an NCP car park and the police took me down to see what I saw and the next day in the Evening Post there was my name in there. I woke up and it was on the fridge, my grandmother had put it on the fridge like I was famous.’

The one who is possessed is also dispossessed – of their own identity and voice. But this kind of dispossession is of course a precondition for the most potent writing and performance. Writers have to tune into other voices; performers must be capable of being taken over by outside forces – and Tricky can be a great live performer because of his capacity to work himself up into a state of head-shaking shamanic self-erasure. Like the occult, religion provides a symbolic repertoire which deals with the idea of an alien presence using the tongue, of the dead having influence on the living, and Tricky’s language has always been saturated with biblical imagery. Maxinquaye’s purgatorial landscape was littered with religious signs, while Pre-Millennium Tension exhibited what seemed like religious mania: ‘I saw a Christian in Christiansands, a devil in Helsinki.’ ‘Here come the Nazarene/look good in a magazine…Mary Magdalene that’ll be my first sin.’

When I interviewed Tricky he had just released the single, ‘Council Estate’. Here, class spectres spoke – but not for the first time in Tricky’s work. Class rage could be detected smouldering in many of his tracks from the beginning. ‘Master your language/and until then, I’ll create my own,’ he warned on 1996’s ‘Christiansands’, casting himself as the proletarian Caliban plotting revenge on his alleged betters. He is acutely aware of the way in which class determines destiny. ‘Breaking into a house or car equals locksmiths, insurance, it’s all making money off me. The longer I’m in prison you’re making more money. Modern-day slavery: instead of slaves, they turn them into criminals.’

Tricky called the album from which ‘Council Estate’ came Knowle West, after the area of Bristol in which he grew up. ‘When I was at school, there was one certain teacher who said, when you go for a job, as soon as you put your postcode down and they know you’re from Knowle West, you ain’t gonna get the job. So lie, if you’re going to fill in your application forms, lie.’

‘Council Estate’ conceived of resentment as a motivating force and success as revenge. It wasn’t about leaving your past behind, as Sylvian wanted to, it is about succeeding so that your class origins can be forced back down the throat of those who said you couldn’t succeed. Like so many working class pop stars before him – including Sylvian – success provided vindication for Tricky and gave him access to a world which both attracted and appalled him. 1996’s ‘Tricky Kid’ was his take on the theme of class dislocation that has preoccupied British pop since at least as far back as The Kinks. It was the best song about a working class male projected out of their milieu into the pleasure gardens of the hyper–successful since The Associates’ ‘Club Country’ (‘A drive from nowhere leaves you in the cold…every breath you breathe belongs to someone there’). With its febrile, Jacob’s Ladder–like vision of leering hedonism – ‘coke in your nose…everyone wants to be naked and famous’ – ‘Tricky Kid’ anticipated the way in which, in the first decade of the 21st century, working class ambitions would be bought off by the fool’s gold of celebrity culture and reality TV. ‘Now they call me superstar…,’ it demonically proclaimed, a line echoed in the refrain of ‘Council Estate’. Why is ‘superstar’ such an important word for him? ‘Because it’s such a stupid word in a way. What used to happen is that you make an album, and if your album’s successful, fame is almost part of the game. When I was starting off, I just wanted to make a good album, I wanted to make something that no one’s ever heard before – I wasn’t interested in anything else.’





01: THE RETURN OF THE 70S





No Longer the Pleasures: Joy Division


Adapted from k–punk post, January 9, 2005


If Joy Division matter now more than ever, it’s because they capture the depressed spirit of our times. Listen to JD now, and you have the inescapable impression that the group were cataton-ically channelling our present, their future. From the start their work was overshadowed by a deep foreboding, a sense of a future foreclosed, all certainties dissolved, only growing gloom ahead. It has become increasingly clear that 1979-80, the years with which the group will always be identified, was a threshold moment – the time when a whole world (social democratic, Fordist, industrial) became obsolete, and the contours of a new world (neoliberal, consumerist, informatic) began to show themselves. This is of course a retrospective judgement; breaks are rarely experienced as such at the time. But the 70s exert a particular fascination now that we are locked into the new world – a world that Deleuze, using a word that would become associated with Joy Division, called the ‘Society of Control’. The 70s is the time before the switch, a time at once kinder and harsher than now. Forms of (social) security then taken for granted have long since been destroyed, but vicious prejudices that were then freely aired have become unacceptable. The conditions that allowed a group like Joy Division to exist have evapo-rated; but so has a certain grey, grim texture of everyday life in Britain, a country that seemed to have given up rationing only reluctantly.

By the early 2000s, the 70s was long enough ago to have become a period setting for drama, and Joy Division were part of the scenery. This was how they featured in Michael Winterbottom’s 24 Hour Party People (2002). The group were little more than a cameo here, the first chapter in the story of Factory records and its buffoon-genius impresario Tony Wilson. Joy Division assumed centre stage in Anton Corbijn’s Control (2007), but the film didn’t really connect. For those who knew the story, it was a familiar trip; for those not already initiated, however, the film didn’t do enough to convey the group’s sorcerous power. We were taken through the story, but never drawn into the maelstrom, never made to feel why any of it mattered. Perhaps this was inevitable. Rock depends crucially on a particular body and a particular voice and the mysterious relationship between the two. Control could never make good the loss of Ian Curtis’s voice and body, and so ended up as arthouse karaoke naturalism; the actors could simulate the chords, could ape Curtis’s moves, but they couldn’t forge the vortical charisma, couldn’t muster the unwitting necromantic art that transformed the simple musical structures into a ferocious expressionism, a portal to the outside. For that you need the footage of the group performing, the sound of the records. Which is why, of the three films featuring the group, Grant Gee’s 2007 documentary, Joy Division, patched together from super-8 fragments, TV appearances, new interviews and old images of postwar Manchester, was most effective at transporting us back to those disappeared times. Gee’s film begins with an epigraph from Marshall Berman’s All That Is Solid Melts Into Air: The Experience Of Modernity: ‘To be modern is to find ourselves in an environment that promises us adventure, power, joy, growth, transformation of ourselves and the world – and, at the same time that threatens to destroy everything we have, everything we know, everything we are.’ Where Control tried to conjure the presence of the group, but left us only with a tracing, an outline, Joy Division is organised around a vivid sense of loss. It is selfconsciously a study of a time and a place, both of which are now gone. Joy Division is a roll call of disappeared places and people – so many dead, already: not only Curtis, but also the group’s manager Rob Gretton, their producer Martin Hannett and of course Tony Wilson. The film’s coup, its most electric moment, the sound of a dead man wandering in the land of the dead: a scratchy old cassette recording of Ian Curtis being hypnotised into ‘a past life regression’. I travelled far and wide through many different times. A slow, slurred voice channelling something cold and remote. ‘How old are you?’ ‘28’, an exchange made all the more chilling because we know that Curtis would die at the age of 23.


Asylums with doors open wide

I didn’t hear Joy Division until 1982, so, for me, Curtis was always-already dead. When I first heard them, aged 14, it was like that moment in John Carpenter’s In the Mouth of Madness when Sutter Cane forces John Trent to read the novel, the hyper-fiction, in which he is already immersed: my whole future life, intensely compacted into those sound images – Ballard, Burroughs, dub, disco, Gothic, antidepressants, psych wards, overdoses, slashed wrists. Way too much stim to even begin to assimilate. Even they didn’t understand what they were doing. How on earth could I, then?

New Order, more than anyone else, were in flight from the mausoleum edifice of Joy Division, and they had finally achieved severance by 1990. The England world cup song, cavorting around with beery, leery Keith Allen, a man who more than any other personifies the quotidian masculinism of overground Brit bloke culture in the late 80s and 90s, was a consummate act of desublimation. This, in the end, was what Kodwo Eshun called the ‘price of escaping the anxiety of influence (the influence of themselves)’. On Movement the group were still in post-traumatic stress, frozen into a barely communicative trance (‘The noise that surrounds me/ so loud in my head…’)

It was clear, in the best interviews the band ever gave – to Jon Savage, a decade and a half after Curtis’s death – that they had no idea what they were doing, and no desire to learn. Of Curtis’ disturbing-compelling hyper-charged stage trance spasms and of his disturbing-compelling catatonic downer words, they said nothing and asked nothing, for fear of destroying the magic. They were unwitting necromancers who had stumbled on a formula for channelling voices, apprentices without a sorcerer. They saw themselves as mindless golems animated by Curtis’ vision(s). (Thus, when he died, they said that they felt they had lost their eyes…)

Above all – and even if only because of audience reception – they were more than a pop group, more than entertainment, that much is obvious. We know all the words as if we wrote them ourselves, we followed stray hints in the lyrics out to all sorts of darker chambers, and listening to the albums now is like putting on a comfortable and familiar set of clothes…. But who is this ‘we’? Well, it might have been the last ‘we’ that a whole generation of not-quite-men could feel a part of. There was an odd universality available to Joy Division’s devotees (provided you were male of course).

Provided you were male of course… The Joy Division religion was, self-consciously, a boys’ thing. Deborah Curtis: ‘Whether it was intentional or not, the wives and girlfriends had gradually been banished from all but the most local of gigs and a curious male bonding had taken place. The boys seemed to derive their fun from each other.’ (Deborah Curtis, Touching from a Distance, 77) No girls allowed…

As Curtis’s wife, Deborah was barred from rock’s pleasure garden, and could not pass into the cult of death that lay beyond the pleasure principle. She was just left to clear up the mess.

If Joy Division were very much a boys’ group, their signature song, ‘She’s Lost Control’ saw Ian Curtis abjecting his own disease, the ‘holy sickness’ of epilepsy, onto a female Other. Freud includes epileptic fits – along, incidentally, with a body in the grip of sexual passion – as examples of the unheimlich, the unhomely, the strangely familiar. Here the organic is slaved to the mechanical rhythms of the inorganic; the inanimate calls the tune, as it always does with Joy Division. ‘She’s Lost Control’ is one of rock’s most explicit encounters with the mineral lure of the inanimate. Joy Division’s icy-spined undeath disco sounds like it has been recorded inside the damaged synaptic pathways of a brain of someone undergoing a seizure, Curtis’ sepulchral, anhedonic vocals sent back to him – as if they were the voice of an Other, or Others – in long, leering expressionistic echoes that linger like acrid acid fog. ‘She’s Lost Control’ traverses Poe-like cataleptic black holes in subjectivity, takes flatline voyages into the land of the dead and back to confront the ‘edge of no escape’, seeing in seizures little deaths (petil mals as petit morts) which offer terrifying but exhilarating releases from identity, more powerful than any orgasm.


In this colony

Try to imagine England in 1979 now…

Pre-VCR, pre-PC, pre-C4. Telephones far from ubiquitous (we didn’t have one till around 1980, I think). The postwar consensus disintegrating on black and white TV.

More than anyone else, Joy Division turned this dourness into a uniform that self-consciously signified absolute authenticity; the deliberately functional formality of their clothes seceding from punk’s tribalised anti-Glamour, ‘depressives dressing for the Depression’ (Deborah Curtis). It wasn’t for nothing that they were called Warsaw when they started out. But it was in this Eastern bloc of the mind, in this slough of despond, that you could find working class kids who wrote songs steeped in Dostoyevsky, Conrad, Kafka, Burroughs, Ballard, kids who, without even thinking about it, were rigorous modernists who would have disdained repeating themselves, never mind disinterring and aping what had been done 20, 30 years ago (the 60s was a fading Pathe newsreel in 1979).

Back in ‘79, Art Rock still had a relationship to the sonic experimentation of the Black Atlantic. Unthinkable now, but White Pop then was no stranger to the cutting edge, so a genuine trade was possible. Joy Division provided the Black Atlantic with some sonic fictions it could re-deploy – listen to Grace Jones’s extraordinary cover of ‘She’s Lost Control’, or Sleazy D’s ‘I’ve Lost Control’, or even to Kanye West’s 808s and Heartbreak (with its sleeve references to Saville’s ‘Blue Monday’ cover design, and its echoes of Atmosphere and ‘In A Lonely Place’). For all that, Joy Division’s relationship to black pop was much more occluded than that of some of their peers. Postpunk’s break from lumpen punk R and R consisted in large part in an ostentatiously flagged return-reclaiming of Black Pop: funk and dub especially. There was none of that, on the surface at least, with Joy Division.

But a group like PiL’s take on dub, now, sounds a little laborious, a little literal, whereas, Joy Division, like The Fall, came off as a white anglo equivalent of dub. Both Joy Division and The Fall were ‘black’ in the priorities and economies of their sound: bass-heavy and rhythm-driven. This was dub not as a form, but a methodology, a legitimation for conceiving of sound-production as abstract engineering. But Joy Division also had a relationship to another super-synthetic, artily artificial ‘black’ sound: disco. Again, it was they, better than PiL, who delivered the ‘Death Disco’ beat. As Jon Savage loves to point out, the swarming syn-drums on ‘Insight’ seem to be borrowed from disco records like Amy Stewart’s ‘Knock on Wood’.

The role in all this of Martin Hannett, a producer who needs to be counted with the very greatest in pop, cannot be underestimated. It is Hannett, alongside Peter Saville, the group’s sleeve designer, who ensured that Joy Division were more Art than Rock. The damp mist of insinuating uneasy listening Sound FX with which Hannett cloaked the mix, together with Saville’s depersonalising designs, meant that the group could be approached, not as an aggregation of individual expressive subjects, but as a conceptual consistency. It was Hannett and Saville who transmuted the stroppy neuromantics of Warsaw into cyberpunks.


Day in/ Day out

Joy Division connected not just because of what they were, but when they were. Mrs Thatcher just arrived, the long grey winter of Reagonomics on the way, the Cold War still feeding our unconscious with a lifetime’s worth of retina-melting nightmares.

JD were the sound of British culture’s speed comedown, a long slow screaming neural shutdown. Since 1956, when Eden took amphetamines throughout the Suez crisis, through the Pop of the 60s, which had been kicked off by the Beatles going through the wall on uppers in Hamburg, through punk, which consumed speed like there was no tomorrow, Britain had been, in every sense, speeding. Speed is a connectivity drug, a drug that made sense of a world in which electronic connections were madly proliferating. But the comedown is vicious.


Massive serotonin depletion.


Energy crash.


Turn on your TV.


Turn down your pulse.


Turn away from it all.


It’s all getting


Too much


Melancholia was Curtis’ art form, just as psychosis was Mark E Smith’s. Nothing could have been more fitting than that Unknown Pleasures began with a track called ‘Disorder’, for the key to Joy Division was the Ballardian spinal landscape, the connexus linking individual psychopathology with social anomie. The two meanings of breakdown, the two meanings of Depression. That was how Sumner saw it, anyhow. As he explained to Savage, ‘There was a huge sense of community where we lived. I remember the summer holidays when I was a kid: we would stay up late and play in the street, and 12 o’clock at night there would be old ladies, talking to each other. I guess what happened in the ‘60s was that the council decided that it wasn’t very healthy, and something had to go, and unfortunately it was my neighbourhood that went. We were moved over the river to a towerblock. At the time I thought it was fantastic; now of course I realise it was an absolute disaster. I’d had a number of other breaks in my life. So when people say about the darkness in Joy Division’s music, by age of 22, I’d had quite a lot of loss in my life. The place where I used to live, where I had my happiest memories, all of that had gone. All that was left was a chemical factory. I realised then that I could never go back to that happiness. So there’s this void.’

Dead end lives at the end of the 70s. There were Joy Division, Curtis doing what most working class men still did, early marriage and a kid…


Feel it closing in

Sumner again: ‘When I left school and got a job, real life came as a terrible shock. My first job was at Salford town hall sticking down envelopes, sending rates out. I was chained in this horrible office: every day, every week, every year, with maybe three weeks holiday a year. The horror enveloped me. So the music of Joy Division was about the death of optimism, of youth.’

A requiem for doomed youth culture. ‘Here are the young men/ the weight on their shoulders,’ went the famous lines from ‘Decades’, on Closer. The titles ‘New Dawn Fades’ and Unknown Pleasures could themselves be referring to the betrayed promises of youth culture. Yet what is remarkable about Joy Division is their total acquiescence in this failure, the way in which, from the start, they set up an Antarctic camp beyond the pleasure principle.


Set the controls for the heart of the black sun

What impressed and perturbed about JD was the fixatedness of their negativity. Unremitting wasn’t the word. Yes, Lou Reed and Iggy and Morrison and Jagger had dabbled in nihilism – but even with Iggy and Reed that had been ameliorated by the odd moment of exhilaration, or at least there had been some explanation for their misery (sexual frustration, drugs). What separated Joy Division from any of their predecessors, even the bleakest, was the lack of any apparent object-cause for their melancholia. (That’s what made it melancholia rather than melancholy, which has always been an acceptable, subtly sublime, delectation for men to relish.) From its very beginnings, (Robert Johnson, Sinatra) 20th-century Pop has been more to do with male (and female) sadness than elation. Yet, in the case of both the bluesman and the crooner, there is, at least ostensibly, a reason for the sorrow. Because Joy Division’s bleakness was without any specific cause, they crossed the line from the blue of sadness into the black of depression, passing into the ‘desert and wastelands’ where nothing brings either joy or sorrow. Zero affect.

No heat in Joy Division’s loins. They surveyed ‘the troubles and the evils of this world’ with the uncanny detachment of the neurasthenic. Curtis sang ‘I’ve lost the will to want more’ on ‘Insight’ but there was no sense that there had been any such will in the first place. Give their earliest songs a casual listen and you could easily mistake their tone for the curled lip of spiky punk outrage, but, already, it is as if Curtis is not railing against injustice or corruption so much as marshalling them as evidence for a thesis that was, even then, firmly established in his mind. Depression is, after all and above all, a theory about the world, about life. The stupidity and venality of politicians (‘Leaders of Men’), the idiocy and cruelty of war (‘Walked in Line’) are pointed to as exhibits in a case against the world, against life, that is so overwhelming, so general, that to appeal to any particular instance seems superfluous. In any case, Curtis expects no more of himself than he does of others, he knows he cannot condemn from a moral high ground: he ‘let them use you/ for their own ends’ (‘Shadowplay’), he’ll let you take his place in a showdown (‘Heart and Soul’).

That is why Joy Division can be a very dangerous drug for young men. They seem to be presenting The Truth (they present themselves as doing so). Their subject, after all, is depression. Not sadness or frustration, rock’s standard downer states, but depression: depression, whose difference from mere sadness consists in its claim to have uncovered The (final, unvarnished) Truth about life and desire.

The depressive experiences himself as walled off from the lifeworld, so that his own frozen inner life – or inner death – overwhelms everything; at the same time, he experiences himself as evacuated, totally denuded, a shell: there is nothing except the inside, but the inside is empty. For the depressive, the habits of the former lifeworld now seem to be, precisely, a mode of playacting, a series of pantomime gestures (‘a circus complete with all fools’), which they are both no longer capable of performing and which they no longer wish to perform – there’s no point, everything is a sham.

Depression is not sadness, not even a state of mind, it is a (neuro)philosophical (dis)position. Beyond Pop’s bipolar oscillation between evanescent thrill and frustrated hedonism, beyond Jagger’s Miltonian Mephistopheleanism, beyond Iggy’s negated carny, beyond Roxy’s lounge lizard reptilian melancholy, beyond the pleasure principle altogether, Joy Division were the most Schopenhauerian of rock groups, so much so that they barely belonged to rock at all. Since they had so thoroughly stripped out rock’s libidinal motor – it would be better to say that they were, libidinally as well as sonically, anti-rock. Or perhaps, as they thought, they were the truth of rock, rock divested of all illusions. (The depressive is always confident of one thing: that he is without illusions.) What makes Joy Division so Schopenhauerian is the disjunction between Curtis’s detachment and the urgency of the music, its implacable drive standing in for the dumb insatiability of the life-Will, the Beckettian ‘I must go on’ not experienced by the depressive as some redemptive positivity, but as the ultimate horror, the life-Will paradoxically assuming all the loathsome properties of the undead (whatever you do, you can’t extinguish it, it keeps coming back).


Accept like a curse an unlucky deal

JD followed Schopenhauer through the curtain of Maya, went outside Burroughs’ Garden of Delights, and dared to examine the hideous machineries that produce the world-as-appearance. What did they see there? Only what all depressives, all mystics, always see: the obscene undead twitching of the Will as it seeks to maintain the illusion that this object, the one it is fixated upon NOW, this one, will satisfy it in a way that all other objects thus far have failed to. Joy Division, with an ancient wisdom (‘Ian sounded old, as if he had lived a lifetime in his youth’ – Deborah Curtis), a wisdom that seems pre–mammalian, pre-multicellular life, pre-organic, saw through all those reproducer ruses. This is the ‘Insight’ that stopped fear in Curtis, the calming despair that subdued any will to want more. JD saw life as the Poe of ‘The Conqueror Worm’ had seen it, as Ligotti sees it: an automated marionette dance, which ‘Through a circle that ever returneth in/ To the self-same spot’, an ultra-determined chain of events that goes through its motions with remorseless inevitability. You watch the pre-scripted film as if from outside, condemned to watch the reels as they come to a close, brutally taking their time.

A student of mine once wrote in an essay that they sympathise with Schopenhauer when their football team loses. But the true Schopenhauerian moments are those in which you achieve your goals, perhaps realise your long-cherished heart’s desire – and feel cheated, empty, no, more – or is it less? – than empty, voided. Joy Division always sounded as if they had experienced one too many of those desolating voidings, so that they could no longer be lured back onto the merry-go-round. They knew that satiation wasn’t succeeded by tristesse, it was itself, immediately, tristesse. Satiation is the point at which you must face the existential revelation that you didn’t want really want what you seemed so desperate to have, that your most urgent desires are only a filthy vitalist trick to keep the show on the road. If you ‘can’t replace the fear or the thrill of the chase’, why stir yourself to pursue yet another empty kill? Why carry on with the charade?

Depressive ontology is dangerously seductive because, as the zombie twin of a certain philosophical wisdom, it is half true. As the depressive withdraws from the vacant confections of the lifeworld, he unwittingly finds himself in concordance with the human condition so painstakingly diagrammed by a philosopher like Spinoza: he sees himself as a serial consumer of empty simulations, a junky hooked on every kind of deadening high, a meat puppet of the passions. The depressive cannot even lay claim to the comforts that a paranoiac can enjoy, since he cannot believe that the strings are being pulled by any one. No flow, no connectivity in the depressive’s nervous system. ‘Watch from the wings as the scenes were replaying’, go the fatalistic lines in ‘Decades’, and Curtis wrote with a depressive’s iron certainty about life as some pre-scripted film. His voice – from the very start terrifying in its fatalism, in its acceptance of the worst – sounds like the voice of man who is already dead, or who has entered an appalling state of suspended animation, death-within-life. It sounds preternaturally ancient, a voice that cannot be sourced back to any living being, still less to a young man barely in his twenties.


A loaded gun won’t set you free – so you say

‘A loaded gun won’t set you free,’ Curtis sang on ‘New Dawn Fades’ from Unknown Pleasures, but he didn’t sound convinced. ‘After pondering over the words to ‘New Dawn Fades’,’ Deborah Curtis wrote, ‘I broached the subject with Ian, trying to make him confirm that they were only lyrics and bore no resemblance to his true feelings. It was a one-sided conversation. He refused to confirm or deny any of the points raised and he walked out of the house. I was left questioning myself instead, but did not feel close enough to anyone else to voice my fears. Would he really have married me knowing that he still intended to kill himself in his early twenties? Why father a child when you have no intention of being there to see it grow up? Had I been so oblivious to his unhappiness that he had been forced to write about it?’ (Touching from a Distance: Ian Curtis and Joy Division, Faber&Faber, 1995, p85) The male lust for death had always been a subtext in rock, but before Joy Division it had been smuggled into rock under libidinous pretexts, a black dog in wolf’s clothing – Thanatos cloaked as Eros – or else it had worn pantomime panstick. Suicide was a guarantee of authenticity, the most convincing of signs that you were 4 Real. Suicide has the power to transfigure life, with all its quotidian mess, its conflicts, its ambivalences, its disappointments, its unfinished business, its ‘waste and fever and heat’ – into a cold myth, as solid, seamless and permanent as the ‘marble and stone’ that Peter Saville would simulate on the record sleeves and Curtis would caress in the lyrics to ‘In a Lonely Place’. (‘In a Lonely Place’ was Curtis’ song, but it was recorded by a New Order in a zombie state of post-traumatic disorder after Curtis’ death. It sounds like Curtis is an interloper at his own funeral, mourning his own death: ‘how I wish you were here with me now’.)

The great debates over Joy Division – were they fallen angels or ordinary blokes? Were they Fascists? Was Curtis’ suicide inevitable or preventable? – all turn on the relationship between Art and Life. We should resist the temptation to be Lorelei-lured by either the Aesthete-Romantics (in other words, us, as we were) or the lumpen empiricists. The Aesthetes want the world promised by the sleeves and the sound, a pristine black and white realm unsullied by the grubby compromises and embarrassments of the everyday. The empiricists insist on just the opposite: on rooting the songs back in the quotidian at its least elevated and, most importantly, at its least serious. ‘Ian was a laugh, the band were young lads who liked to get pissed, it was all a bit of fun that got out of hand…’ It’s important to hold onto both of these Joy Divisions – the Joy Division of Pure Art, and the Joy Division who were ‘just a laff’ – at once. For if the truth of Joy Division is that they were Lads, then Joy Division must also be the truth of Laddism. And so it would appear: beneath all the red-nosed downer-fuelled jollity of the past two decades, mental illness has increased some 70% amongst adolescents. Suicide remains one of the most common sources of death for young males.

‘I crept into my parents’ house without waking anyone and was asleep within seconds of my head touching the pillow. The next sound I heard was “This is the end, beautiful friend. This is the end, my only friend, the end. I’ll never look into your eyes again…” Surprised at hearing the Doors’ ‘The End’, I struggled to rouse myself. Even as I slept I knew it was an unlikely song for Radio One on a Sunday morning. But there was no radio – it was all a dream.’ (Touching From a Distance, p132)





Smiley’s Game: Tinker, Tailor, Soldier, Spy


Film Quarterly, Vol. 65, No. 2, (2011)


What is the allure of George Smiley? Why does Smiley beguile even left-wing viewers who, on the face of it, might be expected to see him as at one point in John le Carré’s 1974 novel he describes himself: ‘the very archetype of a flabby Western liberal’? The enigma of Smiley’s appeal is one of many spectres that haunts Tomas Alfredson’s movie adaptation of Tinker Tailor Soldier Spy. The ghost that most insistently refuses to be exorcised is the 1979 BBC TV version, rightly remembered as one of the greatest ever British television series. Re-adapting a novel after so accomplished a version is risky, especially when you have a mere two hours to play with, as opposed to the series’ more unhurried five.

Pace – and pacing, as in moving around restively while waiting – were central to the coiling tension of the TV series, which caught the crab-like convolutions and slowly interlocking rhythms of le Carré’s narrative exceptionally well. The limitations of television production actually benefited the sense of expansiveness. Sets and action were minimal; the drama was often about faces, and about Alec Guinness’s face in particular, which could suggest a lifetime of regret with the slightest wince. Guinness’s performance was a masterclass in concision and nuance – not words one would always associate with Gary Oldman, cast (emphatically against type) as Smiley in the new Tinker Tailor.

When a novel creates as rich a mythworld as le Carré’s does, no single adaptation will ever completely exhaust it. There is always the possibility of uncovering hitherto underexplored angles and for those of us who are fans of the novel, a strong new version would have had the benefit of liberating the book (and Smiley) from the Guinness portrayal – a prospect that might explain some of le Carré’s enthusiasm for the film. Le Carré has said he felt that Guinness took Smiley from him, making him unable to write the character anymore. When it was announced that this was Alfredson’s next directing project after the success of Let the Right One In (2008), hopes for something special were justifiably high. His brilliant reworking of vampire fiction had a sense of melancholy, violent lives lived in secret that could have carried over most effectively to the closed-world intrigues of British spying. It is thus all the more disappointing that this new Tinker Tailor fails to compellingly reimagine the story, and central to its failure is the film’s inability to make Smiley alluring.

In the novel le Carré reckoned with the sensational exposures that had both traumatised and titillated British society in the 1960s when Soviet double agents Guy Burgess, Donald Maclean, and Kim Philby were revealed to be operating right at the heart of the intelligence establishment. The book begins when Smiley is called out of retirement to search for a deep-cover mole – it was in fact le Carré who popularised this term – in the Secret Intelligence Service (otherwise known as MI6). Tinker Tailor follows Smiley’s circuitous pursuit and exposure of the traitor, who is ultimately revealed to be Smiley’s friend and rival Bill Haydon – one of many men to have affairs with Smiley’s semi-estranged wife, Ann. The narrative is suffused with what Paul Gilroy has called ‘postcolonial melancholia’. Smiley, Haydon, and their contemporaries – notably Jim Prideaux, the former head of the ‘scalphunters’ section, shot in the bungled operation that ultimately leads to the mole being uncovered, and Connie Sachs, the head of intelligence, dismissed when she comes uncomfortably close to the truth – have watched all the expectations born of imperial privilege slowly disappearing. ‘Trained to Empire, trained to rule the waves. All gone, all taken away,’ Sachs laments (Pan Books, 1979, 102).

Postcolonial melancholia is fed more by hostility towards the US than it is by fear of the Soviets – Haydon and Smiley’s boss, the irascible Control, are united in their loathing of Americans. When Control is maneuvered out of his position by the ambitious (and very pro-US) Percy Alleline, this seems to consolidate the sense of irreversible decline which hangs over the novel. England’s glory lies in the past; the future is American. In the novel and its sequels, it is clear that Smiley’s victory is temporary; his world is on the brink of disappearing.

Smiley brings to mind English archetypes both ancient and modern. What is the perpetually cuckolded Smiley, returning to save his ailing kingdom, if not a Cold War King Arthur? Yet this is Arthur done in the style of T. S. Eliot’s Prufrock, whose famous self-characterization as ‘an attendant lord’ applies all too acutely to le Carré’s character as well: ‘Deferential, glad to be of use, / Politic, cautious, and meticulous; / Full of high sentence, but a bit obtuse; / At times, indeed, almost ridiculous – / Almost, at times, the Fool’ (‘The Love Song of J. Alfred Prufrock,’ The Complete Poems and Plays of T. S. Eliot, Faber and Faber, 1969, 16).

While in some respects a pathologically self–blinding figure, Smiley shares some of Prufrock’s self–consciousness; when, in a scene that is powerfully played out in both the BBC and the film version, Smiley recalls his one face-to-face encounter with his counterpart, the Soviet spy chief Karla, he calls himself a ‘fool.’ Crucially, however, he adds that he would rather be his kind of fool than Karla’s.

When Smiley recounts the meeting with Karla to his younger protégé Peter Guillam, he reproaches himself for having talked too much on that memorable occasion in an Indian jail cell. Karla wins the encounter by never speaking, by transforming himself into the blank screen that Smiley cannot on this occasion become – which makes it all the easier for Smiley to fall into the trap of projecting his own anxieties and preoccupations onto the impassive Karla. In the novel, Smiley affects to disdain the psychoanalytic language of ‘projection’ but, tellingly, he cannot resist using these terms to describe himself; appropriately, for in the normal run of things Smiley’s art consists in cultivating a particular kind of silence – not the mere absence of chatter, but the authoritative, probing silence of the psychoanalyst. The face can’t give anything away, yet at the same time it has to invite confidence. Those who don’t want to talk must be drawn into confiding. And isn’t that a large part of Smiley’s appeal to those of us from a more adolescent, more compulsively loquacious time: his grownup capacity to engender respect, and to quietly solicit our need for his approval? Speaking after a London critics’ screening of Tinker Tailor in September, Oldman said that, by contrast with the Guinness version, no-one would want to hug his Smiley. Yet the suggestion that we would want to hug Guinness’s Smiley is absurd. Surely what we find ourselves craving from Smiley is a word, a gesture, the merest hint of approbation. But it is a mistake to see the avuncular seductions of Guinness’s performance as if they were in opposition to the ruthlessness which Oldman emphasises in his rendition of Smiley, for Smiley’s merciless, unblinking hunting down of his prey depends upon this very capacity to draw people out.

Oldman’s reading of Smiley’s blankness is far less sophisticated than Guinness’s. Le Carré’s Smiley is famously corpulent; Oldman’s is angular, stiff, dyspeptic. We can’t imagine ever wanting to confide in him. Oldman’s Smiley is simply an inexpressive mask: forbidding, impassive, unyielding. It is as if Oldman is giving us his shallow reading of his grandparents’ generation: aloof, distanced, bottled-up. They kept it all inside; they didn’t know how to have a good time. For Oldman, Smiley’s restraint plays as repression and a certain malicious self-satis-faction – his silence is a simple lack of demonstrativeness, or a merely inverted demonstrativeness.

Speaking on BBC Radio 4’s Today, le Carré himself identified Oldman’s performance of repression as one of the highlights of this new version. ‘You couldn’t really imagine Alec Guinness () having a sex life,’ he said. ‘You couldn’t imagine a kiss on the screen with Alec, not one that you believed in. Whereas Oldman has quite obviously a male sexuality that he represses, like all his other feelings, in this story. Oldman is a Smiley waiting patiently to explode. I think the air of frustration, of solitude that he is able to convey is something that really does take me back to a novel I wrote 37 years ago.’ Sadly, this remark suggests less a new way of seeing Smiley than a certain coarsening of understanding brought about, no doubt, by the dissemination of a therapeutic wisdom which insists that the truth of a character is to be found in their (narrowly defined) sexuality.

To say that Smiley is waiting patiently to explode is a very curious take on a character defined rather by a lack of heat. When Oldman shouts at Haydon ‘what are you then, Bill?’ at the climax of the film, this is an abandonment of emotional decorum quite out of keeping with Smiley’s character, for whom the English ruling-class habit of transposing aggression into the chill of superficially polite discourse comes as second nature. Anger is one of the emotions that the Smiley of the novel feels at the moment of Haydon’s exposure, yet it is not the dominant one: Smiley


saw with painful clarity an ambitious man born to the big canvas, brought up to rule, divide and conquer, whose vision and vanities all were fixed, like Percy’s, upon the world’s game; for whom the reality was a poor island with scarcely a voice that would carry across the water. Thus Smiley felt not only disgust; but, despite all that the moment meant to him, a surge of resentment against the institutions he was supposed to be protecting’ (297).


Thus, the tone of triumphalism with which the film ends – Smiley gloriously restored to his place of honour in MI6 – strikes another false note.

The Smiley in Alfredson’s film is a figure who is far less queer than the Smiley of the novel or the television series. Homosexual desire is widespread in Tinker Tailor – most notably in Prideaux’s betrayed love for the flamboyantly polysexual Haydon – but there is no suggestion that Smiley shared these passions. The Smiley of novel and series is queer in the more radical sense that a ‘normal’ sexuality cannot be assigned to him. Smiley’s is not a fluid, indeterminate sexuality like, say, that of Patricia Highsmith’s Tom Ripley. His perversity is renunciation itself. At the preview, Oldman referred approvingly to le Carré’s comments on Guinness’s lack of sexuality; but he also characterised Smiley as masochistic (repeatedly subjecting himself to adulterous humiliations) and sadistic (the way he pursues his prey goes far beyond professional duty). Yet the idea that Smiley is sadomasochistic quite clearly contradicts the idea that he is repressed. For sadomasochism entails enjoyment, not repression. Far from being repressed, it’s clear that Smiley is driven – driven by something which will not allow him to ever recline into happy retirement any more than he could settle into the pleasures of conjugal life, were they available to him.

From his earliest appearances in le Carré’s fiction – in the novels Call for the Dead and A Murder of Quality – Smiley is on the edge of things. In most of the novels which feature Smiley, he rarely appears as officially a member of MI6. He is called out of retirement, or pretending to be retired; and when, after Tinker Tailor, he is not only restored to the organization but made chief, it is in a temporary caretaker capacity. One of the paradoxes of Smiley’s character is that he seems to stand for the solidity – and stolidity – ascribed to a certain model of Englishness, yet he is himself an outsider, an interloper, a voyeur. This is the spy’s vocation, and le Carré repeatedly insists on it, nowhere more passionately than in the bitter outburst of the agent Alec Leamas at the end of The Spy who Came in from the Cold, so memorably performed by Richard Burton in the 1965 film adaptation.

‘What do you think spies are, moral philosophers measuring everything they do against the word of God or Karl Marx? They’re not, they’re just a bunch of seedy, squalid bastards like me,’ Burton’s Leamas tells his lover, Liz, after it has been revealed that they were pawns in a complex plot hatched by Control and Smiley. It is the beyond-good-and-evil agent, the one who acts without performing complex moral calculations, the one who cannot belong to the ‘normal’ world, who allows ordinary folk to sleep easily. Yet duty is only the pretext; there is also the matter of the deep libidinal lure of this no-man’s-land for outsiders like Leamas and Smiley. Like writers, they listen and observe; like actors, they play parts.

But, for spies, there are no limits to these roles; one cannot simply step out of them and return to the warm, because everything – including inner life itself, all its wounds and private shames – starts to feel like cover, a series of props. There is a revelatory passage towards the end of the second Smiley novel, A Murder of Quality, first published in 1962. At the end of the novel – a strange whodunit thriller – Smiley confronts the murderer, but, as in the later confrontation with Karla, he ends up talking about himself:


And there are some of us – aren’t there? – who are nothing, who are so labile that we astound ourselves; we’re the chameleons. I read a story once about a poet who bathed himself in cold fountains so that he could recognise his own existence in the contrast of it…The people like that, they can’t feel anything inside them: no pleasure or pain, no love or hate…They have to feel that cold water. Without it, they’re nothing. The world sees them as showmen, fantasists, liars, as sensualists perhaps, not for what they are: the living dead (Coronet, 1994, 174).


There is a clear implication in this slide from first person (‘some of us’) to third person (‘people like that’): the Cold Warrior Smiley is himself one of the ‘living dead.’ In psychoanalytic terms, Smiley is less a ‘sadomasochist’ than an obsessional neurotic. (Lacan in fact argues that the question posed by the obsessional is ‘am I alive or am I dead?’) At the end of Smiley’s People, when Smiley has defeated Karla and has the possibility of winning Ann back, Smiley is very far from being elated. There is little sense of this in Oldman’s Smiley: his ‘sadomasochism’ is too crude to approximate the baroque mechanisms of self-decep-tions and self-torturings which govern Smiley’s psyche. Yet another false note is struck in Alfredson’s film when Smiley sees Ann being embraced by Haydon at the MI6 Christmas party; he throws himself against the wall in a spasm of agony. In other respects, the party scene adds something which wasn’t there in the BBC version, a sense of the camaraderie within the department, but it is hard to imagine Smiley engaging in so public and so spontaneous display of emotion. More troublingly, to suggest that Smiley would straightforwardly feel pain when confronted with Ann’s infidelities is to betray the very idea that he is masochistic. When confronted about Ann in the novel and TV adaptation, Smiley’s preferred pose is one of weary resig-nation; but this conceals the secret satisfaction that he experiences in Ann playing her assigned role as impossible object. But where the masochist would organise his enjoyment around this impossible object, for Smiley, the function of Ann’s unattainability is to keep her at a safe distance. His enjoyment is not organised around Ann – or sexuality – at all, and when she is safely unattainable she cannot trouble him.

Unlike in the TV series, we never see the faces of either Ann or Karla, Smiley’s other Other, in the film. This rightly suggests that both figures are at least partially absent for Smiley, filled in with his fantasies. But what’s missing is an account of the way that Smiley fills in these fantasy screens, and any sense of discrepancy between the fantasy figures that Smiley projects and their real-life counterparts. In the film, Smiley cannot remember what Karla looked like; in the novel he gives a detailed description of his adversary. Defined externally by his struggle against Karla, Smiley’s internal struggle consists of his necessarily thwarted attempts to refuse any identification with his Soviet counterpart. Smiley’s attempts to distance himself from the ‘fanatic’ Karla, his attempts to position himself outside politics itself, are the exemplary gestures of a very English ideology, which appeals to a preor post-political notion of ‘common humanity.’ Yet, ironically, what Smiley and Karla have in common is their inhumanity, their exile from any sort of ‘normal’ world of human passions. When they meet in Delhi, Smiley is baffled, frustrated but also fascinated by Karla’s refusal of the appeal, unable to fathom a commitment to an abstract ideology, especially when – in Smiley’s view – it has self-evidently failed. ‘The irony in le Carré’s fiction,’ writes Tony Barley, ‘is that a sound basis for commitment is always either sought or mourned for its absence, and yet when genuine commitment appears (invariably in communism) it is treated as incomprehensible. Communism becomes fanaticism, not a strength but a weakness’ (Taking Sides: The Fiction of John le Carré (Open University Press, 1986, 95). Barley rightly argues that Smiley cannot be read as a cipher for liberal ideology because the incoherencies and impasses of his own position are never resolved. Behind the manifest content of Smiley’s entreaties to Karla – come and join us, give up your dead generalities, enjoy the particularities of the lived world – the latent message is that all Britain has to offer is disillusionment, the impossibility of belief. (Smiley tells Guillam that ‘fanaticism’ will be the undoing of Karla: in fact, when Karla is defeated in Smiley’s People, it is because of his failure to be sufficiently ‘fanatical’.) Very little of this comes out in Alfredson’s depoliticised film, in which Smiley is simply a wronged hero who ultimately attains justice, Haydon is simply a traitor, and communism is simply an exotic period reference. The nickname for MI6, ‘The Circus,’ in fact openly acknowledges the aberrant enjoyment available to those who have crossed into this fictional Cold World. The multivalent origin of the nickname – in addition to hinting at the way the spies play their deadly game in a spirit of mordant, laconic cynicism, it is also a near homonym of ‘service,’ and a play on the location in the novel of MI6’s offices: Cambridge Circus, central London – tells you a great deal about the world in which Smiley operates. Much of the power of the television version derived from the way it threw us directly into this world. Guinness’s Smiley incarnated a model of BBC paternalism: he guided us through his world, but he had high expectations of us. Very little was explained – we had to pick up le Carré’s invented nomenclature (scalphunters, lamplighters) on the fly. The work slang invoked the exoticism of a rarefied form of labour, while also suggesting the routinisation of espionage for those involved in it on a daily basis. It all contributed to the feeling that the Circus was a lived-in world. One of the major problems with Alfredson’s Tinker Tailor, by contrast, is that its world doesn’t feel lived-in at all. Gratifyingly, the film does not talk down to audiences; just as in the TV series, we are required to orientate ourselves in the Circus’s intrigues. But the combination of Oldman’s inexpressiveness and the compression brought about by having to tell so complicated a story in such a short time results in something that is strangely uninvolving. The film is almost entirely lacking in tension or paranoia; in the TV series, the scene where Guillam steals a file from the Circus is almost unbearably tense. In the film, the same scene plays out in a curiously distanced way. Then there is the question of period, and the film’s striving to create a sense of London in the 1970s. I was too often reminded of Life on Mars, which evoked the decade with a series of clumsily placed period signifiers. As with Life on Mars, much of Alfedson’s film looks like a 1970s theme park. Rather than discreetly constituting a period background, branded goods (Trebor mints, Ajax household cleaner) are distractingly pushed to the foreground of our attention, details that we are invited to approvingly note. But where the details matter, this new version is lacking. Eras produce certain voices, certain faces. What’s missing in Alfredson’s version is something like the grain of the 1970s. Too often, the actors seem like 21st-century moisturised metrosexuals in 1970s drag – and bad drag at that. Presented with photographs of people from the 1970s, the clichéd but accurate observation is that people looked so much older then. But the preposterously fresh-faced likes of Benedict Cumberbatch (who plays Guillam) and Tom Hardy (in the role of rogue agent Ricki Tarr) aren’t nearly weathered enough to convince as 1970s secret agents. The skin, the hair are too good. The faces are without the sallow, harrowed, harried look that Michael Jayston and Hywel Bennett brought to the roles in the 1970s production; their voices unable to convey any sense of the bitter and brutalising effects of the spy’s life. John Hurt’s Control, at least, has the right weatherbeaten complexion and cynical-playful cadences. Accents are a severe problem in the film. Oldman plays Smiley as generically posh, but at the same time he sounds like no one you’ve ever heard; at points there’s an oddly Scottish lilt to his accent. The accent of Toby Jones’s Percy Alleline, meanwhile – played as Scottish in keeping with the novel – keeps drifting southward. Kathy Burke is hopelessly miscast as Connie Sachs: she sounds like a schoolgirl taking on the part of a posh woman in the school play. The problem here isn’t just one of authenticity; it’s that the wayward accents once again undermine the sense of a lived-in world. There is too much conspicuous effort going into this 1970s simulation. Throughout, you can practically hear Gary Oldman straining to hold back the Estuary English. In the BBC version, the Circus was an unprepossessing space – functional, dreary corridors leading into cramped offices. In Alfredson’s version, Control’s office looks more like something from a nightclub than what you would expect to see in MI6. One wants to escape the 1970s version, but Alfredson doesn’t give us nearly enough to do that. There is much that is different, but nothing that is strong enough to displace the television version in the memory. The casting of Colin Firth as Haydon, however, at least allows us to see the character in a different way. The face of Ian Richardson – who would go onto play the Tory grandee and Machiavel in the BBC television series House of Cards – provided a grey-eminence image of British power in the 1970s and 80s. I don’t know who it was who said that Colin Firth looks like the midway point between the current British prime minister David Cameron and his deputy Nick Clegg, but the observation is very astute. The face of the British Establishment no longer has the hawk-like puckishness of Richardson; it has the rumpled, casual youthfulness of Firth. One of the major problems with Alfredson’s film is that it assumes the ruling values of the neoliberal world governed by youth and consumerism (isn’t this what ‘American’ codes for in the Smiley novels?). Richard Sennett has argued that the chronic short-termism of neoliberal culture has resulted in a ‘corrosion of character’ (The Corrosion of Character: The Personal Consequences of Work in the New Capitalism, W. W. Norton, 1999): a destruction of permanence, loyalty, and the capacity to plan. Isn’t Smiley’s allure tied up with the possibilities of character itself? In the 1970s, Smiley showed up all the inadequacies, squalid compromises, and subterranean brutalities of social democracy. Then, Smiley’s doubts and his failings prompted us to imagine a better world even as we struggled to resist Smiley’s blankly and perversely comforting avuncularity; now, when that better world seems if anything further away, it takes all our effort to resist the lure of nostalgia for the social-democratic world of which Smiley was both the conscience and the dirty secret.





The Past is an Alien Planet: The First and

Last Episodes of Life on Mars


k-punk post January 10, 2006


Life On Mars is symptomatic enough to be interesting. Symptomatic of what? Well, of a culture that has lost confidence not just that the future will be good, but that any sort of future is possible. And also: Life On Mars suggests that one of the chief resources of recent British culture – the past – is reaching the point of exhaustion.

The scenario is that Sam Tyler (John Simm), a detective from 2006, is hit by a car and finds himself back in 1973. The game that you can’t help playing as you watch is: how convincing is the simulation of 1973? You’re constantly on the look out for period anachronisms. The answer is that it isn’t very convincing. But not because of anachronisms. The problem is that this is a 73 that doesn’t feel lived in. The actual post-psychedelic, quasi-Eastern Bloc seediness of the 70s is unretrievable; kitsch wallpaper and bell bottoms are transformed instantly into Style quotations the moment the camera falls upon them.

(There must be some technical reason – maybe it’s the film stock they use – that accounts for why British TV is no longer capable of rendering any sense of a lived-in world. No matter what is filmed, everything always looks as if it has been thickly, slickly painted in gloss, like it’s all a corporate video. That remains my problem with the new Dr Who as it happens: the contemporary British scenes look like a theme park, a very stagey stage-set, too well lit.)

‘Look Out There’s a Thief About’ public information films on black and white TV, Open University lecturers with preposterous moustaches and voluminous collars, the test card…Everything is so iconic, and the thing with icons, after all, is that they evoke nothing. The icon is the very opposite of the Madeleine, Chris Marker’s name – rhyming Hitchcock and Proust – for those totemic triggers that suddenly abduct you into the past. The point being that the Madeleine can only manage this time-snatching function because it has avoided museumification and memorialisation, stayed out of the photographs, been forgotten in a corner. Hearing T-Rex now doesn’t remind you of 73, it reminds you of nostalgia programmes about 1973.

And isn’t part of our problem that every cultural object from 1963 on has been so thoroughly, forensically, mulled over that nothing can any longer transport us back? (A problem of digital memory: Baudrillard observes somewhere that computers don’t really remember because they lack the ability to forget.)

k-punk post, April 13, 2007


In the end, the science fiction elements of Life On Mars consisted solely in an ontological hesitation: is this real or not? As such, Life On Mars fell squarely into Todorov’s definition of the Fantastic as that which hesitates between the Uncanny (that which can ultimately be explained naturalistically) and the Marvellous (that which can only be accounted for in supernatural terms). The predicament that Life On Mars explored was: is Sam Tyler in a coma, and the whole 1970s world in which he is lost some kind of unconscious confabulation? Or has he, by some means not yet understood, been transported back into the real 1973? The show maintained the equivocation until the end (the final episode was ambivalent to the point of being cryptic).

Simm has wryly observed that the show’s central conceit lets the production off the hook. If Tyler was in a coma, then any of Life On Mars’s historical inaccuracies could be explained away as gaps in the character’s recollections of the period. No doubt the enjoyment of Life On Mars derived from its imperfect recollection, not of 1973 itself, but of the television of the 1970s. The programme was mitigated nostalgia, I Love 1973 as a cop show. I say cop show, because it is clear that the SF elements of Life On Mars were little more than pretexts; the show was a meta-cop show rather than meta-SF. The time travel conceit permitted the showing of representations which would otherwise be unacceptable, and beneath the framing ontological question (is this real or not?), there was a question about desire and politics: do we want this to be real?

As the avatar of the present, Sam Tyler became the bad conscience of the 70s cop show, whose discontent with the past permitted us to enjoy it again. Simm, as the modern, enlightened ‘good cop’, was less the anti-type of antediluvian ‘bad cop’ Gene Hunt than the postmodern disavowal which made possible our enjoyment of Hunt’s invective and violence. Hunt, played by Philip Glenister, became the show’s real star, beloved of the tabloids who adored quoting his streams of abuse, carefully constructed by the writers so that they could come across as comic rather than inflammatory. Hunt’s ‘no-nonsense policing’ was presented with enough ‘grit’ to make us wince, but never so much violence that it would invoke disgust. (In this respect, the programme was the cultural equivalent of a blow to a suspect that would not show up under later medical examination.)

Undoubtedly, although perhaps unintentionally, the show’s ultimate message was reactionary; in the end, rather than Tyler educating Hunt, it was he would come to an accommodation with Hunt’s methods. When, in the final episode, Tyler is faced with a choice between betraying Hunt or staying loyal (at this point in the narrative, it appears that Tyler’s betrayal of Hunt is the requisite price Tyler must pay in order to return to 2007), this also became a choice between 1973 and the present day that amounted to a decision, not about collar lengths or other cultural preferences, but about policing styles. Audience sympathy is managed such that, however much we disapprove of Hunt, we are never supposed to lose faith in him, so that Tyler’s betrayal seemed far worse than any of Hunt’s many misdemeanours. Tyler’s (apparent) return to 2007 underscores this by presenting the modern environment as sterile, drearily worthy, ultimately far less real than the rough justice of Hunt’s era. Modern wisdom (‘how can you maintain the law by breaking the law?’) is set against Hunt’s renegade-heroic identification of himself with the law (‘I am the law, so how can I break it?’) The deep libidinal appeal of Hunt derives from his impossible duality as upholder of the Law and he who enjoys unlimited jouissance. The two faces of the Father, the stern lawgiver and Pere Jouissance, resolved: the perfect figure of reactionary longing, a charismatic embodiment of everything allegedly forbidden to us by ‘political correctness’.





‘Can The World Be as Sad as It Seems?’:

David Peace and his Adapters


David Peace’s four Red Riding novels were acts of exorcism and excavation of the near-past, a bloody riposte to I Love The 1970s clipshow nostalgia. They stalk the West Yorkshire that Peace grew up in, transforming real events – the framing and intimidation of Stefan Kisco; the incompetent police operation to catch the Yorkshire Ripper – into background for brutal and unrelenting fictions that possess an apocalyptic lyricism.

Peace has always been dogged by comparisons with James Ellroy. There’s no doubt that encountering Ellroy liberated something in Peace, but in the end Peace is the better writer. Peace has called the experience of reading Ellroy’s White Jazz his ‘Sex Pistols moment’. But Peace builds upon what Ellroy achieved much in the way that the postpunk groups leapt into the space that the Pistols had blown open. Peace extrapolates a pulp modernist poetics from Ellroy’s experiments in telegraphic compression, and while Ellroy’s pugilistic prose has a pump-action amphetamine drive, Peace’s writing is hypnotic and oneiric; its incantatory repetitions delaying and veiling plot revelations rather than rushing headlong towards resolution. Despite presenting seemingly similar worlds – in which the police are routinely corrupt, journalists are venal and co-optable, and the wealthy are vampiric exploiters – their political orientations are very different. Ellroy is a Hobbesian conservative, who evinces a macho pragmatism that accepts violence, exploitation and betrayal as inevitable. The same phenomena are oppressively omnipresent in Peace’s world, but there is no sense of acceptance: instead, his novels read like howls of agony and calls for retribution, divine or otherwise.

Peace, who has said that he aimed to produce a Crime fiction which is no longer entertainment, has written Crime works that are hauntological in a triple sense. The Crime genre is of course well suited to explore the (moral, existential, theological) problems posed by what Quentin Meillassoux called ‘odious deaths’: the deaths ‘of those who have met their end prematurely, whose death is not the proper conclusion of a life but its violent curtailment’; and as they moved away from the uneasy combination of fanciful genre trappings, period signifiers, Angry Young Man homage and brutality that characterised 1974, the novels of the Red Riding Quartet were simultaneously drawn towards actuality and theology, as if the proximity of the one entailed the other. Readers are put into the position of spectral mourners by the voices of those who have died odiously, the Ripper’s victims, heard in the visionary ‘Transmissions’ which preface each of the chapters in 1980, sections which combine the actual (gleaned from reportage and biography) with the spectral.

The novels are hauntological in another sense, a sense that is closer to the way in which we have used it in relation to music, but not quite the same. Peace is not at all interested in the problems of degraded memory which preoccupy The Caretaker, Burial or Basinski. His is a past without crackle, rendered in the first person and in a tense that is very nearly present. The occlusions in the narrative are due, not to faulty recording devices or memory disorders (cultural or personal) but to the self-blindings of his characters, who see themselves (and the events of which they are a part) only through a glass darkly. In the end, everything – narrative, intelligibility – succumbs to total murk; as the characters begin to disassociate, it becomes difficult to know what is happening, or what has happened; at a certain point, it is unclear as to whether we have crossed over into the land of the dead.

Hunter, the senior Manchester detective assigned to investigate the West Yorkshire police force in 1980, finds himself caught in a world in which things don’t add up; they don’t fit together. It’s a Gnostic terrain. The Gnostics thought that the world was made of a corrupt matter characterised by heavy weight and impenetrable opacity: a murky, muddy mire in which fallen angels – one of the persistent images in the Red Riding books – are trapped. There is no question of Hunter, or solicitor John Piggott in 1983 – or even Peace – being able to completely illuminate what has happened. This is a world in which, as Tony Grisoni, the screenwriter who adapted the novels for Channel 4, puts it, ‘narratives disappear into the dark’.

The libidinal orientation towards the past is also markedly different in the case of Peace and sonic hauntology: whereas hauntological music has emphasised the unexplored potentials prematurely curtailed in the periods it invokes, Peace’s novels are driven by the unexpiated suffering of Yorkshire at the end of the 70s. And Peace’s writing is also hauntological in its intuition that particular places are stained by particular occurrences (and vice versa). As he has insisted in many interviews, it is no accident that Sutcliffe was the Yorkshire Ripper. Peace’s books are avowedly anti-nostalgic, the anti-Life On Mars, with its ambivalence towards police brutality (and its media representation). There is no such vindication in Peace’s novels, no suppressed yearning for a time in which coppers could beat suspects with impunity. After all, it is corruption, rather than criminality per se, that is the focus of the Red Riding Quartet.

Music in Peace’s books functions as a hauntological trigger. He’s remarked that he uses music, including music he doesn’t like, to take him back to the feel, the grain, of a period. Musical references are embedded in the text either diegetically, as background sound, or more esoterically, as cryptic-epigraphic ciphers and repeated incantations: a portal effect that gratifyingly echoes (in reverse) the way in which music of the 1970s, especially postpunk, would direct listeners to fiction. 1980 is haunted in particular by Throbbing Gristle, especially the phrase that they took from another killer, Charles Manson: ‘can the world be as sad as it seems?’ In Peace’s hands, this question becomes an urgent theological enquiry, the very relentlessness of the sadness and misery he recounts calling forth an absent God, a God who is experienced as absence, the great light eclipsed by the world’s unending tears. The world, the sad, desolated world, is full of angels whose wings have either been shorn off, reduced to stubble, or which have grown into gigantic, dirty monstrosities…addict angels hooked on alcohol, casual but incessant lusts, and the trash of the consumer society that is struggling to be born out of the wreckage of the social democratic consensus…angels whose ultimate response to the world is puking (everyone pukes in Peace’s books), throwing up the whiskies and the undercooked crispy pancakes, but never being able to purge any of it, never being able to take flight.

The religious elements in the books become increasingly foregrounded as the Quartet develops, until the deeply ambiguous, hallucinatory ending of 1983 becomes a quasi-Gnostic treatise on evil and suffering. The final section of the novel, ‘Total Eclipse Of The Heart’ (that transfiguration of pop cultural reference into epigraph being one of Peace’s signature techniques), explicitly posits the idea that, far from undermining the existence of God, evil and suffering entail that God must exist. Eclipse implies something that is eclipsed, a hidden source of light that produces all this shadow. In the philosophy of religion, the problem of evil maintains that suffering, particularly suffering visited upon the innocent, means that the theistic God could not exist, since a benevolent, omnipotent and omniscient being would not countenance undeserved suffering. With his inventory of wretched child abuse cases, Dostoyevsky’s Ivan Karamazov makes the most famous, and most passionate, statement of this position. Yet if there is no God, the suffering remains, only now there is no possibility of its expiation; if there can be no justice to come, the universe is permanently blighted, irrevocably scarred by atrocity, abuse and torture.

The Red Riding novels inspired Channel 4 into making the kind of television dramas that some of us had long since ceased hoping could ever be made in Britain again. The three films, broadcast in 2009, were the most striking British dramas of the first decade of the 21st century, towering above all the facile costume epics, routine police procedurals and emotional pornography which clogged the schedules. Moreover, in their use of setting and landscape, in the epiphanic power of their images, the Red Riding films attained a visual poetry and an expressionist naturalism that exceeded practically anything British cinema has achieved in the past 30 years.

As Nick James observed in his preview of the Red Riding films for Sight & Sound, nothing in the previous career of the Red Riding’s three directors – Julian Jarrold for 1974, James Marsh for 1980, and Anand Tucker for 1983 – gave any hints that they could produce work of this quality. In many ways, it is as if the auteur of these films was Peace himself, and the three directors succeed so consummately because they allowed themselves to be channels of his infernal vision. It was inevitable that some compression occurred in the transition from page to screen; indeed, one whole novel from Peace’s Red Riding sequence – 1977 – was never filmed, but Tony Grisoni deserves immense credit for the way that he weaved the three films into a symphonic coherence that nevertheless refused easy closure and intelligibility.

Peace’s equivalent of Ellroy’s anti-hero Dudley Smith, the corrupt detective who justifies his own running of drugs and vice operations as ‘containment’, is Maurice Jobson, the whey-faced policeman who features in all three of the films. Where Smith (as masterfully played by James Cromwell in the best Ellroy adaptation to date, LA Confidential 1997 ()) is charming, charismatic and flamboyantly loquacious, Jobson (as played by David Morrissey in the C4 adaptations) is taciturn, abstracted, immobile, blank, in a semi-fugue state of disassociation from the atrocities he participates in. Morrissey’s is one of many excellent performances in the trilogy: all of them masterpieces of measure and controlled power, proper television/ film acting, far from the braying thespery that the British theatrical tradition often turns out. Rebecca Hall is damaged and dangerous as Paula Garland, Maxine Peake, angular yet vulnerable as Helen Marshall. Sean Harris manages to make Robert Craven plausibly loathsome without tripping over into grand guignol grotesquerie; while Paddy Considine brings a flinty resolution to the role of Peter Hunter, one of the few lightbringers in the Red Riding’s North, an inverted world in which evil enjoys carnivalesque licence and the police and the powerful are free to ‘do what they want’.

The film adaptation of Peace’s extraordinary novel The Damned Utd lived down to expectations to just about the same extent that the Channel 4 films exceeded them. The team tasked with adapting the novel looked unpromising. Before The Damned Utd, Director Tom Hooper (drafted in after Stephen Frears left the project) had a background in fairly unremarkable television (he would later go on to make The King’s Speech), while the shtick of screenwriter Peter Morgan and lead actor Michael Sheen – as established in The Queen and Frost/ Nixon – didn’t have any obvious fit with Peace’s fractured and abrasive modernism. In the end, Hooper and Morgan didn’t adapt Peace; they eliminated him. Hooper’s film returns us to the found object-narrative – Brian Clough’s bitter 44-day stint as manager of Leeds United in 1974 – that Peace used as the raw material for his ‘fiction based on a fact’. What’s missing is everything that Peace brought to the facts: the bite of a Real that will always elude (bourgeois) realism; and the shaping power of a Gnostic mythography, in which the most malign entity is the cursed land of Yorkshire itself.

It can be tiresome to criticise a film adaptation simply for the ways it differs from its source novel. In this case, however, a close comparison of the two versions of The Damned Utd is instructive, for two reasons. First, because, in erasing Peace’s signature, the film in effect competes with his rendition of the Clough/ Leeds story; and second, because Peace’s pulp modernism precisely offers British culture an escape from the kind of good humoured, well balanced, middle of the road, middlebrow realism that Hooper and Morgan trade in.

At the press screening, Morgan said that when he read The Damned Utd, it brought a nostalgia rush ‘like eating Farley’s rusks’. Yet surely even the most guileless of the readers of Peace’s novel could see that it tastes not of the warm mush of baby food but of bile, scotch and refluxed stomach acid. In Hooper and Morgan’s hands, Clough’s story is reduced to all of the givens, all the off-the-shelf narrative and thematic pegs: he was a ‘misunder-stood genius’, struggling against an establishment represented by puffed-up provincial patriarchs like the Derby County chairman, Sam Longson (well played by Jim Broadbent); he was self-destructive, and he needed his partner Peter Taylor (Timothy Spall) to curb his excesses; he was locked into an oedipal struggle with the man he replaced at Leeds, Don Revie. Even this is told more than it is shown, and throughout, the audience treated as if it is witless: dialogue is too often used for clumsy plot exposition or to crudely telegraph Themes. Not only do Hooper and Morgan fail to evoke Peace’s existential terrain, his blighted vision of Yorkshire, they also convey little of his intense sense of territoriality. In the novel, Leeds’s Elland Road ground is the site of a struggle over space in which Clough is up against both the spectre of Don Revie and the animal aggression of the players he has left behind. (A striking image from the novel – of Clough chopping up and burning Revie’s desk in an attempt to exorcise the absent father’s ghost – inexplicably never made it to screen.) The film also misses the purgatorial rhythm of sport which Peace caught so acutely. As every sports fan – never mind about coach – knows, the jouissance of sport is essentially masochistic. ‘The Damned Utd shows what Clough’s tragedy was,’ Chris Petit put in his review of the novel, ‘deep down, he knew that winning was only loss deferred.’ The intense fear that colours everything in Peace’s novel is dissolved in a tone that is frequently jaunty.

Then there is Michael Sheen. The problem with Sheen’s now well established approach to historical characters is that it deprives the film’s world of any autonomous reality – everything is indexed to a reality external to the film, judged only by how well it matches our already existing image of the character, whether that be Clough, Kenneth Williams, Blair or Frost. (And there are bizarre bleed-throughs between the characters – at one point, it felt as if Sheen’s campy Clough had morphed into Kenneth Williams.) Certainly, Peace has an advantage over the film-makers here: written fiction can move beyond received television images of figures from recent history far more quickly than film can but an actor with more courage and presence than Sheen might have reached beyond physical appearances to reach a truth of Clough not accessible via the TV footage. Instead, Sheen offers his usual tracing of mannerisms and verbal tics, competent enough as far as it goes, but devoid of any of the tortured inner life that Peace gave to his Clough. Even if the acting were uniformly superb, it would have needed far more than Hooper provides in order to summon the dread and misery of Peace’s world; but the indifferent photography and the often appalling soundtrack make Hooper’s The Damned Utd feel more like a dramatisation of actual events than a film of Peace’s novel.





Now Then, Now Then: Jimmy Savile and ‘the 70s On Trial’


July 2013


The turn that events took had all the look of some kind of ritual assassination. The killing not of a body – the body was already dead – but of a name. It was as if some kind of deal had been struck – you’ll get to live out your life with your reputation intact (or as intact as it could be), but a year after your death, it will all be destroyed. Nothing, absolutely nothing, will survive. Your headstone will be dismantled. The penthouse in which you lived will be demolished. Your name will become synonymous with evil.

September 2012, and it all starts to come up. Like a build-up of effluent that could no longer be contained, first seeping, then surging out. Jimmy Savile, the nation’s favourite grotesque, the former DJ and children’s entertainer, is exposed as a serial sex abuser and paedophile. You can’t say it comes as a surprise, and that’s one of the most unsettling aspects of the whole affair. How out in the open it all was…We all read the text purporting to be the transcript of an unbroadcast scene from the BBC’s satirical programme, Have I Got News For You, in which Savile is openly accused of being a child sex abuser, and took it at face value (it seems now that the transcript was a fake, but it was an astonishingly convincing simulation…The rhythm of the interaction between the panellists…The way the verbal sparring escalates into aggression…The name of the supposed victim, Sarah Cornley…it all had a ring of authenticity – the signature of a Real, perhaps, that could not at then be recognised except in fiction…)

Yes, in a certain way, it was all out in the open – we all knew, or felt that we knew – but it mattered that the abuse was never acknowledged in his lifetime. For while the story remained unofficial Savile would not only go unpunished, he could continue to comport himself as a celebrated entertainer, a knight of the realm, stalwart charity fundraiser. No doubt Savile took a sociopathic delight in being able to get away with it in plain sight. In his 1974 autobiography, As It Happens, Savile had boasted about having sex with an underage runaway. The police wouldn’t dare touch him, he taunted. Neither, it seemed, would the media. Occasionally, a journalist would attempt to breach his defences. Louis Theroux did his trademark gentle probing of Savile about the paedophilia allegations in 2000 BBC documentary, but of course there was no question of the old man cracking.

By the end of 2012, the 70s was returning, no longer as some bittersweet nostalgia trip, but as a trauma. The phrase it’s like something out of David Peace has become something of a commonplace in the past few years. Strangely for fiction that is about the past, Peace’s work has actually gained in prophetic power since its publication. Peace wasn’t predicting the future – how could he be, when he was writing about the 70s and the 80s? – so much as he had fixated on those parts of the past which were about to resurface. The Fritzl case had echoes of the underground lair in which children are kept prisoner in the Red Riding novels. And everything that came to light about conspiracies amongst the English power elite – all the murk and tangle of Murdoch and Hillsborough – seemed to throw us back into Peace’s labyrinths of corruption and cover-up. Murdoch, Hillsborough, Savile…Pull on one thread and it all started to connect, and, wherever you looked, there was the same grim troika – police, politicians, media…Watching each other’s backs (partly for fear that they will be stabbed in their own back)…Having the goods on each other, the best kind of insurance policy, the ruling class model of solidarity…

After his death, Savile increasingly started to look like something Peace had dreamt up. We were drawn to a certain kind of fiction because consensual reality, the commonsense world that we like to think we live in, wasn’t adequate to a figure like Savile. At the same time, it became clear that the elements in Peace’s writing that previously seemed most melodramatically excessive were those which ended up rhyming with the new revelations. It’s as if melodramatic excess is built into the Real itself, and the sheer implausibility of corruption and abuse itself forms a kind of cloak for the abuser: surely this can’t be happening?

Savile’s stomping ground was right in the heart of Peace’s territory…in Leeds…where the entrepreneur-DJ started to build his empire, and where, knowing that abuse is easier to get away with when it comes disguised as care, he volunteered as a hospital porter… A spoonful of sugar helps the medicine go down…Incredibly, Savile was for a time a suspect in the Yorkshire Ripper investigation – members of the public had named Savile, and the body of one of the Ripper’s victims, Irene Richardson, had been found very near to his flat. Then there was the infamous photograph of Savile, Peter Sutcliffe and Frank Bruno at Broadmoor in 1991 – Savile, toting his signature cigar, brokering a meeting between a serial killer and a troubled former celebrity boxer. The grinning Sutcliffe looks like he’s wearing one of Savile’s shell-suits. The insanity of a society and of an era – all their occult complicities between celebrity, psychosis and criminality – is screamingly exposed here. Ritual inversion: light (entertainment) transforming into the darkest horror. By the end of 2012, Savile’s name was so irretrievably sullied that his old friend Peter Sutcliffe felt the need to speak up for him.

Savile was the kind of figure who came to dominate popular culture without inspiring much affection. You couldn’t say he was ever loved. Someone writing in to the London Review of Books dug up the BBC’s audience research reports on Savile’s first appearances on Top of the Pops. ‘10 December 1964. Jimmy Savile, who introduced the programme on this occasion, was obviously disliked by a large number of the sample audience. Many indicated their aversion to this artist by remarking that anything they had to say about him would be “quite unprintable”, whilst comment by those who freely expressed their feelings was liberally larded with such terms as “this nutcase”; “this obnoxious ‘thing’”; and “this revolting spectacle”.’ You don’t have to be loved, or even liked, to be a popular figure. Savile didn’t even have the love-to-hate appeal of a national pantomime villain such as Simon Cowell. His ticket to fame was his grotesquerie itself (and this grotesquerie meant that one of the most initially unnerving things about the revelations was being forced to think of Savile as any kind of sexual being). As Andrew O’Hagan argued in his piece on Savile for the London Review of Books, what mattered in the new world of television light entertainment was not likeability, or talent, but a certain larger-than-life aura – call it eccentricity, or call it derangement – which Savile easily possessed as his birthright. Even those who found Savile creepy could accept that he ‘belonged’ on television. After all, where else could he possibly belong? The problem was that, after the 60s, if you belonged on television, there was nowhere that wasn’t open to you. We now know that Savile was given keys to the Broadmoor hospital for the criminally insane, so that he could wander around the institution – just one example of the freedoms that Savile’s celebrity and power would acquire for him. We hear that Savile molested paraplegic patients in their hospital beds, and I’m reminded of Dennis Potter’s 1976 television play, Brimstone and Treacle, in which the lead character, the unctuous Martin, rapes a severely brain-damaged young woman while pretending to care for her. The BBC withdrew the play just before it was due to be broadcast – presumably at around the same time that Savile was appearing on Saturday night kids’ TV while raping helpless patients in private.

As Savile’s reputation descended into the mire, it pulled others’ with it. The police investigation prompted by the scandal, Operation Yewtree, went after a whole slew of former household names with (surely) more to come. Someone, I don’t remember who, says it’s like the 70s have gone on trial. Yes, but it’s a very particular strand of the 70s that is under investigation – not the officially debauched rock ‘n’ roll 70s, not Zeppelin or Sabbath, but the family entertainment 70s.

As the stories mounted up, Savile came to seem more and more unbelievable. Taken together, even facts that were already known about Savile before his death came to look as if they couldn’t possibly be true. Could it really be the case, for instance, that Savile had taken part in negotiations between the Israeli and the Egyptian governments in the 70s? That he had mediated between Prince Charles and Princess Diana as their marriage started to fail? (And how mad, how desperate, would you have to be to take Jimmy Savile’s advice on your marriage?) That he had spent Christmas after Christmas with Margaret Thatcher? (Thatcher had tried four times to ennoble Savile, but was repeatedly rebuffed by her advisers, and only succeeded in knighting him at the fag-end of her period as Prime Minister.)

Murdoch and the Daily Mail wasted no time in pushing the idea that the abuse was an institutional pathology – it was the BBC, and, more broadly, the paternalistic media culture of the 60s and 70s, which had incubated Savile’s corruption. The BBC, now in a permanent state of confusion about its role in a neoliberal world, duly went into a neurotic, narcissistic collapse. Its judgement was shot; it had failed to broadcast a report about Savile’s abuse, and the crisis over Savile would push it into moving too hastily when, a few months later, a Tory peer was wrongly named in another abuse scandal. Murdoch and the Mail crowed on about how the Savile revelations demonstrated the importance of press freedom – but the question that they neatly evaded was, where were their brave hacks? Why didn’t they expose Savile when it mattered, when he was alive?

When the question started to be asked about how he’d got away with it, we already knew the answer. He had connections at the very top. The very top. And he took care to make friends with those in power and authority at lower levels, too. Police officers regularly attended Savile’s now notorious Friday Morning Club meetings at his home in Leeds.

Savile’s ascent to his unlikely position of power and influence required immense amounts of hard work. One thing you could never accuse him of was slacking. A forensically researched post on the Sump Plug blog details how infernally busy Savile was in the early days of his career:


The Plaza Ballroom in Manchester () was just one of many dance halls and clubs that Savile oversaw, managed, diskjockeyed at, wielded shadowy control over or had some kind of undeclared stake in, not only in Manchester but also on the other side of the Pennines —in Bradford, in Wakefield, in Halifax, over on the coast in Scarborough and Whitby, and especially in Leeds. In his hometown the joints he presided over included the Cat’s Whiskers and the Locarno Ballroom in the County Arcade, known by locals simply as ‘the Mecca’ (later rebranded as the Spinning Disc). That’s where, in 1958, his predilection for underage girls first came to the attention of the police. The matter was swiftly resolved by peeling a few hundred quid off the big roll of twenties that he always carried, right up until he died.

Meanwhile, in Manchester on any given night in the late 50s and early 60s, if you couldn’t find Savile at the Plaza at lunchtime, he’d surely be at the Ritz later on. Or, if not, try the Three Coins in Fountain Street. He didn’t even rest on Sundays; that was when he span the platters for upwards of two thousand jivers and twisters at his Top Ten Club at Belle Vue.

The man was everywhere —at practically every major dance hall and nightclub in the North’s heaving conurbations, as much of a fixture as the rotating mirror ball.


Savile’s empire quickly spread down south too, down to the Ilford Palais, and to Decca Records, who would pay him to play their latest releases. Up North, Savile’s rackets were protected by a gang of bodybuilders, boxers, and wrestlers, including – improbably for those of us who came to know him as the comically fat wrestler Big Daddy, cuddly mainstay of Saturday afternoon television – Shirley Crabtree. The roots of 70s television were here, in these ballrooms and dancehalls, their seediness waiting to be transubstantiated into light entertainment.

But, a year after Savile’s death, the transubstantiation would go into extreme reverse. Now then, now then – one of Savile’s catchphrases started to assume an ominous significance. Only a few months previously, the BBC had broadcast a number of programmes celebrating his life and work. Now, condemnation is not enough: all traces of his existence must be removed. Not only is the headstone taken away, but we hear – can this possibly be true? It’s impossible to tell in the fevered atmosphere – that the family of a child buried near to Savile had requested that Savile’s remains be disinterred – as if he were some medieval devil, a noxious cloud of malignancy that can corrupt even the dead. More farcically, CBeebies, one of the BBC’s children’s channels, was censured because it broadcasted a repeat of an episode of the programme the Tweenies, in which one of the characters impersonated Savile.


Now then, now then…


At the time when Savile was abusing, the victims were faced, not with Jimmy Savile the monster, Jimmy Savile the prolific abuser of children, but with Jimmy Savile OBE – Sir Jimmy Savile – Jimmy Savile, Knight Commander of the Pontifical Equestrian Order of Saint Gregory the Great. When we ask how Savile got away with it all, we must remember this. Naturally, fear played a part in keeping Savile’s victims quiet. Who’s going to believe your word against the word of a television entertainer, someone who has raised millions for charity? But we also need to take seriously the way that power can warp the experience of reality itself. Abuse by the powerful induces a cognitive dissonance in the vulnerable – this can’t possibly be happening. What has happened can be pieced together only in retrospect. The powerful trade on the idea that abuse and corruption used to happen, but not any more. Abuse and cover–up can be admitted, but only on condition that they are confined to the past. That was then, things are different now…





02: HAUNTOLOGY





London After the Rave: Burial


k-punk post April 14, 2006


Burial is the kind of album I’ve dreamt of for years; literally. It is oneiric dance music, a collection of the ‘dreamed songs’ Ian Penman imagined in his epochal piece on Tricky’s Maxinquaye. Maxinquaye would be a reference point here, as would Pole – like both these artists, Burial conjures audio-spectres out of crackle, foregrounding rather than repressing sound’s accidental materialities. Tricky and Pole’s ‘cracklology’ was a further development of dub’s materialist sorcery in which ‘the seam of its recording was turned inside out for us to hear and exult in’ (Penman). But rather than the hydroponic heat of Tricky’s Bristol or the dank caverns of Pole’s Berlin, Burial’s sound evokes what the press release calls a ‘near future South London underwater. You can never tell if the crackle is the burning static off pirate radio, or the tropical downpour of the submerged city out of the window.’

Near future, maybe…But listening to Burial as I walk through damp and drizzly South London streets in this abortive Spring, it strikes me that the LP is very London Now – which is to say, it suggests a city haunted not only by the past but by lost futures. It seems to have less to do with a near future than with the tantalising ache of a future just out of reach. Burial is haunted by what once was, what could have been, and – most keeningly – what could still happen. The album is like the faded ten year-old tag of a kid whose Rave dreams have been crushed by a series of dead end jobs.

Burial is an elegy for the hardcore continuum, a Memories From the Haunted Ballroom for the Rave generation. It is like walking into the abandoned spaces once carnivalised by Raves and finding them returned to depopulated dereliction. Muted air horns flare like the ghosts of Raves past. Broken glass cracks underfoot. MDMA flashbacks bring London to unlife in the way that hallucinogens brought demons crawling out of the subways in Jacob’s Ladder’s New York. Audio hallucinations transform the city’s rhythms into inorganic beings, more dejected than malign. You see faces in the clouds and hear voices in the crackle. What you momentarily thought was muffled bass turns out only to be the rumbling of tube trains.

Burial’s mourning and melancholia sets it apart from dubstep’s emotional autism and austerity. My problem with dubstep has been that in constituting dub as a positive entity, with no relation to the Song or to pop, it has too often missed the spectrality wrought by dub’s subtraction-in-process. The emptying out has tended to produce not space but an oppressive, claustrophobic flatness. If, by contrast, Burial’s schizophonic hauntology has a 3D depth of field it is in part because of the way it grants a privileged role to voices under erasure, returning to dub’s phono-decentrism. Snatches of plaintive vocal skitter through the tracks like fragments of abandoned love letters blowing through streets blighted by an unnamed catastrophe. The effect is as heartbreakingly poignant as the long tracking shot in Tarkovsky’s Stalker (1979) that lingers over sublime objects-become trash.

Burial’s London is a wounded city, populated by ecstasy casualties on day release from psychiatric units, disappointed lovers on night buses, parents who can’t quite bring themselves to sell their Rave 12 inches at a carboot sale, all of them with haunted looks on their faces, but also haunting their interpas-sively nihilist kids with the thought that things weren’t always like this. The sadness in the Dem 2 meets Vini Reilly-era Durutti Column ‘You Hurt Me’ and ‘Gutted’ is almost overwhelming. ‘Southern Comfort’ only deadens the pain. Ravers have become deadbeats, and Burial’s beats are accordingly undead – like the tik-tok of an off-kilter metronome in an abandoned Silent Hill school, the klak-klak of graffiti-splashed ghost trains idling in sidings. 10 years ago, Kodwo Eshun compared the ‘harsh, roaring noise’ of No U-Turn’s ‘hoover bass’ with ‘the sound of a thousand car alarms going off simultaneously’. The subdued bass on Burial is the spectral echo of a roar, burned-out cars remembering the noise they once made.

Burial reminds me, actually, of paintings by Nigel Cooke. The morose figures Cooke graffitis onto his own paintings are perfect visual analogues for Burial’s sound. A decade ago, jungle and hip hop invoked devils, demons and angels. Burial’s sound, however, summons the ‘chain-smoking plants and sobbing vegetables’ that sigh longingly in Cooke’s painting. Speaking at the Tate, Cooke observed that much of the violence of graffiti comes from its velocity. There’s something of an affinity between the way that Cooke re-creates graffiti in the ‘slow’ medium of oil paints and the way in which Burial submerges (dubmerges?) Rave’s hyperkinesis in a stately melancholia. Burial’s dilapidated Afro NoFuturism does for London in the 00s what Wu Tang did for New York in the 90s. It delivers what Massive Attack promised but never really achieved. It’s everything that Goldie’s Timeless ought to have been. It’s the Dub City counterpart to Luomo’s Vocalcity. Burial is one of the albums of the decade. Trust me.





Downcast Angel: Interview with Burial


The Wire 286, December 2007


With his self-titled debut LP last year, Burial established himself as an extraordinary sonic mythographer, a sound poet capable of articulating the existential malaise of an era and a place using only sampled voices, broken breakbeats and musique concrète sound effects. Burial was a vivid audio portrait of a wounded South London, a semi-abstract sound painting of a city’s disappointment and anguish. Burial’s was a sound saturated in dance music, but his unsequenced beats were too eccentric to dance to. His sound was too out of step to fit into dubstep, the genre his records were most likely to be filed under because they were released on Kode9’s Hyperdub label. Burial’s sound might have fallen between the cracks, but it wasn’t some eclectic melange of existing forms. What was most impressive about it – and no doubt one of the reasons that it was The Wire’s Record Of The Year for 2006 – was the consistency of its sonic concept. There was an impersonal quality to Burial’s desolate elegies, a quality reinforced by his doing only a few interviews and refusing to allow a photograph of his face to be used in any promotion. Swarming rumours filled the hype-vacuum. Many didn’t believe he actually existed, attributing the record’s production to Basic Channel, The Bug, Kode9 himself – a massive backhanded compliment to how fully realised Burial’s (syn)aesthetic was. In fact, his sound has been gestating slowly, semi-secretly, for at least half a decade. The tracks on the first album had been selected from recordings Burial had made since 2001. His first appearance on vinyl was the track ‘Broken Home’ on Wasteland’s Vulture Culture Mix 2 in 2004. And the 12’ EP South London Boroughs, which trailed some of the most potent tracks from the first LP, followed a year later.

Burial’s refusal to ‘be a face’, to constitute himself as a subject of the media’s promotional machine, is in part a temperamental preference, and in part a resistance to the conditions of ubiquitous visibility and hyper-clarity imposed by digital culture – ‘It’s like a ouija board, it’s like letting someone into your head, behind your eyes. It lets randoms in,’ he says of the internet.

‘I’m just a well low key person,’ he admits. ‘I want to be unknown, because I’d rather be around my mates and family, but there’s no need to focus on it. Most of the tunes I like, I never knew what the people who made them looked like, anyway. It draws you in. You could believe in it more.’ Burial doesn’t DJ or play live, so photographs of him can’t even be surreptitiously taken and circulated. ‘I just want to be in a symbol, a tune, the name of a tune,’ he explains. ‘It’s not like it’s a new thing. It’s one of the old underground ways and it’s easier.’ Burial is more sensitive than most to the way in which people are shaped by impersonal forces. ‘When you are young you are pushed around by forces that are nothing to do with you,’ he says. ‘You’re lost; most of the time you don’t understand what’s going on with yourself, with anything.’ He knows that his sound does not come from anything with a face.

Without being chauvinistic, Burial is fiercely loyal to the British Hardcore continuum from which his sound has emerged. ‘If you’re well into tunes, your life starts to weave around them,’ he says. ‘I’d rather hear a tune about real life, about the UK, than some US hip-hop ‘I’m in the club with your girl’-type thing. I love R&B tunes and vocals but I like hearing things that are true to the UK, like drum ‘n’ bass and dubstep. Once you’ve heard that underground music in your life, other stuff just sounds like a fucking advert, imported.’ Indeed, one track on his new album Untrue is called ‘UK’; another, one of the most sorrowful, is called ‘Raver’. Burial’s London seems to be a city populated by dejected Ravers, returning to the sites of former revels and finding them derelict, forced to contrast the quotidian compromises of their post-Rave life with the collective ecstasy they once lived out. Burial’s is a re-dreaming of the past, a condensation of relics of abandoned genres into an oneiric montage. His sound is a work of mourning rather than of melancholia, because he still longs for the lost object, still refuses to abandon the hope that it will return. ‘A lot of those old tunes I put on at night and I hear something in the tune that makes me feel sad,’ he says. ‘A few of my favourite producers and DJs are dead now too – and I hear this hope in all those old tracks, trying to unite the UK. But they couldn’t, because the UK was changing in a different direction, away from us. Maybe the feeling of the UK in clubs and stuff back then, it wasn’t as artificial, self-aware or created by the Internet. It was more rumour, underground folklore. Anyone could go into the night and they had to seek it out. Because you could see it in people, you could see it in their eyes. Those Ravers were at the edge at their lives, they weren’t running ahead or falling behind, they were just right there and the tunes meant everything. In the 90s you could feel that it had been taken away from them. In club culture, it all became like superclubs, magazines, Trance, commercialised. All these designer bars would be trying to be like clubs. It all got just taken. So it just went militant, underground from that point. That era is gone. Now there’s less danger, less sacrifice, less journey to find something. You can’t hide, the media clocks everything.’ He checks his pessimism: ‘But dubstep nights () DMZ and FWD have that deep atmosphere and real feeling. The true underground is still strong, I hear good new tunes all the time.’

After a statement as definitive as his first LP, it was difficult to imagine where Burial would go next. But Untrue substantially modifies the sound auditioned on Burial. The most obvious difference from the first record is the amount and type of vocal on the new LP. His mentor Kode9 describes it as ‘weird soul’ and, if the reference points for the debut were early to mid-90s Rave and Jungle, the touchstones on Untrue are late 90s Garage and 2-step. The cut-up and pitchshifted voices – looped fragments of longing – make Untrue even more addictive and even more keeningly moving than Burial. Burial had in fact produced a whole album’s worth of material in another style – ‘more technical, all the tunes sounded like some kind of weapon that was being taken apart and put back together again’ – but he scrapped it. ‘I was worrying,’ he recalls, ‘I’d made all these dark tunes and I played them to my mum, and she didn’t like them. I was going to give up, but she was sweet, telling me, ‘Just do a tune, fuck everyone off, don’t worry about it.’ My dog died and I was totally gutted about that. She was just like, ‘Make a tune, cheer up, stay up late, make a cup of tea.’ And I rang her mobile 20 minutes later and I’d made that ‘Archangel’ tune on Untrue (), and I was like, ‘I’ve made the tune, the tune you told me to make.”

Burial’s treatment of voice has always been crucial to his sound. Too much dub-influenced music is content to simply erase the voice and turn up the echo, but Burial instinctively knew that dubbing is about veiling the song, about reducing it to a tantalising tissue of traces, a virtual object all the more beguiling because of its partial desubstantialisation. The drizzly crackle that has become one of his sonic signatures is part of the veiling process. Self-deprecatingly, he claims that he initially used the crackle to conceal ‘the fact that I wasn’t very good at making tunes’. But he is not so much influenced by dub as by the ‘vocal science’ developed by Jungle, Garage and 2-step producers. When he and his brothers would listen to darkside Jungle, Burial found himself increasingly drawn to the vocal tracks. ‘I’d love these vocals that would come in, not proper singing but cut-up and repeating, and executed coldly. It was like a forbidden siren. I was into the cut-up singing as much as the dark basslines. Something happens when I hear the subs, the rolling drums and vocals together. So when I started doing tunes, I didn’t have the kit and I didn’t understand how to do it properly, so I couldn’t make the drums and bass sound massive, so as long as it had a bit of singing in it, it forgave the rest of the tune. Then I couldn’t believe that I’d done a tune that gave me that feeling that proper records used to, and the vocal was the one thing that seemed to take the tune to that place. My favourite tunes were underground and moody but with killer vocals: ‘Let Go’ by Teebee, ‘Being With You Remix’ by Foul Play, Intense, Alex Reece, Digital, Goldie, Dillinja, EL-B, D-Bridge, Steve Gurley. I miss being on the bus to school listening to DJ Hype mixes.’

New Labour Britain is intoxicated by consensual sentimentality, hooked on disposable simulated emotion. With the ubiquity of TV talent shows, religiose emoting has become a fast track to media recognition, secular UK’s equivalent of sanctification and salvation. In this process, singing has become almost incidental – it’s lachrymose back stories that the media really hungers for. Burial’s strategy with singing is exactly contrary to this: he removes voices from biography and narrative, transforming them into fluttering, flickering abstractions, angels liberated from the heavy weight of personal history. ‘I was listening to these Guy Called Gerald tunes,’ he says. ‘I wanted to do vocals but I can’t get a proper singer like him. So I cut up a cappellas and made different sentences, even if they didn’t make sense, but they summed up what I was feeling.’ In the process of changing the pitch of the vocals, buried signals come to light. ‘I heard this vocal and it doesn’t say it but it sounds like ‘archangel’,’ says Burial. ‘I like pitching down female vocals so they sound male, and pitching up male vocals so they sound like a girl singing.’ This is apt, as angels are supposed to be without gender. ‘Well that works nice with my tunes, kind of half boy half girl,’ he enthuses. ‘I understand that moody thing, but some dance music is too male. Some Jungle tunes had a balance, the glow, the moodiness that comes from the presence of both girls and boys in the same tune. There’s tension because it’s close, but sometimes perfect together. I look like her. I am her.’

Kode9 describes the album as ‘downcast euphoria’, and that seems to fit. ‘I wanted to make a half euphoric record,’ Burial agrees. ‘That was an older thing that UK underground music used to have. Old Rave tunes used to be the masters of that, for a reason, to do with the Rave, half human endorphins and half something hypnotised by drugs. It was stolen from us and it never really came back. Mates laugh at me because I like whale songs. But I love them, I like vocals to be like that, like a night cry, an angel animal.’

Angels, again. On Untrue, Burial’s Ravers appear as downcast angels, beings of light exiled into the dull weight of the worldly. Untrue is like German director Wim Wenders’s Wings Of Desire (1987) relocated to the UK: an audio vision of London as a city of betrayed and mutilated angels, their wings clipped. But angels also hover above the hopeless and the abandoned here. ‘My new tunes are about that,’ Burial agrees, ‘wanting an angel to be watching over you, when there’s nowhere to go and all you can do is sit in McDonalds late at night, not answering your phone.’

As you might expect, Burial’s attunement to angels, demons and ghosts goes back to childhood. ‘My dad when I was really little,’ he says, ‘sometimes he used to read me MR James stories. On the South Bank last year, I bunked off from my day job and I found a book of MR James ghost stories. The one that fucked me up when I was little was “Oh, Whistle And I’ll Come To You, My Lad”. Something can betray how sinister it is even at a distance. Something weird happens with MR James, because even though it’s in writing, there’ll be a moment when the person meets the ghost, where you can’t quite believe what you’ve read. You go cold, just for those few lines when you glimpse the ghost for a second, or he describes the ghost face. It’s like you’re not reading any more. In that moment it burns a memory into you that isn’t yours. He says something like, “There’s nothing worse for a human being than to see a face where it doesn’t belong.” But if you’re little, and you’ve got an imagination which is always messing you up and darking you out, things like that are almost comforting to read.

‘Also,’ he continues, ‘there is nothing worse than not recognising someone you know, someone close, family, seeing a look in them that just isn’t them. I was once in a lock-in in a pub and the regulars there and some mates started telling these fucked-up ghost stories from real life, maybe that had happened to them, and I swear if you heard them…One girl told me the scariest thing I ever heard. Some of these stories would stop a few words earlier than seemed right. They don’t play out like a film, they’re too simple, too everyday, slight. Those stories ring true and I never forgot them. Sometimes maybe you see ghosts. On the underground with an empty Costcutters plastic bag, nowhere to go, they are smaller, about 70 per cent smaller than a normal person, smaller than they were in life.’

Burial makes the most convincing case that our zeitgeist is essentially hauntological. The power of Derrida’s concept lay in its idea of being haunted by events that had not actually happened, futures that failed to materialise and remained spectral. Burial craves something he never actually experienced firsthand. ‘I’ve never been to a festival, a Rave in a field, a big warehouse, or an illegal party,’ he says, ‘just clubs and playing tunes indoors or whatever. I heard about it, dreamed about it. My brother might bring back these records that seemed really adult to me and I couldn’t believe I had them. It was like when you first saw Terminator or Alien when you’re only little. I’d get a rush from it, I was hearing this other world, and my brother would drop by late and I’d fall asleep listening to tunes he put on.’ It was his older brother who made Rave a kind of ‘present absence’ in Burial’s life, a space to be filled with yarns and yearnings. ‘He loved tunes, Rave tunes, Jungle,’ Burial tells me. ‘He lived all that stuff, and he was gone, he was on the other side of the night. We were brought up on stories about it: leaving the city in a car and finding somewhere and hearing these tunes. He would sit us down and play these old tunes, and later on he’d play us ‘Metropolis’, Reinforced, Paradox, DJ Hype, Foul Play, DJ Crystl, Source Direct and Techno tunes.’

The Rave relics feed a hunger for escape. ‘I respect working hard but I dread a day job,’ asserts Burial. ‘Or a job interview. I’ve got a truant heart, I just want to be gone. I’d be in the kitchens, the corridors at work, and I’d be staring at the panels on the roof, clocking all the maintenance doors, dreaming about getting into the airducts. A portal. As a kid I used to dream about being put in the bins, escaping from things, without my mum knowing she’d put me out in the bins. So I’m in a black plastic bag outside a building and hearing the rain against it, but feeling all right, and just wanting to sleep, and a truck would take me away.’ A too quick psychoanalytic reading would hear this as a thinly coded wish to return to the womb – and Burial’s warm bass certainly feels enwombing – but that would be to ignore the desire to flee that is also driving this fantasy. Burial wants out, but he cannot positively characterise what lies beyond. ‘We all dream about it,’ he says. ‘I wish something was there. But even if you fight to see it, you never see anything. You don’t have a choice. You’d be on the way to a job, but you’re longing to go down this other street, right there, and you walk past it. No force on Earth could make you go down there, because you’ve got to traipse to wherever. Even if you escape for a second, people are on your case, you can’t go down old Thames side and throw your mobile in.’

But there are always flickers and flashes of the other side. After-images. ‘I used to get taken away to the middle of nowhere, by the sea,’ concludes Burial. ‘I love it out there, because when it’s dark, it’s totally dark, there’s none of this ambient light London thing. We used to have to walk back and hold hands and use a lighter. See the light, see where you were and then you’d walk on, and the image of where you’ve just been would still be on your retina.





Sleevenotes for The Caretaker’s

Theoretically Pure Anterograde Amnesia


May 2006


Could it be said that we all now suffer from a form of theoretically pure anterograde amnesia?

Oliver Sacks’ The Man who Mistook his Wife for a Hat and Christopher Nolan’s Memento (2000) have made the features of the condition – referred to, misleadingly, as short-term memory loss – well-known. In fact, sufferers do produce new memories, but they are not retained. There is no long-term encoding. This type of amnesia is anterograde rather than retrograde because it does not affect any memories formed before the onset of condition. Theoretically: in practice, it is likely that even the old memories will undergo some degradation.

On Theoretically Pure Anterograde Amnesia the album, a tendency in the Caretaker’s music has reached a kind of culmination. The theme was once homesickness for the past. Now, it is the impossibility of the present.

Selected Memories From The Haunted Ballroom was a kind of replicant mnemonic implant, a false memory of the tearoom pop of the twenties and thirties. For those of us haunted by the lambent ache of Al Bowlly’s croon in The Shining and Pennies From Heaven, that kind of Total Recall trip was irresistible. The ghosts were so glamorous, their bob haircuts and pearls glistening in the candlelight, their dance moves oh so elegant.

An occulted reference might have been The Invention of Morel (an influence upon Last Year at Marienbad (1961) and therefore also upon The Shining (1980)), Adolfo Bioy Casares’ science fictional lovesong to Louise Brooks. Casares imagined a world we live in it where the spectres of the beautiful and the damned are preserved forever, their little gestures and banal conversations transformed, by repetition, into holy artefacts. The simulation machine on Morel’s island is film, of course, and who has not at some time wanted to do as Casares’ hero does and pass beyond the screen, so as to finally be able to talk with the ghosts you have for so long mooned over? It is the same temptation that Jack yields to in The Shining when he enters into the consensual hallucination of The Overlook. The Gold Room, in which the Scott Fitzgerald-era elite forever cavort in a ceaseless whirl of wit, cocaine and wealth, is perfectly heavenly. But you know what the price of the ticket to heaven is, don’t you Jack?

Don’t you?

It is that grave-damp, mildewed odour which the perfume and the preservative never quite covered up which has always made The Caretaker’s music uneasy, rather than easy, listening. Queasy listening, actually. It has never been possible to ignore the shadows lurking at the periphery of our audio-vision; the trip down memory lane was deliciously intoxicating but there was a bitter undertaste. A faint horror, something like the dim but insistent awareness of plague and mortality that must have nagged at the entranced-dancers in Poe’s ‘The Masque of the Red Death’.


That’s not all.


Something else was wrong.


The sepia and the soft focus were photoshopped in, we knew that. These thick carpets and china tea-sets weren’t really there. And they never were, not for us. We were in a simulation of another’s mind’s eye. The mottled, honeyed, slurred and reverbed quality of the sound alerted us to the fact that this was not the object itself but the object as it is for someone else’s memory.

On Theoretically Pure Anterograde Amnesia, things have worsened immeasurably. It is as if the Overlook simulation has run out of steam. The lights have gone out. The hotel is rotten, a burned out wreck long since gutted, the band is pale and very nearly translucent.

The threat is no longer the deadly sweet seduction of nostalgia. The problem is not, any more, the longing to get to the past, but the inability to get out of it. You find yourself in a grey black drizzle of static, a haze of crackle. Why is it always raining here? Or is that just the sound of the television, tuned to a dead channel?

Where were we?

You suppose that you could be in familiar territory. It’s difficult to know if you’ve heard this before or not. There’s not much to go on. Few landmarks. The tracks have numbers, not names. You can listen to them in any order. The point is to get lost. That’s easy in this ill-seen, late Beckett landscape. You extemporise stories they call it confabulation – to make sense of the abstract shapes looming in the smoke and fog.

Who is editing the film, and why all the jump–cuts?

By now, very little a few haunting refrains lingering at the back of your mind separates you from the desert of the real.

Let’s not imagine that this condition afflicts only a few unfortunates. Isn’t, in fact, theoretically pure anterograde amnesia the postmodern condition par excellence? The present – broken, desolated is constantly erasing itself, leaving few traces. Things catch your attention for a while but you do not remember them for very long. But the old memories persist, intact…Constantly commemorated … I love 1923…


Do we really have more substance than the ghosts we endlessly applaud?


The past cannot be forgotten, the present cannot be remembered.


Take care. It’s a desert out there…





Memory Disorder: Interview with

The Caretaker


The Wire 304, June 2009


‘I have always been fascinated by memory and its recall especially where sound is concerned,’ writes James Kirby via email. ‘Some things we remember easily and others we never seem to grasp. That idea was developed more on the boxset I did 2006’s Theoretically Pure Anterograde Amnesia () which was based around a specific form of amnesia where sufferers can remember things from the past but are unable to remember new things. To recreate that in sound was a challenge that I relished really. I realised the only way was to make a disorientating set with very few reference points. Fragments of melody breaking out of this monotonous tone and audio quagmire. Even if you listen over and over to all the songs you still can’t remember when these melodies will come in. You have no favourite tracks, it’s like a dream you are trying to remember. Certain things are clear but the details are still buried and distant.’

Kirby’s description perfectly captures the unsettling experience of listening to Theoretically Pure Anterograde Amnesia. With the release of the six CD boxset, his project The Caretaker crossed over from being an exercise in atmospheric nostalgia to being a harrowing investigation of memory disorder. The box set is more like a sonic installation than a record, a work whose conceptual and textural richness puts much sound art to shame. The first three Caretaker records – Selected Memories From The Haunted Ballroom (1999), A Stairway To The Stars (2001) and We’ll All Go Riding On A Rainbow (2003) – swathed sampled British tearoom pop in a gaslit halo of reverb and crackle. On Theoretically Pure Anterograde Amnesia the effects and the surface noise take over, so that instead of a gently dub–dilapidated pop, there is an unnavigable murk, as abstract and minimal as a Beckett landscape. Echoes and reverberations float free of any originating sound source in a sea of hiss and static. If the earlier records suggested spaces that were mildewed but still magnificent – grand hotels gone to seed, long abandoned ballrooms – Theoretically Pure Anterograde Amnesia invokes sites that have deteriorated into total dereliction, where every unidentified noise is pregnant with menace. The 72 tracks – all of them numbered rather than named – simulate the amnesiac condition, and the few fragments of well known tunes that occasionally flare in the gloom are intermittent islands of familiarity in a world that has become hostile and unrecognisable.

‘Maybe it’s a dark humour, a kind of an audio black comedy,’ Kirby says of The Caretaker, but the solemnity of the project belies Kirby’s reputation as a prankster. His label V/Vm notoriously released a version of Lieutenant Pigeon’s ‘Mouldy Old Dough’ just after appearing on the cover of The Wire 176 under the headline ‘Harder! Faster! Louder!’, one of a series of manglings of mainstream music – tracks by Chris de Burgh, John Lennon and Elton John were also butchered and reassembled – that V/Vm issued.

It is the focus on cultural memory that holds together all of Kirby’s work, including the V/Vm mash–ups. If the V/Vm (sub)versions of pop come from the brash side of postmodern pastiche, then The Caretaker is about the dark side of cultural retrospection. Theoretically Pure Anterograde Amnesia was in many ways an act of diagnosis of a cultural pathology. It might seem strange to describe a culture that is so dominated by past forms as being amnesiac, but the kind of nostalgia that is now so pervasive may best be characterised not as a longing for the past so much as an inability to make new memories. Fredric Jameson described one of the impasses of postmodern culture as the inability ‘to focus our own present, as though we have become incapable of achieving aesthetic representations of our own current experience.’ The past keeps coming back because the present cannot be remembered. Memory disorders have recurred as themes in the popular cinema in the past decade or so: it is theoretically pure anterograde amnesia that afflicts Leonard, the lead character in Memento, while the massively successful Bourne films were preoccupied with memory loss. It is not surprising that anxieties about memory should continually surface in late capitalism, where, as Jameson and others have argued, perpetual economic instability and the rapid turnover of ephemeral images leads to a breakdown in any coherent sense of temporality.

Kirby has approached the failure of the future from a different angle on another of his projects, 2006’s The Death Of Rave. Here, Rave is desubstantialised, stripped of all bass weight and drum propulsion, reduced to shimmer and haze. The tracks sound like they are being heard from outside a club: a horribly accurate sonic metaphor, perhaps, of our current state of exile from the future-shocking rate of innovation that dance music achieved in the 80s and 90s. ‘Yeah, that project really is in its infancy,’ Kirby says. ‘It came about as part of the V/Vm 365 project where the aim was to make one audio track a day. I used to go Raves when I was younger, went through that whole explosion in electronic music from 1987 to around 1992-93 when it seemed like there was a new genre every single week. It was an amazing time in music to hear so many things happening and so many new possibilities opening up and to see and feel the energy of new music exploding on dancefloors and in clubs. I think The Death Of Rave is about the loss in that spirit and a total loss of energy in most electronic musics across the board. I feel sorry these days for people when I go to clubs as that energy isn’t there any more. I mean we have some so called very cool clubs in Berlin such as Watergate and Berghain, but you compare them to those back in the late 80s and early 90s in Manchester and it really is no comparison. Of course new things pop up but the difference now really is that if something explodes then before it can grow naturally people have strangled it to death with parodies online and often a scene or new style is dead before it even surfaces. House and Techno for instance took a long time to mature in Chicago and Detroit, now there is no time, once an idea is out of the rabbit’s hat it’s copied ad infinitum until the energy is gone. That is the key word – ‘energy’, it’s the one thing I have always been inspired by. For me those Death Of Rave tracks are about stripping Rave music from all its energy and spirit of fun – taking the audio from the Rave to the grave, if you like.’ The tracks are like energy flashbacks, frail figments of Rave reconstructed in a serotonin-depleted brain.

Kirby’s other project The Stranger is organised around space rather than time. ‘The Stranger really is a darker version of The Caretaker,’ Kirby says, ‘and is its closest relative. The Stranger is about creating a physical location in sound. The last album for example 2008’s Bleaklow () was about the site of Bleaklow which is in the Peak District, it can be a grim place on the dark grey days but also beautiful on sunny days. Weirdly I had a few people get in touch with me who walk up there and they told me I captured the atmosphere perfectly and they used it as they were walking up there. I guess the odd glint of sunshine coming through that slate northern grey sky could be heard aurally.’

Kirby himself now lives in Berlin. ‘I moved to Berlin as it has the atmosphere and opportunities of the big city but also there’s a lot of space here to think more and also it’s easy to hide away on the dark streets here. Also it’s not as brutal as Manchester here, there is more of an openess as people don’t follow the media and news so much.’ Like The Stranger, though, The Caretaker remains a project rooted in Britishness – ‘it’s often only British music which has been used as source material.’ A parallel for The Caretaker’s excavation of pre-rock British pop is Dennis Potter’s musical drama for television, Pennies From Heaven. ‘The use of audio in Pennies From Heaven is amazing along with its vibrancy and colour and of course the way Dennis Potter uses the sadness in the lyrics to keep telling the story is also special as these songs really are stories in themselves. John Clifford and Herk Harvey’s film Carnival of Souls (1962) was also a point of reference, the closing scenes in that film could even be audio from A Stairway To The Stars. I only saw that film after people had mentioned it to me. It works a lot that way, people will draw a line to something and I will then investigate that too.’

But of course the main initial impetus for The Caretaker was Kubrick’s The Shining. The name ‘the caretaker’ was taken from the role that Jack Torrance is condemned to forever play in the haunted Overlook hotel (‘you’ve always been the caretaker’, Torrance is told in one of the film’s most chilling moments). The conceit was simple: inspired by ‘the haunting sequences which feature the ballroom music which is playing only in Jack’s mind’, Kirby thought, why not make a whole album of material that might also have played in the Overlook? The Shining soundtrack includes two tracks by Al Bowlly, the between-the-wars crooner whose songs features in many of Potter’s dramas, and Kirby sought out music in a similar vein. ‘I spent a lot of time searching out music from that era over a two or three year period and constantly started to play around with this source material. The interesting thing for me is the fact that most of that music is about ghosts and loss as it was recorded between both the world wars. It’s of a totally different era and had more or less been forgotten. Titles inspired new ideas as did the audio itself. I was fortunate as there was a great record shop near where I was in Stockport which was ran by two old guys and it specialised in 78s. I would take in audio and ask then what was similar and they would scuttle off into the back of the shop and dig out some old catalogue from the 1930s and then pull out vinyls for me. It was an amazing resource sadly which is no longer there as one of the guys passed away and the other decided to close the shop. It was like a timewarp in there, like going back 30 or 40 years. They would hand write receipts and half of their stock was in this backroom you were denied access too. They had no idea what I was doing in there buying these records, though one of them told me one time ‘You were born in the wrong era as nobody is interested in this music who is your age.”

Kirby has tuned to more recent history for an upcoming project. ‘It has been in my mind for a while to work on a Scragill/Thatcher project and this is the perfect time for this now as we approach the 25th anniversary of the Miners Strike. A lot has been written elsewhere about this conflict and its outcome and legacy, I have been scouring online and also have picked up some amazing footage to reprocess. It will link closely to The Caretaker in terms of its style as it will be like watching a half remembered version due to the processing. Some of the footage is totally ghostlike as it was recorded on VHS tapes from Miners back in 1984, so there is a real loss in quality and the sound fails to match the visuals. It’s looking like a dream version maybe. This will be mainly video work with also an incredibly limited vinyl release featuring audio from these videos and some exclusive audio work.’ This will fit into a series of re-stagings of the Miners Strike this decade, including Jeremy Deller and Artangel’s The Battle Of Orgreave and David Peace’s GB84.

Kirby decided to close V/Vm down last year. ‘V/Vm was a vehicle for a lot of the work I have done but I think now as music consumers we have reached a point where labels are not so important, what is more important is delivery and availability of work.’ It is partly the possibilities for the online distribution of music, which Kirby has always been enthusiastic about, that led him to end V/Vm, but he ‘also found I was using the name V/Vm less and less when it comes to new works. I’ve been working on a very personal album in terms of moods I want to convey and I guess I may use my own name for that.’ In fact, the album, entitled History Always Favours The Winners, will come out under the name Leyland Kirby (‘Leyland is my grandather’s and my middle name. There are already too many James Kirby’s making music out there, if I believe Google. Now I’m only competing with a glamour model from Sheffield in the Google search.’) The Leyland Kirby music was made without the use of samples, but it has clearly been informed by Kirby’s time in the vaults. The tracks have an eerily untimely quality, a stately grace, a filmic scope. On ‘When Did Our Dreams And Futures Drift So Far Apart’, a doleful, echo-refracted piano desolately tracks through subdued electronic textures. ‘The Sound Of Our Music Vanishing’ is a more violent exercise in thwarted recall – here it as if the memories are rushing in and being obliterated at the same time, like Basinski if the tapes were being violently shredded instead of gently disintegrating. The epic ‘When We Parted My Heart Wanted To Die’, meanwhile, has a swelling, magisterial melancholy that recalls Angelo Badalamenti.

The Caretaker project continues, however. ‘I have started to play shows finally as The Caretaker, usually I just like to let the music just creep out of the speakers as if it’s actually the venue playing the audio or that the sounds are in your own mind. I played in Athens last week in a pitch black room which worked well, maybe I can work some visuals into the live process but they would have to add to the audio and not distract the listening process. I am always of course interested in playing more relevant locations, so for instance Blackpool Tower would be amazing as the ballroom there is a great Victorian example and perfect for this particular audio recall.’

‘More than anything it’s all about research and mood when making the albums,’ Kirby replies when I ask him how he makes The Caretaker records. ‘Knowing the source material, maybe hearing a lyrical phrase which opens up an idea in my mind or indeed just reading something, such as with the Anterograde boxset which sparked off another idea and offered a different tangent and possibility. Without going into the specifics, things are reworked totally in a digital realm until the right mood surfaces. It’s very important too that I am in the right mood mentally to make that music which I think comes across certainly in the later albums, as opposed maybe to the first album. I am getting better at realising the days when I get the best results now when working on a specific project. It’s strange really because there is a full range of emotions in the music when I listen back, from loss to happiness, dislocation, regret, longing. Maybe it’s the source music itself which inspires this, but there are still for me a lot of personal moments in amongst those albums. Maybe even some of my own memories are intertwined in there.’

The word ‘research’ keeps coming up in Kirby’s discussion of The Caretaker project. ‘I have been doing a lot of online research in the last couple of years and also have been watching a lot of documentaries about people who suffer from brain disorders and memory problems. The last release 2008’s Persistent Repetition of Phrases () was based around a lot of conditions where the sufferer just repeats themselves, so the audio featured a lot of loops and microloops, it was a lot warmer and more gentle than the boxset release. Not all memories are necessarily bad or disturbing memories.’ On Persistent Repetition of Phrases, one of The Wire’s top ten records of last year, there was accordingly a return of the some of the prettiness that was absent from Theoretically Pure Anterograde Amnesia, but there was also an icy lucidity, an exquisite poise, about the record. It felt like a distillation and a consolidation. ‘The challenge now is to move the sound somewhere else brainwise and memory wise, that will take time to find the new direction. More research will have to be done before I find the best pathway for future exploration. I would also love to use this music on film as it would be perfect for this, so maybe a door will open somewhere.’





Home is Where The Haunt is:

The Shining’s Hauntology


k-punk post, January 23, 2006


1. The sound of hauntology


Conjecture: hauntology has an intrinsically sonic dimension.

The pun – hauntology, ontology – works in spoken French, after all. In terms of sound, hauntology is a question of hearing what is not here, the recorded voice, the voice no longer the guarantor of presence (Ian P: ‘Where does the Singer’s voice GO, when it is erased from the dub track?’) Not phonocentrism but phonography, sound coming to occupy the dis-place of writing.

Nothing here but us recordings…


2. Ghosts of the Real


Derrida’s neologism uncovers the space between Being and Nothingness.

The Shining – in both book and film versions, and here I suggest a side-stepping of the wearisome struggle between King fans and Kubrickians and propose treating the novel and the film as a labyrinth-rhizome, a set of interlocking correspondences and differences, a row of doors – is about what lurks, unquiet, in that space. Insofar as they continue to frighten us once we’ve left the cinema, the ghosts that dwell here are not supernatural. As with Vertigo (1958), in The Shining it is only when the possibility of supernatural spooks has been laid to rest that we can confront the Real ghosts…or the ghosts of the Real.


3. The haunted ballroom


Mark Sinker: ‘ALL Kubrick’s () films are fantastically ‘listenable’ (if you use this in sorta the same sense you use watchable)’

Where does

The conceit of The Caretaker’s Memories from the Haunted Ballroom has the simplicity of genius: a whole album’s worth of songs that you might have heard playing in the Gold Room in The Shining’s Overlook Hotel. Memories from the Haunted Ballroom is a series of soft-focus delirial-oneiric versions of 20s and 30s tearoom pop tunes, the original numbers drenched in so much reverb that they have dissolved into a suggestive audio-fog, the songs all the more evocative now that they have been reduced to hints of themselves. Thus Al Bowlly’s ‘It’s All Forgotten Now’, for instance, one of the tracks actually used by Kubrick on The Shining soundtrack, is slurred down, faded in and out, as if it is being heard in the ethereal wireless of the dreaming mind or played on the winding-down gramophone of memory. As Ian Penman wrote of dub: ‘It makes of the Voice not a self-possession but a dispossession – a ‘re’ possession by the studio, detoured through the hidden circuits of the recording console.’

the singer’s voice

GO?


4. In the Gold Room


Jameson: ‘it is by the twenties that the hero is haunted and possessed…’

Kubrick’s editing of the film does not allow any of the polyvalencies of that phrase, ‘It’s All Forgotten Now’, to go un(re)marked. The uncanniness of the song, today and 25 years ago when the film was released, arises from the (false but unavoidable) impression that it is commenting on itself and its period, as if were an example of the way in which that era of beautiful and damned decadence and Gatsby glamour were painfully, delightfully aware of its own butterfly’s wing evanescence and fragility. Simultaneously, the song’s place in the film – it plays in the background as a bewildered Jack speaks to Grady in the bathroom about the fact that Grady has killed himself after brutally murdering his children – indicates that what is forgotten may also be preserved: through the mechanism of repression.

I don’t have any recollection of that at all.

Why does this Gold Room Pop, all those moonlight serenades and summer romances, have such power? The Caretaker’s spectralised versions of those lost tunes only intensifies something that Kubrick, like Dennis Potter, had identified in the pop of the 20s and 30s. I’ve tried to write before about the peculiar aching quality of these songs that are melancholy even at their most ostensibly joyful, forever condemned to stand in for states that they can evoke but never instantiate.

For Fredric Jameson, the Gold Room revels bespeak a nostalgia for ‘the last moment in which a genuine American leisure class led an aggressive and ostentatious public existence, in which an American ruling class projected a class-conscious and unapologetic image of itself and enjoyed its privileges without guilt, openly and armed with its emblems of top-hat and champagne glass, on the social stage in full view of the other classes’. But the significance of this genteel, conspicuous hedonism must be construed psychoanalytically as well as merely historically. The ‘past’ here is not an actual historical period so much as a fantasmatic past, a Time that can only ever be retrospectively – retrospectrally – posited. The ‘haunted ballroom’ functions in Jack’s libidinal echonomy (to borrow a neologism from Irigaray) as the place of belonging in which, impossibly, the demands of both the paternal and the maternal superegos can be met, the honeyed, dreamy utopia where doing his duty would be equivalent to enjoying himself…Thus, after his conversations with bartender Lloyd and waiter Grady (Jack’s frustrations finding a blandly indulgent blank mirror sounding board in the former and a patrician, patriarchal voice in the latter), Jack comes to believe that he would be failing in his duty as a man and a father if he didn’t succumb to his desire to kill his wife and child.

White man’s burden, Lloyd…white man’s burden…

If the Gold Room seems to be a male space (it’s no accident that the conversation with Grady takes place in the men’s room), the place in which Jack – via male intermediaries, intercessors working on behalf of the hotel management, the house, the house that pays for his drinks – faces up to his ‘man’s burdens’, it is also the space in which he can succumb to the injunction of the maternal super-ego: ‘Enjoy’.

Michel Ciment: ‘When Jack arrives at the Overlook, he describes this sensation of familiarity, of well-being (‘It’s very homey’), he would ‘like to stay here forever’, he confesses even to having ‘never been this happy, or comfortable anywhere’, refers to a sense of dèja vu and has the feeling that he has ‘been here before’. ‘When someone dreams of a locality or a landscape,’ according to Freud, ‘and while dreaming thinks “I know this, I’ve been here before”, one is authorised to interpret that place as substituting for the genital organs and the maternal body.’


5. Patriarchy/hauntology


Isn’t Freuds thesis – first advanced in Totem and Taboo and then repeated, with a difference, in Moses and Monotheism, simply this: patriarchy is a hauntology? The father – whether the obscene Alpha Ape Pere-Jouissance of Totem and Taboo or the severe, forbidding patriarch of Moses and Monotheism – is inherently spectral. In both cases, the Father is murdered by his resentful children who want to re-take Eden and access total enjoyment. Their father’s blood on their hands, the children discover, too late, that total enjoyment is not possible. Now stricken by guilt, they find that the dead Father survives – in the mortification of their own flesh, and in the introjected voice which demands its deadening.


6. A History of Violence


Ciment: ‘The camera itself – with its forward, lateral and reverse tracking shots…following a rigorously geometric circuit – adds further to the sense of implacable logic and an almost mathematical progression.’

Even before he enters the Overlook, Jack is fleeing his ghosts. And the horror, the absolute horror, is that he – haunter and the hunted – flees to the place where they are waiting. Such is The Shining’s pitiless fatality (and the novel is if anything even more brutal in its diagramming of the network of cause–and–effect, the awful Necessity, the ‘generalized determinism’, of Jack’s plight than the film).

Jack has a history of violence. In both novel and film of The Shining, the Torrance family is haunted by the prospect that Jack will hurt Danny…again. Jack has already snapped, drunkenly attacked Danny. An aberration, a miscalculation, ‘a momentary loss of muscular coordination. A few extra foot-pounds of energy per second, per second’: so Jack tries to convince Wendy, and Wendy tries to convince herself. The novel tells us more. How has it come to this, that a proud man, an educated man, like Jack, is reduced to sitting there, false, greasy grin plastered all over his face, sucking up everything that a smarmy corporate non-entity like Stuart Ulman serves up? Why, because he has been sacked from his teaching job for attacking a pupil, of course. That is why Jack will accept, and be glad of, Ulman’s menial job in Overlook.

The history of violence goes back even further. One of the things missing from the film but dealt with at some length in the novel is the account of Jack’s relationship with his father. It’s another version of patriarchy’s occult history, now not so secret: abuse begetting abuse. Jack is to Danny as Jack’s father was to him. And Danny will be to his child…?

The violence has been passed on, like a virus. It’s there inside Jack, like a photograph waiting to develop, a recording ready to be played.

Refrain, refrain…


7. Home is where the haunt is


The word ‘haunt’ and all the derivations thereof may be one of the closest English word to the German ‘unheimlich’, whose polysemic connotations and etymological echoes Freud so assiduously, and so famously, unravelled in his essay on ‘The Uncanny’. Just as ‘German usage allows the familiar (das Heimliche, the ‘homely’) to switch to its opposite, the uncanny (das Unheimliche, the ‘unhomely’)’ (Freud), so ‘haunt’ signifies both the dwelling-place, the domestic scene and that which invades or disturbs it. The OED lists one of the earliest meanings of the word ‘haunt’ as ‘to provide with a home, house.’

Fittingly, then, the best interpretations of The Shining position it between melodrama and horror, much as Cronenberg’s History of Violence (2005) is positioned between melodrama and the action film. In both cases, the worst Things, the real Horror, is already Inside…. (and what could be worse than that?)

You would never hurt Mommie or me, would ya?


8. The house always wins


What horrors does the big, looming house present? For the women of Horrodrama, it has threatened non-Being, either because the woman will be unable to differentiate herself from the domestic space or because – as in Rebecca (itself an echo of Jane Eyre) – she will be unable to take the place of a spectral-predecessor. Either way, she has no access to the proper name. Jack’s curse, on the other hand, is that he is nothing but the carrier of the patronym, and everything he does always will have been the case.


I’m sorry to differ with you, sir. But you are the caretaker. You’ve always been the caretaker. I should know, sir. I’ve always been here.


9. I’m right behind you Danny


Metz: ‘When Jack chases Danny into the maze with ax in hand and states, ‘Im right behind you Danny’, he is predicting Dannys future as well as trying to scare the boy.’

Predicting Dannys future Jack might be, but that is why he could equally well say ‘I’m just ahead of you Danny…’ Danny may physically have escaped Jack, but psychically…? The Shining leaves us with the awful suspicion that Danny may become (his) Daddy, that the damage has already been done (had already been done even before he was born), that the photograph has been taken, the recording made; all that is left is the moment of development, of playing back.

Unmask!

(And how does Danny escape from Jack? By walking backwards in his father’s footsteps).


10. The No Time of trauma


Jack: Mr. Grady. You were the caretaker here. I recognise ya. I saw your picture in the newspapers. You, uh, chopped your wife and daughters up into little bits. And then you blew your brains out.

Grady: That’s strange, sir. I don’t have any recollection of that at all.

What is the time when Jack meets Grady?

It seems that the murder – and suicide – has already happened, Grady tells Jack that he had to correct his daughters. Yet – not surprisingly – Grady has no memory – Bowlly’s ‘It’s All Forgotten Now’ wafting in the background – of any such events.

‘I don’t have any recollection of that at all.’

(And you think, well, it’s not the sort of thing that you’d forget, killing yourself and your children, is it? But of course, it’s not the sort of thing that you could possibly remember. It is an exemplary case of that which must be repressed, the traumatic Real.)

Jack: Mr. Grady. You were the caretaker here.

Grady: I’m sorry to differ with you, sir. But you are the caretaker. You’ve always been the caretaker. I should know, sir. I’ve always been here.


11. Overlooked


Overlook:

To look over or at from a higher place.

To fail to notice or consider; miss.





Hauntological Blues: Little Axe


k-punk post, October 3, 2006


Since we’re talking about hauntology, we ought to have mentioned Beloved by now: not only Morrison’s novel, but also Demme’s astonishing film. It’s telling that Demme is celebrated for his silly grand guignol, The Silence of the Lambs, while Beloved is forgotten, repressed, screened out. Hopkins’ pantomime ham turn as Lecter surely spooks no-one, whereas Thandie Newton’s automaton-stiff, innocent-malevolent performance as Beloved is almost unberable: grotesque, disturbing, moving in equal measure.

Like The Shining – a film that was also widely dismissed for nigh on a decade – Beloved (1998) reminds us that America, with its anxious hankerings after an ‘innocence’ it can never give up on, is haunted by haunting itself. If there are ghosts, then what was supposed to be a New Beginning, a clean break, turns out to be a repetition, the same old story. The ghosts were meant to have been left in the Old World…but here they are…

Whereas The Shining digs beneath the hauntological structure of the American family and finds an Indian Burial Ground, Beloved pitches us right into the atrocious heart of America’s other genocide: slavery and its aftermath. No doubt the film’s commercial failure was in part due to the fact that the wounds are too raw, the ghosts too Real. When you leave the cinema, there is no escape from these spectres, these apparitions of a Real which will not go away but which cannot be faced. Some viewers complain that Beloved should have been reclassifed as Horror…well, so should American history…

Beloved comes to mind often as I listen to Stone Cold Ohio, the outstanding new LP by Little Axe. Little Axe have been releasing records for over a decade now, but, in the 90s, my nervous system amped up by jungle’s crazed accelerations, I wasn’t ready to be seduced by their lugubrious dub blues. In 2006, however, the haunted bayous of Stone Cold Ohio take their place alongside Burial’s phantom-stalked South London and Ghost Box’s abandoned television channels in hauntological Now. Since I received Stone Cold Ohio last week, I’ve listened to little else; and when I wasn’t immersed in Stone Cold Ohio I was re-visiting the other four Little Axe LPs. The combination of skin-tingling voices (some original, some sampled) with dub space and drift is deeply addictive. Little Axe’s world is entrancing, vivid, often harrowing; it’s easy to get lost in these thickets and fogs, these phantom plantations built on casual cruelty, these makeshift churches that nurtured collective dreams of escape…

Shepherds…

Do you hear the lambs are crying?

Little Axe’s records are wracked with collective grief. Spectral harmonicas resemble howling wolves; echoes linger like wounds that will never heal; the voices of the living harmonise with the voices of the dead in songs thick with reproach, recrimination and the hunger for redemption. Yet utopian longings also stir in the fetid swamps and unmarked graveyards; there are moments of unbowed defiance and fugitive joy here too.

I know my name is written in the Kingdom….

Little Axe is Skip McDonald’s project. Through his involvement with the likes of Ohio Players, the Sugarhill Gang and Mark Stewart, McDonald has always been associated with future-orientated pop. If Little Axe appear at first sight to be a retreat from full-on future shock – McDonald returning to his first encounter with music, when he learned blues on his father’s guitar – we are not dealing here the familiar, tiresome story of a ‘mature’ disavowal of modernism in the name of a re-treading of Trad form. In fact, Little Axe’s anachronistic temporality can be seen as yet another rendering of future shock; except that this time, it is the vast unassimilable trauma, the SF catastrophe, of slavery that is being confronted. (Perhaps it always was…)

Even though Little Axe are apt to be described as ‘updating the blues for the 21st century’ they could equally be seen as downdating the 21st century into the early 20th. Their dyschronia is reminiscent of those moments in Stephen King’s It where old photographs come to (a kind of) life, and there is a hallucinatory suspension of sequentiality. Or, better, to the time slips in Octavia Butler’s Kindred, where contemporary characters are abducted back into the waking nightmare of slavery. (The point being: the nightmare never really ended…)

There is no doubt that blues has a privileged position in pop’s metaphysics of presence: the image of the singer-songwriter alone with his guitar provides rockism with its emblem of authenticity and authorship. But Little Axe’s return to the supposed beginnings unsettles this by showing that there were ghosts at the origin. Hauntology is the proper temporal mode for a history made up of gaps, erased names and sudden abductions. The traces of gospel, spirituals and blues out of which Stone Cold Ohio is assembled are not the relics of a lost presence, but the fragments of a time permanently out of joint. These musics were vast collective works of mourning and melancholia. Little Axe confront American history as a single ‘empire of crime’, where the War on Terror decried on Stone Cold Ohio’s opening track – a post 9/11 re-channelling of Blind Willie Johnson’s ‘If I had My Way’ – is continuous with the terrordome of slavery.

When I interviewed Skip, he emphasised that Little Axe tracks always begins with the samples. The origin is out of joint. He has described before the anachronising Method-ology he uses to transport himself into the past. ‘I like to surf time. What I like to do is study time-periods – get right in to ‘em, so deep it gets real heavy in there.’ McDonald’s deep immersion in old music allows him to travel back in time and the ghosts to move forward. It is a kind of possession (recalling Winfrey’s claim that she and the cast were ‘possessed’ when they were making Beloved). Little Axe’s records skilfully mystify questions of authorship and attribution, origination and repetition. It is difficult to disentangle sampling from songwriting, impossible to draw firm lines between a cover version and an original song. Songs are texturally-dense palimpsests, accreted rather than authored. McDonald’s own vocals, by turns doleful, quietly enraged and affirmatory, are often doubled as well as dubbed. They and the modern instrumentation repeatedly sink into grainy sepia and misty trails of reverb, falling into a dyschronic contemporeanity with the crackly samples.

In his landmark piece on Tricky (the piece, really, in which sonic hauntology was first broached), Ian Penman complained about Greil Marcus’ ‘measured humanism which leaves little room for the UNCANNY in music’. Part of the reason Little Axe are intriguing is that their use of dub makes it possible for us to encounter blues as uncanny and untimely again. Little Axe position blues not as part of American history, as Marcus does, but as one corner of the Black Atlantic. What makes the combination of blues and dub far more than a gimmick is that there is an uncanny logic behind the superimposition of two corners of the Black Atlantic over one another.

Adrian Sherwood’s role in the band is crucial. Sherwood has said that Little Axe take inspiration from the thought that there is a common ground to be found in ‘the music of Captain Beefheart and Prince Far I, King Tubby and Jimi Hendrix’. In the wrong hands, a syncresis like this could end up as a recipe for stodgy, Whole Earth humanism. But Sherwood is a designer of OtherWorld music, an expert in eeriness, a kind of anti-Jools Holland. What is most pernicious about Holland is the way in which, under his stewardship, pop is de-artificialised, re-naturalised, blokily traced back to a facialised source. Dub, evidently, goes in exactly the opposite direction – it estranges the voice, or points up the voice’s inherent strangeness. When I interviewed Sherwood, he was delighted by my description of his art as ‘schizophonic’ – Sherwood detaches sounds from sources, or at least occults the relationship between the two. The tyranny of Holland’s Later … has corresponded with the rise of no-nonsense pop which suppresses the role of recording and production. But ‘Dub was a breakthrough because the seam of its recording was turned inside out for us to hear and exult in; when we had been used to the “re” of recording being repressed, recessed, as though it really were just a re-presentation of something that already existed in its own right.’ (Penman)

Hence what I have called dubtraction; and what is subtracted, first of all, is presence. Pierre Schaeffer’s term for a sound that is detached from a source is ‘acousmatic’. The dub producer, then, is an acousmatician, a manipulator of sonic phantoms that have been detached from live bodies. Dub time is unlive, and the producer’s necromantic role – his raising of the dead – is doubled by his treating of the living as if dead. For Little Axe, as for the bluesmen and the Jamaican singers and players they channel, hauntology is a political gesture: a sign that the dead will not be silenced.

I’m a prisoner

Somehow I will be free





Nostalgia for Modernism: The Focus Group and Belbury Poly


‘Myself and my friend Jim Jupp had been making music, independently and together for a while, and also obsessing over the same things – the cosmic horror of Machen, Lovecraft, the Radiophonic Workshop, weird folk and the occult. We realised that we wanted to put our music out, but also create our own world where we could play with all these reference points. Starting our own label was the only way to do it.’ Julian House is describing how he and his school-friend Jim Jupp came to found the Ghost Box label.

Off-kilter bucolic, drenched in an over-exposed post-psyche-delic sun, Ghost Box recordings are uneasy listening to the letter. If nostalgia famously means ‘homesickness’, then Ghost Box sound is about unhomesickness, about the uncanny spectres entering the domestic environment through the cathode ray tube. At one level, the Ghost Box is television itself; or a television that has disappeared, itself become a ghost, a conduit to the Other Side, now only remembered by those of a certain age. No doubt there comes a point when every generation starts pining for the artefacts of its childhood – but was there something special about the TV of the 1970s which Ghost Box releases obsessively reference?

‘I think there definitely was something powerful about the children’s TV from that period,’ House maintains. ‘I think it was just after the 60s, these musicians and animators, film makers had come through the psychedelic thing and acid folk, they had these strange dark obsessions that they put into their TV programmes. Also, someone like Nigel Kneale had obviously come from a tradition of HP Lovecraft – 20th century science used as a background to cosmic horror and the occult. The themes he explored in the Quatermass series eventually found their way into Doctor Who, Children of the Stones, Sapphire and Steel. If you look at the BBC Radiophonic workshop, people like David Cain also studied medieval music, and he did a great dark folky electronic album called The Seasons. And a few of Paddy Kingsland’s arrangements bring to mind Pentangle. It’s like there was this strange past/future thing which had come through psychedelia.’

The affect produced by Ghost Box’s releases (sound and images, the latter absolutely integral) are the direct inverse of irritating postmodern citation-blitz. The mark of the postmodern is the extirpation of the uncanny, the replacing of the unheimlich tingle of unknowingness with a cocksure knowingness and hyper-awareness. Ghost Box, by contrast, is a conspiracy of the half-forgotten, the poorly remembered and the confabulated. Listening to sample-based sonic genres like Jungle and early hip-hop you typically found yourself experiencing déjà vudu or déjà entendu, in which a familiar sound, estranged by sampling, nagged just beyond recognisability. Ghost Box releases conjure a sense of artificial déjà vu, where you are duped into thinking that what you are hearing has its origin somewhere in the late 60s or early 70s: not false, but simulated, memory. The spectres in Ghost Box’s hauntology are the lost contexts which, we imagine, must have prompted the sounds we are hearing: forgotten programmes, uncommissioned series, pilots that were never followed-up.

Belbury Poly, The Focus Group, Eric Zann – names from an alternative 70s that never ended, a digitally-reconstructed world in which analogue rules forever, a time-scrambled Moorcockian near-past. This return to the analogue via the digital is one of the ways in which Ghost Box records are not straight-up simulations of the past. ‘We like to confuse the boundaries between analogue and digital. Jim uses a combination of analogue synths and digital technology. In the Focus Group stuff there are samples of old percussion albums and digital effects, electronic sounds generated on the computer and processed found sounds. I think it’s do with this space between what happens in the computer and what happens outside of it. The recording of space, real reverb/room sound and the virtual space on the hard drive. Like different dimensions.’

‘It was bang on 1980 when Fairlights and DX7s appeared in electronic music,’ Jupp points out. ‘I suppose that digital technology is a tipping point in culture in general, even in the way that television is made.’ Yet Belbury Poly’s sound relies on digital equipment. ‘At the heart of it is a computer and we don’t hide that fact. Having said that, I’m sitting in the studio now and it’s mostly analogue synths and a pile of acoustic instruments, what we do couldn’t exist without hip-hop and sampling culture and the access to cheap electronic instruments. It’s revisiting old textures and old imagined worlds with new tools.’

Jupp laughs when I suggest that there was a certain grain to 70s British culture that got smoothed away by 80s style culture gloss. ‘It’s almost as if we became totally Americanised, got our teeth fixed and had a proper wash. I was talking to someone the other day whose girlfriend can’t stand him watching old sitcoms, she always calls it grot TV. I know what she means. But maybe in TV, radio and records then there was a feel that was washed clean in the 80s when everything was angular, digital, American, upbeat and colourful.’

Ghost Box explore a sonic continuum which stretches from the quirkily cheery to the insinuatingly sinister. The most obvious predecessors lie in ‘functional music’, sounds designed to hover at the edge of perceptibility, not to hog centre-stage: signature tunes, incidental music, music that is instantly recognizable but whose authors, more often (self-)styled as technicians rather than artists, remain anonymous. The Radiophonic Workshop (whose two ‘stars’, Delia Derbyshire and Daphne Oram, became widely recognised only after their deaths) would be the obvious template. House agrees: ‘I think the key reference is the Radiophonic Workshop, which is wildly experimental (Britain’s electronic avant garde, the equivalent of GRM Pierre Schaeffer in France etc.) but it’s also incredibly evocative of radio and television with which we grew up. It’s got a sort of duality to it, it’s haunting in its own right but also serves as a memory trigger. I think this dim, half remembered aspect of old Hammer films, Doctor Who, Quatermass is important – it’s not like an I Love 1974 reminiscence. Rather than being just nostalgia, it’s triggering something darker, you’re remembering the strange ideas in these programmes, the stuff under the surface, rather than just knowing the theme tune. I think this is why Library music is such an influence – you listen to the albums divorced from context and it operates on an unconscious level, like musical cues for missing visuals.

When I grew up Doctor Who episodes like The Sea Devils haunted me, the way slightly shaky monsters and sets have their own uncanny horror. The loud blasts of Atonal music. The first time I saw the Hammer film of Quatermass and the Pit really affected me. And those dimly remembered eastern European animations had a certain quality. Also, certain public information films and adverts.’

Ghost Box preside over a (slightly) alternative world in which the Radiophonic Workshop were more important than the Beatles. In a sense that is our world, because the Workshop rendered even the most experimental rock obsolete even before it had happened. But of course you are not comparing like with like here; the Beatles occupied front stage in the Pop Spectacle, whereas the Radiophonic Workshop insinuated their jingles, idents, themes and special FX into the weft of everyday life. The Workshop was properly unheimlich, unhomely, fundamentally tied up with a domestic environment that had been invaded by media.

Naturally, Ghost Box have been accused of nostalgia, and of course this plays a part in their appeal. But their aesthetic in fact exhibits a more paradoxical impulse: in a culture dominated by retrospection, what they are nostalgic for is nothing less than (popular) modernism itself. Ghost Box are at their most beguiling when they foreground dyschronia, broken time – as on Belbury Poly’s ‘Caermaen’ (from 2004’s The Willows) and ‘Wetland’ (from 2006’s The Owl’s Map) where folk voices summoned from beyond the grave are made to sing new songs. Dyschronia is integral to the Focus Group’s whole methodology; the joins are too audible, the samples too jagged, for their tracks to sound like refurbished artefacts.

In any case, at their best, Ghost Box conjure a past that never was. Their artwork fuses the look of comprehensive school text books and public service manuals with allusions to weird fiction, a fusion that has more to do with the compressions and conflations of dreamwork than with memory. House himself talks of ‘a strange dream of a school textbook’. The implicit demand for such a space in Ghost Box inevitably reminds us that the period since 1979 in Britain has seen the gradual but remorseless destruction of the very concept of the public. At the same time, Ghost Box also remind us that the people who worked in the Radiophonic Workshop were effectively public servants, that they were employed to produce a weird public space – a public space very different from the bureaucratic dreariness invoked by neoliberal propaganda.

Public space has been consumed and replaced by something like the third place exemplified by franchise coffee bars. These spaces are uncanny only in their power to replicate sameness, and the monotony of the Starbucks environment is both reassuring and oddly disorientating; inside the pod, it’s possible to literally forget what city you are in. What I have called nomadalgia is the sense of unease that these anonymous environments, more or less the same the world over, provoke; the travel sickness produced by moving through spaces that could be anywhere. My, I… what happened to Our Space, or the idea of a public that was not reducible to an aggregate of consumer preferences?

In Ghost Box, the lost concept of the public has a very palpable presence-in-absence, via samples of public service announcements. (Incidentally one connection between rave and Ghost Box is the Prodigy’s sampling of this kind of announcement on ‘Charly’.) Public service announcements – remembered because they could often be disquieting, particularly for children – constitute a kind of reservoir of collective unconscious material. The disinterment of such broadcasts now cannot but play as the demand for a return of the very concept of public service. Ghost Box repeatedly invoke public bodies – through names (Belbury Poly, the Advisory Circle) and also forms (the tourist brochure, the textbook).

Confronted with capital’s intense semiotic pollution, its encrustation of the urban environment with idiotic sigils and imbecilic slogans no-one – neither the people who wrote them nor those at whom they are aimed – believes, you often wonder: what if all the effort that went into this flashy trash were devoted to a public good? If for no other reason, Ghost Box is worth treasuring because they make us pose that question with renewed force.





The Ache of Nostalgia:

The Advisory Circle


‘The Advisory Circle – helping you make the right decisions.’ With its suggestions of a benevolent bureaucracy, The Advisory Circle was always the perfect name for a Ghost Box act. On Mind How You Go (2005), producer and vinyl archivist Jon Brooks produced a kind of Anglo-analogue pastoralism that is as affecting as anything that the label has released. In what has since been established to be the customary Ghost Box fashion, Brooks’s analogue synthesizer doodles – all the more powerful, somehow, for their unassuming slightness – gently trigger drifts down (false) memory lanes, inducing you to recall a mass mediated past which you never quite experienced. Mind How You Go frequently invokes that talisman of 1970s paternalism, the Public Information Film, and it’s perhaps no accident that the rise of Ghost Box has coincided with the emergence of YouTube, which has made public information films and other such street furniture of 1970s audio–visual experience widely available again.

What Brooks captures extremely poignantly is the conflicted cluster of emotions involved in nostalgic longing. ‘Mind How You Go’ and ‘Nuclear Substation’ summon remembered sunlight from childhood summers even as their doleful melodies are laced with a deep sense of loss. Yet there’s a very definite but subdued joy here, too, in the way that a track such as ‘Osprey’ achieves a kind of faltering soaring. It’s not for nothing that the word ache is often associated with nostalgia; and The Advisory Circle’s music positively aches with a sadness that is simultaneously painful and enjoyable. 2011’s As The Crow Flies felt folkier than The Advisory Circle’s previous releases, with acoustic guitars creeping over the analogue synthesizers like ivy spreading over the frontage of a brutalist building. The album’s closing track, ‘Lonely Signalman’, brings these different textures together beautifully: its vocodered refrain (‘signalman lives all alone/ signalman is all alone’) is simultaneously playful and plangent, a combination that is typical of Brooks’s work. I asked Brooks about the roots of the exquisite sadness that colours his music.

‘A lot of it stems from my childhood. Without wishing to go too far down the ‘tortured artist’ path, I will say that my upbringing was a cyclic period of safety, security, contentment, anxiety, despair and sadness. As an adult, I’ve managed to work through a lot of these childhood feelings and channel them into what I’m doing musically. Thankfully, I can now make sense of a lot of stuff that happened back then; I can balance this against any residual scars I might be left with. I’m not saying I’m glad that I had a turbulent childhood, but for what it’s worth, it has shaped my art, quite indelibly.’

A paradoxical impulse lies behind Brooks’s work. He is fascinated by functional culture – that which we don’t consciously hear or see but which shapes our experience of environments – yet the attention on what was background necessarily pushes it into the foreground. 2011’s Music For Dieter Rams, a homage to the designer best known for his work with Braun released under Brooks’s name, was an attempt to bring functional music together with functional design. Rams’s slogan ‘less, but better’ could equally apply to the original conception of Ambient music. After all, What was the ambition for Ambient if not that music attain the unassuming ubiquity of many of Rams’s products – all those radios, coffee makers and calculators which were embedded into everyday life, their designer unknown to the general public? Perhaps for that reason, Brooks isn’t the first artist to dedicate music to Rams: Alva Noto devoted two wonderfully eerie tracks on his For 2 album to the designer. It’s those things lurking at the background of attention, things that we took for granted at the time, which now evoke the past most powerfully.

‘With hindsight,’ Brooks says, ‘the fact that these things are so evocative of the past, accentuates and crystallises my interest in them; but actually, I’ve always been interested in things ‘in the background’ – for me, that’s where the really interesting stuff has always been. As a kid, I was equally fascinated by library music used on TV (or TV themes) as I was about pop music; things that we weren’t supposed to take any real notice of. I used to look out for TV test transmissions, for example, and of course Public Information Films. Open University broadcasts held the same fascination; these broadcasts weren’t targeted at an eight-year-old child, but I was drawn towards them nonetheless. I was also drawn to logos, branding and so forth. I remember being particularly entranced by certain record labels’ logos – Polydor, Decca and Pye were my favourites. I loved the way they looked on the records and would quite often sit at the turntable and watch them go round, as the record played. There was something very elegant about them. Again, these things were presented as ‘functional’, in their own way. So, the fascination was always there. It’s just stayed with me.’

Those objects and spaces are also functional. Is Brooks particularly fascinated by culture that operates in this ostensibly functional way?

‘I am absolutely fascinated by that aspect. At the risk of being slightly tangential, taking the concept of Muzak as an example, I very much enjoyed reading Joseph Lanza’s Elevator Music. This is a great example of bringing the background to the foreground, in the form of strictly ‘functional’ music. It goes a step further in this respect than even Library music does. I have always been fascinated by the cultural aspect of this – how we can have small speakers installed in ceilings in shops and the music just filters through and no-one is really supposed to notice; they called it ‘non-entertainment music’ at the time. Muzak gained a really bad reputation in the 1970s, but if you go back and listen to some of the music that was produced for the system, you’ll find some very tight, compact arrangements hidden in there. Composers that are highly regarded by record collectors now, for example Sven Libaek and Syd Dale, did a lot of work for Muzak. In much the same way, I apply this fascination to domestic design or motorway service stations. Dieter Rams was interested in creating something that just worked, with elegance and simplicity. I love the fact that he wasn’t searching for fame with his designs, but now we can celebrate those designs publicly and hand him the spotlight, as it were, in much the same way as we have discovered composers like Sven Libaek.’





Someone Else’s Memories: Asher,

Philip Jeck, Black To Comm, G.E.S.,

Position Normal, Mordant Music


In 2009, an artist known as Asher released an album called Miniatures on the Sourdine label. The only information on the sleeve was the following terse statement: ‘recorded in Somerville, MA, winter 2007’. Rumours and mysteries proliferate in a data vacuum, and Miniatures puts the listener into a state of suspension and suspicion: what exactly are we listening to? Who made it? What does ‘making’ it mean in this context? And what sense of ‘recorded’ is being used?

Let’s consider the audio facts, such as they are. Even here there is veiling – all the tracks are covered in a fog of crackle. What we hear is mostly piano, although occasionally strings can also be detected. The piano is contemplative, reflective, exquisitely sad: the lugubrious tempo seems to literalise the notion of longing. The haze of the crackle and the quietness of the playing mean that you have to ‘lean in’ to hear the music – played on ipod headphones, it practically disappears into the background noise of the street.

How were the tracks made? At least two theories circulated online. One, the closest there seems to be to any official story, maintains that the tracks on Miniatures were all short sections recorded by Asher from the radio and then digitally looped. (If so, he should buy himself a radio with better reception.) The other theory is that the piano pieces were played by Asher on poor quality tape, then subjected to further processes of digital distortion to give the impression that they are found sound objects. The tracks’ unresolved status is not some dry conceptual riddle detracting from the experience of listening to them; instead, the enigma actually heightens the music’s fragile, fragmentary beauty, its uncanny intimacy.

Miniatures was one of a number of records from the 00s whose sound centred on crackle. Why should crackle resonate now? The first thing we can say is that crackle exposes a temporal pathology: it makes ‘out of joint’ time audible. Crackle both invokes the past and marks out our distance from it, destroying the illusion that we are co-present with what we are hearing by reminding us we are listening to a recording. Crackle now calls up a whole disappeared regime of materiality – a tactile materiality, lost to us in an era where the sources of sound have retreated from sensory apprehension. Artists like Tricky, Basic Channel and Pole started to foreground vinyl crackle at the very moment when records were becoming superseded. Back then, it was the CD that was making vinyl obsolete. Now, the MP3 can neither be seen nor touched, still less manipulated by the hand in the way that the vinyl record could be.

The digital seems to promise nothing less than an escape from materiality itself, and the story of Willam Basinski’s 2002 album Disintegration Loops – a recording of tapes that destroyed themselves in the very process of their transfer to digital – is a parable (almost too perfect) for the switch from the fragility of analogue to the infinite replicability of digital. What we have lost, it can often seem, is the very possibility of loss. Digital archiving means that the fugitive evanescence that long ago used to characterise, for instance, the watching of television programmes – seen once, and then only remembered – has disappeared. Indeed, it turns out that experiences which we thought were forever lost can – thanks to the likes of YouTube – not only be recovered, but endlessly repeated.

Crackle, then, connotes the return of a certain sense of loss. At the same time, it is also the sign of a found (audio) object, the indication that we are in a scavenger’s space. That is why crackle is a stock-in-trade of someone like turntable artist Philip Jeck. Jeck’s first record had appeared in 1999, but his work gained a new currency because of its convergence with what Burial and The Caretaker were doing. Jeck had been inspired by hearing mixers like Walter Gibbons, Larry Levan and Grandmaster Flash in the 80s, but his montages reconceive DJing as the art of producing sonic phantasmagoria. Using Dansette turntables, FX units and records found in charity shops, Jeck defamiliarises the vinyl source material to the point of near-abstraction. Occasionally, recognizable fragments (60s rock, Mantovani-like lite classical kitsch) thrillingly bob up out of the whooshing delirium-stream.

Jeck began the extraordinary 2008 version of Gavin Bryars’ The Sinking of the Titanic (which he performed in collaboration with Italian ensemble Alter Ego and Bryars himself) with nearly 14 minutes of crackle. In this audio-fog, threatening objects loom, barely perceived. As we listen, we come to distrust our own hearing, begin to lose confidence in our ability to distinguish what is actually there from audio hallucinations. Ominous strings and a solitary bell produce an atmosphere of quiet foreboding, and the ensemble – at first indistinct shadows in a Turner-esque squall – only gradually emerge from the cloud of crepitation. Here, as in Asher’s Miniatures, crackle suggests radio static. The sinking of the Titanic in fact prompted the first use of wireless in sea rescue. As Bryars points out in his sleevenotes, Marconi had conceived of telegraphy as a spectral science. He ‘became convinced that sounds once generated never die, they simply become fainter and fainter until we no longer perceive them. Marconi’s hope was to develop sufficiently sensitive equipment, extraordinarily powerful and selective filters I suppose, to pick up and hear these past sounds. Ultimately, he hoped to be able hear Christ delivering the Sermon on the Mount.’

Jeck has referred to the sonic sources he uses as ‘fragments of memory, triggering associations’ but it is crucial that the memories are not necessarily his; the effect is sometimes like sifting through a box of slides, photographs and postcards from anonymous people, long gone. This same feeling of coming upon other people’s orphaned memories could be heard in the 2009 album Circulations by G.E.S. (Gesellschaft zur Emanzipation des Samples/ Society For The Emancipation Of Sampling). There is some mystery about who is behind G.E.S., but the project appears to be a front for genre-hopping dilettante Jan Jelinek, best known for his Loop-finding Jazz Records, which constructed a version of minimal Techno out of minuscule jazz samples; Jelinek has also produced microhouse under the name Farben and Ambient as Gramm. G.E.S.’s idea was to take micro-samples, loop and collage them, play them in public spaces, and record the results. Would the ordinary laws of copyright apply if music was sampled in these conditions? The tracks are like unsigned audio-postcards, recorded sometimes in named places (Mount Zermatt and Hong Kong are mentioned in the track titles), sometimes in places we can only guess at, using the voices and background noises to orientate ourselves. ‘Birds Of Heraklion’ begins with distorted electronic pulses before being swept up by a backwards rush of very cinematic strings that sound like they might have come from a black and white film extolling the benefits of train travel. ‘Orinoco, Bullerbü, (Crossfade)’ is initially built from the violent juxtaposition of crazed bird noises with what could be a sample from some forgotten film noir or a highly strung melodrama, but it ends with echoes, and strange, abstract whistles. ‘Im Schilf’ puts one in mind of the kind of alien piping noises you would hear in an Oliver Postgate animation or an early Cabaret Voltaire tape experiment, while ‘Farnballett’ and ‘Farnballett (In Dub)’ recall a Binatone tennis game having a HAL-like nervous breakdown. The random sounds, the passing conversations, make you feel like you are witnessing stray frames from a film no whole version of which exists anywhere. This sense that action is continuing beyond what we are hearing, together with the record’s travelogue-cosmopolitanism, remind me of nothing so much as the cold, dislocated beauty of Antonioni’s The Passenger. The closing track, ‘Schlaf (Nach Einführung Der Psychoanalyse)’ – which sounds like windchimes on some dust-blown alien planet – is like a memory of a Cold War science fiction that never quite happened. What stops this being a dry exercise or a disparate mélange is the inescapable sense of anonymous sadness which pervades the whole record.

This same sense of depersonalised tragedy hung over Alphabet 1968, the 2010 album by Black to Comm, aka Marc Richter, the man behind the ‘death Ambient’ genre and the Hamburg-based Dekorder label. Richter mischievously described Alphabet 1968 – on which the only human voices are on field recordings at the edge of audibility – as an album of songs. What if we were to take Richter’s provocation seriously – what would a song without a singer be like? What would it be like, that is to say, if objects themselves could sing? It’s a question that connects fairy tales with cybernetics, and listening to Alphabet 1968, I’m fittingly reminded of a filmic space in which magic and mechanism meet: J F Sebastian’s apartment in Blade Runner. The tracks on the album are crafted with the same minute attention to detail that the genetic designer and toymaker Sebastian brought to his plaintive automata, with their bizarre mixture of the clockwork and the computerised, the antique and the ultramodern, the playful and the sinister. Richter’s pieces have been built from similarly heterogeneous materials – record crackle, shortwave radio, glockenspiels, all manner of samples, mostly of acoustic instruments. Except on ‘Void’ – a steampunk John Carpenter-like track with susurrating voices conspiring in the background – the music does not feel very electronic. As with Sebastian’s talking machines, you get the impression that Richter has used the latest technology in order to create the illusion of archaism. This is a record in which you feel that you can smell the dust coming off the retrieved objects. But so intricately are these sonic palimpsests layered that it’s impossible to determine what Richter and his collaborators have played and what has been conjured from the archives. The sounds are treated, reversed and slowed down in a way that makes their original sources mysterious. There is a sense of subtle but constant movement, of sound shadows flitting in and out of earshot.

Richter so successfully effaces himself as author that it is as if he has snuck into a room and recorded objects as they played (to) themselves. On the opening track, ‘Jonathan’, crackle, a field recording of drizzle and cut-aways to white noise set the scene for a pensive piano. Children’s voices can be heard in the distance, and it is like we are being ushered out of the human world into the mysterious world of objects-amongst-themselves, a world just adjacent to ours, yet utterly foreign to it. It is as if Richter has attuned himself to the subterranean raptures and sadnesses of objects in unoccupied rooms, and it is these ‘songs’ that he hears. It’s not for nothing that the theme of objects coming to life was taken up so often in cinema animation (for, as its name suggests, what is animation if not a version of this process?), and most of the tracks on Alphabet 1968 could be tunes for cartoon sequences – the ‘song’ an object sings as it stirs itself into motion, or declines back into inertia.

In fact, the impression of things winding down is persistent on Alphabet 1968. Richter has made an enchanted sound-world, but one from which entropy has not been excluded. It feels as if the magic is always about to wear off, that the enchanted objects will slip back into the inanimate again at any moment – an effect which only heightens the tracks’ poignancy. The labouring, looped double bass on ‘Rauschen’ has all the mechano–melan-choly of a phonograph winding down – or perhaps of one of Sebastian’s automata running out of power. On ‘Trapez’, reverbed wind chimes create a gentle Narnian snowfall. As so often on this album, the track recalls a running-down music box – one parallel might be Colleen’s 2006 album Boîtes à Musique, except that, where Colleen restricted herself to actually using music boxes, Richter loops and sequences his sonic material so that it simulates clockwork. But it’s an uncanny clockwork, running to a crooked time. On ‘Amateur’ – with its hints of artificial respiration, as if the walls themselves are breathing – the piano loop seems bent out of shape.

Entropy is everywhere in the work of Position Normal, an act whom Simon Reynolds once called ‘the godfathers of hauntology’, but it is a very English kind of entropy. In Position Normal’s music, it is like London has finally succumbed to the entropy that always threatens to engulf the city in Michael Moorcock’s Jerry Cornelius mythos. Except there’s something attractive about the deep daydreamy lassitude that reigns here: entropy isn’t a threat so much as a lysergic promise, a chance to uncoil, unwind, unspool. Gradually, you are made to forget all of your urgencies as your brain is lulled and lured into the sunny Sunday afternoon when all Position Normal tunes seem to take place. The allure of this indolent London was touched upon by a certain trajectory in 60s’ rock: the sunny daze of The Kinks’ ‘Sunny Afternoon’, The Small Faces ‘Lazy Sunday Afternoon’, The Beatles’ ‘Tomorrow Never Knows’ and ‘I’m Only Sleeping’. Yet this particular strand of Anglo-languor didn’t originate here, in the acid and weed reveries of rockers in repose. You can look even further back for antecedents, to moments in Great Expectations – the airless, inertial stasis of Satis House – or to Alice’s Adventures in Wonderland (especially well captured in the hookah-hazes and fugues of Jonathan Miller’s 1968 BBC television version).

Position Normal’s London is a city far distant from the corporate gloss of busy/ business London as it is from the tourist London of pageantry. The tour guide for this anachronistic city would be the James Mason in The London That Nobody Knows, the 1969 film directed by Norman Cohen and based on the book by Geoffrey Fletcher. It’s a palimpsest city, a space where many times are layered. Sometimes, when you walk down an unfamiliar street, you might stumble into aspects of it. Street markets that you’d imagined had closed long ago, shops that (so you think) couldn’t possibly survive into the 21st century, ripe old voices fit only for the Victorian music hall…

Position Normal’s tracks are Dadaist dub-doodles, disarming in their seeming slightness. They feel like skits or sketches;

unwilling to be seen taking themselves too seriously, but at the same time entirely lacking in knowing smirks. There’s a daydreamy quality to the way the music is constructed: ideas waft in but trail off inconclusively while still half-baked. It can be frustrating, at least initially, yet the effect is accretive and seductive. A Position Normal album comes off like an anglo-Fantasia scavenged out of charity shops, all the detritus of the English 20th century made to sing. For the most part, you are left to guess the sources of all the funny voices. Who are they, this cheery gang – children’s radio presenters, comedians, character actors, light entertainers, newsreel announcers, jazz trumpeters (mutes always at the ready), ragpickers, costermongers, chancers, idlers, thespians gone to seed, frothy coffee café proprietors…? And where have they come from – scratchy old shellac, unmarked tapes, soundtrack LPs? The tracks bleed into one another, and so do the albums, like failing memories.

It turns out that decaying memory is at the heart of Position Normal’s music. In an interview with Joakim Norling for Friendly Noise magazine, Position Normal’s Chris Bailiff has said that the roots of the PN sound lay in his father’s Alzheimer’s disease. ‘My dad went into hospital and had to sell the family home, I had to move out and whilst doing this I found so many old records of his and records that he bought for me. Nursery rhymes, documentaries and jazz. I didn’t want to throw anything away so took them with me. I started to listen to all of them and recorded on to tape my favourite sounds and made incredibly varied mix tapes. I then edited them down and down until there were what I suppose are called samples.’ It’s as if Bailiff was simultaneously attempting to simulate Alzheimer’s and counteract it.

Position Normal can be fitted into the venerable English tradition of Nonsense. (Another Small Faces parallel: Stanley Unwin provided some of his trademark gobbledygook for Ogden’s Nut Gone Flake, the album which included ‘Lazy Sunday Afternoon’.)

This same sense of lyrical dementia is at work on Mordant Music’s 2006 masterpiece Dead Air. Mordant explicitly affirm decay and deliquescence as productive processes, and on Dead Air it is as if the mould growing on the archives is the creative force behind the sound. The album sounds like an electro/Rave version of The Disintegration Loops, except what was disintegrating here was a moment in British broadcasting history. The loose concept behind the album was a dead television studio, and what’s crucial to its unnerving allure is the presence of former Thames TV continuity announcer Phillip Elsmore. There’s a lunatic calm about the way that Elsmore reading Baron Mordant’s Nonsense (best heard in its own right on his collaboration with Ekoplekz, eMMplekz). Listening to Dead Air is like stumbling into an abandoned museum 200 years into the future where old Rave tracks play on an endless loop, degrading, becoming more contaminated with each repetition; or like being stranded in deep space, picking up fading radio signals from a far distant earth to which you will never return; or like memory itself re-imagined as an oneiric television studio, where fondly recalled continuity announcers, drifting in and out of audibility, narrate your nightmares in reassuring tones.





‘Old Sunlight From Other Times and Other

Lives’: John Foxx’s Tiny Colour Movies


k-punk post, June 19, 2006


He was in the market crowds, wearing a shabby brown suit. Trying to find me through all the years. My ghost coming home. How do you get home through all the years? No passport, no photo possible. No resemblance to anyone living or dead. Tenderly peering into windows


John Foxx’s Tiny Colour Movies is a welcome addition to this decade’s rich cache of hauntological releases.

Foxx’s music has always had an intimate relationship with film. Like sound recording, photography – with its capturing of lost moments, its presentation of absences – has an inherently hauntological dimension. It wouldn’t be an exaggeration to say that Foxx’s entire musical career has been about relating the hauntology of the visual with the hauntology of sound, transposing the eerie calmness and stillness of photography and painting onto the passional agitation of rock.

In the case of Tiny Colour Movies, the relationship between the visual and the sonic is an explicit motivating factor. The inspiration for the album was the film collection of Arnold Weizcs-Bryant. Weizcs-Bryant collects only films that are short – no movie in his collection is longer than eight minutes long – and that have been ‘made outside commercial consideration for the sheer pleasure of film. This category can include found film, the home movie, the repurposed movie fragment.’ The album emerged when, a few weeks after he attended a showing of some of Weizcs-Bryant films in Baltimore, Foxx found himself unable to forget ‘the beauty and strangeness’ of Weizcs-Bryant’s movies – ‘juxtapositions of underwater automobiles, the highways of Los Angeles, movies made from smoke and light, discarded surveillance footage from 1964 New York hotel rooms’ – so he decided ‘to give in to it – to see what would happen if he () made a small collection of musical pieces using the memory of those Tiny Colour Movies.’

The result is Foxx’s most (un)timely LP since 1980’s Metamatic. Tiny Colour Movies fits right into the out of joint time of hauntology. Belbury Poly’s Jim Jupp cites Metamatic as a major touchstone, and time has bent so that the influence and the influenced now share an uncanny contemporaneity. Certainly, many of the tracks on Tiny Colour Movies – synthetic but oneiric, psychedelic but artificial – resemble Ghost Box releases. This is an electronic sound removed from the hustle and bustle of the present. An obvious comparison for a track like the majestically mournful ‘Skyscraper’ would be Vangelis’ Blade Runner soundtrack, but, in the main, the synthetic textures are relieved from the pressure of signifying the Future. Instead, they evoke a timeless Now where the urgencies of the present have been suspended. Some of the best tracks – especially the closing quartet of ‘Shadow City’, ‘Interlude’, ‘Thought Experiment’ and ‘Hand Held Skies’ – are slivers of sheer atmosphere, delicate and slight. They are gateways to what Heronbone used to call ‘slowtime’, a time of meditative detachment from the commotions of the current.


I constantly feel a distant kind of longing. The longest song, the song of longing. I walk the same streets like a fading ghost. Flickering grey suit. The same avenues, squares, parks, colonnades, like a ghost. Over the years I find places I can go through, some process of recognition. Remnants of other almost forgotten places. Always returning.


Tiny Colour Movies is a distillation of an aesthetic Foxx has dedicatedly explored since Ultravox’s Systems of Romance. Although Foxx is most associated with a future-shocked amnesiac catatonia (‘I used to remember/ now it’s all gone/ world war something/ we were somebody’s sons’), there has always been another trance-mode – more beatific and gently blissful, but no less impersonal or machinic – operative in Foxx’s sound, even on the McLuhanite Metamatic.

Psychedelia had explicitly emerged as a reference point on Systems of Romance (1978) – particularly on tracks such as ‘When You Walk Through Me’ and ‘Maximum Acceleration’, with their imagery of liquifying cities and melting time (‘locations change/ the angles change/ even the streets get re-arranged’). There might have been the occasional nod to the psychedelia of the past – ‘When You Walk Through Me’ stole the drum pattern from ‘Tomorrow Never Knows’ for instance – but Systems of Romance was remarkable for its attempt to repeat psychedelia ‘in–becoming’ rather than through plodding re-iteration. Foxx’s psychedelia was sober, clean-shaven, dressed in smartly anonymous Magritte suits; its locale, elegantly overgrown cities from the dreams of Wells, Delvaux and Ernst.

The reference to Delvaux and Ernst is not idle, since Foxx’s songs, like Ballard’s stories and novels, often seemed to take place inside Surrealist paintings. This is not only a matter of imagery, but also of mood and tone (or, catatone); there is a certain languor, a radically depersonalised serenity on loan from dreams here. ‘If anything,’ Ballard wrote in his 1966 essay on Surrealism, ‘Coming of the Unconscious’, ‘surrealist painting has one dominant characteristic: a glassy isolation, as if all the objects in its landscapes had been drained of their emotional associations, the accretions of sentiment and common usage.’ It’s not surprising that Surrealism should so often turn up as a reference in psychedelia’s ‘derangement of the senses’.

The derangement in Foxx’s psychedelia has always been a gentle affair, disquieting in its very quietude. That is perhaps because the machinery of perceptual re-engineering seemed to be painting, photography and fiction more than drugs per se. One suspects that the psychotropic agent most active on/in Foxx’s sensibility is light. As he explained in an interview from 1983: ‘some people at certain times seem to have a light inside them, it’s just a feeling you get about someone, it’s kind of radiance – and it’s something that’s always intrigued me – it’s something I’ve covered before in songs like ‘Slow Motion’ and ‘When You Walk Through Me’. I like that feeling of calm…It’s like William Burroughs summed it up perfectly – “I had a feeling of stillness and wonder.”’

There is a clear Gnostic dimension to this. For the Gnostics, the World was both heavy and dark, and you got a glimpse of the Outside through glimmers and shimmers (two recurrent words in Foxx’s vocabulary). Around the time of Systems of Romance, Foxx’s cover art shifted from harsh Warhol/Heartfield cut/paste towards gentle detournements of Renaissance paintings. What Foxx appeared to discover in Da Vinci and Botticelli is a Catholicism divested not only of pagan carnality but of the suffering figure of Christ, and returned to an impersonal Gnostic encounter with radiance and luminescence.

What is suppressed in postmodern culture is not the Dark but the Light side. We are far more comfortable with demons than angels. Whereas the demonic appears cool and sexy, the angelic is deemed to be embarrassing and sentimental. (Wim Wenders’ excruciatingly cloying and portentous Wings of Desire is perhaps the most spectacular failed contemporary attempt to render the angelic.) Yet, as Rudolf Otto establishes in The Idea of the Holy, encounters with angels are as disturbing, traumatic and overwhelming as encounters with demons. After all, what could be more shattering, unassimilable and incomprehensible in our hyper-stressed, constantly disappointing and overstimulated lives, than the sensation of calm joy? Otto, a conservative Christian, argued that all religious experience has its roots in what is initially misrecognised as ‘daemonic dread’; he saw encounters with ghosts, similarly, as a perverted version of what the Christian person would experience religiously. But Otto’s account is an attempt to fit the abstract and traumatic encounter with ‘angels’ and ‘demons’ into a settled field of meaning.

Otto’s word for religious experience is the numinous. But perhaps we can rescue the numinous from the religious. Otto delineates many variants of the numinous; the most familiar to us now would be ‘spasms and convulsions’ leading to ‘the strangest excitements, to intoxicated frenzy, to transport, and to ecstasy’. But far more uncanny in the ultra-agitated, present is that mode of the numinous which ‘come(s) sweeping like a gentle tide, pervading the mind with a tranquil mood of deepest worship.’ Foxx’s instrumental music – on Tiny Colour Movies and on the three Cathedral Oceans CDs, and with Harold Budd on the Transluscence and Drift Music LPs – has been eerily successful in rendering this alien tranquillity. On Transluscence in particular, where Budd’s limpid piano chords hang like dust subtly diffusing in sunlight, you can feel your nervous system slowing to a reptile placidity. This is not an inner but Outer calm; not a discovery of a cheap New Age ‘real’ self, but a positive alienation, in which the cold pastoral freezing into a tableau is experienced as a release from identity.

Dun Scotus’ concept of the haecceity – the ‘here and now’ – seems particularly apposite here. Deleuze and Guattari seize upon this in A Thousand Plateaus as a depersonalised mode of individuation in which everything – the breath of the wind, the quality of the light – plays a part. A certain use of film – think, particularly, of the aching stillness in Kubrick and Tarkovsky – seems especially set up to attune us to haecceity; as does the polaroid, a capturing of a haecceity which is itself a haecceity.

The impersonal melancholy that Tiny Colour Movies produces is similar to the oddly wrenching affect you get from a website like Found Photos. It is precisely the decontextualised quality of these images, the fact that there is a discrepancy between the importance that the people in the photographs place upon what is happening and its complete irrelevance to us, which produces a charge that can be quietly overwhelming. Foxx wrote about this effect in his deeply moving short story, ‘The Quiet Man’. The figure is alone in a depopulated London, watching home movies made by people he never knew. ‘He was fascinated by all the tiny intimate details of these films, the jerky figures waving from seaside and garden at weddings and birthdays and baptisms, records of whole families and their pets growing and changing through the years.’

‘Here you see old sunlight from other times and other lives’, Foxx observes in his evocative sleevenotes for Tiny Colour Movies. To leaf through other people’s family photos, to see moments that were of intense emotional significance for them but which mean nothing to you, is, necessarily, to reflect on the times of high drama in your own life, and to achieve a kind of distance that is at once dispassionate and powerfully affecting. That is why the – beautifully, painfully – dilated moment in Tarkovsky’s Stalker where the camera lingers over talismanic objects that were once saturated with meaning, but are now saturated only with water is for me the most moving scene in cinema. It is as if we are seeing the urgencies of our lives through the eyes of an Alien–God. Otto claims that the sense of the numinous is associated with feelings of our own fundamental worthlessness, experienced with a ‘piercing acuteness and () accompanied by the most uncompromising judgment of self-depreciation’. But, contrary to today’s ego psychology, which hectors us into reinforcing our sense of self (all the better to ‘sell ourselves’), the awareness of our own Nothingness is of course a pre-requisite for a feeling of grace. There is a melancholy dimension to this grace precisely because it involves a radical distanciation from what is ordinarily most important to us.


He stood in the soft beams of sunshine diffused by the curtains, caught for a moment in the stillness of the room, watching the dust swirling slowly golden through patches of light that fell across the carpets and furniture, feeling a strange closeness to the vanished woman. Being here and touching her possessions in the dusty intimacy of these rooms was like walking through her life, everything of her was here but for the physical presence, and in some ways that was the least important part of her for him.


Longing and aching are words that recur throughout Foxx’s work. ‘Blurred Girl’ from Metamatic – its lovers ‘standing close, never quite touching’ – would almost be the perfect Lacanian love song, in which the desired object is always approached, never attained, and what is enjoyed is suspension, deferral and circulation around the object, rather than possession of it – ‘are we running still? or are we standing still?’ On Tiny Colour Machines, as on Cathedral Oceans and the albums with Budd, where there are no words, this feeling of enjoyable melancholy is rendered by the minimally disturbed stillness and barely perturbed poise of the sounds themselves.


I can detect tiny edges of time leaking through. I feel nothing is completely separate. At some point everything leaks into everything else. The trick is in finding the places. They are slowly moving. Drifting. You can only do this accidentally. If you set out to do it deliberately you will always fail.

It is only when you remember, only then will you realise that you caught a glimpse. While you were talking to someone, or thinking of something else. When your attention was diverted. Just a hint, a glimmer, a shade.

Much later, you will remember. Without really knowing why. Vague peripheral sensations gather. Some fraction of a long rhythm is beginning to be recognised. The hidden frequencies and tides of the city. Geometry of coincidence.


Listening to Tiny Colour Movies, as with all of Foxx’s best records, one has a sense of returning to a dream-place. Foxx’s shifting or shadow city, with its Ernst-like ‘green arcades’ and De Chirico colonnades, is urban space as seen from the unconscious on a derive; an intensive space in which elements of London, Rome, Florence and other, more secret places are given an oneiric consistency.

I lost myself in that city more than 20 years ago.


Sleeping in cheap boarding houses. A ghost with leaves in his pocket and no address. The good face half blind. A nebula of songs and memories slipping in and out of focus. Someone told me he was there but it didn’t register at the time. The voice came unfocussed from all around. Still and quiet like the shadows of an ocean in the moving trees.


Indented text from John Foxx’s ‘Quiet Man’ and ‘Shifting City’ texts and the Cathedral Oceans booklet.





Electricity and Ghosts: Interview with John Foxx


k-punk post, September 23, 2006


MF: Which films were most influential on you early on?

JF: Oh, very cheap science fiction films mostly. There was one particularly memorable movie called Robot Monster, so bad it was surreal, it had the quality of a dream, an exceptional movie.

I now think it’s one of the best films I’ve ever seen, partly because it had no regard for plot or anything else recognizable as conventional cinema of the time. This of course made it an event of inestimable importance to me, because, as a child I took it all literally – swallowed it whole, like Alice’s potion.

And like that potion, it allowed entry to an unexpected universe. One which had unfathomable logic and laws which were endlessly flexible. A deeply exhilarating experience. I still dream sequences from it, or rather I seem to have permanently incorporated sections of it into my dream grammar.

Growing up with movies as a child and being subjected to them before I could understand the adult preoccupations and motivations involved in the plots, pitched me into conscripting these films as a personal grammar. I had no choice, so I ended up with this Lynchian reservoir of sequences that carried every dread and joy and everything in between.

These events are still imbued with unfathomable, inexplicable, tantalizing mystery, because I couldn’t really understand them at all. It was hallucinogenic and vivid, and provided me with an image bank and a gorgeous range of emotional tones I still haven’t managed to exhaust.

Much later, when I got to ‘Cinema’ – or the official critical view of it – the more intellectual, often French aspect. I didn’t recognise it at all.

Later, I ended up enjoying this sort of perspective a little, but in a rather disengaged, sceptical way. To me, it seems a method of criticism which is often marvelously baroque and can be engaging, but has little to do with my own experience of Cinema.

I can only deal with it as a marvelous fictional construct, like medieval religion or quantum physics – a consensual social hallucination developed by a priesthood. In the end it’s as tangential as my own individual one.

But that very crude, improvisational, amateurish side of cinema or filmmaking, I continue to find deeply fascinating. Take for example Ed Wood’s films. He made them simply because he was in a place where it could be done.

I think of Ed Wood as a sort of advanced naive artist. He was among the first to make cut-up movies. He achieved this by using props he came across in warehouses and stock footage he discovered in the film vaults of Hollywood cutting rooms, then he built movies around these fragments.

This is the art of collage and sampling. It is art as found object, as coincidence, as accident, as Surrealism, as Dada, as Situationism. All made possible and motivated also by the dynamo of American opportunism, but with great love and inadequacy and tenderness.

Ed Wood was doing, fifty years ago, what the avant garde are only now beginning to do with film.

(This is also very similar to the way rock ‘n’ roll often manages to parallel or prefigure avant garde concepts, by arriving at them from a totally different direction. Pop is such a virile mongrel it’s capable of effortlessly demonstrating, realising, manifesting, absorbing, remaking any sort of academic intellectual concept. It can do this so well, it often makes any parallel or previous version appear weak or even redundant).

An admiration for that sort of visceral, sensual, opportunistic, native intelligence led to an interest in, and respect for, home video and super-8 – very low grade domestic ways of making films – I suddenly realised there was a whole other world there, one which hadn’t been properly discussed, but as real, in fact more real and potentially at least as powerful, as official cinema.


MF: The film collection you refer to in the sleeve notes to Tiny Colour Movies – you write about it very beautifully. Are there any plans for those films to be shown in the UK?

JF: Thanks. I’d like to – there are some problems with these fragments, because they’re so small. They’re physically difficult things, and they’re unique irreplaceable and very fragile, so you can only ever show digital copies of them. But it would be interesting to do something like that. I’m beginning to look at some possibilities now, working with Mike Barker, who has accumulated a marvellous archive, and we’re discussing this with some film festivals.


MF: I noticed you thanked Paul Auster in the sleeve notes, why was that?

JF: Paul Auster has is very interesting to me, because I wrote this thing called ‘The Quiet Man’ years ago, in the 80s, in fact I’m still writing it. Then I read the New York Trilogy, and it struck so many chimes. It was as if I’d written it, or it was the book I should have written. I have to be very careful to find my way around it now.

Such occurrences are simultaneously rewarding and terrifying. They illustrate the fact that there is something in the air, which is tremendously heartening after working alone for years, yet they scare you because it feels as if someone has published first, and therefore registered their claim to where you discovered gold.

I simply wanted to acknowledge the effect, and the odd sort of encouragement of recognised themes, as well as a continuing parallel interest in the idea of lost movies and fragments MF: There’s a certain kind of London affect that’s interesting, of stillness, and the city being overgrown, which is sort of recurrent in your work – where’s that come from do you think?

JF: When I first came to London it seemed a great deal like Lancashire, where I’d come from. But Lancashire had fallen into ruin. The factories had closed, the economy had faltered. We felt like the Incas after the Spaniards had passed. Helpless, nostalgic savages adrift in the ruins.

I grew up playing in empty factories, huge places which were overgrown. I remember trees growing out of the buildings. I remember a certain moments of looking at it all and thinking what it would have been like when it was all working. What life might be like, if it were all working still.

All of my family worked in mills and factories and mines. And all this was gently subsiding, spinning away.

Coming to London, I couldn’t help but wonder if it might also fall into dissolution. Then I saw a picture a friend had. It was a realistic painting of what appeared to be a view over a jungle from a high place. Gradually you came to realise that it was a view of an overgrown city from a tower, then you realised that this panorama was from a ruined Centre Point and you could see Tottenham Court Road, Oxford Street, Charing Cross road in the undergrowth. It felt like a revelation. It manifested so perfectly this vision I’d had of everything becoming overgrown, an overgrown London. A vision of longing and nostalgia tinged with fear.

I would often experience a feeling of stillness and wonder as I walked through certain parts of London. I often walked through empty buildings and neglected, overlooked places and they would replay that sensation very strongly.

I went to Shoreditch, in 1982, and made a studio there. When we first went into the studio building it had trees growing out of the windows on the upper stories. It was very like Lancashire, that whole area was derelict, had been abandoned, because that had been the industrial bit of the East End. Now there was no-one there, it was empty. It gave me that calm drifting feeling of recognition.

There was some kind of collective image of overgrown and abandoned cities at that time. Perhaps it’s always there. Such images were present in Ballard, Burroughs, Philip K Dick. In those science fiction authors writing about the near future – conducting thought experiments, exploring likely consequences and views of the unrecognised present, which I think is very valuable. They offer perspectives and meditations on our vanity and endeavours. As such they maintain continuity with a long line of imagery, from religious myths and folk stories to science fiction.


MF: It seems to have a real unconscious resonance, this idea of overgrown cities, it’s obviously there in surrealist paintings, which seem to be a constant reference, especially in your early work –

JF: Yes, there’s that side of it too. In science fiction films you often get those recurrent images, which I think are very beautiful, of someone walking through an abandoned city.

We have accumulated a range of such images all along the line, from folk and fairytales, to the actual construction of follies and romantic overgrown gardens, to the truly dislocated, such as Piranesi’s ruins and prisons, to Max Ernst’s paintings, or Breughel’s Tower of Babel, or the background urban locations in Bosch, as well as De Chirico’s townscapes and shadows.

Planet of the Apes has one of the most shocking and resonant – the end of original movie, where we see the Statue of Liberty tilted in the sand. A real jolt, the first time you see it. A modern take on Shelley’s Ozymandias.

The radiance I sometimes refer to occupies this sort of area. I often see people as if in a frozen moment and they seem to have an internal glow inside them. Their skin seems translucent and they carry their own time. I feel calm and distant and warm from this. It can happen in an instant. In very mundane urban situations. You realise you are not looking at a single person, but at a sort of stream or cascade.

It happened yesterday in a supermarket. I happened to glance at a young woman who looked like a transfigured hidden Madonna. She wore jeans and a teeshirt, an ordinary woman. But equally, she was a continuity, a lovely genetic physical thread to other times, both previous and ahead and still unformed. She simply glowed. Quietly and unknowingly luminous. The Eternal Woman.


MF: The sort of feelings you deal with are more abstract; it’s like you go to those states without reference to the way they’ve traditionally been coded, really. You often use the word ‘angelic’, or ‘angel’…

JF: Yes, very perilous territory, especially since these terms have since been co-opted by New Agers. I’ll put on the grey suit to dispel all that.

Many of these spring from what I think of as ‘thought exper-iments’ – things I employ all the time, as a tool to get at half buried or emerging realisations. If you’re at all interested, I’ll try to outline a few.

Firstly, the idea interested me – still does – of parallel evolutions – imagine something that may have evolved alongside us, something we’re not quite aware of yet, that we haven’t yet discovered.

That may include things which exist in other planes or by other means, or things which resemble human beings so well that we assume them to be human, but they may not be. Yet they live among us undetected – the possibility that other forms of life may have evolved alongside us, but invisible because of their proximity.

‘Hiding in plain sight’ is a great idea, something that’s very interesting in itself – on one level connected with sleight of hand and parlour tricks and conmen, but on the other hand, very subtle, intuition led perceptions. It could give rise to situations that are tremendously moving, fragile, tender. Metaphorically very resonant.

Another one – I’m also very interested in the concept of a singularity. An event that only happens once, or once every thousand or million years.

There may be rhythms which extend over tens of millions of years and are therefore unrecognisable to us, except as single unconnectable and unexplainable events.

But the fact that we have no context to fit them into doesn’t mean they don’t happen.

Yet another thought experiments posits the concept of Angels as a connection between things. An entity that only exists between. A sort of web or connection. They arise purely as an intrinsic, invisible and unsuspected component of the evolution of the ecology that supports whatever they exist between. They cannot exist on their own.

Many of us have these little incidents – everything from coincidences onward – things that we can’t explain using the references we commonly employ.

I’m very interested in those things, always have been. Through those odd things, we glimpse something that’s outside the way we usually look at the world, and realise there might be another way of looking at it, an alternate perception to the one we have, and I think that’s a very valuable possibility to keep hold of. The awareness that maybe there are gaps in our perception that we aren’t able to fill yet.

MF: Yes, because I think one of the most powerful things – which comes out in Tiny Colour Movies but in retrospect has always been there – is that you’re able to deal with positive, affirmatory feelings that are eerie and uncanny, and possess a certain kind of calm serenity.

JF: Good, somehow that’s always been a vital component of that sort of experience, for me. A sensation of utter calm and stillness. Miles away from any agitation. It seems deeply positive.

It’s an opposite to the excitement you get from, say, rock and roll…I think in general we like to stir ourselves up in various ways, using art or using media or whatever, and I think it’s just as valid to move against the norm, and the norm at the moment is to speed everything up.

I mean, that’s what we’re trying to attain, aren’t we, through media? – That awful maximisation of time and efficient transmission of ‘information’. Some of this is economic – time equals money – and some is simply done because it can be done, and has become an unquestioned convention.

If you could time-jump to show the average TV ad of today to someone 20 or 30 years ago, they wouldn’t understand it. The ad would depend on the viewer’s perception speed and also on a series of recent references. Our parents simply weren’t fast enough, they hadn’t been accelerated as we have been by media and the pace of modern life, and they also don’t have the inculcated, busy reference chain.

Acceleration is also kind of exciting and interesting, I mean I really enjoy it, sometimes – but it equally leads you to think ‘what happens if you do the opposite?’–it might be just as pleasurable and just as valid to do that.

So, one of the things I want to try to do is work on the other end of this spectrum – see what happens when you slow things down.

I was surprised when I was doing the first music for Cathedral Oceans, using echoes that were 30 seconds long, so the rhythms were 30 seconds between the beats.

It was very interesting slowing down enough to work with that intuitively. You had to do it, you had to synchronise with the track in order to be able to work with it. And it’s very interesting what kind of state you get into – intense, yet calm and tranquil. A sort of trance state.

MF: I think it’s particularly on the LPs with Harold Budd, where you get that sort of aching plateau, where you slow down so much that any peturbation has a massive effect really.

Harold was one of the first people who got that right, I think. One of the very first to have sufficient courage to leave enough space in the music and not fill spaces unnecessarily. Not decorate. Takes an awful lot of quiet courage to do that.

When this is done, it allows an alternative ecology to emerge – one based on events that are much less frequent. And that, of course, affects their significance. You are drawn to them in a sort of smiling fascination, rather than the usual pop music method of lapel grabbing bombardment.

MF: It seems to be something similar to what you get in Tarkovsky films – where either people say ‘oh, this is too slow I can’t stand it’, or they enter into the slow time of the film and anything that happens almost becomes too much.

JF: Exactly, you can concentrate on any event very thoroughly, when that mode of perception is made available. Events become stately and welcome and valued and significant, and their arrival and departure can be fully experienced. The lack of jostling allows that sort of elegant notional space to open up.

It functions at the other end of the spectrum from commercial TV and cinema, and of rock & roll. Both ends can be equally interesting, I think.

MF: It seems to me that you’ve always imposed the stillness and calmness of painting and photography or a certain type of film onto the agitation of rock, really. Certain kind of dreams - the dreams we’re most familiar with – are hyper-agitated, full of urgency etc, but there’s another type of dream quality you seem to get to where those urgencies are suspended and you’re out of that everyday life push-and-pull, really. I wondered - there seems to be a certain aching, or longing quality - these are words you seem to use a lot in your music…

JF: Well, dreams are a very important component. I realised that it is not simply the image you present yourself with, in a dream, which is important – it’s also the emotional tone of the scene. You can see a cloud, but this will be accompanied by a sense of wonder or by a sense of dread, and it is that accompaniment which determines its meaning.

The employment of these images and tones are some of the things that everyone shares, aren’t they? They’re composed of bits of unique personal events and references and memories, such as longings that you might have had when you’re a child.

When your parents are away even for an hour it feel as though it goes on forever and you really deeply miss them – and the abstraction, the tone component of that just carries on through life. Gets applied to different situations. These longings – and all other emotional parts of the spectrum – join the repertoire of tones we carry and apply. Some moments last forever.

MF: But there’s almost a positive side, almost an enjoyment of longing and ache.

JF: Oh yes, where the observer part of you acknowledges an emotional connection with the rest. Simultaneously you feel as though you are very integrated, yet you are being gently pulled away from yourself. Gently disengaged.

MF: Isn’t the ‘emotionless’ quality of your music more to do with a certain kind of calm?

JF: Yes, it’s quite a complex thing, a compound. There are states where there’s a sensation of time passing, things changing, knowing the world is changing, falling in on itself, and reforming. And you may even be in the process of doing just that yourself.

But there are moments where you just stand by and watch it all, where you’re aware of it, in a moment that seems to go on forever. So it’s something of standing in a still place and watching the patterns in passing crowds and even in your own life. It can be a very powerful experience.

That stillness, and the maintenance of a quiet dignity in the face of insurmountable circumstances can be immensely moving to witness.

It can be much more effective and moving if someone tells the story in an unemotional or undramatic way. You find that in Ishiguro. Remains of the Day or Never Let Me Go are good examples of that kind of writing, where the most important components remain unstated. The Leopard is suffused with, and is dependent on a variant of this.

It’s also allied to a device used in different ways by Charlie Chaplin, Buster Keaton and Cary Grant. – An archetypical figure attempts to retain dignity in the face of the worldly chaos while remaining ever hopeful of romance.

And with Ballard and Burroughs, you get an almost gentlemanly, middle class version of a similar sort of stance – mayhem of all kinds observed from a disengaged viewpoint.





Another Grey World: Darkstar,

James Blake, Kanye West, Drake and

‘Party Hauntology’


‘It’s a really grey-sounding synth, really organic and grainy. We call them “swells” – where synthesisers start quite minimal and then develop into a huge chord, before progressing. I felt like it wouldn’t be right if we just carried on with that dayglo Hyperdub sound of a couple of years ago. I mean I love those songs, but it already feels like a lifetime away.’ I felt vindicated when I read these remarks of Darkstar’s James Young in an interview with Dan Hancox. When I first heard the album about which Young is talking – 2010’s North – the phrase that came to my mind was ‘Another Grey World’. The landscape of North felt like the verdant Max Ernst forest of Eno’s Another Green World become ash.


…with winter ahead of us


The depressive’s world is black and/ or white, (you only have to remember the covers of Joy Division’s Unknown Pleasures and Closer), but North does not (yet) project a cold world entirely swathed in snow. North is the direction that the album is heading towards, not a destination it has reached. Its landscape is colourless rather than black, its mood tentative – it is grey as in unresolved, a grey area. This is an album defined by its negative capability of remaining in doubts, disquiet and dissatisfactions that it unable to name. It is grey as in The Cure’s ‘All Cats Are Grey’ from Faith, a record that stood between the spidery psychedelia of Seventeen Seconds and the unrelieved darkness of Pornography. Yet North is ultimately too jittery to muster the glacial fatalism of Faith but what North has in common with The Cure’s great records is the sense of total immersion in a mood. It is a work that came out of method immersion: Young told Dan Hancox that, as they recorded North, the group had listened obsessively to Radiohead, Burial, the Human League and the first album by Orchestral Manouevres in the Dark. The record demands the same kind of involvement, which is perhaps why some found it unengaging. On a casual listen, the very unresolved quality of the tracks could seem simply undercooked. James Buttery’s vocals could come off as limp, anaemic. In addition, many were disappointed by Darkstar’s failure to provide an album full of the ‘robotic 2-step’ that they had invented on ‘Aidy’s Girl is a Computer’. In fact, they made the robotic 2-step album but ditched it, dissatisfied with its lack of ambition. (This wholly completed album that was never released is one of several parallels with Burial.) ‘Aidy’s Girl is a Computer’ apart, if you heard North without knowing the history, you wouldn’t assume any connection with dubstep. At the same time, North isn’t straightforwardly a return to a pre-dance sound. It is more a continuation of a certain mode of electronic pop that was prematurely terminated sometime in the mid-80s: like New Order if they hadn’t abandoned the sleek cybernetic mausoleum that Martin Hannett built for them on Movement.

Except, of course, that it is not possible to simply continue that trajectory as if nothing had happened. Darkstar acknowledge the present only negatively. It impinges on their music in perhaps the only way it can, as a failure of the future, as a temporal disorder that has infected the voice, causing it to stutter and sibilate, to fragment into strange slithering shards. Part of what separates Darkstar from their synthpop forebears is the fact that the synthesiser no longer connotes futurity. But Darkstar are not retreating from a vivid sense of futurity – because there is no such futurity from which they could retreat. This becomes clear when you compare the Darkstar cover of ‘Gold’ to the Human League original. It’s not just that one is no more futuristic than the other; it’s that neither are futuristic. The Human League track is clearly a superseded futurism, while the Darkstar track seems to come after the future.

It’s this sense of living in an interregnum, that makes North so (un)timely. Where Burial made contact with the secret sadness underlying the boom, Darkstar articulate the sense of foreboding that is everywhere after the economic crash of 2008. North is certainly full of references to lost companionship: the album can be read as an oblique take on a love affair gone wrong.


Our fate’s not to share….


The connection between us gone….


But the very focus on the love couple rather than the rave massive is itself symptomatic of a turn inward. In a discussion that Simon Reynolds and I had about North shortly after it was released, Reynolds argued that it was a mistake to talk as if rave was bereft of emotion. Rave was a music saturated with affect, but the affect involved wasn’t associated with romance or introspection The introspective turn in 21st century (post)dance music was therefore not a turn towards emotion, it was a shift from collectively experienced affect to privatised emotions. There was an intrinsic and inevitable sadness to this inward turn, regardless of whether the music was officially sad or not. The twinning of romance and introspection, love and its disappointments, runs through 20th century pop. By contrast, dance music since disco offered up another kind of emotional palette, based in a different model of escape from the miseries of individual selfhood.

The 21st century has often felt like the comedown after a speed binge, or the exile back into privatised selfhood, and the songs on North have the jittery clarity of Prozac withdrawal.

It’s significant that most of the digital interference on North is applied to James Buttery’s voice. Much of the vocal sounds as if it has been recorded on a shaky mobile phone connection. I’m reminded of Franco Berardi’s arguments about the relationship between informational overload and depression. Berardi’s argument is not that the dot.com crash caused depression, but the reverse: the crash was caused by the excessive strain put on people’s nervous systems by new informational technologies. Now, more than a decade after the dot.com crash and the density of data has massively increased. The paradigmatic labourer is now the call centre worker – the banal cyborg, punished whenever they unplug from the communicative matrix. On North, James Buttery, afflicted by all manner of digital palsies, sounds like a cyborg whose implants and interfaces have come loose, learning to be a man again, and not liking it very much.

North is like Kanye West’s 2008 album 808s and Heartbreak with all the gloss removed. There is the same method melancholia, the same anchoring in early 80s synthpop, explicitly flagged in 808’s case by the cover design’s echo of Peter Saville’s sleeves for New Order’s Blue Monday and Power, Corruption and Lies. The opening track ‘Say You Will’ sounds like it has been worked up out of the crisp synthetic chill of Joy Division’s ‘Atmosphere’ and the funereal drum tattoo of New Order’s ‘In A Lonely Place’. As with North, though, the 80s parallels are disrupted by the digital effects used on the voice. 808s and Heartbreak pioneered the use of Auto–Tune, which would subsequently come to dominate R&B and hip-hop from the late 00s onwards. In a sense, the conspicuous use of Auto-Tune – that is to say, its use as an effect, as opposed to its official purpose as a device to correct a singer’s pitch – was a 90s throwback, since this was popularised by Cher on her 1998 single ‘Believe’. Auto-Tune is in many ways the sonic equivalent of digital airbrushing, and the (over) use of the two technologies (alongside the increasing prevalence of cosmetic surgery) result in a look and feel that is hyperbolically enhanced rather than conspicuously artificial. If anything is the signature of 21st century consumer culture, is this feeling of a digitally upgraded normality – a perverse yet ultra-banal normality, from which all flaws have been erased.

On 808s and Heartbreak, we hear the sobs in the heart of the 21st century pleasuredome. Kanye’s lachrymose android shtick reaches its maudlin depths on the astonishing ‘Pinocchio Story’. This is the kind of Auto-Tuned lament you might expect neo-Pinocchio and android-Oedipus David from Spielberg’s AI (2001) to sing; a little like Britney Spears’s ‘Piece Of Me’, you can either hear this as the moment when a commodity achieves selfconsciousness, or when a human realises he or she has become a commodity. It’s the soured sound at the end of the rainbow, an electro as desolated as Suicide’s infernal synth-opera ‘Frankie Teardrop’.

A secret sadness lurks behind the 21st century’s forced smile. This sadness concerns hedonism itself, and it’s no surprise that it is in hip-hop – a genre that has become increasingly aligned with consumerist pleasure over the past 20-odd years – that this melancholy has registered most deeply. Drake and Kanye West are both morbidly fixated on exploring the miserable hollowness at the core of super-affluent hedonism. No longer motivated by hip-hop’s drive to conspicuously consume – they long ago acquired anything they could have wanted – Drake and West instead dissolutely cycle through easily available pleasures, feeling a combination of frustration, anger, and self-disgust, aware that something is missing, but unsure exactly what it is. This hedonist’s sadness – a sadness as widespread as it is disavowed – was nowhere better captured than in the doleful way that Drake sings, ‘we threw a party/ yeah, we threw a party,’ on Take Care’s ‘Marvin’s Room’.

It’s no surprise to learn that Kanye West is an admirer of James Blake. There’s an affective as well as sonic affinity between parts of Kanye’s 808s and Heartbreak and My Beautiful Dark Twisted Fantasy and Blake’s two albums. You might say that Blake’s whole MO is a partial re-naturalisation of the digitally manipulated melancholy Kanye auditioned on 808s: soul music after the Auto-Tune cyborg. But liberated from the penthouse-prison of West’s ego, unsure of itself, caught up in all kinds of impasses, the disaffection languishes listlessly, not always even capable of recognizing itself as sadness.

You might go so far as to say that the introspective turn reached a kind of conclusion with Blake’s 2013 album Overgrown. In his transformation from dubstep to pop, Blake had gone from digitally manipulating his own voice to becoming a singer; from constructing tracks to writing songs. The initial motivation for Blake’s approach to the song no doubt came from Burial, whose combination of jittery 2-step beats and R&B vocal samples pointed the way to a possible vision of 21st century pop. It was as if Burial had produced the dub versions; now the task was to construct the originals, and that entailed replacing the samples with an actual vocalist.

Listening back to Blake’s records in chronological sequence is like hearing a ghost gradually assume material form; or it’s like hearing the song form (re)coalescing out of digital ether. A track such as ‘I Only Know (What I Know Now)’ from the Klavierwerke EP is gorgeously insubstantial – it’s the merest ache, Blake’s voice a series of sighs and unintelligible pitch-shifted hooks, the production mottled and waterlogged, the arrangement intricate and fragile, conspicuously inorganic in the way that it makes no attempt to smooth out the elements of the montage. The voice is a smattering of traces and tics, a spectral special effect scattered across the mix. But with Blake’s self-titled debut album, something like traditional sonic priorities were restored. The reinvention of pop that his early releases promised was now seemingly given up, as Blake’s de-fragmented voice moved to the front of the mix, and implied or partially disassembled songs became ‘proper’ songs, complete with un-deconstructed piano and organ. Electronics and some vocal manipulation remained, but they were now assigned a decorative function. Blake’s blue-eyed soul vocals, and the way that his tracks combined organ (or organ-like sounds) with electronica, made him reminiscent of a half-speed Steve Winwood.

Just as with Darkstar’s North, Blake’s turn to songs met with a mixed response. Many who were enthusiastic about the early EPs were disappointed or mildly dismayed by James Blake. Veiling and implying an object is the surest route to producing the impression of sublimity. Removing the veils and bringing that object to the fore risks de-sublimation, and some found Blake’s actual songs unequal to the virtual ones his early records had induced them into hallucinating. Blake’s voice was as cloyingly overpowering as it was non-specific in its feeling. The result was a quavering, tremulous vagueness, which was by no means clarified by lyrics that were similarly allusive/elusive. The album came over as if it were earnestly entreating us to feel, without really telling us what is was we were supposed to be feeling. Perhaps it’s this emotional obliqueness that contributes to what Angus Finlayson, in his review of Overgrown for FACT, characterised as the strangeness of the songs on James Blake. They seemed, Finlayson said, like ‘half-songs, skeletal place-markers for some fuller arrangement yet to come.’ The journey into ‘proper’ songs was not as complete as it first appeared. It was like Blake had tried to reconstruct the song form with only dub versions or dance mixes as his guide. The result was something scrambled, garbled, solipsistic, a bleary version of the song form that was as frustrating as it was fascinating. The delicate insubstantiality of the early EPs had given way to something that felt overfull. It was like drowning in a warm bath (perhaps with your wrists cut).

On Blake’s albums, there is a simultaneous feeling that the tracks are both congested and unfinished, and that incompleteness – the sketchy melodies, the half-hooks, the repeated lines that play like clues to some emotional event never disclosed in the songs themselves – may be why they eventually get under your skin. The oddly indeterminate – irresolute and unresolved – character of Blake’s music gives it the quality of gospel music for those who have lost their faith so completely that they have forgotten they ever had it. What survives is only a quavering longing, without object or context, Blake coming off like an amnesiac holding on to images from a life and a narrative that he cannot recover. This negative capability means that Overgrown is like an inversion of the oversaturated high-gloss emotional stridency of chart and reality TV pop, which is always perfectly certain of what it is feeling.

Yet there’s an unconvincing – or perhaps unconvinced – quality to so much of mainstream culture’s hedonism now. Oddly, this is most evident in the annexing of R&B by club music. When former R&B producers and performers embraced dance music, you might have expected an increase in euphoria, an influx of ecstasy. But the reverse has happened, and it’s as if many of the dancefloor tracks are pulled down by a hidden gravity, a disowned sadness. The digitally–enhanced uplift in the records by producers such as Flo-Rida, Pitbull and will.i.am is like a poorly photoshopped image or a drug that we’ve hammered so much we’ve become immune to its effects. It’s hard not to hear these records’ demands that we enjoy ourselves as thin attempts to distract from a depression that they can only mask, never dissipate.

In a brilliant essay on The Quietus website, Dan Barrow analysed the tendency in a slew of chartpop over the past few years – including Jay-Z and Alicia Keys’s ‘Empire State of Mind’ Kesha’s ‘Tik Tok’, Flo Rida’s ‘Club Can’t Even Handle Me Yet’ – ‘to give the listener the pay–off, the sonic money-shot, as soon and as obviously as possible’. Pop has always delivered sugar-sweet pleasure, of course, but, Barrow argues, there’s a tyrannical desperation about this new steroid-driven pop. It doesn’t seduce; it tyrannises. This, Barrow argues, is ‘a crude, overdetermined excess, as if pop were forcing itself back to its defining characteristics – chorus hooks, melody, “accessibility” – and blowing them up to cartoonish size.’ There’s an analogy to be drawn between this artificially inflated pop and Berardi’s discussion of internet pornography and drugs such as Viagra, which, similarly, dispense with seduction and aim directly at pleasure. According to Berardi, remember, we are so overwhelmed by the incessant demands of digital communications, we are simply too busy to engage in arts of enjoyment – highs have to come in a no-fuss, hyperbolic form so that we can quickly return to checking email or updates on social networking sites. Berardi’s remarks can give us an angle on the pressures that dance music has been subject to over the last decade. Whereas the digital technology of the 80s and 90s fed the collective experience of the dancefloor, the communicative technology of the 21st century has undermined it, with even clubbers obsessively checking their smartphones. (Beyoncé and Lady Gaga’s ‘Telephone’ – which sees the pair begging a caller to stop bugging them so they can dance – now seems like a last failed attempt to keep the dancefloor free of communicational intrusion.)

Even the most apparently uncomplicated calls to enjoyment can’t fully suppress a certain sadness. Take Katy Perry’s ‘Last Friday Night’. On the face of it, the track is a simple celebration of pleasure (‘Last Friday night/ Yeah we maxed our credit cards/ And got kicked out of the bar’). Yet it’s not hard to hear something Sisyphean, something purgatorial, in the song’s evocation of a (not so) merry-go-round of pleasure that Perry and her friends can never get off: ‘Always say we’re gonna stop/ This Friday night/ Do it all again…’ Played at half-speed, this would sound as bleak as early Swans. David Guetta’s ‘Play Hard’ calls up a similarly interminable repetition. Pleasure becomes an obligation that will never let up – ‘us hustler’s work is never through/ We work hard, play hard’ – and hedonism is explicitly paralleled with work: ‘Keep partyin’ like it’s your job’. It’s the perfect anthem for an era in which the boundaries between work and non-work are eroded – by the requirement that we are always-on (that, for instance, we will answer emails at any hour of the day), and that we never lose an opportunity to marketise our own subjectivity. In a (not at all trivial) sense, partying is now a job. Images of hedonistic excess provide much of the content on Facebook, uploaded by users who are effectively unpaid workers, creating value for the site without being remunerated for it. Partying is a job in another sense – in conditions of objective immiseration and economic downturn, making up the affective deficit is outsourced to us.

Sometimes, a free-floating sadness seeps into the grain of the music itself. On their blog No Good Advice, the blogger J describes the use of a sample from Kaoma’s 1989 track ‘Lambada’ on Jennifer Lopez’s 2011 hit ‘On The Floor’: ‘The snatch of ‘Lambada’ functions as a buried-memory trigger, a sort of party hauntology that lends the song a slight edge of wistful, nostalgic sadness.’ There is no reference to sadness in the official text of the track, which is a simple exhortation to dance. So it’s as if the sorrow comes from outside, like traces of the waking world incorporated into a dream, or like the grief which creeps into all the embedded worlds in Inception (2010).

‘Party hauntology’ might even be the best name for the dominant 21st century form of pop, the transnational club music produced by Guetta, Flo-Rida, Calvin Harris and will.i.am. But the debts to the past, the failure of the future are repressed here, meaning that the hauntology takes a disavowed form. Take a track like the Black Eyed Peas’ immensely popular ‘I Gotta Feeling’. Although ‘I Gotta Feeling’ is ostensibly an optimistic record, there’s something forlorn about it. Perhaps that’s because of will.i.am’s use of Auto-Tune – there seems to be Sparky’s Magic Piano-like machinic melancholy intrinsic to the technology itself, something which Kanye drew out rather than invented on 808s and Heartbreak. In spite of the track’s declamatory repetitions, there’s a fragile, fugitive quality about the pleasures ‘I Gotta Feeling’ so confidently expects. That’s partly because ‘I Gotta Feeling’ comes off more like a memory of a past pleasure than an anticipation of a pleasure that is yet to be felt. The album from which the track comes, The E.N.D. (The Energy Never Dies) was – like its predecessor, The Beginning – so immersed in Rave that it effectively operated as an act of homage to the genre. The Beginning’s ‘Time (Dirty Bit)’ could have actually passed for a Rave track from the early 90s – the crudeness of its cut and paste montage recalls the ruff ‘n’ ready textures that samplers would construct at that time, and its borrowing from Dirty Dancing’s ‘(I’ve Had) The Time of my Life’ was just the kind of subversion/sublimation of cheesy source material that Rave producers delighted in. Yet, the Black Eyed Peas’ Rave-appropri-ations didn’t function so much as revivals of Rave as denials that the genre had ever happened in the first place. If Rave hasn’t yet happened, then there is no need to mourn it. We can act as if we’re experiencing all this for the first time, that the future is still ahead of us. The sadness ceases to be something we feel, and instead consists in our temporal predicament itself, and we are like Jack in the Gold Room of the Overlook Hotel, dancing to ghost songs, convincing ourselves that the music of yesteryear is really the music of today.





03: THE STAIN OF PLACE





‘Always Yearning For The Time That Just

Eluded Us’ – Introduction to Laura Oldfield

Ford’s Savage Messiah (Verso, 2011)


June 2011


‘I regard my work as diaristic; the city can be read as a palimpsest, of layers of erasure and overwriting,’ Laura Oldfield Ford has said. ‘The need to document the transient and ephemeral nature of the city is becoming increasingly urgent as the process of enclosure and privatisation continues apace.’ The city in question is of course London, and Ford’s Savage Messiah offers a samizdat counter-history of the capital during the period of neoliberal domination. If Savage Messiah is ‘diaristic’, it is also much more than a memoir. The stories of Ford’s own life necessarily bleed into the stories of others, and it is impossible to see the joins. ‘This decaying fabric, this unknowable terrain has become my biography, the euphoria then the anguish, layers of memories colliding, splintering and reconfiguring.’ The perspective Ford adopts, the voices she speaks in – and which speak through her – are those of the officially defeated: the punks, squatters, ravers, football hooligans and militants left behind by a history which has ruthlessly photoshopped them out of its finance-friendly SimCity. Savage Messiah uncovers another city, a city in the process of being buried, and takes us on a tour of its landmarks: The Isle of Dogs…The Elephant…Westway…Lea Bridge…North Acton…Canary Wharf…Dalston…Kings Cross…Hackney Wick…

In one of many echoes of punk culture, Ford calls Savage Messiah a ‘zine’. She began producing it in 2005, eight years into a New Labour government that had consolidated rather than overturned Thatcherism. The context is bleak. London is a conquered city; it belongs to the enemy. ‘The translucent edifices of Starbucks and Costa Coffee line these shimmering promenades, ‘young professionals’ sit outside gently conversing in sympathetic tones.’ The dominant mood is one of restoration and reaction, but it calls itself modernisation, and it calls its divisive and exclusionary work – making London safe for the super-rich – regeneration. The struggle over space is also a struggle over time and who controls it. Resist neoliberal modernisation and (so we are told) you consign yourself to the past. Savage Messiah’s London is overshadowed by the looming megalith of ‘London 2012’, which over the course of the last decade has subsumed more and more of the city into its banal science fiction telos, as the Olympic Delivery Authority transformed whole areas of East London into a temporary photo opportunity for global capitalism. Where once there were ‘fridge mountains and abandoned factories’ out of Tarkovsky and Ballard, a semi-wilderness in the heart of the city, now a much blander desert grows: spaces for wandering are eliminated, making way for shopping malls and soon-to-be-abandoned Olympic stadia. ‘When I was writing the zines,’ Ford remembers, ‘I was drifting through a London haunted by traces and remnants of rave, anarcho-punk scenes and hybrid subcultures at a time when all these incongruous urban regeneration schemes were happening. The idea that I was moving through a spectral city was really strong, it was as if everything prosaic and dull about the New Labour version of the city was being resisted by these ghosts of brutalist architecture, of ‘90s convoy culture, rave scenes, ‘80s political movements and a virulent black economy of scavengers, peddlers and shoplifters. I think the book could be seen in the context of the aftermath of an era, where residues and traces of euphoric moments haunt a melancholy landscape.’

All of these traces are to be eliminated from the Restoration London that will be celebrated at London 2012. With their lovingly reproduced junk-strata, overgrowing vegetation and derelict spaces, Savage Messiah’s images offer a direct riposte to the slick digital images which the Olympic Delivery Authority has pasted up in the now heavily policed, restricted and surveilled Lee valley. Blair’s Cool Britannia provides the template for an anodyne vision of London designed by the ‘creative indus-tries’. Everything comes back as an advertising campaign. It isn’t just that the alternatives are written over, or out, it is that they return as their own simulacra. A familiar story. Take the Westway, West London’s formerly deplored dual carriageway, once a cursed space to be mythologised by Ballard, punks and Chris Petit, now just another edgy film set:


This liminal territory, cast in a negative light in the 70s was recuperated by MTV and boring media types in the 90s. The Westway became the backdrop for Gorillaz imbecility, bland drum & bass record sleeves and photo shoots in corporate skate parks.


Cool Britannia. Old joke.

‘Space’ becomes the over arching commodity. Notting Hill. New Age cranks peddling expensive junk. Homeopathy and boutiques, angel cards and crystal healing.


Media and high finance on the one hand, faux-mysticism and superstition on the other: all the strategies of the hopeless and those who exploit them in Restoration London…Space is indeed the commodity here. A trend that started 30 years ago, and intensified as council housing was sold off and not replaced, culminated in the insane super-inflation of property prices in the first years of the 21st century. If you want a simple explanation for the growth in cultural conservatism, for London’s seizure by the forces of Restoration, you need look no further than this. As Jon Savage points out in England’s Dreaming, the London of punk was still a bombed-out city, full of chasms, caverns, spaces that could be temporarily occupied and squatted. Once those spaces are enclosed, practically all of the city’s energy is put into paying the mortgage or the rent. There’s no time to experiment, to journey without already knowing where you will end up. Your aims and objectives have to be stated up front. ‘Free time’ becomes convalescence. You turn to what reassures you, what will most refresh you for the working day: the old familiar tunes (or what sound like them). London becomes a city of pinched-face drones plugged into iPods.

Savage Messiah rediscovers the city as a site for drift and daydreams, a labyrinth of side streets and spaces resistant to the process of gentrification and ‘development’ set to culminate in the miserable hyper-spectacle of 2012. The struggle here is not only over the (historical) direction of time but over different uses of time. Capital demands that we always look busy, even if there’s no work to do. If neoliberalism’s magical voluntarism is to be believed, there are always opportunities to be chased or created; any time not spent hustling and hassling is time wasted. The whole city is forced into a gigantic simulation of activity, a fantacism of productivism in which nothing much is actually produced, an economy made out of hot air and bland delirium. Savage Messiah is about another kind of delirium: the releasing of the pressure to be yourself, the slow unravelling of biopolitical identity, a depersonalised journey out to the erotic city that exists alongside the business city. The eroticism here is not primarily to do with sexuality, although it sometimes includes it: it is an art of collective enjoyment, in which a world beyond work can – however briefly – be glimpsed and grasped. Fugitive time, lost afternoons, conversations that dilate and drift like smoke, walks that have no particular direction and go on for hours, free parties in old industrial spaces, still reverberating days later. The movement between anonymity and encounter can be very quick in the city. Suddenly, you are off the street and into someone’s life-space. Sometimes, it’s easier to talk to people you don’t know. There are fleeting intimacies before we melt back into the crowd, but the city has its own systems of recall: a block of flats or a street you haven’t focused on for a long time will remind you of people you met only once, years ago. Will you ever see them again?


I got invited up for a cup of tea in one of those Tecton flats on the Harrow road, one of the old men from the day centre I work in. I took him up Kilburn High Road shopping and watered the fuchsias on his balcony. We talked about the Blitz and hospitals mostly. He used to be a scientist and wrote shopping lists on brown envelopes dated and filed in a stack of biscuit tins.


I miss him.


I miss them all.


Savage Messiah deploys anachronism as a weapon. At first sight, at first touch – and tactility is crucial to the experience: the zine doesn’t feel the same when it’s JPEGed on screen – Savage Messiah seems like something familiar. The form itself, the mix of photographs, typeface-text and drawings, the use of scissors and glue rather than digital cut and paste; all of this make Savage Messiah seem out of time, which is not to say out of date. There were deliberate echoes of the para-art found on punk and postpunk record sleeves and fanzines from the 1970s and 1980s. Most insistently, I’m reminded of Gee Vaucher, who produced the paradoxically photorealistically delirious record covers and posters for anarcho-punk collective Crass. ‘I think with the look of the zine I was trying to restore radical politics to an aesthetic that had been rendered anodyne by advertising campaigns, Shoreditch club nights etc.,’ Ford says. ‘That anarcho-punk look was everywhere but totally emptied of its radical critique. It seemed important to go back to that moment of the late ‘70s and early ‘80s to a point where there was social upheaval, where there were riots and strikes, exciting cultural scenes and ruptures in the fabric of everyday life.’ The ‘return’ to the postpunk moment is the route to an alternative present. Yet this is a return only to a certain ensemble of styles and methods – nothing quite like Savage Messiah actually existed back then.

Savage Messiah is a gigantic, unfinished collage, which – like the city – is constantly reconfiguring itself. Macro-and micro-narratives proliferate tuberously; spidery slogans recur; figures migrate through various versions of London, sometimes trapped inside the drearily glossy spaces imagined by advertising and regeneration propaganda, sometimes free to drift. She deploys collage in much the same way William Burroughs used it: as a weapon in time-war. The cut-up can dislocate established narratives, break habits, allow new associations to coalesce. In Savage Messiah, the seamless, already-established capitalist reality of London dissolves into a riot of potentials.

Savage Messiah is written for those who could not be regenerated, even if they wanted to be. They are the unregenerated, a lost generation, ‘always yearning for the time that just eluded us’: those who were born too late for punk but whose expectations were raised by its incendiary afterglow; those who watched the Miners’ Strike with partisan adolescent eyes but who were too young to really participate in the militancy; those who experienced the future-rush euphoria of rave as their birthright, never dreaming that it could burn out like fried synapses; those, in short, who simply did not find the ‘reality’ imposed by the conquering forces of neoliberalism liveable. It’s adapt or die, and there are many different forms of death available to those who can’t pick up the business buzz or muster the requisite enthusiasm for the creative industries. Six million ways to die, choose one: drugs, depression, destitution. So many forms of catatonic collapse. In earlier times, ‘deviants, psychotics and the mentally collapsed’ inspired militant-poets, situationists, Rave-dreamers. Now they are incarcerated in hospitals, or languishing in the gutter.


No Pedestrian Access To Shopping Centre


Still, the mood of Savage Messiah is far from hopeless. It’s not about caving in, it’s about different strategies for surviving the deep midwinter of Restoration London. People living on next to nothing, no longer living the dream, but not giving up either: ‘Five years since the last party but he held his plot, scavenging for food like a Ballardian crash victim.’ You can go into suspended animation, knowing that the time is not yet right, but waiting with cold reptile patience until it is. Or you can flee Dystopian London without ever leaving the city, avoiding the central business district, finding friendly passages through the occupied territory, picking your way through the city via cafes, comrade’s flats, public parks. Savage Messiah is an inventory of such routes, such passages through ‘territories of commerce and control’.

The zines are saturated in music culture. First of all, there are the names of groups: Infa Riot and Blitz. Fragments of Abba, Heaven 17 on the radio. Japan, Rudimentary Peni, Einstürzende Neubauten, Throbbing Gristle, Spiral Tribe. Whether the groups are sublime or sub-charity shop undesirable, these litanies have an evocative power that is quietly lacerating. Gig posters from 30 years ago – Mob, Poison Girls, Conflict – call up older versions of you, half-forgotten haircuts, long-lost longings, stirring again. But the role of music culture goes much deeper in Savage Messiah. The way the zine is put together owes as much to the rogue dance and drug cultures that mutated from Rave as to punk fanzines; its montage methodology has as much in common with the DJ mix as with any precursor in visual culture. Savage Messiah is also about the relationship between music and place: the zine is also a testament to the way in which the sensitive membranes of the city are reshaped by music.


This sombre place is haunted by the sounds of lost acid house parties and the distant reverberations of 1986. Test Department. 303. 808. Traces of industrial noise.

The roundhouse was easy to get into, and the depot itself, disused for years is lit up with tags and dubs.

You can hear these deserted places, feel the tendrils creeping across the abandoned caverns, the derelict bunkers and broken terraces. Mid summer, blistering heat under the concrete, Armagideon Time(s), a hidden garden, to be found, and lost again.


Superficially, the obvious tag for Savage Messiah would be psychogeography, but the label makes Ford chafe. ‘I think a lot of what is called psychogeography now is just middle-class men acting like colonial explorers, showing us their discoveries and guarding their plot. I have spent the last twenty years walking around London and living here in a precarious fashion, I’ve had about fifty addresses. I think my understanding and negotiation of the city is very different to theirs.’ Rather than subsuming Savage Messiah under the increasingly played-out discourses of psychogeography, I believe it is better understood as an example of a cultural coalescence that started to become visible (and audible) at the moment when Ford began to produce the zine: hauntology. ‘The London I conjure up…is imbued with a sense of mourning,’ Ford says. ‘These are the liminal zones where the free party rave scene once illuminated the bleak swathes of marshland and industrial estates.’ So many dreams of collectivity have died in neoliberal London. A new kind of human being was supposed to live here, but that all had to be cleared away so that the restoration could begin.

Haunting is about a staining of place with particularly intense moments of time, and, like David Peace, with whom her work shares a number of affinities, Ford is alive to the poetry of dates. 1979, 1981, 2013: these years recur throughout Savage Messiah, moments of transition and threshold, moments when a whole alternative time-track opens. 2013 has a post-apocalyptic quality (in addition to being the year of the London Olympics, 2012 is also, according to some, the year that the Mayans predicted for the end of the world). But 2013 could also be Year Zero: the reversal of 1979, the time when all the cheated hopes and missed chances are finally realised. Savage Messiah invites us to see the contours of another world in the gaps and cracks of an occupied London:


Perhaps it is here that the space can be opened up to forge a collective resistance to this neo liberal expansion, to the endless proliferation of banalities and the homogenising effects of globalisation. Here in the burnt out shopping arcades, the boarded up precincts, the lost citadels of consumerism one might find the truth, new territories might be opened, there might be a rupturing of this collective amnesia.





Nomadalgia: The Junior Boys’ So This is Goodbye


k-punk post, March 4, 2006


Space comes as standard with the Junior Boys. The synthpop that inspired them remained attached, for the most part, to the three-minute format; ‘extended’ remixes were a concession to the imperatives of dance. Only one of So This is Goodbye’s 10 tracks is under four minutes. Space is integral, not only to their sound, but to their songs. Space is a compositional component, a presupposition of the songs, not something retrospectively inserted at a producer’s whim. The pauses, the imagist-allusiveness of the lyrics, the breathy phrasing would not work, or make much sense, outside a plateau-architecture imported from dance; crushed into three minutes Junior Boys’ songs would lose more than length.

House references are everywhere: the title track is gorgeously, oneirically poised on a honeyed Mr Fingers’ plateau, and it is not only the arpeggiated synth which drives many of the tracks that is reminiscent of Jamie Principle. Yet the LP does not sound either like House or like most previous attempts to synthesize pop with House. So This is Goodbye is like House if it had started in the wilds of Canada rather the clubs of Chicago. Too many House-pop hybrids fill up House’s space with business, hectic activity. On Vocalcity and, to some extent The Present Lover, Luomo did the opposite: dilating the Song into an unfolding driftwork. But the Luomo LPs were more pop House than pop per se. So This is Goodbye is, however, very definitely a pop record; if anything, it’s even more seductively catchy than Last Exit.

The obvious difference between So This is Goodbye and its predecessor is the absence of the tricksy stop-start stutter beats on the new record. If Junior Boys’ inventiveness is no longer concentrated on beats, that is a reflection as much of a decline of the surrounding pop context as it a sign of the JB’s newfound taste for rhythmic classicism. Last Exit’s reworkings of Timbaland/Dem 2 tic-beats meant that it had a relationship with a rhythmic psychedelia that was, then, still mutating pop into new shapes. In the intervening period, of course, both hip hop and British garage have taken a turn for the brutalist, and pop has consequently been deprived of any modernising force. Timbaland’s beat surrealism became water-treading repetition years ago, displaced by the ultra-realist thuggish plod of corporate hip hop and the ugly carnality of crunk; and 2 Step’s ‘feminine pressure’ has long since been crushed by the testos-terone-saturated bluntness of Grime and Dubstep. That skunk-fugged heaviness remains the antipodes of the Junior Boys’ cyberian, etherealised, plaintive physicality; listening to the Junior Boys after Grime or Dubstep is like walking out of a locker room thick with dope smoke out onto a Caspar David Friedrich mountain. A lung-cleansing experience. (Significant also that those other ultra-heterosexual post-Garage musics should have bred out the influence of House, while the Junior Boys return to it so emphatically.)

But the removal of rhythmic tricksiness perhaps also indicates something of the scale of the Junior Boys’ pop ambitions, which are best seen as the pioneering of a New MOR rather than another attempt at New Pop. If there is no cutting edge, then it makes more sense to abandon the former margins and refurbish the middle of the road. The Junior Boys’ songs have always had more in common with a certain type of modernist MOR – Hall and Oates, Prefab Sprout, Blue Nile, Lindsay Buckingham – than with any rock. Modernist MOR is the opposite of the discredited strategy of entryism: it doesn’t ‘conform to deform’, it locates the alien right in the heart of the familiar. The problem with current Pop is not the predominance of MOR, but the fact that MOR has been corrupted by the wheedling whine of Indie authenticity. In any just world, the Junior Boys, not the drippy moroseness of James Blunt nor the earthy earnestness of KT Tunstall, would be the globally dominant MOR brand in 2006.

Ultimately, though, So This is Goodbye sounds more middle of the tundra than middle of the road. It’s as if the Junior Boys’ journey into North America Endless has continued beyond the late-night freeways of Last Exit. It’s like the first LP’s city lights and Edward Hopper coffee bars have receded, and we’re taken out, beyond even the small towns, into the depopulated wildernesses of Canada’s Northern Territories. Or rather, it’s as if those wildernesses have crept into the very marrow of the record. In The Idea of North, Glenn Gould suggests that the North’s icy desolation has a special pull on the Canadian imagination. You hear this on So This is Goodbye not in any positive content so much as in the songs’ gaps and absences; the gaps and absences that make the song what they are.

Those crevices and grottoes seem to multiply as the album progresses. The second half of the album (what I hear as the ‘second side’; one of the most gratifying things about So This is Goodbye is that it is structured like a classic pop album, not an extras-clogged CD) diffuses forward motion into trails of electro-cumulae. The title track sets stately synths against the anticlimactic urgency of Acid House’s Forever Now: the effect like running up a down escalator, frozen in an aching moment of transition. ‘Like a child’ and ‘Caught in a Wave’ immerse the agitated drive of the LP’s signature arpeggiated synth in a vapour trail of opiated atmospherics.

The reading of Sinatra’s ‘When No-one Cares’ is the knot which holds together all of So This is Goodbye, a clue to its modernist MOR intentions (lines from the song – ‘count souvenirs’, ‘like a child’ – provide the titles for other tracks, almost as if the song is a puzzle the whole album is trying to solve). So This is Goodbye’s songs bear much the same relation to high-energy as the late Sinatra’s bore to big band jazz: what was once a communal, dance-oriented music has been hollowed out into a cavernous, contemplative space for the most solitary of musings. On the Junior Boys’ ‘When No-one Cares’ beats are abandoned altogether, the track’s ‘endless night’ lit only by the dying-star flares and stalactite-by-flashlight pulse of reverbed electronics.

The Junior Boys have transformed the song from the lonely-crowd melancholy of the original – Frank at the bar staring into his whisky sour, happy couples partying obliviously behind him (or in his imagination) – into a lament whispered in the wilderness, icy-breathed into the black mirror indifference of a Great Lake at midnight. It is as cosmically desolated as the Young Gods’ version of ‘September Song’, as arctic-white as Miles Davis’ Aura. ‘When No-one Cares’ is one of my favourite Sinatra songs, and I must have first heard it 20 years ago, but with the Junior Boys’ version – which makes the catatonic stasis of the original’s grief seem positively busy – it is as if I am hearing the words for the first time.

Sinatra’s No-One Cares (which could have been subtitled: From Penthouse to Satis House) was like pop’s take on literary modernism, an affect (rather than a concept) album, a series of takes on a particular theme – disconnection from a hyper-connected world – with Frank the ageing sophisticate adrift in the McLuhan wasteland of the late 50s, Elvis already here, the Beatles on the way (who is the ‘no-one’ who doesn’t care if not the teen audience who have found new objects of adoration?), the telephone and the television offering only new ways to be lonely. So This is Goodbye is like a globalised update of No-One Cares, its images of ‘hotel lobbies’, ‘shopping malls we’ll never see again’ and ‘homes for sale’ sketching a world in a state of permanent impermance (should we say precarity?). The songs are overwhelmingly preoccupied with leave-taking and change, fixated on doing things for the first or the last time. ‘So This is Goodbye’ is not the title track for nothing.

Sinatra’s melancholy was the melancholy of mass (old) media technology – the ‘extimacy’ of the records facilitated by the phonograph and the microphone, and expressing a peculiarly cosmopolitan and urban sadness. ‘I’ve flown around the world in plane/ designed the latest IBM brain/ but lately I’m so downhearted’, Sinatra song on No-One Cares’ ‘I Can’t Get Started’. Jetsetting is now not the privilege of the elite so much as a veritiginous mundanity for a permanently dispossessed global workforce. Every town has become the ‘tourist town’ alluded to in So This is Goodbye’s final track, ‘FM’, because now at home everyone is a tourist, both in the sense of permanently on the move but also in the sense of having the world at their fingertips, via the net. If Sinatra’s best records, like Hopper’s paintings, were about the way in which the urban experience produces new forms of isolation (and also: that such mass mediated private moments are the only mode of affective connection in a fragmented world), then So this is Goodbye is a response to the cyberspatial commonplace that, with the net, even the most remote spot can be connected up (and also: that such connection often amounts to a communion of lonely souls). Hence the impression that, if Sinatra’s ‘When No-one Cars’ was an unanswered call from the heartless heart of the Big Apple, then the Junior Boys’ version has been phoned-in down a digital line from the edge of Lake Ontario. (Is it accidental that the term ‘cyberspace’ was invented by a Canadian?)

So this is Goodbye is a very travel sick record. It expresses what we might call nomadalgia. Nomadalgia, the sickness of travel, would be a complement to, not the opposite of, the sickness for home, nostalgia. (And what of the relation between nomadalgia and hauntology?) It’s entirely fitting that the final track, ‘FM’, should invoke both ‘a return home’ and radio (not the only reference to that ghost-medium on the album), since internet radio – with local stations available from any hotel in the world – is perhaps more than anything else the objective correlative of our current condition. A condition in which, as Žižek so aptly puts it, ‘global harmony and solipsism strangely coincide. That is to say, does not our immersion in cyberspace go hand in hand with our reduction to a Leibnizian monad which, although “without windows” that would directly open up to external reality, mirrors in itself the entire universe? Are we not more and more monads, interacting alone with the PC screen, encountering only the virtual simulacra, and yet immersed more than ever in the global network, synchronously communicating with the entire globe?’ (‘No Sex Please, We Are Post-humans’, http://www.egs.edu/faculty/slavoj-zizek/articles/no-sex-please-we-are-post-humans/)





Grey Area: Chris Petit’s Content


BFI/ Sight & Sound Website, March 2010


At one point in Chris Petit’s haunting new film Content, we drive through Felixstowe container port. It was an uncanny moment for me, since Felixstowe is only a couple of miles from where I now live – what Petit filmed could have been shot from our car window. What made it all the more uncanny was the fact that Petit never mentions that he is in Felixstowe; the hangars and looming cranes are so generic that I began to wonder if this might not be a doppelgänger container port somewhere else in the world. All of this somehow underlined the way Petit’s text describes these ‘blind buildings’ while his camera tracks along them: ‘non-places’, ‘prosaic sheds’, ‘the first buildings of a new age’ which render ‘architecture redundant’.

Content could be classified as an essay film, but it’s less essayistic than aphoristic. This isn’t to say that it’s disconnected or incoherent: Petit himself has called Content a ‘21st-century road movie, ambient’, and its reflections on ageing and parenthood, terrorism and new media are woven into a consistency that’s non-linear, but certainly not fragmentary.

Content is about ‘correspondence’, in different senses of the word. It was in part generated by electronic correspondence between Petit and his two major collaborators: Ian Penman (whose text is voiced by the German actor Hanns Zischler) and the German musician Antye Greie. Penman’s text is a series of reflections on the subject of email, that ‘anonymous yet intimate’ ethereal communication. Some of Penman’s disquisitions on email are accompanied by images of postcards – the poignant tactility of this obsolete form of correspondence all the more affecting because the senders and addressees are now forgotten. Greie, meanwhile, produces skeins of electronica that provide Content with a kind of sonic unconscious in which terms and concepts referred to in the images and the voice track are refracted, extrapolated and supplemented.

One of the first phrases cited in Greie’s soundwork – which resembles sketches for unrealised songs – is a quotation from Roy Batty’s famous speech in Blade Runner: ‘If only you could see what I have seen with your eyes.’ This is a phrase Penman has made much of in his own writings on recording, technology and haunting – and it brings us to the other meaning of ‘correspon-dence’ Content plays with: correspondences in the sense of connections and associations. Some of these are underscored by Petit in his dryly-poetic text; others he leaves the viewers to make for themselves.

One of the most gratifying aspects of Content, in fact, is that by contrast with so many contemporary television documentaries, which neurotically hector the audience by incessantly reiterating their core thesis, Petit trusts in the intelligence and speculative power of the viewer. Where so much television now involves a mutual redundancy of image and voice – the image is slaved into illustrating the text; the voice merely glosses the image – Content is in large part about the spaces between image and text, what is unsaid in (and about) the images.

The use of a German actor and musician and the many references to Europe in Content reflect Petit’s childhood which, as he describes in the film, was partly spent as a forces child in Germany. But it also reflects Petit’s long-standing desire for some kind of reconciliation between British culture and European modernism. Petit has described Content as an ‘informal coda’ to his 1979 film Radio On (recently reissued on BFI DVD). With its strong debt to European art cinema, Radio On projected a rapprochement between British and European film that never happened – a rapprochement anticipated in the 1970s art pop (Kraftwerk, Bowie) used so prominently in that film. Petit imagined a British cinema that, like that music, could assert its Europeanness not by rejecting America, but by confidently absorbing American influences. Yet this future never arrived.

‘Radio On,’ Petit said in a recent interview, ‘ended with a car ‘stalled on the edge of the future’, which we didn’t know then would be Thatcherism.’ Ahead lay a bizarre yet banal mix of the unprecedented and the archaic. Instead of accelerating down Kraftwerk’s autobahn, we found ourselves, as Petit puts it in Content, ‘reversing into a tomorrow based on a non-existent past’, as the popular modernism Radio On was part of found itself eclipsed by a toxic-addictive confection of consumer-driven populism, heritage kitsch, xenophobia and US corporate culture. In this light, Content stands as a quiet but emphatic reproach to the British cinema of the last 30 years, which in its dominant variants – drab social realism, faux gangster, picture-book costume drama or mid-Atlantic middle-class fantasia – has retreated from modernity. It isn’t only the poor and the nonwhite who are edited out of Notting Hill, for example – it’s also the Westway, west London’s Ballardian flyover, which now stands as a relic of ‘the modern city that London never became’.

Yet Content isn’t just a requiem for the lost possibilities of the last 30 years. In its use of stunning but underused locations – the ready-made post-Fordist science-fiction landscapes of Felixstowe container port, the eerie Cold War terrain of nearby Orford Ness – Content demonstrates not only what British cinema overlooks, but what it could still be.





Postmodern Antiques: Patience (After Sebald)


Sight & Sound, April 2011


The first time I saw Andrei Tarkovsky’s Stalker – when it was broadcast by Channel 4 in the early 1980s – I was immediately reminded of the Suffolk landscapes where I had holidayed as a child. The overgrown pill boxes, the squat Martello towers, the rusting groynes which resembled gravestones: this all added up to a readymade science fiction scene. At one point in Grant Gee’s Patience (After Sebald) (2011) – an essay film inspired by W G Sebald’s novel The Rings of Saturn – theatre director Katie Williams makes the same connection, drawing a comparison between the demilitarised expanses of the Suffolk coast and Tarkovsky’s Zone.

When I read Rings of Saturn, I was hoping that it would be an exploration of these eerily numinous spaces. Yet what I found was something rather different: a book that, it seemed to me at least, morosely trudged through the Suffolk spaces without really looking at them; that offered a Mittel–brow miserabilism, a stock disdain, in which the human settlements are routinely dismissed as shabby and the inhuman spaces are oppressive. The landscape in The Rings of Saturn functions as a thin conceit, the places operating as triggers for a literary ramble which reads less like a travelogue than a librarian’s listless daydream. Instead of engaging with previous literary encounters with the Suffolk – Henry James went on a walking tour of the county; his namesake MR James set two of his most atmospheric ghost stories there – Sebald tends to reach for the likes of Borges. My scepticism was fed by the solemn cult that settled around Sebald suspiciously quickly, and which seemed all-too-ready to admire those well-wrought sentences. Sebald offered a rather easy difficulty, an anachronistic, antiqued model of ‘good literature’ which acted as if many of the developments in 20th century experimental fiction and popular culture had never happened. It is not hard to see why a German writer would want to blank out the middle part of the 20th century; and many of the formal anachronisms of Sebald’s writing – its strange sense that this is the 21st century seen through the restrained yet ornate prose of an early 20th century essayist – perhaps arise from this desire, just as the novels themselves are about the various, ultimately failed, ruses – conscious and unconscious – that damaged psyches deploy to erase traumas and construct new identities. The writer Robert Macfarlane has called Sebald a ‘postmodern antiquarian’, and the indeterminate status of The Rings of Saturn – is it autobiography, a novel or a travelogue? – points to a certain playfulness, but this never emerges at the level of the book’s content. It was necessary for Sebald to remain po-faced in order for the ‘antiquing’ to be successful. Some of Gee’s images of Suffolk take their cue from the black and white photographs which illustrate The Rings Of Saturn. But the photographs were a contrivance: Sebald would photocopy them many times until they achieved the required graininess.

Gee’s film was premiered as part of a weekend of events superbly curated by Gareth Evans of Artevents under the rubric After Sebald: Place and Re-Enchantment at Snape Maltings, near Aldeburgh, in Suffolk. In the end, however, Sebald’s novels fits into any discussion of place and enchantment only very awkwardly: his work is more about displacement and disenchantment than their opposites. In Patience (After Sebald), the artist Tacita Dean observes that only children have a real sense of home. Adults are always aware of the precariousness and transitoriness of their dwelling place: none more so than Sebald, a German writer who spent most of his life in Norfolk.

Patience (After Sebald) follows Gee’s documentaries about Radiohead and Joy Division. The shift from rock to literature, Gee told Macfarlane, was one that came naturally to someone whose sensibilities were formed by the UK music culture of the 1970s. If Sebald had been writing in the 1970s, Gee claimed, he would surely have been mentioned in the NME alongside other luminaries of avant-garde literature. Gee started reading Sebald in 2004, after a recommendation from his friend, the novelist Jeff Noon. The film’s somewhat gnomic title was a relic of an earlier version of what the film would be. It now suggests the slowing of time that the Suffolk landscape imposes, a release from urban urgencies, but it is actually a reference to a passage in Sebald’s novel Austerlitz: ‘Austerlitz told me that he sometimes sat here for hours, laying out these photographs or others from his collection the wrong way up, as if playing a game of patience, and that then one by one, he turned them over, always with a new sense of surprise at what he saw, pushing the pictures back and forth and over each other, arranging them in an order depending on their family resemblances, or withdrawing them from the game until either there was nothing left but the grey tabletop, or he felt exhausted from the constant effort of thinking and remembering and had to rest on the ottoman.’

Gee had originally intended to make a film about the non-places in Sebald’s work: the hotel rooms or railway station waiting rooms in which characters ruminate, converse or break down (Austerlitz himself comes to a shattering revelation about his own identity in the waiting room at Liverpool Street station). In the end, however, Gee was drawn to the book which – osten-sibly at least – is most focused on a single landscape.

Gee filmed practically everything himself, using a converted 16 mm Bolex camera. He wanted something that would produce frames that were ‘tighter than normal’, he said, ‘as if a single character is looking’. Gee sees Patience (After Sebald) as an essay film, in the tradition of Chris Petit’s work and Patrick Keiller’s Robinson trilogy. But when I put it to him that Patience lacks the single voice that defines Petit or Keiller’s essay films, Gee responded self-deprecatingly. He had tried to insert himself into his own films, but he had always been dissatisfied with the results: his voice didn’t sound right; his acting didn’t convince; his writing wasn’t strong enough. In Patience, as in the Joy Division documentary, the story is therefore told by others: Macfarlane, Dean, Iain Sinclair, Petit, the literary critic Marina Warner and the artist Jeremy Millar. Millar provided one of the most uncanny images in Patience. When he lit a firework in tribute to Sebald, the smoke unexpectedly formed a shape which resembled Sebald’s face, something which Gee underlines in the film by animating a transition between Millar’s photograph and an image of the novelist.

More than one of the speakers at the Towards Re-Enchantment symposium acknowledged that they misremem-bered The Rings of Saturn. There’s something fitting about this, of course, given that the duplicity of memory might have been Sebald’s major theme; but my suspicion is that misremembering of a different kind contributes to the Rings of Saturn cult; that the book induces its readers to hallucinate a text that is not there, but which meets their desires – for a kind of modernist travelogue, a novel that would do justice to the Suffolk landscape – better than Sebald’s actually novel does. Patience (After Sebald) is itself a misremembering of The Rings of Saturn which could not help but reverse many of the novel’s priorities and emphases. In The Rings of Saturn, Suffolk frequently (and frustratingly) recedes from attention, as Sebald follows his own lines of association. By contrast, the main substance of the film consists of images of the Suffolk landscape – the heathland over which you can walk for miles without seeing a soul, the crumbling cliffs of the lost city of Dunwich, the enigma of Orford Ness, its inscrutable pagodas silently presiding over Cold War military experiments which remain secret. Sebald’s reflections, voiced in Patience by Jonathan Pryce, anchor these images far less securely than they do in the novel. At Snape, some of those who had re-created Sebald’s walk – including Gee himself – confessed that they had failed to attain the author’s lugubrious mood: the landscape turned out to be too energising, its sublime desolation proving to be fallow ground for gloomy psychological interiority. In a conversation with Robert Macfarlane after the screening of the film, Gee said that it was not really necessary that Sebald had taken the walk. He meant that it was not important whether or not Sebald actually did the walk exactly as The Rings of Saturn’s narrator described it, in one go: that the novel could have been based on a number of different walks which took place over a longer period of time. But I couldn’t help but hear Gee’s remark in a different way: that it was not necessary for Sebald to have taken the walk at all: that, far from being a close engagement with the Suffolk terrain, The Rings of Saturn could have been written had Sebald never set foot in Suffolk.

This was the view of Richard Mabey, cast in the role of doubting Thomas at the Towards Re-Enchantment symposium. Mabey – who has written and broadcast about nature for 40 years, and whose latest book Weeds has the glorious subtitle How Vagabond Plants Gatecrashed Civilisation and Changed the Way We Think About Nature – argued that Sebald was guilty of the pathetic fallacy. When he read The Rings Of Saturn, Mabey said, he felt as if a very close friend had been belittled; although he had walked the Suffolk coastland countless times, he couldn’t recognise it from Sebald’s descriptions. But perhaps the issue with Sebald is that he wasn’t guilty enough of the pathetic fallacy, that instead of staining the landscape with his passions, as Thomas Hardy did with Wessex, or the Brontes did with Yorkshire, or, more recently, as the musician Richard Skelton has done with the Lancashire moorland – Sebald used Suffolk as a kind of Rorschach blot, a trigger for associative processes that take flight from the landscape rather than take root in it. In any case, Mabey wanted a confrontation with nature in all its inhuman exteriority. He sounded like a Deleuzean philosopher when he expostulated about the ‘nested heterogeneity’ and ‘autonomous poetry’ of micro-ecosytems to be found in a cow’s hoof print; of how it was necessary to ‘think like a mountain’, and quoted approvingly Virginia Woolf’s evocation of a ‘philosophising and dreaming land’. I was struck by the parallels between Mabey’s account of nature and Patrick Keiller’s invocation of lichen as ‘a non-human intelligence’ in Robinson in Ruins. With its examination of the ‘undiscovered country of nearby’, Robert Macfarlane’s film for the BBC, The Wild Places of Essex, shown as part of the Towards Re-Enchantment symposium, was also close to Mabey’s vision of a nature thriving in the spaces abandoned by, or inhospitable to, humans. (Macfarlane’s film now seems like a counterpart to Julien Temple’s wonderful Oil City Confidential, which rooted Dr Feelgood’s febrile rhythm and blues in the lunar landscape of Essex’s Canvey Island.) Patience (After Sebald) could appeal to a Sebald sceptic like me because – in spite of Sebald – it reaches the wilds of Suffolk. At the same time, Gee’s quietly powerful film caused me to doubt my own scepticism, sending me back to Sebald’s novels, in search of what others had seen, but which had so far eluded me.





The Lost Unconscious: Christopher Nolan’s

Inception


Film Quarterly, Vol. 64, No. 3, 2011


In Christopher Nolan’s breakthrough memory-loss thriller Memento from 2000, the traumatised and heavily tattooed protagonist Lenny has a suggestive conversation with a detective:


TEDDY: Look at your police file. It was complete when I gave it to you. Who took the twelve pages out?

LEONARD: You, probably.

TEDDY: No, you took them out.

LEONARD: Why would I do that?

TEDDY: To set yourself a puzzle you won’t ever solve.


Like Lenny, Christopher Nolan has specialised in setting puzzles that can’t be solved. Duplicity – in the sense of both deception and doubling – runs right through his work. It’s not only the case that Nolan’s work is about duplicity; it is itself duplicitous, drawing audiences into labyrinths of indeterminacy.

Nolan’s films have a coolly obsessive quality, in which a number of repeating elements – a traumatised hero and his antagonist; a dead woman; a plot involving manipulation and dissimulation – are reshuffled. These film noir tropes are then further scrambled in the manner of a certain kind of neo-noir. Nolan acknowledges Angel Heart (1987) and The Usual Suspects (1995) as touchstones (he mentions both in an interview which is included on the Memento DVD, singling out Parker’s film as a particular inspiration), but one can also see parallels with the meta-detective fictions of Robbe-Grillet and Paul Auster. There’s a shift from the epistemological problems posed by unreliable narrators to a more general ontological indeterminacy, in which the nature of the whole fictional world is put into doubt.

Memento remains emblematic in this respect. At first glance, the film’s enigma resolves relatively simply. Lenny, who suffers from anterograde amnesiac condition which means that he can’t make new memories, is ‘setting puzzles for himself that can’t be solved’ so that he can always be pursuing his wife’s murderer, long after Lenny has killed him. But after repeated viewings, the critic Andy Klein – in a piece for Salon.com pointedly entitled ‘Everything You Wanted To Know About Memento’– conceded that he wasn’t ‘able to come up with the ‘truth’ about what transpired prior to the film’s action. Every explanation seems to involve some breach of the apparent ‘rules’ of Leonard’s disability – not merely the rules as he explains them, but the rules as we witness them operating throughout most of the film.) The rules are crucial to Nolan’s method. If Memento is a kind of impossible object, then its impossibility is generated not via an anything-goes ontological anarchy but by the setting up of rules which it violates in particular ways – just as the effect of Escher’s paintings depend upon unsettling rather than ignoring the rules of perspective.

Nolan nevertheless maintains that, however intractable his films might appear, they are always based on a definitive truth which he knows but will not reveal. As he said of Inception in the interview with Wired, ‘I’ve always believed that if you make a film with ambiguity, it needs to be based on a true interpretation. If it’s not, then it will contradict itself, or it will be somehow insubstantial and end up making the audience feel cheated. Ambiguity has to come from the inability of the character to know – and the alignment of the audience with that character’. When the interviewer Robert Capps puts it to Nolan that there might be several explanations of the film’s ending, that the ‘right answer’ is impossible to find, the director flatly contradicts him: ‘Oh no, I’ve got an answer.’ But Nolan’s remarks may only be another act of misdirection; and, if a century of cultural theory has taught us anything, it is that an author’s supposed intentions can only ever constitute a supplementary (para)text, never a final word. What are Nolan’s films about, after all, but the instability of any master position? They are full of moments in which the manipulator – the one who looks, writes or narrates – becomes the manipulated – the object of the gaze, the character in a story written or told by someone else.

In Inception, Cobb is an ‘extractor’, an expert at a special kind of industrial espionage, which involves entering into people’s dreams and stealing their secrets. He and his team have been hired by hyper-wealthy businessman Saito to infiltrate the dreams of Robert Fischer, the heir to a massive energy conglomerate. But this time Cobb’s team is not required to extract information, but to do something which the film tells is much more difficult: they are tasked with implanting an idea into Fischer’s mind. Cobb’s effectiveness as a dream thief is compromised by the projection of his dead wife, Mal, the pathological stain he now brings with him into any dream caper. Mal died after she suffered an apparent psychotic break. She and Cobb set up a lover’s retreat in the ‘unconstructed dreamspace’ that the dream thieves call Limbo. But after she became too attached to this virtual love nest, Cobb ‘incepted’ in her the idea that the world in which they were living was not real. As Cobb mordantly observes, there is nothing more resilient than an idea. Even when she is restored to what Cobb takes to be reality, Mal remains obsessed with the idea that she the world around her is not real, so she throws herself from a hotel window in order to return to what she believes is the real world. The film turns on how Cobb deals with this traumatic event – in order to incept Fischer, Cobb has first of all to descend into Limbo and defeat Mal. He achieves this by simultaneously accepting his part in Mal’s death and by repudiating the Mal projection as an inadequate copy of his dead wife. With the Mal projection vanquished and the dream-heist successfully completed, Cobb is finally able to return to the children from whom he has been separated. Yet this ending has more than a suggestion of wish fulfilment fantasy about it, and the suspicion that Cobb might be marooned somewhere in a multi-layered oneirc labyrinth, a psychotic who has mistaken dreams for reality, makes Inception deeply ambiguous. Nolan’s own remarks have carefully maintained the ambiguity.’ I choose to believe that Cobb gets back to his kids,’ Nolan told Robert Capps.

Nolan’s films are preoccupied with, to paraphrase Memento’s Teddy, ‘the lies that we tell ourselves to stay happy’. Yet the situation is worse even than that. It’s one thing to lie to oneself; it’s another to not even know whether one is lying to oneself or not. This might be the case with Cobb in Inception, and it’s notable that, in the Wired interview, Nolan says that ‘The most important emotional thing about the top spinning at the end is that Cobb is not looking at it. He doesn’t care.’ Not caring whether we are lying to ourselves may be the price for happiness – or at least the price one pays for release from excruciating mental anguish. In this respect, Dormer in Insomnia (2002) could be the anti-Cobb. His inability to sleep – which naturally also means an inability to dream – correlates with the breakdown of his capacity to tell himself a comforting story about who he is. After the shooting of his partner, Dormer’s identity collapses into a terrifying epistemological void, a black box that cannot be opened. He simply doesn’t know whether or not he intended to kill his partner (just as Borden in The Prestige cannot remember which knot he tied on the night that Angier’s wife died in a bungled escapology act.) But in Nolan’s worlds, it is not only that we deceive ourselves; it is also that we are deceived about having a self. There is no separating identity from fiction. In Memento, Lenny literally writes (on) himself, but the very fact that he can write a script for future versions of himself is a horrifying demonstration of his lack of any coherent identity – a revelation that his Sisyphian quest both exemplifies and is in flight from. Inception leaves us with the possibility that Cobb’s quest and apparent rediscovery of his children could be a version of the same kind of loop: a Purgatorio to Memento’s Inferno.

‘The urge to rewrite ourselves as real-seeming fictions is present in us all,’ writes Christopher Priest in his novel The Glamour. It’s not at all surprising that Nolan has adapted a novel by Priest, since there are striking parallels between the two men’s methods and interests. Priest’s novels are also ‘puzzles that can’t be solved’, in which writing, biography and psychosis slide into one another, posing troubling ontological questions about memory, identity and fiction. The idea of minds as datascapes which can be infiltrated inevitably puts one in mind of the ‘consensual hallucination’ of Gibson’s cyberspace, but the dreamsharing concept can be traced back to Priest and his extraordinary 1977 novel, A Dream of Wessex. In Priest’s novel, a group of researcher-volunteers use a ‘dream projector’ to enter into a shared dream of a (then) future England. Like the dreamsharing addicts we briefly glimpse in one of Inception’s most suggestive scenes, some of the characters in A Dream of Wessex inevitably prefer the simulated environment to the real world, and, unlike Cobb, they choose to stay there. The differences in the way that the concept of shared dreaming is handled in 1977 and 2010 tell us a great deal about the contrasts between social democracy and neoliberalism. While Inception’s dreamsharing technology is – like the internet – a military invention turned into a commercial application, Priest’s shared dream project is government-run. The Wessex dream world is lyrical and languid, still part of the hazy afterglow of 60s psychedelia. It’s all a far cry from Inception’s noise and fury, the mind as a militarised zone.

Inception (not entirely satisfactorily) synthesizes the intellectual and metaphysical puzzles of Memento and The Prestige (2006) with the big budget ballistics of Batman Begins (2005) and The Dark Knight (2008). The problem is the prolonged action sequences, which come off as perfunctory at best. At points, it as if Inception’s achievement is to have provided a baroquely sophisticated motivation for some very dumb action sequences. An unkind viewer might think that the entirety of Inception’s complex ontological structure had been constructed to justify clichés of action cinema – such as the ludicrous amount of things that characters can do in the time that it takes for a van to fall from a bridge into a river. Blogger Carl Neville complains that Inception amounts to ‘three uninvolving action movies playing out simultaneously’ ‘What could have been a fascinatingly vertiginous trip into successively fantastic, impossible worlds, not to mention the limbo of the raw unconscious into which a couple of the central characters plunge,’ Neville argues,


ends up looking wholly like a series of action movies, one within the other: “reality” looks and feels like a “globalisation” movie, jumping from Tokyo to Paris to Mombasa to Sydney with a team of basically decent technical geniuses who are forced to live outside the law, making sure there are lots of helicopter shots of cityscapes and exotic local colour. Level one dream is basically The Bourne Identity…rainy, grey, urban. Level two is the Matrix, zero gravity fistfights in a modernist hotel, level three, depressingly, turns out to be a 70s Bond film while the raw Id is basically just a collapsing cityscape.


The ‘level three’ snow scenes at least resemble one of the most visually striking Bond films – 1969’s On Her Majesty’s Secret Service – but it’s hard not to share Neville’s sense of anti-climax. Rather than picking up pace and ramping up the metaphysical complexity, the film rushes towards its disappointing denouement. The elaborate set-up involving the ‘dream architect’ Ariadne is summarily abandoned, as she is told to forget the labyrinth and ‘find the most direct route through.’ When Ariadne and the film accede to these demands, it as if the imperatives of the action thriller have crashed through the intricacies of Nolan’s puzzle narrative with all the subtlety of the freight train that erupts into the cityscape in an earlier scene.

Neville is right that Inception is very far from being a ‘fascinat-ingly vertiginous trip into successively fantastic, impossible worlds’, but it is worth thinking about why Nolan showed such restraint. (His parsimony couldn’t contrast more starkly with the stylistic extravagances of something like Peter Jackson’s The Lovely Bones (2009), which aims at the fantastic and the impossible, but ends up CGI-onanistic rather than lyrically oneiric.) One initially strange thing about Inception is how un-dreamlike the dreams in the film are. It’s tempting to see the Nolan of Inception as a reverse Hitchcock – where Hitchcock took De Chirico-like dream topographies and remotivated them as thriller spaces, Nolan takes standard action flick sequences and repackages them as dreams. Except in a scene where the walls seem to close in around Cobb when he is being pursued – which, interestingly, takes place in the film’s apparent ‘reality’ – the spatial distortions at work in Inception do not resemble the ways in which dreams distend or collapse space. There are none of the bizarre adjacencies or distances that do not diminish that we see in Welles’s The Trial (1962), a film which, perhaps better than any other, captures the uncanny topographies of the anxiety dream. When, in one of Inception’s most remarked upon scenes, Ariadne causes the Paris cityspace to fold up around herself and Cobb, she is behaving more like the CGI engineer who is creating the scene than any dreamer. This is a display of technical prowess, devoid of any charge of the uncanny. The Limbo scenes, meanwhile, are like an inverted version of Fredric Jameson’s ‘surrealism without the unconscious’: this is an unconscious without surrealism. The world that Cobb and Mal ‘create’ out of their memories is like a Powerpoint presentation of a love affair rendered as some walk-through simulation: faintly haunting in its very lack of allure, quietly horrifying in its solipsistic emptiness. Where the unconscious was, there CGI shall be.

In an influential blog post, Devin Faraci argues that the whole film is a metaphor for cinematic production itself: Cobb is the director, Arthur the producer, Ariadne the screenwriter, Saito ‘the big corporate suit who fancies himself a part of the game’, Fischer the audience. ‘Cobb, as a director, takes Fischer through an engaging, stimulating and exciting journey,’ Faraci argues, ‘one that leads him to an understanding about himself. Cobb is the big time movie director…who brings the action, who brings the spectacle, but who also brings the meaning and the humanity and the emotion.’ In fact, as a director Cobb is something of a mediocrity (who we must conclude is far less accomplished than Nolan) – as Neville argues, Fischer’s ‘journey’ takes him through a series of standard-issue action set pieces, which are ‘engaging, stimulating and exciting’ only in some weakly generic way. Significantly and symptomatically, Faraci’s hyperbole here sounds as if it might belong in a marketing pitch for Cobb and his team; just as when Cobb and the others eulogise the ‘creativity’ of the dream architecture process – you can create worlds that never existed! – they sound like they are reciting advertising copy or the script from a corporate video. The scenes in which the team prepare for Fischer’s inception might have been designed to bring out the depressing vacuousness of the concept of the ‘creative industries’. They play like a marketing team’s own fantasies about what they themselves are doing: the view from inside an Apprentice contestant’s head, perhaps. In any case, Inception seems to be less a meta-meditation on the power of cinema than a reflection of the way in which cinematic techniques have become imbricated into a banal spectacle which – fusing business machismo, entertainment protocols and breathless hype – enjoys an unprecedented dominion over our working lives and our dreaming minds.

It is no doubt this sense of pervasive mediation, of generalised simulation, that tempts Faraci into claiming that ‘Inception is a dream to the point where even the dream-sharing stuff is a dream. Dom Cobb isn’t an extractor. He can’t go into other people’s dreams. He isn’t on the run from the Cobol Corporation. At one point he tells himself this, through the voice of Mal, who is a projection of his own subconscious. She asks him how real he thinks his world is, where he’s being chased across the globe by faceless corporate goons.’ The moment when Mal confronts Cobb with all this is reminiscent of the scene in Verhoeven’s Total Recall (1990) when a psychiatrist attempts to persuade Arnold Schwarzenegger’s Quaid that he is having a psychotic breakdown. But while Total Recall presents us with a strong distinction between Quaid’s quotidian identity as a construction worker and his life as a secret agent at the centre of an interplanetary struggle – a distinction that the film very quickly unsettles – Inception gives us only Cobb the generic hero: handsome, dapper, yet troubled. If, as Faraci claims, Cobb isn’t an extractor and he isn’t on the run from faceless corporate goons, then who is he? The ‘real’ Cobb would then be an unrepresented X, outside the film’s reality labyrinth – the empty figure who identifies with (and as) Cobb the commercially-constructed fiction; ourselves, in other words, insofar as we are successfully interpellated by the film.

This leads to another difference between Inception and its Philip K Dick-inspired 80s and 90s precursors such as Total Recall, Videodrome (1983) and Existenz (1999). There is very little of the ‘reality bleed’, the confusion of ontological hierarchy, that defined those films: throughout Inception, it is surprisingly easy for both the audience and the characters to remember where they are in the film’s ontological architecture. When Ariadne is being trained by Cobb’s partner, Arthur, she is taken round a virtual model of the impossible Penrose Steps. On the face of it, however, Inception is remarkable for its seeming failure to explore any paradoxical Escheresque topologies. The four different reality levels remain distinct, just as the causality between them remains well-formed. But this apparently stable hierarchy might be violated by the object upon which much of the discussion of the film’s ending has centred: the thimble, the ‘totem’ that Cobb ostensibly uses to determine whether he is in waking reality or not. If it spins without falling, then he is in a dream. If it falls, then he is not. Many have noted the inadequacy of this supposed proof. At best, it can only establish that Cobb is not in his ‘own’ dream, for what is there to stop his dreaming mind simulating the properties of the real thimble? Besides, in the film’s chronology, the thimble – that ostensible token of the empirical actual – first of all appears as a virtual object, secreted by Mal inside a doll’s house in Limbo. And a totem, it should be remembered, is an object of faith (it’s worth noting in passing that there are many references to faith throughout the film).

The association of the thimble with Mal – there are online debates as to whether the thimble was first of all Cobb’s or Mal’s – is suggestive. Both Mal and the thimble represent competing versions of the Real. For Cobb, the thimble stands in for the Anglo-Saxon empiricist tradition’s account of what reality is – something sensible, tangible. Mal, by contrast, represents a psychoanalytic Real – a trauma that disrupts any attempt to maintain a stable sense of reality; that which the subject cannot help bringing with him no matter where he goes. (Mal’s malevolent, indestructible persistence recalls the sad resilience of the projections which haunt the occupants of the space station in Tarkovsky’s Solaris (1972).) No matter what ‘reality level’ Cobb is on, Mal and the thimble are always there. But where the thimble supposedly ‘belongs’ to the ‘highest’ reality level, Mal ‘belongs’ to the ‘lowest’ level, the lover’s limbo which Cobb repudiated.

Mal conflates two roles that had been kept separate in Nolan’s films – the antagonist-double and the grief object. In Nolan’s debut, Following (1998), the antagonist-double of the unnamed protagonist is the thief who shares his name with Inception’s hero. The theme of the antagonist-double is nowhere more apparent than in Nolan’s remake of Insomnia and The Dark Knight, films which are in many ways about the proximity between the ostensible hero and his beyond-good-and-evil rival. Nolan’s adaptation of Christopher Priest’s novel, The Prestige, meanwhile, is in effect a film in which there is a defining antagonism but no single protagonist: by the end of the film, the illusionists Angier and Borden are doubled in multiple ways, just as they are defined and destroyed by their struggle with one another. More often than not, grief is the source of these antagonistic doublings. Grief itself is a puzzle that cannot be solved, and there’s a certain (psychic) economy in collapsing the antagonist into the grief object, since the work of grief is not only about mourning the lost object, it is also about struggling against the object’s implacable refusal to let go. Yet there’s something hollow about Cobb’s grief; on its own terms, it doesn’t convince as anything other than a genre-required character trait. It instead to stand in for something else, another sadness – a loss that the film points to but can’t name.

One aspect of this loss concerns the unconscious itself, and here we might take Nolan’s script quite literally. For those with a psychoanalytic bent, the script’s repeated references to the ‘subconscious’ – as opposed to the unconscious – no doubt grate, but this might have been a Freudian slip of a particularly revealing kind. The terrain that Inception lays out is no longer that of the classical unconscious, that impersonal factory which, Jean-Francois Lyotard says, psychoanalysis described ‘with the help of images of foreign towns or countries such as Rome or Egypt, just like Piranesi’s Prisons or Escher’s Other Worlds’. (Libidinal Economy, Athlone, 1993, 164) Inception’s arcades and hotel corridors are indeed those of a globalised capital, whose reach easily extends into the former depths of what was once the unconscious. There is nothing alien, no other place here, only a ‘subconscious’ recirculating deeply familiar images mined from an ersatz psychoanalysis. So in place of the eerie enigmas of the unconscious, we are instead offered an Oedipal-lite scene played out between Robert Fischer and a projection of his dead father. The off-the-shelf pre-masticated quality of this encounter is entirely lacking in any of the weird idiosyncrasies which give Freud’s case histories their power to haunt. Cod Freudianism has long been metabolised by an advertising-entertainment culture which is now ubiquitous, as psychoanalysis gives way to a psychotherapeutic self-help that is diffused through mass media. It’s possible to read Inception as a staging of this superseding of psychoanalysis, with Cobb’s apparent victory over the Mal projection, his talking himself around to accepting that she is just a fantasmatic substitute for his dead wife, almost a parody of psychotherapy’s blunt pragmatism.

The question of whether Cobb is still dreaming or not at the film’s end is ultimately too simple. For there is also the problem of whose dream Cobb might be in, if not his ‘own’. The old Freudian paradigm made this a problem too, of course – but there the issue was the fact that the ego was not master in its own house because the subject was constitutively split by the unconscious. In Inception, the ego is still not a master in its own house, but that is because the forces of predatory business are everywhere. Dreams have ceased to be the spaces where private pyschopathologies are worked through and have become the scenes where competing corporate interests play out their banal struggles. Inception’s ‘militarised subconscious’ converts the infernal urgencies and languid poise of the old unconscious into panicked persecution and a consolatory familialism: pursued at work by videogame gunmen, you later unwind with the kids building sandcastles on a beach. This is another reason that the dreams in Inception appear so undream-like. For, after all, these are not ‘dreams’ in any conventional sense. The designed virtual spaces of Inception’s dreams, with their nested ‘levels’, evidently resemble a videogame more than they recall dreams. In the era of neuromarketing, we are presided over by what J G Ballard called ‘fictions of every kind’, the embedded literature of branding consultancies, advertising agencies and games manufacturers. All of which makes one of Inception’s premisses – that it is difficult to implant an idea in someone’s mind – strangely quaint. Isn’t ‘inception’ what so much late capitalist cognitive labour is about?

For inception to work, Arthur and Cobb tell Saito early in the film, the subject must believe that the implanted idea is their own. The self-help dictums of psychotherapy – which Cobb affirms at the end of Inception – offer invaluable assistance in this ideological operation. As Eva Illouz argues, discussing the very conversion of psychoanalysis into self-help that Inception dramatises, ‘if we secretly desire our misery, then the self can be made directly responsible for alleviating it…The contemporary Freudian legacy is, and ironically so, that we are in the full masters in our own house, even when, or perhaps especially when, it is on fire.’ (Cold Intimacies: The Making of Emotional Capitalism, Polity, 2007, 47) Yet our misery, like our dreams, our cars and our refrigerators, is in fact the work of many anonymous hands. This impersonal misery may be what Inception is ultimately about. The ostensibly upbeat ending and all the distracting boy-toy action cannot dispel the non-specific but pervasive pathos that hangs over the film. It’s a sadness that arises from the impasses of a culture in which business has closed down any possibility of an outside – a situation that Inception exemplifies, rather than comments on. You yearn for foreign places, but everywhere you go looks like local colour for the film set of a commercial; you want to be lost in Escheresque mazes, but you end up in an interminable car chase.





Handsworth Songs and the English Riots


BFI/ Sight and Sound Website, September 2011


‘I’m sure that a group of people who brought the British state to its knees can organise themselves.’ So argued John Akomfrah, the director of the Black Audio Film Collective’s Handsworth Songs at a screening of the film at Tate Modern last month. The film was released in 1986, a year after riots in Handsworth, Birmingham and Tottenham. Not surprisingly, given that the Tate had convened the event as a consequence of the recent uprisings in England, the question of the continuities and discontinuities between the 80s and now hung over the whole evening, dominating the discussion that followed the screening.

Watched – and listened to – now, Handsworth Songs seems eerily (un)timely. The continuities between the 80s and now impose themselves on the contemporary viewer with a breathtaking force: just as with the recent insurrections, the events in 1985 were triggered by police violence; and the 1985 denunciations of the riots as senseless acts of criminality could have been made by Tory politicians yesterday. This is why it is important to resist the casual story that things have ‘progressed’ in any simple linear fashion since Handsworth Songs was made. Yes, the BAFC can now appear at Tate Modern in the wake of new riots in England, something unthinkable in 1985; but, as Rob White pointed out in the discussion at the Tate event, there is little chance now of Handsworth Songs or its like appearing on Channel 4 now, still less being commissioned. The assumption that brutal policing and racism were relics of a bygone era was part of the reactionary narrativisation of the recent riots: yes, there was politics and racism back then, but not now, not any more…The lesson to be remembered – especially now that we are being asked to defend abortion and oppose the death penalty again – is that struggles are never definitively won. As the academic George Shire pointed out in the Tate discussion, many struggles have not been lost so much as diverted into what he called ‘the privatisation of politics’, as former activists become hired as ‘consultants’. Shire’s remarks strikingly echoed recent comments made by Paul Gilroy. ‘When you look at the layer of political leaders from our communities,’ Gilroy observed, ‘the generation who came of age during that time 30 years ago, many of those people have accepted the logic of privatization. They’ve privatised that movement, and they’ve sold their services as consultants and managers and diversity trainers.’ (See http://dreamof-safety.blogspot.com/2011/08/paul-gilroy-speaks-on-riots-august-2011.html) This points to one major discontinuity between now and 25 years ago. In 1985, political collectivities were in the process of being violently decomposed – this was also the year in which the Miners’ Strike ended in bitter defeat – as the neoliberal political programme began to impose the ‘privatisation of the mind’ which is now everywhere taken for granted. Akomfrah’s optimistic take on the current riots – that those who rioted will come to constitute themselves as a collective agent – suggests that we might be seeing the reversal of this psychic privatisation.

One of many striking things about Handsworth Songs is the serene confidence of its experimental essayism. Instead of easy didacticism, the film offers a complex palimpsest comprising archive material, anempathic sound design and footage shot by the Collective during and after the riots. The Collective’s practice coolly assumed, not only that ‘black’, ‘avant garde’ and ‘politics’ could co-exist, but that they must entail one another. Such assumptions, such confidence, were all the more remarkable for the fact that they were so hard won: the Collective’s Lina Gopaul remembered that the idea of a black avant-garde was greeted with incomprehension when the BAFC began their work. Even the sight of young black people carrying cameras provoked bemusement: are they real? Gopaul recalled police officers asking as the Collective filmed events in Handsworth and Broadwater Farm 25 years ago.

At a time when reactionaries once again feel able to make racist generalisations about ‘black culture’ in mainstream media, the Collective’s undoing of received ideas of what ‘black’ supposedly means remains an urgent project. In The Ghost of Songs: The Film Art of the Black Audio Film Collective, the outstanding survey of the BAFC’s work that he co-edited with fellow Otolith Group member Anjalika Sagar, Kodwo Eshun argued that, for the Collective, ‘black’ ‘might be profitably understood…as a dimension of potentiality.’ At the Tate discussion, which he chaired, Eshun pointed to the use in Handsworth Songs of Mark Stewart and the Maffia’s dub-refracted cut-up version of ‘Jerusalem’: the track makes a bid for an account of Englishness from which ‘blackness’, far from being something that can be excluded, becomes instead the only possible fulfilment of the millenarian promise of Blake’s revolutionary poem. The use of Stewart’s music also brings home the extent to which Handsworth Songs belonged to a postpunk moment which was defined by its unsettling of concepts of ‘white’ and ‘black’ culture. Trevor Mathison’s astonishing sound design certainly draws upon dub, but its voice loops and seething electronics are equally reminiscent of the work of Test Department and Cabaret Voltaire. So much film and television now deploys sound as a crude bludgeon which closes down the polyvalency of images. Whooshing sound effects subordinate audiences to the audio equivalent of a spectacle, while the redundant use of pop music enforces a terroristic sentimentalism. By strong and refreshing contrast, Mathison’s sound – which is simultaneously seductive and estranging – liberates lyricism from personalised emotion, and frees up the potentials of the audio from the strictures of ‘music’. Subtract the images entirely, and Handsworth Songs can function as a gripping audio-essay.

Mathison’s sound recording equipment captured one of the most extraordinary moments in the film, an exchange between the floor manager and the producer of the long-defunct documentary series TV Eye in the run-up to a special edition of the programme which was about to be filmed in front of a Tottenham audience. The exchange reveals that it is not possible to securely delimit ‘merely technical’ issues from political questions. The producer’s anxieties about lighting quickly shade into concerns about the proportion of non-whites in the audience. The matter-of-fact tone of the discussions make this sudden peek into the reality studio all the more disturbing – and illuminating.

The screening and the discussion at the Tate were a reminder that ‘mainstream media’ is not a monolith but a terrain. It wasn’t because of the largesse of broadcasters that the BBC and Channel 4 became host to popular experimentalism between the 60s and the 90s. No: this was only possible on the basis of a struggle by forces – which were political at the same time as they were cultural – that were content neither to remain in the margins nor to replicate the existing form of mainstream. Handsworth Songs is a glorious artefact of that struggle – and a call for us to resume it.





‘Tremors of an imperceptible future’:

Patrick Keiller’s Robinson in Ruins


Sight & Sound, November 2010


In Ellis Sharp’s short story ‘The Hay Wain’, a Poll Tax rioter in 1990 takes refuge in the National Gallery and ‘notices what he has never noticed before on biscuit tins or calendars, or plastic trays on the walls of his aunt’s flat in Bradford, those tiny figures bending in the field beyond.’ Constable’s supposedly timeless painting of English landscape ceases to be a kind of pastoral screensaver and becomes what it always really was: a snapshot of agricultural labour. Far from being some refuge from political strife, the English landscape is the site of numerous struggles between the forces of power and privilege and those who sought to resist them. Sharp replaces the dominant pastoral image of the English countryside, not with a deflated quotidian realism, but with a different kind of lyricism, one coloured by revolt: fields and ditches become hiding places or battlegrounds; landscapes that on the surface seem tranquil still reverberate with the unavenged spectral rage of murdered working class martyrs. It is not the sunlit English afternoon that is ‘timeless’, but the ability of the agents of reaction to escape justice. When the Poll tax rioter is clubbed by police and his blood starts to stain Constable’s emblem of English nationhood, we’re uncomfortably reminded of more recent episodes. ‘He was resisting arrest, right? Right mates? (Right, Sarge.)… We used minimal force, right? … Don’t piss yourself and we’ll see this thing through together, right mates?…Everyone’ll be on our side, remember that. The commissioner. The Federation. The papers. And, if it comes to it, the Coroner. Now fucking go and call for an ambulance.’

Patrick Keiller’s latest film, Robinson in Ruins, the long-awaited sequel to his two 1990s films, London (1994) and Robinson in Space (1997), performs a similar politicisation of landscape. Or rather, it exposes the way in which the rural landscape is always-already intensely politicised. ‘I had embarked on landscape film-making in 1981, early in the Thatcher era, after encountering a surrealist tradition in the UK and elsewhere, so that cinematography involved the pursuit of a transformation, radical or otherwise, of everyday reality,’ Keiller wrote in 2008, as he was preparing Robinson in Ruins. ‘I had forgotten that landscape photography is often motivated by utopian or ideological imperatives, both as a critique of the world, and to demonstrate the possibility of creating a better one.’ London was a melancholy, quietly angry study of the city after 13 years of Tory rule. Its unnamed narrator, voiced by Paul Scofield, told of the obsessive researches undertaken by Robinson, a rogue – and fictional – theorist, into the ‘problem of London’. London was the capital of the first capitalist country, but Keiller was interested in the way that the city was now at the heart of a new, ‘post-Fordist’ capitalism, in which manufacturing industry had been superseded by the spectral weightlessness of the so-called service economy. Robinson and his narrator friend bitterly surveyed this brave new world with the doleful eyes of men formed in a very different era: a world in which public service broadcasters could commission films of this nature.

London was as remarkable for the unique way that it combined fiction with the film-essay form. The film was composed of a series of striking images captured by Keiller’s static camera, which unblinkingly caught the city in unguarded epiphanic moments. Robinson in Space retained the same methodology, but broadened the focus from London to the rest of England. Rural landscapes featured in Robinson in Space, but as something which Keiller’s camera looked over rather than at. In the first two films, Robinson’s interest was in the cities where capitalism was first built, and in the non-places where it now silently spreads: the distribution centres and container ports that are unvisited by practically anyone except Robinson and his narrator-companion, but which web Britain into the global market. Keiller saw that, contrary to certain dominant narratives, the British economy was not ‘declining’. Rather, this post-industrial economy was thriving, and that was the basis of its oppressive and profoundly inegalitarian power.

London and Robinson in Space were made in the space between two political non-events, the general elections of 1992 and 1997. 1992 was the year when change was supposed to come – the end of Tory rule was widely expected, not least by the Conservative Party itself, yet John Major was re-elected. 1997 saw the long–anticipated change finally arrive, but it turned out to be no kind of change at all. Far from ending the neoliberal culture that Keiller anatomised, Tony Blair’s government would consolidate it. Robinson in Space, largely assembled in the dying days of the Major government, was made too early for it to properly register this. Yet its focus on the banal, Ballardian infrastructure of British post–Fordist capitalism made it a deeply prophetic film. The England of Robinson in Space was still the England presided over by Gordon Brown a decade later.

The traumatic event which reverberates through Robinson in Ruins is the financial crisis of 2008. It’s still too early to properly assess the implications of this crisis, but Robinson in Ruins shares with Chris Petit’s Content – a film with which it has many preoccupations in common – the tentative sense that a historical sequence which began in 1979 ended in 2008. The ‘ruins’ which Robinson walks through here are partly the new ruins of a neoliberal culture that has not yet accepted its own demise, and which, for the moment, continues with the same old gestures like a zombie that does not know that it is dead. Citing Fredric Jameson’s observation in The Seeds of Time that ‘it seems to be easier for us today to imagine the thoroughgoing deterioration of the earth and of nature than the breakdown of late capitalism; perhaps that is due to some weakness in our imaginations’, Robinson nevertheless dares to hope, if only for a moment, that the so-called credit crunch is something more than one of the crises by which capitalism periodically renews itself.

Perhaps strangely, it is the ‘thoroughgoing deterioration of the earth and nature’ that seem to give Robinson some grounds for hope, and the most evident difference between Robinson in Ruins and the previous films is the emergence of a radical Green perspective. In part, Keiller’s turn towards Green themes reflects changes in mainstream political culture. At the time of the previous two Robinson films, Green politics could still appear to be a fringe concern. In the last decade or so, however, anxieties about global warming in particular have come into the very centre of culture. Now, every corporation, no matter how exploitative, is required to present itself as Green. The emergence of ecological concerns gives Keiller’s treatment of landscape a properly dialectical poise. In the opposition between capital and ecology, we confront what are in effect two totalities. Keiller shows that capitalism – in principle at least – saturates everything (especially in England, a claustrophobic country that long ago enclosed most of its common land, there is no landscape outside politics); there is nothing intrinsically resistant to capital’s drive to commoditisation, certainly not in the ‘natural world’. Keiller demonstrates this with a long excursus on how the prices of weight increased in the immediate wake of the 2008 crisis. Yet from the equally inhuman perspective of a radical ecology, capital, for all that it may burn out the human environment and take large swathes of the nonhuman world with it, is still a merely local episode.

Environmental catastrophe provides what a political unconscious totally colonised by neoliberalism cannot: an image of life after capitalism. Still, this life may not be a human life, and there is the feeling that, like the narrator’s father in Margaret Atwood’s coldly visionary novel Surfacing, Robinson may have headed off into some kind of dark Deleuzean communion with Nature. As with Surfacing, Robinson in Ruins begins with a disappearance: Robinson’s own. Paul Scofield having died in 2010, the narration is no longer handled by Robinson’s friend, but by Vanessa Redgrave, playing the head of a group seeking to reconstruct Robinson’s thinking from notes and films recovered from the caravan where he was last known to live. If the Redgrave narration doesn’t quite work, then that is partly because there is a feeling that Keiller has slightly tired of the Robinson fiction, or it has ceased to serve much of a function for him. For what seems like large parts of the film, the Robinson framing narrative disappears from view, to the extent that it can be something of a jolt when Robinson is mentioned again. Lacking Paul Scofield’s sardonic insouciance, Redgrave’s narrative is often oddly tentative, her emphasis not quite mustering Scofield’s assured mastery of Keiller’s tone.

In tracking the historical development of capitalism in England, and the sites of struggle against it, Robinson in Ruins shows a sensitivity to the way that landscape silently registers (and engenders) politics that echoes the concerns of Danièle Huillet and Jean-Marie Straub. As in Straub-Huillet’s films, Robinson in Ruins returns to landscapes where antagonism and martyrdom once took place: Greenham Common, the woodland where Professor David Kelly committed suicide.

Keiller’s decision to retain film rather than switch to a digital medium carries more charge now than it did when he used a cine camera for London and Robinson in Space. In many ways, even in 1997, we had yet to really enter the digital realm; now, with cyberspace available on every smartphone handset, we are never outside it. The return to film made him appreciate the materiality of the medium in a new way. ‘Compared with videotape,’ Keiller has written, ‘film stock is expensive to purchase and process, and the camera’s magazine holds only 122m of stock, just over 4 minutes at 25fps. Film hence tends to involve a greater commitment to an image before starting to turn the camera, and there is pressure to stop as soon as possible, both to limit expenditure and to avoid running out of loaded film. Results are visible only after processing, which, in this case, was usually several days later, by which time some subjects were no longer available and others had changed, so as to rule out the possibility of a retake. I began to wonder why I had never noticed these difficulties before, or whether I had simply forgotten them. Another problem was that, with computer editing, it is no longer usual to make a print to edit. Instead, camera rolls are transferred to video after processing, so that the footage is never seen at its best until the end of the production process. This hybridity of photographic and digital media so emphasises the value of the material, mineral characteristics of film that one begins to reimagine cinematography as a variety of stone-carving.’

When we hear early on in the film that Robinson has made contact with a series of ‘non-human intelligences’, we initially suspect that he has finally succumbed to madness. Yet the ‘non-human intelligences’ turn out not to be the extra-terrestrials of a florid pulp science fiction-inspired psychosis, but the intra-terrestrial lifeforms that an ecological awareness reveals growing with a silent stubbornness that matches the brute tenacity of capitalism. In one of the many slow spirals that typify Keiller’s approach in Robinson in Ruins, the lichen that his camera lingers on in an early shot, apparently for merely picturesque effect, will eventually come to take centre stage in the film’s narrative. Lichen, Robinson comes to realise, is already the dominant life-form on large areas of the planet. Inspired by the work of American biologist Lynn Margulis, Robinson confesses to a growing feeling of ‘biophilia’, which Keiller seems to share. While his camera lingers tenderly on wildflowers, the film’s verbal narrative is suspended, projecting us for a few long moments into this world without humans. These moments, these unnarrativised surveys of a non-human landscape, are like Keiller’s version of the famous ‘Straubian shot’, the cut-aways to depopulated landscapes in Straub and Huillet’s films. Robinson is drawn to Margulis because she rejects the analogies between capitalism and the biological that are so often used to naturalise capitalist economic relations. Instead of the ruthless competition which social Darwinians find in nature, Margulis discovers organisms engaging in co-operative strategies. When Keiller turns his camera on these ‘non-human intelligences’, these mute heralds of a future without humanity, I’m reminded of the black orchids in Troy Kennedy Martin’s Edge Of Darkness, those harbingers of an ecology that is readying to take revenge on a humanity that thoughtlessly disdained it. Kennedy Martin’s inspiration was the anti-humanist ecology of James Lovelock, and Lovelock’s apocalyptic message seems to haunt Robinson in Ruins too. Keiller finds extinction looming everywhere – species dying off at a far faster rate than scientists had thought possible only a few years ago. The emphasis on extinction means that the concerns of Robinson in Ruins rhyme with the preoccupations that have emerged in speculative realist philosophy, which has focused on the spaces prior to, beyond and after human life. In some respects, the work of philosophers such as Ray Brassier and Tim Morton re-stages the old confrontation between human finitude and the sublime which was the former subject of a certain kind of landscape art. But where the older sublime concentrated on local natural phenomenon such as the ocean or volcanic eruptions which could overwhelm and destroy the individual organism or whole cities, speculative realism contemplates the extinction, not only of the human world, but of life and indeed matter itself. The prospect of ecological catastrophe means that disjunction between the lived time of human experience and longer durations is now not just a question of metaphysical contemplation, but a matter of urgent political concern, as one of Robinson’s touchstones, Fredric Jameson, noted. ‘A ()s organisms of a particular life span,’ Jameson writes in his essay ‘Actually Existing Marxism’,


we are poorly placed as biological individuals to witness the more fundamental dynamics of history, glimpsing this or that incomplete moment, which we hasten to translate into the alltoo-human terms of success or failure. But neither stoic wisdom nor the reminder of a longer-term view are really satisfactory responses to this peculiar existential and epistemological dilemma, comparable to the science-fictional one of beings inhabiting a cosmos they do not have organs to perceive or identify. Perhaps only the acknowledgement of this radical incommensurability between human existence and the dynamic of collective history and production is capable of generating new kinds of political attitudes; new kinds of political perception, as well as of political patience; and new methods for decoding the age as well, and reading the imperceptible tremors within it of an inconceivable future. (Valences of the Dialectic, Verso, 2010, pp369-70)


Amongst its requiem for neoliberal England, Robinson in Ruins gives us some intimations of those imperceptible tremors and inconceivable futures.

k-punk


“We have to invent the future.”


why k?1

1. Why I started the blog? Because it seemed like a space — the only space — in which to maintain a kind of discourse that had started in the music press and the art schools, but which had all but died out, with what I think are appalling cultural and political consequences. My interest in theory was almost entirely inspired by writers like Ian Penman and Simon Reynolds, so there has always been an intense connection between theory and pop/film for me. No sob stories, but for someone from my background it’s difficult to see where else that interest would have come from.

2. Because of that, my relation to the academy has always been uh difficult. The way in which I understood theory — primarily through popular culture — is generally detested in universities. Most dealings with the academy have been literally — clinically — depressing.

3. The Ccru as an entity was developed in hostile conditions as a kind of conduit for continuing trade between popular culture and theory. The whole pulp theory/theory-fiction thing was/is a way of doing theory through, not “on”, pop cultural forms. Nick Land was the key figure here, in that it was he who was able to hold, for a while, a position “within” a university philosophy department whilst dedicatedly opening up connections to the outside. Kodwo Eshun is key as someone making connections the other way — from popular culture INTO abstruse theory. But what we all concurred upon was that something like jungle was already intensely theoretical; it didn’t require academics to judge it or pontificate upon it — the role of a theorist was as an intensifier.

4. The term k-punk came out of Ccru. “K” was used as a libidinally preferable substitution for the California/Wired captured “cyber” (the word cybernetics having its origins in the Greek, Kuber). Ccru understood cyberpunk not as a (once trendy) literary genre, but as a distributive cultural tendency facilitated by new technologies. In the same way, “punk” doesn’t designate a particular musical genre, but a confluence outside legitimate(d) space: fanzines were more significant than the music in that they allowed and produced a whole other mode of contagious activity which destroyed the need for centralised control.

5. The development of cheap and readily available sound production software, the web, blogs means there is an unprecedented punk infrastructure available. All that is lacking is the will, the belief that what can happen in something that does not have authorisation/legitimation can be as important — more important — than what comes through official channels.

6. In terms of will, there has been an enormous retrenchment since 1970s punk. The availability of the means of production has seemed to go alongside a compensatory reassertion of spectacular power.

7. To return to the academy: universities have either totally excluded or at least marginalised not only anyone connected with Ccru but also many who were at Warwick. Steve “Hyperdub” Goodman and Luciana Parisi are both Ccru agents who have managed, against the odds, to secure a position within universities. But most of us have been forced into positions outside the university. Perhaps as a result of not being incorporated (“bought off”), many in the Warwick rhizome have maintained an intense connection and robust independence. Much of the current theoretical drift on k-punk has been developed via a collaboration with Nina Power, Alberto Toscano and Ray Brassier (co-organiser of the NoiseTheoryNoise conference at Middlesex University last year). The growing popularity of philosophers like Žižek and Badiou means there is now an unexpected if rogue and fugitive line of support within the academy.

8. I teach Philosophy, Religious Studies and Critical Thinking at Orpington College. It is a Further Education college, which means that its primary intake is sixteen to nineteen year-olds. This is difficult and challenging work, but the students are in the main excellent, and far more willing to enter into discussion than undergraduates. So I don’t at all regard this position as secondary or lesser than a “proper” academic post.



book meme1

At least two people have asked me to do this, so here — at last — goes.

1) How many books do you own?

No way of knowing. Certainly can’t count them and have no reliable way of calculating.

2) What was the last book you bought?

The Sex Appeal of the Inorganic, Mario Perniola.

3) What was the last book you read?

Read and finished: Michael Bracewell’s England is Mine — disappointing and frustrating. There are flashes of insight but the organisation of the book seems to change from chapter to chapter; at one moment the narrative is historical, the next it is thematic, and then regional. There is a sense of always just approaching the time when things are happening or just having missed it. Can’t help thinking that Bracewell will benefit from a more focused subject matter, which is why still I’m looking forward to his Roxy book, due out later this year. (And there’s way too much attention paid to Eng Lit: nothing will ever interest me in W.H. Boredom, for instance.)

Finishing: Houllebecq’s Atmomised. No wonder Žižek likes this one. Is there a better savaging of desolate hippie hedonism and its pathetic legacy in New Age zen bullshit?

4) Five books that mean a lot to me.

(I hate all those surveys of best films/books/LPs which have the Latest Thing at the top, so I have only allowed myself to select books that have meant something to me for at least a decade.)

Kafka: The Trial, The Castle

Is it possible to reproduce, later in life, the impact that books, records and films have between the ages of fourteen and seventeen? The periods of my adult life that have been most miserable have been those in which I lost fidelity to what I discovered then, in the pages of Joyce, Dostoyevsky, Burroughs, Beckett, Selby… Any of those could have been selected, but I choose Kafka, because of all of them, it is he who has been the most intimate and constant companion.

I actually encountered Kafka first in a Penguin compendium of The Novels of Franz Kafka that my parents, who knew very little about literature, bought me for Christmas because they thought “it looked like my kind of thing”. So it proved.

It’s difficult for me now to remember how I first received the text. Whether I initially enjoyed it or was frustrated by it I couldn’t say. Kafka, after all, is a writer who doesn’t waylay you. He invades subtly, slowly. I imagine that at the time I wanted and expected a more straightforward statement of existentialist alienation. Yet there was very little of that in Kafka. This was not a world of metaphysical grandstanding but a seedy, cramped burrow, whose ruling affect is not heroic alienation but creeping embarrassment. Physical force plays almost no role in Kafka’s fictions — it is the ever-present possibility of social shaming that is the motive force of his winding non-plots.

Remember the pitiful scenes in The Trial when K, looking for the court in an office block, knocks in turn on each door, making the pathetic excuse that he is a “house painter”? Kafka’s genius consists in banalising the absurdity of this: surprisingly, against all our expectations, it is indeed the case that K’s hearing is taking place in one of the apartments in the building. Of course it is. And why is he late? The more absurd K thinks things are, the more embarrassed he becomes for failing to understand “the ways” of the Court or of the Castle. The bureaucratic convolutions appear ridiculous and frustrating to him, but that is because he “has not understood” yet. Witness the comedy of the opening scenes of The Castle, which are less an anticipation of totalitarianism than of call centres, in which K is told that the telephones “function like musical instruments”. What kind of an idiot is he, if when he phones someone’s desk, he expects them to answer? Is he so wet behind the ears?

It’s not for nothing that Alan Bennett, the laureate of embarrassment, is an ardent admirer of Kafka. Both Bennett and Kafka understand that, no matter how absurd their rituals, pronunciations, clothes might appear to be, the ruling class are unembarrassable; that is not because there is a special code which only they understand — there is no code, precisely — but that whatever they do is alright, because it is THEM doing it. Conversely, if you are not of the “in-crowd”, nothing you can do could EVER be right; you are a priori guilty.

Atwood: Cat’s Eye

A while back, Luke asked me what an example of “cold rationalist” literature would look like. Atwood, with her reputation for coldness, is an obvious answer, but in truth, more or less all literature is cold rationalist. Why? Because it allows us to see ourselves as chains of cause and effect and thereby, paradoxically, to attain the only measure of freedom available to us. (Even Wordsworth, who admired Spinoza, described poetry as “emotion recollected in tranquility”, i.e. not raw emotion expressed in some Dionysian ejaculation.)

Cat’s Eye isn’t my favourite Atwood novel — that would be the stark Surfacing — but it is the one that means most to me. I don’t even remember all of the plot; what I will never forget are Atwood’s horribly vivid descriptions of the pitiless Hobbesian cruelty of teenage “friendships”. They walk behind you so as they can criticise your shoes, the way you walk… They are worse than your worst enemies. The long days, the breakfast toast turning to cardboard in your mouth, the anxiety so sharp and constant that you forget it is there, no longer even register it.

Are your most formative years those of your early childhood or your early teens? Reading Cat’s Eye in my early twenties was a kind of auto-psychoanalysis, a way out of the legacy of misanthropy, suppressed rage and cosmic sense of inadequacy that had been the legacy of my teenage years. Atwood’s icy analysis beautifully demonstrated that the humiliations of those teenage years were a structural effect of teenage relationships, not at all anything specific to me.

Spinoza: The Ethics

Spinoza changes everything, but gradually. There is no “road to Damascus” conversion to Spinozism, only a steady but implacable deletion of default assumptions. As with all the best philosophy, reading it is like running a Videodrome cassette: you think you are playing it, but it ends up playing you, effecting a gradual mutation of the way you think and perceive.

I’d been attracted to Spinoza as an undergraduate, but I only really read him at Warwick, under the influence of Deleuze. We spent over a year pouring over The Ethics in a reading group. Here was a philosophy that was at once forbiddingly abstract and immediately practical, pitched at both the largest conceivable cosmic scale and the minutiae of the psyche. The “impossible” bringing together of structural analysis and existentialism?

Ballard: The Atrocity Exhibition

If Spinoza and Kafka were slow-acting, Ballard’s impact was instant. He connected immediately with an unconscious saturated in media signal.

That was partly because I had in effect encountered Ballard long before I had actually read any of his work: in Joy Division (though more in Hannett’s sound than in many of the lyrics; the song “The Atrocity Exhibition”, with its anguished pleading, couldn’t be further from Ballard’s dispassionate sobriety), in Foxx and Ultravox, in Cabaret Voltaire, in Magazine.

The Drowned World is the best of his disaster novels, inundated London as a literalised surrealist landscape coolly surveyed by a latter-day Conrad, but it is The Atrocity Exhibition that is indispensable. Much more than the better-known Crash, The Atrocity Exhibition provided a conceptual and methodological repertoire for approaching the twentieth century assembled from the century’s own resources. It is austerely modernist, making little concession to either plot or character, more like a fictive sculpture than a story, an obsessively repeated series of patterns.

Yes, Ballard has been accepted into the review columns, become an elder statesman, but let’s not forget how different his background was from the standard Oxbridge man of letters. Ballard rescued Britain from Eng Lit, from “decent” humanist certainties and Sunday supplement sleepiness.

Greil Marcus: Lipstick Traces

I’ve written before about the importance of this book to me. I read it when I had just finished university, no plans, the future collapsing into a grim attempt — bound to fail — to commensurate myself to the Thatcherite economic reality principle. Marcus’ vast web of connections opened up an escape route. It was a description of a transhistorical Event, a break-out embracing anabaptists, situationists, dadaists, surrealists, punks. Such an Event was the exact opposite of the Grand Spectacles of the Eighties, the scripted and organised Non events which played out on global television with Live Aid at their epicentre. It was fugitive, secret, even when — necessarily — massively collective. Lipstick Traces was sure that pop can only have any significance when it ceases to be “just music”, when it reverberates with a politics that has nothing to do with capitalist parliamentarianism and a philosophy that has nothing to do with the academy.

Lipstick Traces is itself best read as part of a textual rhizome which attempted to register, a decade or more on, the impact of punk. See also Vague magazine (if you are looking for one of the most powerful triggers for Ccru-style cyberpunk theory, check out Mark Downham’s pieces in Vague), Savage’s England’s Dreaming. (This set not really complete until Rip It Up of course.)

5) Tag five people.

I can’t think of one other blog that hasn’t done this, so I’m stuck.





space, time, light, all the essentials — reflections on j.g. ballard season (bbc four)1

Like his admirer Jean Baudrillard,2 Ballard has for a long time resembled a rogue AI, re-permutating the same few themes ad infinitum, occasionally adding a sprinkling of contemporary detail to freshen up a limited repertoire of fixations. Fixations, fixations. Appropriate, since, after all, Ballard’s obsession is… obsession.

In the BBC Four profile — nothing new here, the old man gamely and tirelessly going over his favourite riffs, once again — Ballard repeated one of his familiar, but still powerfully sobering observations. People often comment on how extreme his early life was, Ballard said. Yet, far from being extreme, that early life — beset by hunger, fear, war and the constant threat of death — is the default condition for most human beings on the planet, now and in every previous century. It is the comfortable life of the Western Suburbanite which is in every way the planetary exception.

Thus Home, BBC Four’s brilliant adaptation of Ballard’s short story “The Enormous Space”.3 Home is the kind of thing the BBC used to excel at: drama that was genuinely, unsettlingly weird without being insufferably, unwatchably experimental. Not that Home has much hope of appealing to popular taste stuck away on BBC Four, of course. A sign of the times.

Home revealed itself to be a perverse cousin of the suburban drop-out situation comedy, The Good Life or The Fall and Rise of Reginald Perrin spliced with Polanski’s Repulsion. (No surprise to see director Richard Curson-Smith name-checking Polanksi as an influence.) Anthony Sher was superbly, charmingly unhinged as Gerald Ballantyne, an accident victim who, instead of returning to work after his convalescence, decides to embark upon an experiment. “Decides” is no doubt too active a word; in every respect the typical Ballard character, Gerry discovers rather than initiates, finds himself drawn into a logic he is compelled to investigate. (In many ways a faithful Freudian, Ballard has no doubt that obsession always has/is a logic.)

The experiment, it turns out, has a simple premise. Gerry will stay indoors, indefinitely, living off the supplies of his well-stocked larder and freezer until… until what? Well, that is what the experiment will establish. Can he survive by “using his front door as a weapon”? What unfolds is the descent into the maelstrom Ballard has explored since High-Rise and Concrete Island, a quest to the outer edges of the human that follows a well-defined sequence, whose stages can be readily enumerated:

A letting go of the old identity. This is given up easily. Ballard’s twist on the disaster novel as far back as The Drowned World lay in the readiness of his characters to embrace rather than resist the new conditions which catastrophe had visited upon them. Ever since High-Rise, Ballard has seen characters going one-step further, actually initiating disaster as a revolt, not so much against conformity, as against air-conditioned comfort. Here, Gerry burns all his correspondence, his photographs, then his birth-certificate and — in the most sacrilegious act of all, which made mortified my Protestant soul — his money.

The loosening of the hold of civilisation Bataille phase (). Ballard is endlessly rewriting Civilisation and its Discontents 4, and his fictions are attempts to imagine a libidinal utopia in which the pay-off between survival and repression spelled out by Freud’s mordant pessimism is somehow circumvented. The return to savagery, even the experiencing of raw hunger pangs, are eagerly savoured opportunities to relax civilisation’s impulse control and neutralising of affect. In Home, when Gerry’s conventional food supplies are running low, he turns first to the flowers in his garden and then to his neighbours’ pets. The scene in which Gerry’s neighbour questions him — in that middle-class ever-so-slightly-insinuating way — about the disappearance of his dog “Mr Fred” and his wife’s cat is a masterpiece of grisly comedy. “Perhaps they’ve eloped,” Sher gibbers, by then constantly on the edge of all-but illegible hysteria. Laughter, a strange, snorting, sniffling chortle that he can barely contain: it is that laughter which signals, more than anything else, that Gerald has left polite society, never to return.

The exploration of the transcendental beyond Kant/Blake phase (). I mean transcendental in its strict Kantian sense, of course. Ballard likes to refer to this as his exploration of inner space, but I have always found this to be a profoundly misleading description. Much more than astronauts floating in empirical space, it is the “Outer” which Ballard’s suburban cosmonauts investigate: what they confront is time and space themselves, as preconditions of all perceptions and experiences, and what their explorations open up is an intensive zone beyond — outside — standard perceptual thresholds. Hence Home becomes an aberrant version of The Incredible Shrinking Man. Cut off from the world beyond his door — I refuse to call it the outside world — Gerry’s sense of space massively expands. “The rooms are getting bigger.” The attic becomes an antarctic “white world” of blank, freezer-burning vastness, the irruption of the transcendental outside into the empirical interior of the house, now a very cosmos, teeming with texture and previously unsuspected detail. “I feel like an explorer, or an astronaut.”

Curson-Smith’s use of the video-diary format gave the film a queasy intimacy and a suitably unheimlich relation to Pop TV now, something underscored by Gerry’s sign-off remarks about undertaking the “ultimate home makeover.” Yes, that’s one way to make the most of your space.

The man whose head expanded. “Are you on drugs, Gerald?”

And self-denial, starving, the withdrawal from company, it’s all very topical. I wonder — I hope — something Gerald-like is going on in David Blaine’s head right now.5





why i want to fuck ronald reagan1

At the 1980 Republican Convention in San Francisco, pranksters reproduced and distributed the section of The Atrocity Exhibition called “Why I Want to Fuck Ronald Reagan”,2 without the title and adorned with the Republican Party seal. “I’m told,” Ballard reports, “that it was accepted for what it resembled, a psychological position paper on the candidate’s subliminal appeal, commissioned from some maverick think tank.”3

What does this neo-Dadaist act of would-be subversion tell us? In one sense, it has to be hailed as the perfect act of subversion. But, viewed another way, it shows that subversion is impossible now. The fate of a whole tradition of ludic intervention — passing from the Dadaists into the Surrealists and the Situationists — seems to hang in the balance. Where once the Dadaists and their inheritors could dream of invading the stage, disrupting what Burroughs — still very obviously a part of this heritage — calls the “reality studio” with logic bombs, now there is no stage — no scene, Baudrillard would say — to invade. For two reasons: first, because the frontier zones of hypercapital do not try to repress so much as absorb the irrational and the illogical, and, second, because the distinction between stage and offstage has been superseded by a coolly inclusive loop of fiction: Reagan’s career outstrips any attempt to ludically lampoon it, and demonstrates the increasing pliability of the boundaries between the real and its simulations. For Baudrillard, the very attacks on “reality” mounted by groups such as the Surrealists function to keep the real alive (by providing it with a fabulous dream world, ostensibly entirely alternative to but in effect dialectically complicit with the everyday world of the real). “Surrealism was still in solidarity with the real it contested, but which it doubled and ruptured in the imaginary.”4 In conditions of third (and fourth-order) simulacra, the giddy vertigo of hyperreality banalises a coolly hallucinogenic ambience, absorbing all reality into simulation. Fiction is everywhere — and therefore, in a certain sense, eliminated as a specific category. Where once Reagan’s own role as actor-president seemed “novel”, his subsequent career, in which moments from film history become montaged — in Reagan’s own hazy memory and in media accounts — with Reagan’s role in particular movies, the ludic becomes the ludicrous.

The apparent acceptance, by the Republican delegates, of the genuineness of the “Why I Want to Fuck Ronald Reagan” text, is both shocking and oddly predictable, and both responses are in fact a testament to the power of Ballard’s fictions, which resides no more in their ability to mimetically reflect a pre-existing social reality than it does in their capacity to imaginatively overturn it. What Ballard achieves, rather, is what Iain Hamilton-Grant calls “realism about the hyperreal”, a homeopathic participation in the media-cybernetisation of reality in late capitalism. The shock comes when we remind ourselves of (what would seem to be) the radical aberrance of Ballard’s material. “Why I Want to Fuck Ronald Reagan”, like many of the sections of The Atrocity Exhibition, particularly in the latter part of the novel, is presented as a report on experiments into audience responses to prepared media stimuli.

Ronald Reagan and the conceptual auto-disaster. Numerous studies have been conducted upon patients in terminal paresis (G.P.I.), placing Reagan in a series of simulated auto-crashes, e.g. multiple pile-ups, head on collisions, motorcade attacks (fantasies of Presidential assassinations remained a continuing preoccupation, subjects showing a marked polymorphic fixation on windshields an rear-trunk assemblies). Powerful erotic fantasies of an anal-sadistic character surrounded the image of the Presidential contender.5

But this shock is counterposed by a sense of predictability arising from the cool elegance of Ballard’s simulations. The technical tone of Ballard’s writing — its impersonality and lack of emotional inflection — performs the function of neutralising or normalising the ostensibly unacceptable material. Is this simulation of the operations of hypercontrol agencies a satire on them, or do their activities — and the whole cultural scene of which they are a part — render satire as such impossible now? What, after all, is the relationship between satire and simulation? To begin to answer that question we need to compare Ballard’s text with other, more definitively “satirical” texts. Before that, though, we need to bear in mind Jameson’s comments on the eclipse of parody by pastiche, which we shall examine, briefly, now.

This is not the place to interrogate the differences between parody and satire; we shall proceed on the assumption that, whatever differences there are between parody and satire, they share enough in common so as to be jointly subject to Jameson’s analyses. Parody, Jameson argues, depended upon a whole set of resources available to modernism but which have faded now: the individual subject, whose “inimitable” idiosyncratic style, Jameson wryly observes, could precisely gave rise to imitations; a strong historical sense, which has its necessary obverse a confidence that there is a genuinely contemporary means of expression; and a commitment to collective projects, which could motivate writing and give it a political purpose. As these disappear, Jameson suggests, so does the space of parody. Individual style gives way to a “field of stylistic and discursive heterogeneity without a norm”, just as the belief in progress and the faith that one could describe new times in new terms wanes, to be replaced by “the imitation of dead styles, speech through all the masks and voices stored up in the imaginary museums of a new global culture”. Late capitalism’s “postliteracy”, meanwhile, points to “the absence of any great collective project.” What results, according to Jameson, is a depthless experience, in which the past is everywhere at the same time as the historical sense fades; we have a “society bereft of all historicity” that is simultaneously unable to present anything that is not a reheated version of the past. Pastiche displaces parody:

In this situation, parody finds itself without a vocation; it has lived, and that strange new thing pastiche comes to take its place. Pastiche is, like parody, the imitation of a peculiar or unique, idiosyncratic style, the wearing of a linguistic mask, speech in a dead language. But it is a neutral practice of such mimicry, without any of parody’s ulterior motives, amputated of the satiric impulse, devoid of laughter and of any conviction that alongside the abnormal tongue you have momentarily borrowed, some healthy linguistic normality still exists. Pastiche is thus blank parody, a statue with blind eyeballs…6

Despite what Jameson himself writes on Ballard,7 one of the important differences between the Ballard text and pastiche as Jameson describes it is the absence of “nostalgia” or the “nostalgia mode” — an insistent presence in other postmodernist science fiction texts, as Jameson shows — in Ballard’s work. Indeed, Ballard’s commitment to striking textual innovations — as evidenced in the layout of the pages themselves in The Atrocity Exhibition — mark him as something of an anomaly in Jameson’s terms; in this sense, at least, Ballard seems to be continuous with modernism as Jameson understands it. Yet in certain other respects — specifically in terms of the collapse of individual subjectivity and the failure of collective political action

— Ballard is emblematic of Jameson’s postmodernity. But, unlike Jameson’s pastiche, Ballard does not imitate “a peculiar or unique idiosyncratic style”. The style that Ballard simulates in “Why I Want to Fuck Ronald Reagan” — a style towards which the whole of The Atrocity Exhibition tends — is precisely lacking in any personality: if there are any idiosyncrasies, they belong to the technical register of (pseudo)scientific reportage, not to the characteristics of an individual subject. The fact that the text concerns a political leader draws attention to the lack of any explicit — or, more importantly when discussing satire or parody, implicit — political teleology in Ballard’s writing. It is in this sense that “Why I Want to Fuck Ronald Reagan”, like Jameson’s pastiche, is “without any of parody’s ulterior motives”.

Certainly, this is one way in which “Why I Want to Fuck Ronald Reagan” differs greatly from a classical work of satire such as Swift’s A Modest Proposal (1729). A Modest Proposal is a paradigmatic work of what Joyce called “kinetic” art, produced in particular political and cultural circumstances with a particular aim, to sway an audience into action. Swift’s political purpose — his disparaging of the cruelty of certain English responses to the Irish potato famine — is marked by a certain stylistic and thematic excess (an excess that famously bypassed altogether certain of Swift’s readers, who were able to take the text at face value), whereas Ballard’s text — which emerged, no less than Swift’s, from a very particular sociocultural situation — can be defined by its flatness. This marks a move on, (even), from Burroughs. For all their linguistic inventiveness, Burroughs’ humorous “routines” such as “The Complete All-American Deanxietised Man”8 remain in a classical tradition of satire through their use of exaggeration and their clear political agenda: using a series of excessive tropes, Burroughs mocks the amoral mores of American techno-science. By contrast, what Ballard’s text “lacks” is any clear designs on the reader, any of Jameson’s “ulterior motives”; the parodic text always gave central importance to the parodist behind it, his implicit but flagged attitudes and opinions, but “Why I Want to Fuck Ronald Reagan” is as coldly anonymous as the texts it imitates. Whereas we hear Burroughs’ cackling at the absurd excesses of the scientists in “The Complete All-American Deanxietized Man”, the response of Ballard to the scientists whose work he simulates is unreadable. What does “Ballard” want the reader to feel: disgust? amusement? It is unclear, and, as Baudrillard argues in relation to Crash,9 it is somewhat disingenuous of Ballard the author to overcode his texts — in prefatory authorial remarks — with all the traditional baggage of “warning” that they themselves clearly elude. The mode Ballard adopts in “Why I Want to Fuck Ronald Reagan” is not that of (satirical) exaggeration, but is a kind of (simulated) extrapolation. The very genre of the poll or the survey, as Baudrillard shows, makes the question unanswerable, undecidable.

Despite what Ballard himself suggests, (see above), what matters is less the (possible) resemblance of “Why I Want to Fuck Ronald Reagan” to (possible) reports than the circulation of simulation to which such reports already contribute. Writing on pastiche, Jameson comes upon the concept of simulation, but attributes it to Plato rather than referring — here at least — to Baudrillard’s reinvention of it. Yet Jameson’s intuition about the relationship between pastiche and simulation is important. We could perhaps suggest a correlation between Baudrillard’s third-order simulacra and Jameson’s pastiche, on the one hand, and Ballard’s text on the other. What simulation in Baudrillard’s third-order sense entails is, as we have repeatedly insisted, the collapse of distance between the simulation and what is simulated. Satire, in its classical sense, we would probably want to locate as part of “first-order simulacra” — a simulation that resembles the original, but with certain tell-tale differences. Ballard simulates the simulation (the poll, the survey).





a fairground’s painted swings1

Speaking of the pathology of amour, is it anywhere better exemplified than in the lyrics of “These Foolish Things” (the title track, significantly, of Ferry’s first LP of covers).

What is fascinating about the song’s litany of lost affects (“wild strawb’ries only seven francs a kilo… the sigh of midnight trains in empty stations… a fairground’s painted swings”) is that the lover features in them only as a series of absences (“a cigarette that bears a lipstick’s traces… gardenia perfume ling’ring on a pillow”) and is never directly invoked. This, of course, is because there is no “loved object itself”. What is loved is the petit objet a, which is not a particular object, but the object as such, the “void presupposed by a demand”. The physical and psychical “presence” of the lover is required only as that which allows the assemblage of affects to be given an apparent cohering centre. But, in the end, the lover is just that: the space, the canvas, on which the collage of memories and associations can be arranged.

Nevertheless, even though it is not the lover “herself” that is desired, the lover cannot be dispensed with altogether: otherwise we are in straightforward fetishism. Žižek illustrates the difference between “normal” pathology and fetishism by reference to that scene in Vertigo where Scotty is embracing Judy (re)made-over as Madeleine. The camera cuts away to show his pausing from kissing her to anxiously check that her hair colour is still blond. But this is NOT fetishism, since the fetishist would dispense with the woman altogether and derive his enjoyment from the lock of hair itself.

Vertigo’s horror lies in its unstinting revelation of the artificiality of desire. Scottie can look into the void presupposed by his demands and still, grotesquely, make the demands. That is the difference between Vertigo and many of the film noirs it references, comments upon and surpasses: it is not, in the end, that he is being deceived by a femme fatale, duped into believing that she is something that she is not. On the contrary, he knows full well that there is no Madeleine. But knowledge is nothing, and the explanation for his continued fixation upon a Madeleine that is not even a ghost is the one provided by Zupančič: for Scottie to give up his object would be for him to give up himself, to die.

There is no doubt a specifically male relationship to the objet petit a which Vertigo reveals. This goes some way to answering the question posed by

I.T.2 a while ago, after Žižek: namely, why would men, given the choice of sex with a monkey or sex with a robot always choose the robot? The more disturbing thought is that men would always in practice prefer a robot to an actual woman — and this is why the libidinal economics, if not yet the technical feasibility, of The Stepford Wives are horribly credible.

The text which most explicitly lays bare this male desiring mechanism is Villiers de l’Isle-Adam’s The Future Eve (1877), which anticipates both Vertigo and The Stepford Wives, as well as Metropolis and Blade Runner.

The story concerns a dissolute decadent who is enchanted with his beloved, Alicia’s, form, but who detests what he considers to be the frivolity and shallowness of her personality. He is persuaded by an inventor-mentor figure (given the name, in some versions, incredibly, of the then still-living Thomas Edison) that he should simply accept an automaton-copy of his lover, prepared by the inventor, which will be a perfect replica in every respect, except that it will be programmed to be a stimulating companion.

“Edison” couldn’t be more forthright, more demystificatory, more Lacanian:

the creature whom you love, and who for you is the sole REALITY is by no means the one who is embodied in this transient human figure, but a creature of your desire. … () This illusion is the one thing you struggle against all odds to VITALISE in the presence of your beloved, depsite the frightful, deadly, withering nullity of Alicia. What you love is this phantom alone; it’s for the phantom that you want to die. That and that alone is what you recognise as unconditionally REAL. In short, it is this objectified projection of your own mind that you call on, that you perceive, that you CREATE in your living woman, and which is nothing but your mind reduplicated in her.3

Of course, the “creative” force that really animates the loved object is not the freeplay of the Romantic imagination, but the implacable mechanism of the unconscious. It’s for the phantom that you want to die: but such a “death” would mean that the desiring frame that makes sense of the world would survive. The only real death would be one in which that whole framework was destroyed, and the subject was confronted with the “white space” of pure potential.

This is what the subject slaved to the pleasure principle must avoid at all costs. The well-known tedium of Sadean desire is the inevitable consequence when this impasse is honestly confronted. If the object of Sadean desire is, as Žižek, says, the eternally beautiful undead victim, who can suffer all manner of privations and yet be magically renewed forever, then the subject of this desire is, as Burroughs knew very well, the vampire-junky. The vampire-junky must be insatiable and must pursue their desires up to the point of self-destruction, but must never cross the line into annihilation.

The empirical narrative would have it that the junkie is gradually “drawn into” addiction, lured into dependence by a chemical need. But it is clear that the junkie chooses to be addicted — the desire to get high is only the ostensible motivation for the drive, just as “winning money” is only the official alibi for the gambler’s enjoyment.

Burroughs’ paralleling of love with addiction is thus by no means cynical hyperbole. Burroughs understood very well that, if love is addiction (“If there’s a cure for this, I don’t want it”), then addiction is also a form of love (“It’s my wife and it’s my life”). There is always, as Gregory Bateson observed in his essay on alcoholism, a meta addiction to be dealt with: the addiction to addiction itself.4 It is on this that Burroughs’ “control addict” Bradley Martin is hooked: “I am not AN addict. I am THE addict.”

The lyrical power of Burroughs’ writing — especially in the early cut-up novels, which are consensually dismissed as difficult and boring — is often overlooked. But much of its mechanical melancholia is generated from its displaying of the “foolish things” of desire, the heroin-hacceities of train whistles, radio jingles, billboard images and sexual contact. Although initially random, these affect-collages, when repeated and remixed by memory and desire, become necessary. Thus only THAT shade of blue for Madeleine’s suit, only THAT shade of lipstick on the cigarette tip, will do.

Yes, the painted swings of desire’s cruel fairground…





what are the politics of boredom? (ballard 2003 remix)1

“Prosperous suburbia was one of the end states of history. Once achieved, only plague, flood, or nuclear war could threaten its grip.”

— J.G. Ballard, Millennium People2

“J.G. Ballard” is the name of a repetition.

That’s very different from saying that Ballard repeats himself. On the contrary, it is Ballard’s formalism, his re-permutation of the same few concepts and fixations — disasters, pilots, random violence, mediatisation, the total colonisation of the unconscious by images — that prevent his name being easily attributed to any self.

The obsessive quality of his preoccupations and his methodology is a sign that Ballard has never lost faith with his earliest inspirations: psychoanalysis and surrealism. In both, he found a rigorously depersonalised account of the formations of the person. The so-called interior had a logic that could be both exposed and externalised.

Ballard’s career can be seen as a repeated rewriting of two texts of Freud, Civilisation and its Discontents and Beyond the Pleasure Principle. The environmental catastrophes in his earliest phase of novels (The Drowned World, The Drought, The Crystal World) tend to be greeted by the characters as opportunities, chances to shuck off the dull routines and protocols of sedentary society. The second phase of his work, which began in the mid-Sixties and to some extent continues to this day, follows this logic through so that the catastrophes and atrocities that afflict the characters in these fictions are actively willed by them. (Or is it that the humans seek to manage, through repetition, the originary trauma of their being?) Disasters are now the disasters of the media landscape — the space in which humans now primarily live, and one which is both shaped by, and manufactured from, their desires and drives. Once again, though, we must qualify this claim with the further observation that human beings are not the “owners” of desires and drives — they don’t “have” them. Rather, human beings are the playing out of these impulses, instruments through which trauma is registered.

Since High-Rise in 1975, Ballard has directed most of his attention to the hyper-affluent and bored denizens of closed communities. If Ballard’s treatment of the mores of this population had begun to pall, it was refreshed by Millennium People, his latest and best rendition of this theme.

The world of Millennium People is ruled, “for the first time in history” (but not for the first time in Ballard’s work), by a “vicious boredom”, “interrupted by meaningless acts of violence”. At first glance, the novel can look like a long overdue savaging of the middle class, in which the reader can revel in the brutal destruction of bourgeois sacred cows. Tate Modern… Pret A Manger… the NFT… all of them burn in Ballard’s Bourgeois Terror.

“I’m a fund raiser for the Royal Academy. It’s an easy job. All those CEOs think art is good for their souls.”

“Not so?”

“It rots their brains. Tate Modern, the Royal Academy, the Hayward… They’re Walt Disney for the middle classes.”3

The novel’s middle-class insurgents seem, at first, to be merely the hard done-to whiners whose complaints about the rising expense of child care and school fees and the “inequity” of too high rents in their not quite luxurious enough apartments are the stuff of endless media columns. “Believe me, the next revolution is going to be about parking”4, one character announces, echoing the petrol blockades of four years ago and anticipating the Ikea riots of 2005. Once their discontent is stirred up, however, the goals of this group of former professionals become less specific, less instrumentalist.

Like the Situationists, the insurgents of Ballard’s fictional Chelsea Marina want to “destroy the twentieth century”:

“I thought it was over.”

“It lingers on. It shapes everything we do, the way we think… Genocidal wars, half the world destitute, the other half sleepwalking through its own brain-death. We bought its trashy dreams and now we can’t wake up.”5

Millennium People is in many ways Britain’s answer to Fight Club (though, needless to say, the chances of Britain producing Millennium People as a film that would even remotely do the book justice are not even slight — precisely because the British film industry is under the control of the same militantly complacent whingers that it attacks). Like Fight Club, the novel begins with a rage against the bullet-pointed, brand-consulted hyper-conformity of modern professional life, but ends up in surfascism.

The most important figure in this respect is Richard Gould who, like most of Ballard’s other characters, is little more than a spokesperson for the author’s theories. (Which is fine, of course: we need more “well-drawn characters” like we need more “well-wrought sentences”. The UEA Eng Lit mafia are as ripe for immolation as are any of the other cosily depressing targets of Ballard’s pyromaniac prose.)

Gould reiterates essentially the same attack on the “air-conditioned totalitarianism” of contemporary securo-culture that had been essayed by Nietzsche, Mauss, Bataille, Dada, Surrealism, Situationist theory, Lettrism, Baudrillard and Lyotard:

We’re living in a soft regime prison built by earlier generations of inmates. Somehow we have to break free. The attack on the World Trade Centre in 2001 was a brave attempt to free America from the 20th century. The deaths were tragic, but otherwise it was a meaningless act. And that was its point. Like the attack on the NFT.6

Gould re-states the Nietzschean claim that human beings need cruelty, danger and challenge, but that civilisation gives them security. Gould, though, is as reminiscent of Fukuyama’s rehearsal of Nietzsche’s discontent with civilisation as he is of Nietzsche himself.

It is Fukuyama’s Nietzsche — the scourge of bland egalitarianism and empty inclusiveness — that is the most relevant Nietzsche today. As you read the appalled invective with which Nietzsche blasts the herd-cult of managed security (which is so weak and insipid that it can never utter its real rallying cry: “long live mediocrity!”) you can’t help but think of Blair and the Millennium Dome, whose pallid, paradoxically self-deprecatory pomposity contrasts unhappily with the cruel opulence of the monuments erected in Nietzsche’s beloved tragic and heroic aristocratic societies.

“Democratic societies,” Fukuyama wrote in The End of History and the Last Man,

tend to promote a belief in the equality of all lifestyles and values. They do not tell their citizens how they should live, or what will make them happy virtuous and great. Instead they cultivate the value of toleration, which becomes the chief virtue in democratic societies. And if men are unable to affirm that any particular way of life is superior to another, they will fall back on the affirmation of life itself, that is, the body, its needs, and fears. While not all souls may be equally virtuous, all bodies can suffer; hence democratic societies will tend to be compassionate and raise to the first order of concern the question of preventing the body from suffering. It is not an accident that people in democratic societies are preoccupied with material gain and live in an economic world devoted to the myriad small needs of the body. According to Nietzsche, the last man has “left the region where it was hard to live, for one needs warmth”.7

“We need to pick targets that don’t make sense.”8

If the characters in The Atrocity Exhibition wanted to re-stage the founding traumatic moment of the media Sixties — the assassination of Kennedy — then Gould and his allies want to re-stage the founding traumatic moment of the media Noughties — 9/11. But where Traven/Tallis/Travis wanted to kill Kennedy again, “but this time in a way that makes sense”, Gould wants 9/11 to happen again, but in a way that doesn’t make sense.

For Gould, the (post)modern world is oppressed by an excess of Sense, a surplus of Meaning. “Kill a politician and you’re tied to the motive that made you pull the trigger. Oswald and Kennedy, Princip and the Archdukes. But kill someone at random, fire a revolver into McDonald’s — the universe stands back and holds its breath. Better still, kill fifteen people at random.”9 Thus, the Jill Dando murder is more of a template for Gould’s anti-political insurgency than is September 11th, whose violence was (still) too motivated, too freighted with Meaning. Dando’s killing however — brutal, meaningless, and without any apparent motive — was a direct attack on the BBC’s “regime of moderation and good sense”10 and the “castle of obligations”11 it protects. An action like this, whose only motive is an attack on the concept of motive itself, blows open an “empty space we could stare into with real awe. Senseless, inexplicable, as mysterious as the Grand Canyon.”12

Gould is an elegant and eloquent salesman of the Deleuze-Guattari “line of abolition”, the fascist drive to destruction which is ultimately a drive towards self-destruction. Ballard, who, to his credit has always refused to endorse facile moralising, would no doubt object to that characterisation, since to in any way condemn or censure Gould would be to confirm the very securocratic values he seeks to undermine.

However, the most compelling aspect of Millennium People, politically speaking, is not the in many ways familiar asignifying violence, but its punk theory of class revolt.

“Twickenham is the Maginot Line of the English class system. If we can break through here, everything will fall.”

“So class systems are the target. Aren’t they universal — America, Russia…?”

“Of course. But only here is the class system a means of political control. Its real job isn’t to suppress the proles, but to keep the middle classes down, make sure they’re docile and subservient.”13

The moment at which Ballard’s “new proletariat” (“furnished with private schools and BMWs”) become real political actors is when they cease to pursue their own class interests. Only then can they come to the Marxist revelation that bourgeois class interests are in no one’s interests.

“They see that private schools are brainwashing their children into a kind of social docility, turning them into a professional class who will run the show for consumer capitalism.”

“The sinister Mr Bigs?”

“There are no Mr Bigs. The system is self-regulating. It relies on our sense of civic responsibility. Without that society would collapse. In fact, the collapse may even have begun.”14

Blairism has consolidated and outstripped the ideological gains of Thatcherism by ensuring the apparently total victory of PR over punk, of politeness over antagonism, of middle-class utility over proletarian art. It manages the tricky ideological dodge of reducing everything to instrumentality whilst at the same time dedicating all resources to the production of cultural artefacts of no possible use or function. From the Mayan codices to Mission Statements… Spin engenders a meaninglessness which, in the mandatory banality of its corrosive nihilism, makes Gould’s grand poetics of asignifying rupture seem quaintly nostalgic.

Blair has made middle-class security the horizon of all aspiration. In this over-conscious, over-lit twenty-four-hour office of the soul, business, preposterously, is served up to us as the closest thing to anything animated by libido. Ballard knows that a break-out from this affective prison must involve the explicit de-cathexis of the “nice house, nice family” picture that bourgeois culture is still capable of projecting as ideal.

In histories of punk, much is made of the role of the middle classes, but the crucial catalytic role of that particular kind of middle-class refusal remains under-thought. The middle-class defection from reproductive futurism into scarification and tribalisation did nothing more than state the obvious — middle-class careers and the privileges they bring are empty, tedious and ennervating — but, now more than ever, it is this obviousness that cannot be stated.

The interesting thing is that they’re protesting against themselves. There’s no enemy out there. They know that they are the enemy.15





let me be your fantasy1

What Ballard, Lacan and Burroughs have in common is the perception that human sexuality is essentially pornographic. For all three, human sexuality is irreducible to biological excitation; strip away the hallucinatory and the fantasmatic, and sexuality disappears with it. As Renata Salecl argues in (Per)Versions of Love and Hate,2 it is easier for an animal to enter the Symbolic Order than it is for a human to unlearn the Symbolic and attain animality, an observation confirmed by the news that, when an orangutan was presented with pornography, it ceased to show any sexual interest in its fellow apes and spent all day masturbating. The orangutan had been inducted into human sexuality by the “inhuman partner”, the fantasmatic supplement, upon which all human sexuality depends.

The question is not, then, whether pornography, but which pornography? For Burroughs, pornosexuality would always be a miserable repetition, a Boschian negative carnival in which the rusting fairground wheel of desire forever turns in desolate circles. But in Ballard, and in Cronenberg’s version of Ballard’s Crash, it is possible to uncover a version of pornography that is positive, even utopian.

Cronenberg’s work can be seen as a response to the challenge Baudrillard posed in Seduction.3 Hardcore pornography haunts late capitalism, functioning as the cipher of a supposedly demystified, disillusioned “reality”. “A pornographic culture par excellence: one that pursues the workings of the real at all times and all places.” Here, hardcore is the reality of sex, and sex is the reality of everything else. Hardcore trades on a kind of earnest literalism, a belief that there is some empirically specifiable “it” which = sex in/as the real. As Baudrillard wryly noted, this empiricist bio-logic is fixated on a kind of technical fidelity — the pornographic film must be faithful to the (supposed) unadorned, brute mechanism of sex. Yet, sign and ritual are inescapable: in hardcore, especially in bukkake, the function of semen is, after all, essentially semiotic. No sex without signs. The higher the resolution of the image, the closer you get to the organs, the more that the “it” disappears from view. There is no better image of this “orgy of realism” than the “Japanese vaginal cyclorama” Baudrillard described in the “Stereoporno” section of Seduction. “Prostitutes, their thighs open, sitting on the edge of a platform, Japanese workers in their shirt-sleeves… permitted to shove their noses up to their eyeballs within the woman’s vagina in order to see, to see better — but what?” “Why stop with genitalia?” Baudrillard asks, “Who knows what profound pleasure is to be found in the visual dismemberment of mucous membranes and smooth muscles?”4

Cronenberg’s early work — from Shivers and Rabid through to Videodrome — is an answer to that very question. Cronenberg famously posed his own question, “why aren’t there beauty contests for the inside of the body?”, and Shivers and Rabid posit an equivalence between body horror and eroticism. The ostensible catastrophe with which both films conclude — the total degeneration of social structure into a seething, anorganic orgy — functions ambivalently. The disintegration of organismic integrity, the reversion to the condition of the pre-multicellular, is a kind of parodic-utopian riposte to Freud’s Civilzation and its Discontents. If civilisation and unbound libido are incommensurate, it is implied, so much the worse for civilisation. The apartment block taken over by mindless sex zombies at the end of Shivers is the Sixties dream of liberated sex come true…

Crash is a sober retreat from all this, a model for a new mecho-Mascohistic mode of pornography in which it is no longer the so-called inside of the body that matters, but the body as surface — a surface to be adorned with clothes, marked by scars, punctured by technical machinery. Possessed by a mad passion to exchange biotic code, the sex plague victims in Shivers devolve beyond animality into a kind of bacterial replicator frenzy. By firm contrast, Crash is as passionless as a Delvaux dream. Sex here is entirely colonised by culture and language. All the sex scenes are meticulously constructed tableaux, irreducibly fantasmatic, not because they are “unreal”, but because their staging and their consistency depend on fantasy. The film’s opening scene, with Catherine Ballard in the aircraft hangar, is quite clearly an acting out of a fantasmatic scenario; it also functions, later, via its recounting, as a fantasmatic supplement to the first sexual encounter we see between Catherine and James. There is no “it” of sex, no brute, naked, definable moment when “it” happens, only a plateau that is (paradoxically) both dilated and deferred, in which words and memories reverberate more powerfully than any penetration.

Crash is so indebted to Helmut Newton that it often looks like little more than a series of animated Newton images. Or, better: in Crash, the bodies attain the near-inanimate stillness of Newton’s living mannequins. The echoes of Newton are entirely fittingly, since Ballard regarded Newton as “our greatest visual artist”,5 a Surrealist image-maker whose vision shamed the mediocrity of those officially working in the fine arts. “In Newton’s work,” Ballard writes, “we see a new race of urban beings, living on a new human frontier, where all passion is spent and all ambition long satisfied, where the deepest emotions seem to be relocating themselves, moving into a terrain more mysterious than Marienbad.”6

When Cronenberg talks about the future sexuality of the “new race of urban beings” in Crash, he tends to refer to it in negative terms:

The conceit that underlies some of what is maybe difficult or baffling about Crash, the sci-finess of it, comes from Ballard anticipating a future pathological psychology. It’s developing now, but he anticipates it and brings it back to the past — now — and he applies it as though it exists completely formed.

The Ballards’ marriage is to be understood as inherently dysfunctional:

Some potential distributors said, “You should make them more normal at the beginning so that we can see where they go wrong.” In other words, it should be like a Fatal Attraction thing. Blissful couple, maybe a dog and a rabbit, maybe a kid. And then a car accident introduces them to these horrible people and they go wrong. I said, “That isn’t right, because there’s something horribly wrong with them right now. That’s why they’re vulnerable to going even further.7

Yet the Ballards’ “pathology” in Crash seems oddly healthy, their marriage a model of well-adjusted perversity. Theirs is a utopian sexuality, where sexual contact is voided of all sentimentality, stripped of any reference to reproduction, and unfreighted by any guilt. The lack of face-to-face sex in the Ballards’ marriage — which, again Cronenberg himself tends to talk of negatively, as if it were a deviation from some wholesome, facialised sex in which the partners achieve a harmonious oneness — points to an awareness that there is no sexual relationship. Yet, very far from being a difficulty for the Ballards’ marriage, the lack of a direct rapport, the recognition that any sexual encounter has to go via fantasy, is the basis of all their erotic adventures. Compare the Ballards’ marriage to that of the Harfords’ in Eyes Wide Shut. The Ballards’ using of their sexual encounters with others as a stimulus for their own — impassive, poised, oneiric — sex forms a clear contrast with the deadlock of the Harfords’ marriage, which is exposed in Bill’s failure to cope, or keep up, with Alice’s fantasy. While Bill is scandalised by Alice’s articulation of her fantasies, sex in the Ballards’ marriage is governed by the “feminine” drive to talk; it is almost as if all of the physical encounters happen only so that they can be converted into stories to be recounted later.

The most charged scene in Crash takes place in the carwash, where James looks on through the rearview mirror at Catherine and Vaughan, who — in the words of Cronenberg’s script — are “like two semi-metallic human beings of the future making love in a chromium bower”. Deborah Unger, the film’s real star, is particularly impressive here. A kind of feline automaton, she “acts with her hair, minor adjustments, tosses of the head that advertise the transit of small emotions.”8

Who is using whom here? The answer is that all three of the characters are using each other. Catherine’s encounter with Vaughan stimulates James, just as Catherine is stimulated by the thought that James is watching her with Vaughan. Vaughan is using the couple as subjects of his own libidinal experiments, while the Ballards are using Vaughan as the third figure in their marriage. A mis-en-abyme of desire…

Far from being some nightmare of mutual domination, this is Cronenberg/ Ballard’s sexual utopia, a perverse counterpart to Kant’s kingdom of ends. The kingdom of ends was Kant’s ideal ethical community, in which everyone is treated as an end in themselves. Kant reasoned that, from the point of view of his ethics, sex was inherently problematic, because to engage in sexual congress entails treating the other as an object to be used. The only way in which sex could be commensurate with the categorical imperative — which in one of its versions maintains that one should never treat others as a means to an end — was if it took place in the context of a marriage, in which each partner has contracted out the use of their organs in exchange for the use of their partner’s.

Desire is construed here in terms of simple appropriation (this equivalence is yet another way in which Kant is in tune with Sade). But what Kant — and those who follow him in condemning pornography because it “objectifies” — fails to recognise is that our deepest desire is not to possess an other but to be objectified by them, to be used by them in/as their fantasy. This is one sense of the famous Lacanian formula that “desire is the desire of the other”. The perfect erotic situation would involve neither a dominance of, nor a fusion with, the other; it would consist rather in being objectified by someone you also want to objectify.

Crash, of course, follows Masoch and Newton in delocalising sex from genitality. Libido is invested in the mis-en-scene more than in the meat, which draws its attraction almost entirely from its adjacency to the decorous nonorganic — to clothes as much as cars. Clothes differentiate glam’s cold and cruel cultivation of appearances from hardcore’s passion for the real. Without suits, dresses and shoes, without fur, leather and nylon, pornography might as well be arranging meat in a butcher’s window. Newton told Ballard that he “loved Cronenberg’s Crash”, but one thing bothered him. “The dresses,” he whispered. “They were so awful.” This strikes me as waspishly unfair to Denice Cronenberg’s elegant wardrobe selections. (One major problem with Jonathan Weiss’ version of The Atrocity Exhibition, however, is precisely the dreadfulness of the clothes.) Crash takes its cues from high fashion magazines, whose images are more sumptuously arty than fine art, more suffused with deviant eroticism than hardcore porn. Would it be impossible for there to be a pornography, sponsored by Dior or Chanel, scripted by a latter-day Masoch or Ballard, whose fantasies were as artfully staged as the most glamorous fashion photo shoot?





fantasy kits:1 steven meisel’s “state of emergency”2

A few weeks ago, I asked whether it would be possible “for there to be a pornography, sponsored by Dior or Chanel, scripted by a latter-day Masoch or Ballard, whose fantasies were as artfully staged as the most glamorous fashion photo shoot?”3 Steven Meisel’s Vogue photo-shoot, much more than Mike Figgis’ drearily vanilla promotional films for Agent Provocateur, suggests that such a pornography is conceivable.

“State of Emergency” shows, once again, that it is left to high fashion to take up the role that fine art has all but abandoned. While much of fine art has succumbed to the “passion for the real”, high fashion remains the last redoubt of Appearance and Fantasy.

The used tampons and pickled animals of Reality Art offer, at best, tracings of the empirical. Their quaint biographism reveals nothing of the unconscious. Meisel’s elegantly-staged photographs, meanwhile, drip with an ambivalence worthy of the best Surrealist paintings. They are uncomfortable and arousing in equal measure because they reflect back to us our conflicted attitudes and unacknowledged libidinal complicities. (In this respect, they form a sharp contrast with the infinitely more exploitative image being used to front the American Express Red campaign4, whose meaning is easily anchored to the coordinates of the currently dominant ideological constellation.)

Reframed as Art, the Vogue photographs would no doubt be described — in the all-too familiar terms of art-critical muzak — as “negotiating with ideas of violence/ terror/etc.” As high fashion, they meet instead with a type of liberal denunciation that is no less familiar. In the Guardian, Joanna Bourke complained that, “It is no coincidence that the security forces are shown to be protecting us from a person who is neither male nor obviously Muslim”.5 Would Bourke have preferred it, then, if the images did feature a Muslim man?

Bourke continues:

Instead, the terrorist threat is an unreal woman. In contrast to the security personnel depicted, she is placed beyond the realm of the human. Her skin is as plastic as a mannequin’s; her body is too perfect, even when grimacing in pain. When the model is depicted as the aggressor, she remains nothing more than the phallic dominatrix of many adolescent boys’ wet dreams. In both instances, the beauty of the photographs transforms acts of violence and humiliation into erotic possibilities.

Again, what would Bourke have preferred: simulated snuff in which “reallooking” women were roughed up by security staff? Bourke’s hostility to the fantasmatic is oddly doubled by the aggression of the security personnel towards the “unreal” women. And what does it mean to substitute an “unreal woman” for an all-too-real Muslim male, in any case? What does the confusion of ontological levels — agents of reality conjoined with the waxy artificiality of Bellmer-doll fashion models — tell us? The photographs are fascinating and unsettling because there are no straightforward answers to these questions.

Needless to say, Meisel’s photographs do find erotic possibilities in violence and humiliation, but this is not so much a “transformation” as a rediscovery. Two hundred years after Sade, a century after Bataille and Masoch, it appears that anything which publicly acknowledges that eroticism is inseparable from violence and humiliation is more unacceptable than ever. The issue is not how “healthy” sexuality can be purged of violence, but how the violence inherent to sexuality can be sublimated. Meisel’s photographs — which, we should remember, appear in a magazine the vast majority of whose readership is not “adolescent males” but women — are “fantasy kits” which offer just such sublimations, providing scenarios, role-play cues and potential fantasmatic identifications.

“State of Emergency” demonstrates that, rather than simply retaining its capacity to shock, The Atrocity Exhibition is more disturbing than ever. The overt sexualisation and compulsory carnality of postmodern image culture distracts us from the essential staidness of its rendition of the erotic. As Baudrillard argues in Seduction, biologised sex functions as the reality principle of contemporary culture: everything is reducible to sex, and sex is just a matter of meat mechanics. Ours is an age of cynicism and piety, which, as Simon suggested in his initial post on “State of Emergency”,6 primly and pruriently resists the equivalences between eroticism, violence and celebrity that Ballard explored:

Entering the exhibition, Travis sees the atrocities of Vietnam and the Congo mimetised in the “alternate” death of Elizabeth Taylor; he tends the dying film star, eroticising her punctured bronchus in the over-ventilated verandas of the London Hilton; he dreams of Max Ernst, superior of the birds.7

To imagine the atrocities of September 11th and Abu Ghraib mimetised in the alternate death of Paris Hilton feels far more unacceptable, because contemporary piety has sacralised its atrocities in a way that the Sixties could not. In Atrocity, Dr Nathan’s reminder that, at the level of the unconscious, “the tragedies of Cape Kennedy and Vietnam… may in fact play very different parts from the ones we assign them” is extremely timely. (As Burroughs tells us in his preface to The Atrocity Exhibition, “Surveys indicate that wet dreams in many cases have no overt sexual content, whereas dreams with an overt sexual content in many cases do not result in orgasm”.) It is clear that the appalling Abu Ghraib photographs were already intensely eroticised stagings whose scenarios were derived from cheap American pornography. Love and Napalm: Export USA, indeed. Part of the reason that the Abu Ghraib images were so traumatic for a deeply conflicted American culture which combines religious moralism with hyper-sexualised commerce, and which is united only by a taste for mega-violence, is that they exposed the equation between military intervention and sexual humiliation that the official culture both depends upon and must suppress.

It’s interesting to compare both The Atrocity Exhibition and “State of Emergency” to Martha Rosler’s series of collages, “Bringing the War Home”8. “Sixties iconography: the nasal prepuce of LBJ, crashed helicopters, the pudenda of Ralph Nader, Eichmann in drag, the climax of a New York happening: a dead child”: this typical section from The Atrocity Exhibition could almost be a gloss on Rosler’s images, with their irruptions of war and atrocity amidst domestic scenes. But in Rosler’s case, unlike in Ballard’s, surrealist juxtaposition has a clear polemical purpose. The Atrocity Exhibition, like “State of Emergency”, is devoid of any decipherable intent; the oneiric juxtapositions in Ballard’s and Meisel’s work seemed to be conceived of as neutral re-presentations of the substitutions and elisions made by the mediatised unconscious.

Meisel’s fantasy kits, their narratives left implicit and mysterious, suggest ways in which Ballard might be adapted in future. Part of the problem with Weiss’ film adaptation of The Atrocity Exhibition is that it subordinated the fragmentary mode of the novel to the duree — the lived time — of the feature film.9 The most successful part of the film was perhaps the first few moments, where Ballard’s text was intoned over still images in a style reminiscent of Marker’s La Jetee (a film which Ballard adores, of course). That is partly because it is the profound stillness of the Surrealist paintings which The Atrocity Exhibition describes and appropriates — their beaches drained of time — which sets the rhythm of the novel. The most successful adaptation of The Atrocity Exhibition would, precisely, be an exhibition — not only of photographs, but also of newsreel footage, mandalas, diagrams, paintings and notebooks. It would be left for the viewer-participant to assemble their own narratives from these fantasy kits.





the assassination of j.g. ballard1

They wanted to kill Ballard again, but this time in a way that made sense. The British know how best to kill something, softly. Assimilation is sometimes the most effective kind of assassination.

“You say these constitute an assassination weapon?”

So here they come again — all the familiar profiles, all the old routines. All that over-rehearsed musing about the supposed contrast between Ballard’s writing and his lifestyle and persona. All that central London cognoscenti condescension: he lived in Shepperton, he wore a tie and drank gin and yet he could come up with this — imagine that. As if it isn’t obvious that English suburbs are seething with surrealism. As if you could think for a minute that The Drowned World or The Atrocity Exhibition were written by anyone wearing jeans. Ballard mapped another America, another 1960s, one beyond the pleasure principle of rock ‘n’ roll and its paraphernalia. (That was one of the reasons that Ballard should have been so integral to post-punk’s unlearning of r and r and to electro’s pursuit of a colder mechano-erotics outside rock’s passional regime.) As if Ballard’s works could be mistaken as anything other than the work of a bourgeois — Ballard’s was to have unashamedly fixated on the psychopathologies of his class (so no Keith Talents here, only a litany of deranged professionals), a class which he had a special insight into because he was always semi-detached from it.

You: Coma: Princess Diana

Assessing cultural figures by their alleged influence, their legacy, is an egregious postmodern tic — as if it reflected any merit to have inspired the Klaxons. Ballard is important precisely because it is completely unimaginable that any equivalent of his work could emerge from current conditions. As he made clear in his 1989 annotations to his most important work, The Atrocity Exhibition, he was a meta-psychologist of the pop age, his sensibility unsuited to the era of Reality, with its flattening fusion of celebrity and the hyper-banal.

A unique collision of private and public fantasy took place in the 1960s, and may have to wait some years to be repeated, if ever. The public dream of Hollywood for the first time merged with the private imagination of the hyper-stimulated TV viewer. People have sometimes asked me to do a follow-up to The Atrocity Exhibition, but our perception of the famous has changed — I can’t imagine writing about Meryl Streep or Princess Di, and Margaret Thatcher’s undoubted mystery seems to reflect design faults in her own self-constructed persona. One can mechanically spin sexual fantasies around all three, but the imagination soon flags. Unlike Elizabeth () Taylor, they radiate no light. … () A kind of banalisation of celebrity has occurred: we are now offered an instant, ready-to-mix fame as nutritious as packet soup.2

Ballard’s Sixties were inaugurated by the Kennedy assassination. The founding event of the media environment we live in now, in which consensual sentimentality has long since occluded Ballard’s death of affect, was Princess Diana’s car crash death in 1997. In his later novels, Ballard tried to get a grip on this mall-world of Ikea psychosis and shopping channel charismatics, but they never produced the same spinal charge as his encounters with the Sixties tele-cinematic arcades presided over by Elizabeth Taylor and Ronald Reagan. Ballard’s most probing contributions in later years came in interviews and articles rather than in the novels: it was here that he identified retail parks and anonymous non-places as the authentic landscape of the twenty-first century, but he was not able to poeticise this hyper-banal terrain in the same way that he mythologised the brutalist concourses and high-rises of the Sixties and Seventies.

A Pulp Modernist Magus

What better way to destroy something than send in Martin Amis to praise it? Ballard was never a “good writer” in the way that Amis and his admirers and cronies in urbane Brit lit, with their handcrafted sentences, their well-drawn characters, their concerned social commentary, were. The significance of The Atrocity Exhibition was to have obsolesced this machinery of mediocrity, which he eviscerated in his 1964 profile of Burroughs.

To use the stylistic conventions of the traditional oral novel — the sequential narrative, characters “in the round”, consecutive events, balloons of dialogue attached to “he said” and “she said” — is to perpetuate a set of conventions ideally suited to a period of great adventures in the Conradian mode, or to an overformalised Jamesian society, but now valuable for little more than the bedtime story and the fable.3

But Ballard’s strategy in his best works was also opposed to that of another of his admirers and appropriators, Iain Sinclair. Whereas Sinclair transforms pop-cultural material into something opaque, obscure and hermetic, Ballard innovated a kind of pulp modernism in which the techniques of high modernism and the riffs of popular fiction intensified one another, avoiding both high cultural obscurantism and middlebrow populism. Ballard understood that collage was the great twentieth century artform and that the mediatised unconscious was a collage artist. Where are his twenty-first century inheritors, those who can use the fiction-kits Ballard assembled in the Sixties as diagrams and blueprints for a new kind of fiction?





a world of dread and fear1

“You couldn’t sleep. You had to work.

Always light.

Head against the window, sun coming up —

The troops were gathering on the street below him. The Red Guard in good voice:

SCAB, SCAB, SCAB —

The dawn chorus of the Socialist Republic of South Yorkshire.

Another cup of coffee. Another aspirin”

— David Peace, GB842

David Peace’s GB84 is typed in prose as stark and unforgiving as motorway service station strip-lights.

The harsh expressionist realism Peace honed over the course of the four books of the Red Riding Quartet is perfect for handling GB84’s subject matter, the events of the 1984-85 Miners’ Strike. The Quartet counted forward — 1974-1977-1980-1983 — as if it is was approaching but would never reach the fateful date that will provide the title of GB84. From here we count backwards; GB84 “is actually the last of an inverse post-war trilogy which will include UKDK, a novel about the plot to overthrow Wilson and the subsequent rise of Thatcher and another book, possibly about the Atlee Govt.” From gothic crime to Political gothic…3

The fiercely partisan novel ends with the incantation: “the Year is Zero”. But 1985, when both the strike and the book end, was very far from being a year of beginning or of possibilities for the novel’s “us”. (In fact, the very existence of that “us”, the collective proletarian subject, is itself in question by then. At the same time, however, this is the first of Peace’s novels in which the possibility of any sort of group-subject is raised. More typically, his characters are solipsistically alone, connected only by violence, their only shared project dissimulation.) On the contrary, it was a year of catastrophic defeat, the scale of which would not become apparent for a decade or more. (Perhaps it was only in the election of New Labour twelve years later that the defeat was both registered and finally secured.)

We now know — although this cannot enter into the present tension of the novel — that the strike was about a failed Proletarianisation. After the events the novel describes, what awaited was fragmentation, new opportunities for the few, unemployment and underemployment for the majority. The technique of flying picketing that Scargill had pioneered so successfully in the late Sixties and early Seventies (and which had contributed to the humiliation and collapse of the Heath government) was combatted by a comprehensive range of strategies (including a highly-organised counter-subversion operation run by MI5) that were designed while the Tories were still in opposition. The aim was to fragment miners’ solidarity and to prevent support from sympathetic workers in other industries. In this, the creation of the Working Miners Committee and the Union of Democratic Mineworkers would prove crucial. The deterritorialisation of capital — its transmutation into “messages which pass instantaneously from one nodal point to another across the former globe, the former material world”4 — was not to be met by a complementary deterritorialisation of labour. Miners were inveigled into identifying with their own terrirory rather than with the industry as a whole; hence the return to work of the Nottinghamshire and Derbyshire miners, who believed that they were safeguarding their future but in a satisfying irony found themselves no better off than miners from any other coalfield. Within a decade, the industry would be all but closed down in Britain, with members of the UDM no more likely to be in employment than those of the NUM.

Yes, we know all this, now. But Peace restores drama by excluding any of the knowledge hindsights brings. The events come at you as if they were happening for the first time, and without the emollient shield of an omniscient authorial voice. As Joseph Brooker identifies in a lengthy piece on GB84 in the current issue of Radical Philosophy,5 the novel is bereft of any mediating meta-language. The tragic quality the novel possesses even in its earliest scenes comes courtesy of the knowledge we, the readers, bring — but which is, naturally, is denied to the protagonists — of the eventual course that the strike will take.

Counterfactuals are largely the preserve of the reactionary right, and Peace refuses the temptation to change the facts. He writes his retro-speculative fiction in the spaces between the recorded facts, extrapolating, inferring, guessing. Yet the question the reader cannot help but pose is: what would have happened if the miners had won? (A question that has added piquancy since subsequent revelations have shown that the government was much closer to defeat than was ever suspected at the time.) The narrative in which the strike is now embedded — the only narrative in town, the story of Global Capital — has it that it was part of a receding ebb tide of organised working-class insurgency. Defeat was inevitable, written into the historical passage from Fordism to post-Fordism. The hard left are outflanked, fighting under the banner of the Past for “the history of the Miner. The tradition of the Miner. The legacies of their fathers and their fathers’ fathers.”6

But such a narrativisation is question-begging, since the very credibility of this story relies upon the events of the strike unfolding as they did. What if they hadn’t? Under the aspect of eternity, everything is inevitable and we are all Spinozists. But life has to be lived “forward”, making us Sartreans. Reading the book now inevitably dramatises the tension between these two positions, between knowing that everything has already happened and acting as if it hasn’t.

A gang of doppelgangers, near-duplicates, haunt the pages of GB84, this “fiction based upon a fact”. Peace writes an occulted history of the present by constructing a simulation of the near-past. The dramatis personae do not bear the names of their real-life counterparts, and sometimes don’t have names at all, merely titles designating their structural role: The President, The Chairman, The Minister. Sometimes, real world names are slightly altered; in GB84 the NUM’s Chief Executive Roger Windsor becomes the hapless Terry Winters. The relationship of these simulations to their real-life counterparts is complex. The President is not Scargill. But he’s not not Scargill. No doubt Peace changed the names in part to avoid legal action, but in an odd way the extra imaginative latitude he is granted by not being compelled into fidelity to actual biography gives the characters more reality. He is able to get inside their heads in a way that would not be possible with actual biographical individuals.

The most controversial characterisation is that of Stephen Sweet, the professional strikebreaker based on Thatcher’s right-hand man throughout the strike, David Hart. Hart was the driving force behind the creation of the Working Miners’ Committee and the UDM. In the novel, Sweet is seen planning the crucial battle between police and pickets at the coking plant, Orgreave. (Devoting all its resources to Orgreave is now regarded as a major strategic error by the NUM.) Sweet is referred to throughout the novel as “The Jew”. Although this designation remains uncomfortable — as it is intended to be, Peace has said — suspicions of anti-semitism are immediately rebutted by any sort of close reading of the novel. Everything we see of Sweet is focalised through his chauffeur-factotum, Neil Fontaine. (This distancing is significant, since Sweet’s pomposity and grandiosity strike a slightly unconvincing note. It is almost as if Peace is unable to find the sympathy necessary for a convincing characterisation. On the other hand, perhaps Hart was the faintly absurd figure that Peace paints his fictional counterpart as. Peace does not make the mistake of portraying Sweet as a self-consciously evil figure; on the contrary, Sweet sees his efforts in a messianic light.)

Fontaine, presumably a co-opted member of the working class who has worked for the security services, is a blank slate of a figure, a man reduced to function (he is doubled in the novel by David Johnson, The Mechanic, who becomes an antagonist but who was clearly an ally in the past). It is Fontaine, a man with right-wing affiliations and connections but few passions, who will never stop seeing Sweet as “The Jew”. That description foregrounds the provisional nature of the political alliance that Thatcher built: somehow, the Thatcher programme allowed fascists to consort with Jews, nationalists to find common cause with the agents of multinational capitalism.

Fontaine is also the connecting link between the overt and the covert counter-“subversion” operations undertaken by the state in GB84. It is in the unraveling of the MI5’s role in proceedings that leads Peace into the territory of endemic corruption and betrayal that he staked out so viscerally in the Red Riding Quartet. Unusually for Peace, so skilled at putting himself (and therefore us) into the shoes of irredeemably corrupt power puppets, there is no major character in GB84 who is a policeman. But there are state functionaries: Fontaine, Johnson, but, most vividly, Malcolm Morris, a man whose role is to be a shadow, a cipher, an expert phone-tapper who, in a Francis Baconoid delirium, fancies that his ears are always bleeding…

In GB84, MI5 are the key players in organising Terry Winters’ spectacularly ill-judged trip to Libya. Who can forget the television images of Roger Windsor kissing Gadaffi in his tent? Winters/Windsor’s Libyan visit — only a few months after the policewoman Yvonne Fletcher had been killed by Libyan agents — proved an important, perhaps decisive, PR defeat for the NUM. (The actual role of Libya in the strike was somewhat different: the Thatcher government had illicitly increased oil imports from the supposedly outlawed regime so as to see off the threat of power cuts.) Peace deliberately leaves the degree of Windsor/Winters’ collusion with the security services unclear. He wanted the novel to be a “mess”, like the strike itself.

The doubling of historical fact with Peace’s version of it is internal to the novel’s own structure, whose main fictional thread is cut through by a diary account of the strike by two miners, Martin and Peter. Martin and Peter’s accounts, rendered in the Yorkshire dialect Peace captures so ably, were “not fictionalised”, Peace has said. It is here that Scargill, Macgregor, Thatcher, McGahey and Heathfield appear in their own names. The first person accounts register the grim miseries of the strike, as well as its comaraderie, forming a contrast with the skullduggery, the corruption and the high-level meetings of the novel’s central narrative.

Peace says that he first puts himself into the past, and then imagines. It’s like method writing, or time travel. Peace has tried and tested tricks to get back. He uses jaundiced newsprint, books but most of all pop — not the stuff he would have listened to himself, then, and has listened to ever since, but the songs that, ubiquitous then, forgotten now, can function as audio-madeleines. Digging through the carboot sale detritus of 84 and 85 pop, Peace finds a coded history of the strike secreted beneath the dull sheen of thrownaway post-new pop. GB84 begins with Nena’s execrable “99 Red Balloons”, which here becomes an apocalyptic carnival tune, bursting with all the hopes that will sag and bleed by the end of the novel’s gruelling, long, long march. “Two Tribes” soundtracks the next phase, the confrontation between police and miner (both this and the Nena song, of course, played upon Cold War anxieties when they were released. Another reminder, and there are many in this novel, that 1984 was a world away). The exhilaration and adrenalin of out and out confrontation, Us and Them, gives way to suspicion (who is with us, and who is against us?) “Two Tribes — Must have heard that bloody song ten times a day now for weeks. Ought to make it National Anthem, said Sean.”7 The songs that Peace dredges up for the final phase of the strike are “Careless Whisper” (“guilty feet have got no rhythm”) and, for the 84-85 winter that was cold, but not cold enough — the power cuts never come — Band Aid’s “Do They Know It’s Christmas”. Characters speculate that Band Aid is a government-backed scheme to distract from the plight of the miners, and the line that Peace selects for sampling is, naturally, “There’s a world outside your window, and it’s a world of dread and fear.”

Sampling is precisely the right term, since pop, much more than literature, film or TV (Peace actively distrusts these latter two) provides Peace with a methodology for drilling his words into the repetitions and refrains that are his stock-in-trade. Repetition is a hallmark of Peace’s style; he has famously remarked that the strike was intensely repetitive and that the prose would reflect that. But in all of Peace’s writing, repetition is what substitutes for both plot and character. His crime novels make no attempt to interest readers in the intrigue and enigma of plots; the plot of GB84, meanwhile, is given in advance, a kind of readymade. And one strange quality of Peace’s writing that is not immediately evident is that, although it is unusually intimate — reading his novels is always like rifling through someone else’s most secret places — his characters lack what is usually called “inner life”. They are identified less by a reflexive vitality than by death-drive repetitions, riffs, echoes, habit-forms.

In GB84 the result is more poetic than most poetry; it is, naturally, a poetry stripped of all lyricism, a harshly dissonant word-music. Peace is a writer particularly attentive to sound: the unsleeping vigilance of state power is signified by the “Click, Click” of the telephone tap, the massed ranks of the police by the Krk, Krk of boots and truncheons beaten against shields, both sounds repeated so much that they become background noise, part of the ambience of paranoia. The Telegraph review was right to observe that, “At times, the novel feels like an eardrum buzz, the literary equivalent of late-1970s Northern bands such as Throbbing Gristle and Cabaret Voltaire.” It resembles even more closely the two great post-punk responses to the strike: Mark Stewart’s As the Veneer of Democracy Starts to Fade (Keith Leblanc also produced the single “The Enemy Within”) and Test Department’s The Unacceptable Face of Freedom. Perhaps for this reason, Post-punk recedes as an explicit reference in GB84. It had been present in Nineteen Eighty Three in titles of sections of the novel: “Miss the Girl” (the Creatures) and “There are No Spectators” (the Pop Group). The tone for GB84 is in every sense set by the title of the last section of Nineteen Eighty Three: “Total Eclipse of the Heart”.

Part of the reason that 1985 seemed like the worst year for pop ever was that it was the beginning of the restoration. Up to 1984, British popular and political culture was still a battleground. 1985 was the year of Live Aid, the beginning of a time of the fake consensus that is the cultural expression of global capital. If Live Aid was the non-event that happened, the strike was the Event that didn’t.

Swords and shields. Sticks and stones. Horses and dogs. Blood and bones—

The armies of the dead awoken, arisen for one last battle.

The windscreen of the Granada lit by a massive explosion—

The road. The hedges. The trees—

Fire illuminating the night. The fog now smoke. Blue lights and red—

Terry shook Bill’s arm. Shook it and shook it. Bill opened his eyes—

“Where are we?” shouted Terry. “Where is this place?”

“The start and the end of it all,” said Bill. “Brampton Bierlow. Cortonwood.”

“But what’s going on?” screamed Terry Winters. “What’s happening? What is it?”

“It’s the end of the world,” laughed Bill Reed. “The end of all our worlds.”8





ripley’s glam1

“He hated becoming Thomas Ripley again, hated being nobody, hated putting on his old set of habits again, and feeling that people looked down on him and were bored with him unless he put on an act for them like a clown, feeling incompetent and incapable of doing anything with himself except entertaining people for minutes at a time.”

— Patricia Highsmith, The Talented Mr Ripley2

We can learn a great deal about the glam impulse from these lines from The Talented Mr Ripley.

Significantly, Highsmith wrote the first Ripley novel in 1955 and only returned to the character in 1970. Tom Ripley was not a character that could fit into the rock and roll era, with its emphasis on teen desire, social disruption and Dionysiac excess. But Ripley’s “hedonic conservatism”, his snobbery and his facility with masks and disguise, mean that he would be perfectly at home in the Marienbad-like country estate of glam. If Sixties rock was characterised, on the one hand, by appeals made to the big Other (demands for social change and/or more pleasure) and, on the other hand, by the denial of the existence of the Symbolic order as such (psychedelia), then glam was defined, initially, by a hyperbolic/parodic identification with the big Other — by the return of Signs and/of Status.

In the sentence cited above, there are, evidently, two Toms — “Thomas Ripley” the performed social role, and the Tom who performs that role; Tom the speaking subject and Tom the subject of the statement. At the outset of The Talented Mr Ripley both these Toms are “nobodies” — as a speaking subject, like all speaking subjects, Tom is ontologically nothing; and as the subject of the statement is socially nothing. At this stage, Tom is very far from being the insouciant, poised figure he will appear to be later; he is capable of simulating confidence only when taking on the role of Other people. It is not that Tom lacks status; it is that he has no place whatsoever in the social hierarchy. His status is not even low. His indeterminate social origins and his ability as a mimic and as a forger (skills upon which his anti-career as a fraudster are based) mean that he fits in nowhere (or anywhere). Tom experiences this nothingness in classic existentialist terms, feeling himself to be inchoate, a void, unresolved, unreal.

But the novel is a kind of existentialist picaresque by the end of which Tom has the (financial) means to create a Thomas Ripley he will not hate being. At the beginning of the next novel, Ripley Under Ground, it is immediately evident that Tom has created/become such a figure. Tom has fashioned his best forgery — a Thomas Ripley who is independently wealthy, owns an elegant house in the Paris suburbs and is married to a beautiful, hedonistic heiress. From now on, Ripley’s anxieties will concern not the establishment of an identity, but the preserving and defending of the status he has acquired.

Ripley’s trajectory is uncannily in sync with that of Bryan Ferry. Roxy Music and For Your Pleasure, those exercises in learning and unlearning of accent and manners, are pop’s equivalent of The Talented Mr Ripley. The clothes, the bearing and the voice are faked, but not yet perfectly. The roots still show, and the painful drama of becoming something you are not still carries an existential charge. Stranded and the subsequent albums, meanwhile, are the equivalent of the later novels; here, success is assumed, and the threats to the tasteful but banal idyll come from ennui, a certain unease with contentment, and — most ominous of all — the danger of the past returning. The vapid bucolia of Roxy’s Avalon — recorded when Ferry was himself married to an heiress and living on a country estate — would be the perfect soundtrack to Ripley puttering around in his Harpers and Queens dream home, Belle Ombre, with his wife, Heloise.

The first step to Ripley’s becoming a Something turns out to be his vampirising of the identity of Dickie Greenleaf. I say “turns out” because, contrary to what Anthony Minghella’s film implies, it is clear that Tom does not to go to Europe with the thought of destroying Dickie already in his mind. Ripley is a brilliant improviser, not a planner; the plans he does make are short-term, often leading to more problems than they solve, and he derives enjoyment from cleaning up messes rather than from avoiding them in the first place.

Initially, Tom’s attitude to Dickie is ambivalent and is not straightforwardly predatory — he is aggressive and envious but also affectionate. If Tom is Nothing, a turmoil of unresolved purposes, a tumult of shame and inadequacy, then Dickie is really Something, an Object, resolved and real, possessing “the solidity of a stone”. By taking the place of Dickie, Ripley can escape the pain, anxiety and awkwardness of being himself, a self. To become an Object — to be relieved of the pressures of subjectivity, untroubled by any interiority — isn’t this one of central fantasies of glam?

Žižek is certainly right to argue that the sexualisation of the relationship between Tom and Dickie in Anthony Minghella’s film is a mis-step. Yet Žižek’s interpretation is not fully adequate either. According to Žižek:

Dickie is for Tom not the object of his desire, but the ideal desiring subject, the transferential subject “supposed to know how to desire.” In short, Dickie becomes for Tom his ideal ego, the figure of his imaginary identification: when he repeatedly casts a coveting side-glance at Dickie, he does not thereby betray his erotic desire to engage in sexual commerce with him, to HAVE Dickie, but his desire to BE like Dickie.3

What is missing from Žižek’s analysis is a recognition of the way that Dickie fails to serve as an adequate ideal ego. The pivotal moment of the novel comes when Ripley is no longer capable of sustaining his fantasy identification with Dickie. When Tom looks into Dickie’s eyes and sees not the windows of a soul with which he can identify but the dead, glassy surface of an inert and idiotic dummy, he falls (back) into a deep existential nausea and vertigo, experiencing a moment of profound cosmic loathing and miserable dislocation:

He stared at Dickie’s eyes that were still frowning, the sun bleached eyebrows white and the eyes themselves shining and empty, nothing but little pieces of blue jelly with a black dot in them. You were supposed to see the soul through the eyes, to see the love through the eyes, the one place where you could look at another human being and see what really went on inside, and in Dickie’s eyes Tom saw nothing more than he would have seen if he had looked at the hard, bloodless surface of a mirror. Tom felt a painful wrench in his breast, and he covered his face with his hands. It was as if Dickie had suddenly been snatched away from him. They were not friends. They didn’t know each other. It struck Tom like a horrible truth, true for all time, true for the people he had known in the past and for those he would know in the future: each had stood and would stand before him, and he would know time and time again that he would never know them, and the worst was that there would always be the illusion, for a time, that he did know them, and that he and they were completely in harmony and alike. For an instant the wordless shock of the realisation seemed more than he could bear. He felt in the grip of a fit, as if he would fall to the ground.4

No doubt this is partly a registering of Dickie’s rejection of Tom. But it also expresses Tom’s feelings of revulsion for Dickie. What has been “snatched away” from Tom is not just Dickie “himself”, but the fantasy of Dickie. It is as if Tom is no longer capable of pretending (to himself) that Dickie is anything other than a really rather mediocre person; as if he has encountered, for the first time, the brute, stupid physicality of Dickie — has seen Dickie, directly, without the screen/sheen of fantasy to beatify him.

Tom’s break from Dickie is inevitable after the desperately painful scene, slightly earlier, when Dickie discovers Tom wearing his clothes and imitating him in front of the mirror. Dickie is disgusted and angered by Tom’s imitation (what is more horrifying than being someone else’s ideal ego?), just as Tom is utterly mortified by the fact that Dickie has discovered him in the act (what is more shameful than being caught by your ego ideal fantasising about them?). Significantly, Dickie makes the same error as Minghella, (mis) interpreting Tom’s behaviour in terms of sexual obsession, choosing this moment to emphatically deny to Tom that he is “queer”. But Tom’s wanting to be Dickie is far more obscene, far more deadly, far more Burroughsian, than his wanting to have him would have been.

Once Tom can no longer sustain his fantasy identification with Dickie, the logic of his psychosis insists that he will only be able to resolve his existential crisis — his lack of Being — by killing Dickie. That is partly because, in Ripley’s mind, Dickie is already dead: a soulless shell who illegitimately possesses wealth and social status that the more tasteful and refined Tom feels that he rightfully deserves. Tom is sure that he can be Dickie better than Dickie himself could be, and Dickie will be the daub that Tom will use as the basis for his masterpiece, the new Thomas Ripley. There is also a sense in which, by killing Dickie, Tom “earns” his place in the unproductive leisure class. Even before he is elevated into the leisure class, Tom shares its disdain for “drudgery”. The difference between Tom the common thief and con artist and Tom the member of the leisured elite is a successful act of violence. Veblen argues that “leisure class society” is founded on the “barbarian” distinction between exploit — “the conversion to his own ends of energies previously directed to some end by another agent” — and industry (or drudgery) — “the effort that goes to create a new thing with a new, (‘brute’) material”.5 The Masters must always vampirise, never produce.

The performance of productive work, or employment in personal service, falls under the same odium for the same reason. An invidious distinction arises between exploit and acquisition by seizure on the one hand and industrial employment on the other. Labour acquires a character of irksomeness by virtue of the indignity imputed to it.6

Hunting has always been one of the activities upon which the leisured elite has prided itself, and Ripley is a consummate hunter (prey is one of the meanings of Ripley’s Game).

The use of homicidal violence to achieve and protect a position of privilege is very far from being aberrant, and Tom is no more likely to face justice than are the brigands of our real life ruling elites. (Highsmith’s refusal to impose a justice in the novels that is conspicuously lacking in the world is one of the most subversive aspects of her depictions of the character.) If Tom is pathological, his pathologies are the pathologies of a class; it is only the freshness of the blood of his victims (and his willingness to spill it himself) that separates Ripley’s exploits from those of his new peers. Yet Ripley is not a Slasher who enjoys killing. On the contrary, he is horrifying because he treats murder as a practical task devoid of any special existential or affective charge. Ripley’s commission of murders are remarkable for their their coldness and lack of cruelty; famously, Ripley only kills because he needs to, not because he enjoys it. Ripley kills out of cold, utilitarian logic, eliminating those who stand in his way or threaten to expose him. Again, far from being aberrant, a carefully maintained distinction between a violent, obscene underside and a bland, official front is the normal practice of power and privilege. It is not moral scruples that motivate Ripley (he notoriously has none), but a fear of humiliation. As Julie Walker argues:

What Tom does fear is unmasking; not merely the unmasking of himself as Dickie or even the unmasking of himself as a killer but the unmasking of his lack of a real self and therefore his self-perceived inadequacy in the face of others — there is no appreciable difference between fear of discovery for his tax scam or for his murders. His main fear is that of socially not quite making the grade.

This rendition of amorality is what is (post)modern about Ripley. Classic psychosis consisted in the confusion of the Real and the Symbolic (the most obvious example of which would be hearing the voice of God). But Ripley’s psychosis resides in his conviction that only the big Other exists. Tom is not troubled by specific, named others being aware of, or suspecting, his criminality, so long as his crimes are not Symbolically inscribed. What is distinctive about Ripley’s postmodern take on the big Other is that it is radically atheistic — he neither believes in God nor in any moral order written into the fabric of the universe. The postmodern big Other is a Symbolic Order stripped of its symbolisation of itself; it no longer poses as God or History and openly announces itself as a social construct — but this ostensible demystification does nothing to impede its functioning. On the contrary, the big Other has never functioned more effectively.





methods of dreaming1

Two novels that — purely by coincidence, or so it would seem — I happened to read one after the other which both draw on dreaming, but which emphasise opposite poles of the dreaming experience.

Christopher Priest’s A Dream Of Wessex (1977) is about a collective dreaming project, a government-sponsored initiative to tap the unconscious in order to come up with solutions to the economic and political problems that have paralysed the society in the novel’s present day of 1985. In the projected future world, the USA has converted to Islam and the UK has been annexed by the Soviet Union. The result is a strange kind of utopia, in which the bureaucratic provides a background to the bucolic: the irritations of the Soviet official machinery seem built into the dreamspace as a necessary precondition for the aching languor of the Wessex idyll, where everyday life is suffused by a Mediterranean eroticism. Priest conjures the atmosphere of a gentle solar trance, broken, significantly, by small circular mirrors, which are used to trigger the dreamer’s return to the dismal drizzle of the novel’s real world.

Once inside the Wessex projection, the participants cannot remember their real world identities. This means that, although they are referred to by the same name, the dreamers in the simulation are different entities from their real world counterparts (just as any dreamer is a different being from their double in waking life). A classic case of the Real (of unconscious wishes) versus reality. When they exit the Wessex simulation, the dreamers are replaced in the consensual hallucination by placeholder doppelgangers, programmed selves that, possessing no inner life, only exist for the Others in the dreamspace. Some of the participants come to recognise the points at which other dreamers depart from the simulation and come back to it: something in the other, that which is in them more than themselves perhaps, disappears or (seemingly miraculously) returns. What the novel renders especially powerfully is the overwhelming, intoxicating intensity of erotic connections with a dream Other, the uncanny sense of recognition, the deja vu of dreamlove. In the case of A Dream Of Wessex, the sense of recognition between the lovers can be accounted for by the fact that the two, Julia and David, know each other in the novel’s real world; and yet Julia and David are not in love in the real world, nor is there any suggestion that they would necessarily fall in love. It is their dream-selves that fall for each other. What ultimately unsettles the idyll is the kind of reality bleed or ontological haemorrhage which Priest’s later novels all turn around. A Dream Of Wessex looks forward to Gibson’s cyberspace, but it is also a vision of the Sixties recalled at the bitter end of the Seventies.

Kazuo Ishiguro’s The Unconsoled (1995) makes contact with another kind of dream space-time altogether. The novel is well-titled since it plunges us, like Alice projected into Wonderland, into a world without consolation, a world of unrelieved urgencies. This is the first and most obvious point of contrast with A Dream Of Wessex, where the official imperatives, both inside and outside the dreamspace, operate as receding pretexts for libidinal trajectories which depart from “what should be happening” (this tendency puts the whole project at risk). In The Unconsoled, the official too recedes, but assumes now not the benign quality of the libidinal pretext (the ostensible goal which allows jouissance to happen precisely by being endlessly missed) but the tortuous, tantalising, thwarted object whose failure to be attained casts a pall of terrible anxiety over everything.

Upon arriving in a nameless central European city to give a performance, the renowned pianist Ryder finds himself assailed by countless demands which distract him from his official duties, but which he seems powerless to resist. He must listen to young hopefuls playing the piano; he must speak at late-night meetings of which he was not previously aware; he must go to the outskirts of the city and be photographed in front of a monument whose significance he does not understand. New urgencies are embedded within older urgencies, endlessly.

The Unconsoled is, in part, a pastiche of Kafka, and what Ishiguro borrows from Kafka above all else is his oneiric geography, at once bizarre and strangely familiar. Spaces which had seemed to be very far from one another are suddenly revealed to be adjacent; a meeting hall which Ryder has traveled to turns out to be the very hotel that he started from. This allows problems which had seemed intractable to suddenly resolve themselves; yet the solutions bring no relief, for by now Ryder has been gripped by another urgency. The previous imperative, once so overwhelmingly important, recedes into irrelevance at the moment the next one arrives.

In The Unconsoled, as in Kafka, this perverse spatiality of contiguity without consistency arises because all space (and time) is subordinated to the urgency. There is no time except that of the urgency; and all space is curved by the urgency (and its frustrations). Obstacles suddenly emerge: most notably a wall that inexplicably looms up at the last moment preventing Ryder from getting to the concert hall where he is due to give his recital. The hectic pace is driven by the improvisational logic of retrospective confabulation, which is always making sense of things a moment too late. Ryder is perpetually noticing things that should have been obvious. As with Kafka, then, The Unconsoled is coloured by an ingenue’s sense of embarrassment.

Two opposed methods of dreaming, then: the one languid, laconic, the other harried, harassed.





atwood’s anti-capitalism1

“Regressive it all is”, Jameson remarks of the “God’s Gardeners” cult in Atwood’s The Year of the Flood, adding a provocative parenthesis: “it is always helpful to wonder what politics today could possibly be otherwise.”2 The Year of the Flood is disappointing in part because it has no alternatives to regression — the only way forward, it seems, is back to nature.

It isn’t the focus on religion per se that is the signature of this regression; rather, it is Atwood’s retreat from the questions about religion that Oryx and Crake posed so intriguingly. One of the climactic moments of Oryx was the foundation of religious feeling amongst the lab-designed neo-noble savages, the Crakers. As per Totem and Taboo and Moses And Monotheism, the religion emerges as a consequence of the death of the father figure. Ironies abound here: since the “Crakers” were made, not begotten, the “father” is actually their creator-designer, the misanthropic wunderkind Crake — who had precisely designed them without the neurological configuration which he believes gives rise to religion. Crake is not so much an eliminative materialist as a materialist eliminativist: “Crake thought he’d done away with all that, eliminated what he called the G-spot in the brain. God is a cluster of neurons, he’d maintained. It had been a difficult problem, though: take out too much in the area and you got a zombie or a psychopath.” If, at first sight, the emergence of religion amongst the Crakers appears to be a kind of miracle, in the end it is only a testament to the power of other (psychoanalytic and cultural) determining factors in addition to neurology.

Crake’s experiments constitute a retort to the hoary old reactionary homily that utopia is alien to human nature. (For a recent version of this, see one of the antagonists in Žižek’s latest book, the uber-capitalist realist Guy Sorman3, with his claim that, “w ()hatever the truths uncovered by economic science, the free market is finally only the reflection of human nature, itself hardly perfectible.”) If that’s the case, Crake concludes with the pragmatism of the autist, we should change human nature: the means are now available. Crake in effect responds to Freud’s argument in Civilisation and its Discontents that, even if property relations were made egalitarian, antagonism would continue to arise because of sexual competition. “Maybe Crake was right,” Snowman reflects,

Under the old dispensation, sexual competition had been relentless and cruel: for every pair of happy lovers there was a dejected onlooker, the one excluded. Love was its own transparent bubble-dome you could see the two inside it, but you couldn’t get in there yourself. That had been the milder form: the single man at the window, drinking himself into oblivion to the mournful strains of the tango. But such things could escalate into violence. Extreme emotions could be lethal. If I can’t have you nobody will, and so forth. Death could set in.4

So Crake replaces what Toby in The Year of the Flood calls “romantic pain” with sedate animal courtship rituals. “Their sexuality was not a constant torment to them, not a cloud of turbulent hormones: they came into heat and regular intervals, as did most other mammals other than man.”5 It would have been fascinating for Atwood to have given a fictional testing to Crake’s claim to have eliminated hierarchy, hunger and racism amongst his genetic creations. There’s also the problem of language. The Crakers are able to maintain their genetically-designed innocence, Atwood suggests, because they lack the past subjunctive tense. (“T ()he idea of the immortality of the soul … () was a consequence of grammar. And so was God, because as soon as there is a past tense, there has to be a past before the past until you get to I don’t know, and that’s what God is. It’s what you don’t know — the dark, the hidden, the underside of the visible, and all because we have grammar.”6 But, this too, is fixable with a little genetic engineering: “G () rammar would be impossible without the FoxP2 gene gene.”)

Yet the loss of Crake — which is nothing less than an encounter with loss and negation itself — threatens to project the Crakers out of their animal-time into the wounded time of human abjection. But the Crakers recede from focus in The Year of the Flood: a sign, perhaps, that Atwood has lost interest in them, or — maybe — that such creatures cannot elicit much interest from beings such as us. What looms to the fore in the narrative is the progressive-regressive religious form that a less pacific group of humans cleave to in the dying days of the world.

Atwood has said that one inspiration for the creation of the eco-religion was “the death of her father and mother … () and the necessity to choose hymns for their funerals that would have been acceptable to them: both were scientists.” It’s easy to sneer at the difficulty that Atwood touches upon here, and the familiar problems of reconciling religion and science may ultimately be less intractable than the issue of symbolic deficit in contemporary secularism that she is pointing to. Atheism has yet to come up with rituals that can muster the symbolic weight of religion, and there are strong reasons to suspect that the failure is more than a contingent one. That’s because Atheism typically construes the death of God in terms of a disavowal of the Symbolic (=big Other) itself. There’s a close fit between this quintessentially postmodern disavowal — where official denial of the existence of the big Other is combined with a de facto observance of the symbolic at another level — and capitalist realism. As Althusser realised, the rituals of capitalist ideology function all the better for not being acknowledged as rituals at all. In place of the intransigent solemnity of the religious ritual, postmodern secularism presents us with either an eschewal of ritual altogether (no need for any kind ceremony), or “write-your-own-vows” personalisation, or a kind of ersatz humanist-kitsch, in which religious form is preserved even as belief in a supernatural God is denied. The problem is not a secular “lack of meaning”, but almost the opposite: it is religious rituals’ very meaninglessness, their lack of personal significance, which gives them much of their power. Partly, as Jameson suggests in his LRB piece on The Year of the Flood, the problem is time: any new “belief system” “demands a supplement in the form of deep time, ancient cultural custom, or revelation itself”. Time precisely allows a ritual to become a custom, an empty form to which the individual is subjected — and, very far from being a disadvantage, this is what yields funeral rites much of their power to console.

Mourning and loss are not only at the origins of religion, but also, it goes without saying, at the root of much of its continuing appeal. One of the most contentious — and borderline acrimonious — discussions amongst students that I’ve seen for a while came up in a session on Philosophy of Religion that I taught earlier this year. What prompted the controversy was my contention that atheism has far more of a problem with evil and suffering than religion does — not least because of the suffering of those who are now dead. Ivan Karamazov’s howl of anguish can be directed at the atheist architects of the radiant city as much as at God, since what can any revolutionary eschatology, no matter how glorious, do about the agonies of those who are long dead? No amount of secular good will can guarantee any correlation between virtue and happiness, as Kant argues in an incendiary passage of “The Critique of Teleological Judgment”:

Deceit, violence, and envy will be rife around the righteous non-believer (), even though he himself is benevolent. Moreover, as concerns the other righteous people, he meets: no matter how worthy of happiness they may be, nature, which pays no attention to that, will still subject them to all the evils of deprivation, disease, and untimely death, just like all the other animals on the earth. And they will stay subjected to these evils always, until one vast tomb engulfs them one and all (honest or not, that makes no difference here), and hurls them, who managed to believe that they were the final purpose of creation, back into the abyss of the purposeless chaos of matter from which they were taken.7

Note also that Kant’s argument here applies equally well to the neopaganism of God’s Gardeners as it does to “righteous non-believers”, for Kant absolutely refuses the equation of nature with beneficence that the Gardeners preach. On the contrary, Kant argues, God is necessary to make good a nature characterised by amoral purposelessness. The true atheist must be able to look this “vast tomb”, this “abyss of purposeless chaos”, full in the face — whereas I suspect that most (of us) non-believers manage only to look away from it. But Kant’s moral argument is less easily dismissed than it would appear, because it is far harder to eliminate belief in a providential structure of the universe than we first imagine — precisely because this kind of belief lurks far beneath anything that we would admit to accepting. (Watch an edition of Deal or No Deal, though, and it’s clear that many openly evince such a belief.) Perhaps it would indeed take a Crake’s genetic tinkering to eradicate it.

The problem with The Year of the Flood is that politics and religion become synonymous — and while there’s every reason to be positive about politicised religion, there are deep problems with a politics which cannot shed the redemptive and messianic mantles of religious eschatology. It’s striking how much God’s Gardeners resemble the Greens as abominated by Sorman, in a passage quoted in First As Tragedy, Then As Farce:

No ordinary rioters, the Greens are the priests of a new religion that puts nature above humankind. The ecology movement is not a nice peace-and-love lobby but a revolutionary force. Like many a modern-day religion, its designated evils are ostensibly decried on the basis of scientific knowledge: global warming, species extinction, loss of biodiversity, superweeds. In fact, all these threats are figments of the Green imagination. Greens borrow their vocabulary for science without availing themselves of its rationality. Their method is not new; Marx and Engels also pretended to root their world vision in the science of their time, Darwinism.8

Atwood makes a case for such a religion. (Clarifactory note: just to be 100% clear — I in no way endorse Sorman’s views of the Greens. I just thought it was amusing that Atwood constructed an eco-cult which so closely fitted Sorman’s stereotype.) In an exchange with Richard Dawkins on Newsnight a couple of weeks ago, Atwood maintained that arguing against religion from the perspective of evolution makes little sense, because the persistence of religion itself suggests that it confers evolutionary benefit on humans. Given this, Atwood suggested, religion should be used as a tool for “progressive” struggles; and Adam One, the leader of God’s Gardeners, is interesting only when he sounds like a Machiavelli or a Strauss, who uses religion to manipulate popular sentiment — the rest of the time his ecopiousness is made bearable only by virtue of Atwood’s gentle satirical teasing (witness, for instance, the convolutions into which Gardener-doctrine is forced in its attempts to reconcile vegetarianism with both the carnivorebias of the Bible and the “amoral chaos” of a nature red in tooth and claw). Initially, what appeals about the idea of God’s Gardeners is the promise that Atwood will describe a new kind of political organisation. Yet the Gardeners’ doctrine and structure turns out to be a disappointing ragbag of stale and drab No Logo-like anti-consumerist asceticism, primitivist lore, natural remedies and self-defence that is as alluring as last week’s patchouli oil. Ultimately, The Year of the Flood feels like a symptom of the libidinal and symbolic impasses of so much so-called anti-capitalism. Atwood imagines the end of capitalism, but only after the end of the world. Oryx was like the first part of Wall-E; The Year of the Flood is like the second part, where we find that the last survivor was nothing of the sort, and there were existing bands of human beings already wandering around, mysteriously just out of sight. (At least in Wall-E the surviving humans were off-world, whereas in Oryx, we are now asked to believe, they had somehow remained just outside Snowman’s eyeline.) It has a retrospectively deflationary effect, subtracting most of the pathos and nobility from Snowman’s plight, and converting what had seemed like a cyberpunk-Beckett tragicomedy into mere comedy. (Incidentally, perhaps the greatest “achievement” of The Year of the Flood is that, by the end, it no longer feels like an Atwood novel at all. Instead, it’s written in the kind of functional prose of a middling Stephen King novel, and populated by cyberpunk genre-standard hardass women, in a post-apocalyptic setting which is surprisingly lacking in vividness. The result is what Robert Macfarlane memorably calls a “dystoap-opera”.)

The question that kept recurring when I was reading both Oryx and Crake and The Year of the Flood was: why do these books not succeed in the way that The Handmaid’s Tale did? If The Handmaid’s Tale was an exemplary dystopia, it was because the novel made contact with the Imaginary-Real of neoconservatism. Gilead was “Real” at the level of a neo-conservative desire that was operating in the Reaganite Eighties; a virtual present that conditioned the actual present. Offred, the handmaids, the Marthas, the Wall — these names have the resonant consistency of a world. But Atwood does not have so assured a handle on neoliberalism as she did on neoconservatism. Atwood gives every appearance of underestimating the cheap poetry of brands, banal as it is; her corporate names are ugly and clunky, no doubt deliberately so — perhaps this is the way that she hears the absurd infantilisms of late capitalist semiotics. AnooYoo, HelthWyzer, Happicuppa, ReJoovenEssens, and — most ungainly of all — Sea(H)ear Candies: these practically caused me physical pain to read, and it is hard to conceive of any world in which these would be leading brands. Atwood’s mistake is always the same — the names are unsightly plays on the function or service that the corporations offer, whereas capitalism’s top brand names — Coca-Cola, Google, Starbucks — have attained an asignifying abstraction, in which any reference to what the corporation does is merely vestigial. Capitalist semiotics echo capital’s own tendency towards ever-increasing abstraction. (For the Imaginary-Real of neoliberalism, you’d be far better off reading Nick Land’s Nineties texts, shortly to be re-published.) Atwood’s names for genetically-spliced animals — the pigoon, the spoat/gider, the liobam — are also examples of linguistic butchery; perhaps she was trying to provide a parallel in language for the denaturalising violence of genetic engineering. In any case, these linguistic monsters are unlikely to roam far beyond Atwood’s texts (they certainly don’t have anything like the dark sleekness and hyperstitional puissance of, say, Gibson’s neologisms).

But the principal failing of The Year of the Flood’s anti-capitalism consists in its inability to grasp the way in which capitalism has absorbed the organic and the green. Some of the strongest passages in Žižek’s First As Tragedy, Then As Farce keep reiterating this message. (One of my favourite lines in the book: “Who really believes that half-rotten and overpriced ‘organic’ apples are really healthier than the non-organic varieties?”) Needless to say, while any credible leftism must make ecological issues central it is a mistake to seek out an “authentic” organicism beyond capitalism’s simulated-organic. (Another of my favourite lines in First As Tragedy: “if there is one good thing about capitalism, it is that, precisely, mother earth now no longer exists.”) Organicism is the problem, and it’s not some eco-spirituality that will save the human environment (if it can be saved), but new modes of organisation and management.





toy stories: puppets, dolls and horror stories1

“In many horror stories there is an assortment of figures that appear as walk-ons or extras whose purpose is to lend their spooky presence to a narrative for atmosphere alone, while the real bogey is something else altogether. Puppets, dolls, and other caricatures of the human often make cameo appearances as shapes sagging in the corner of a child’s bedroom or lolling on the shelves of a toy store … () As backdrops or bit-players, imitations of the human form have a symbolic value because they seem connected to another world, one that is all harm and disorder- the kind of place we sometimes feel is a model for our own home ground, which we must believe is passably sound and secure, or at least not an environment where we might mistake a counterfeit person for the real thing.”

— Thomas Ligotti, The Conspiracy Against the Human Race2

So writes the horror author Thomas Ligotti in his recently published book, The Conspiracy Against the Human Race. The book is not a work of fiction — it is, instead, a work of amateur philosophy in the best possible sense, driven by a metaphysical hunger that is so often lacking in the work of professional philosophers. Ligotti is unembarrassed to return to those questions which academic philosophers typically disdain in favour of an entanglement in scholarly minutiae. Why is there something rather than nothing? Should we be glad to be alive? Ligotti’s answer to this latter question is emphatically in the negative. Possessed of a cold, sober seriousness that couldn’t be more at odds with the atmosphere of cheery vitalism and inane lightness that prevails in early twenty-first-century culture, The Conspiracy Against the Human Race has the feel of a nineteenth-century tract.

Puppets are one of the leitmotifs of Ligotti’s work, but the terror that they cause does not primarily arise from any malicious intentions on their part, or from the suspicion that they might secretly move when we do not watch them. Rather, the puppet is an emissary of what Ligotti repeatedly characterises in The Conspiracy Against the Human Race as the “malignantly useless” nature of the cosmos itself. The painted-faced marionette is a symbol of the horror of consciousness, the instrument which, for Ligotti, allows that “malignant uselessness” to be perceived, and which brings all suffering into the world.

The puppet is a figure which belongs equally as much to the children’s story as to the weird tale. Ian Penman has written of how the most famous puppet story, Carlo Collodi’s The Adventures of Pinocchio (1883),

contains scarcely credible levels of cruelty and pain … () Accusations of abuse. Thrown hammers. Burned-off feet. Children used as firewood: innocence kindling. Curiosity rewarded with concussion and kidnap. Hanging, amputation, suffocation. A snake laughs so hard at Pinocchio’s fear he bursts an artery and dies. On his way to school Pinocchio sells his schoolbooks to join a Street Theatre: forget education, become a marionette. A dancing fool. Apprentice Golem. Malignant clown. Neuter, castrato.

(Penman’s remarks were made in the piece that he contributed to a book on Michael Jackson I edited last year — and Jackson’s own story is one in which kitsch and Gothic, puppet and master manipulator, frequently reversed into one another.3)

On his blog on memory and technology, Bat, Bean, Beam, the theorist Giovanni Tiso recently noted the echoes of Pinocchio in the Toy Story films.4 For the Marxist Richard Seymour,

Toy Story 3 is a story of how freedom is achieved through commodification, and how “the consent of the governed” roughly equals the willing embrace of bondage … () Everyone, and everything, has its place in the Toy Story scheme of things. That scheme is a hierarchy of commodities with toys near the bottom, subordinate and devoted to their owners.5

Yet, at an ontological level, the Toy Story films constitute something of a “tangled hierarchy”. The toys that are depicted in the films do not only exist at the “ontologically inferior” level of the film’s fiction; they are real in the sense that you can buy them outside the cinema. In Ligotti, puppets and puppetry frequently symbolise this tangling of ontological hierarchy: what should be at the “inferior” level of the manipulated manikin suddenly achieves agency, and, even more horrifyingly, what is at the supposedly “superior” level of the puppet master suddenly finds itself drawn into the marionette theatre. Ligotti writes that it is a terrible fate indeed

when a human being becomes objectified as a puppet and enters a world that he or she thought was just a creepy place inside of ours. What a jolt to find oneself a prisoner in this sinister sphere, reduced to a composite mechanism looking out on the land of the human, or that which we believe to be human by any definition of it, and yet be exiled from it.

With Ligotti, it is not clear which is the more terrifying prospect — an ultimate puppet master pulling the strings or the strings fraying off into blind senseless chaos.

Tiso noticed something peculiar about the desire of the toys in the Toy Story series: “what they like best is to be played with by children. But it so happens that at those times they are limp and inanimate; as is the case whenever they are in the presence of people, their spark abandons them, their eyes become vacant.”6 It’s as if the message of the Toy Story films rhymes with that of Ligotti’s pessimistic tract: consciousness is not a blessing bestowed on us by a kindly toymaker standing in for a beneficent God, but a loathsome curse.





Zer0 books statement1

Contemporary culture has eliminated both the concept of the public and the figure of the intellectual. Former public spaces — both physical and cultural — are now either derelict or colonised by advertising. A cretinous anti-intellectualism presides, cheered by expensively educated hacks in the pay of multinational corporations who reassure their bored readers that there is no need to rouse themselves from their interpassive stupor. The informal censorship internalised and propagated by the cultural workers of late capitalism generates a banal conformity that the propaganda chiefs of Stalinism could only have dreamt of imposing. Zer0 books knows that another kind of discourse — intellectual without being academic, popular without being populist — is not only possible: it is already flourishing, in the regions beyond the striplit malls of so-called mass media and the neurotically bureaucratic halls of the academy. Zer0 is committed to the idea of publishing as a making public of the intellectual. It is convinced that in the unthinking, blandly consensual culture in which we live, critical and engaged theoretical reflection is more important than ever before.





PART TWO

SCREENS, DREAMS AND SPECTRES: FILM AND TELEVISION





a spoonful of sugar1

The worst aspect of Dennis Potter’s final two indulgent and indulged works (Cold Lazarus and Karaoke) was that they had the effect of retrospectively introducing doubts over everything else he’d done. Could he possibly be anything like as good as we’d always believed?

Actually, there’s a case for saying that, if 1986’s The Singing Detective marked the peak of Potter’s career, it also preceded a slow and painful decline. It would only be slightly harsh to say that everything after 1986 was either formulaic reiteration (Lipstick On Your Collar) or tortuously introspective, failed experimentalism (Blackeyes, the film Secret Friends). By the time of his death in 1994, Potter had been lionised by the great and good everywhere, his reputation for controversy forgotten (or forgiven?). Melvyn Bragg’s famous interview-cum-hagiography elevated Potter to the state of an unimpeachable morphine saint. All of this solemnity had the effect of devitalising Potter’s work, prematurely shrouding it with all the cobwebs of respectability and reverence.

Well, I had the opportunity to see Potter’s 1976 masterpiece Brimstone and Treacle again very recently. (The play is shortly to be reissued as part of a must-have Potter DVD boxset, which also includes The Singing Detective, Pennies from Heaven and Casanova). In 2004, when TV drama is corporate, committee-driven, blandly homogenous, Potter looks even more of an anomaly than ever. Today, there’s almost no way of identifying TV dramas by who has written them; they are routinely conceived of as vehicles for actors, not authors. By contrast, even at its worst, Potter’s work was marked by an indelible signature, characterised by a singular VISION. (The tendency to fall back on these trademark elements without remixing them was one of the weaknesses of his last pieces.) It’s hard to imagine that Potter’s peculiar portfolio of obsessions and techniques (his playful anti-naturalism, his disturbed disquisitions on sexuality, politics and religion, his loving interrogation of the appeal of pop music and pulp genres, his exemplification/ analysis of misogyny) would get past our Noughties culture’s gatekeepers (which might be tolerant of representations of sex, but which are, in every other way, more censorious than those of the Seventies). As the Independent pointed out when it reappraised Potter in the light of the US film version of The Singing Detective, his influence is more likely to be felt on American than on British TV, in an expressionist drama such as Six Feet Under or even in the delirial departures from naturalism of something like Ally McBeal.

In any case, Potter did fall foul of Seventies sensibilities with Brimstone and Treacle. Filmed in March 1976, it was due for broadcast as a Play for Today in April, but was pulled at the last minute when the BBC authorities quailed at its “nauseating” qualities. It didn’t surface until over a decade later, when, in the wake of the success of The Singing Detective, the play was eventually shown in 1987. An inferior film version, starring Sting, was released in 1982.

Brimstone and Treacle features a young Michael Kitchen as the devil. In an echo of Potter’s earlier “visitation” plays, Kitchen’s character, Martin, inveigles himself into people’s lives and homes by cold reading them like a stage hypnotist.

Potter’s vision of evil is a million miles away from the white-catting portentousness or Pacino-like histrionics to which countless clichéd cinema renderings have accustomed us. Kitchen’s devil is impeccably polite, insufferably, cloyingly nice, sanctimoniously religiose. “Religiose” is a word Potter used with a particular contempt, carefully contrasting its pious pomposity with what he saw as the genuine religious sensibility.

The play opens with two epigraphs: the first from Kierkegaard’s Fear and Trembling: “there dwells infinitely more good in a demoniac than in a trivial person”, the second from Mary Poppins (“A spoonful of sugar helps the medicine go down”). For Kierkegaard, the most pressing danger for Christianity was not doubt, but the kind of bluff certainty peddled by pompous philosophers like Hegel. Kierkegaard’s Faith was indistinguishable from terrible anxiety. The paradox of Faith for Kierkegaard was that, if God completely revealed himself, Faith would be unnecessary. Faith is not a form of knowing; on the contrary. Kierkegaard’s models were Abraham on the day he was asked to sacrifice Isaac and Jesus’ disciples: tormented by uncertainty, unmoored from any of society’s ethical anchors, staking their life on fabulous improbabilities.

Martin is a perverse double of 1976’s most iconic of icons, Johnny Rotten, that demonic purge of trivia and mediocrity. If Rotten’s Nietzscheanism (“I yam an antichrist”) concealed a burning core of righteousness, Martin’s surface charm belies malevolence. At the limit though, what both Rotten and Martin show is the deep complicity of “good” and “evil”, their mutual interdependence. Both Martin and Rotten are ultimately deliverers, destroyers of fragile status quos, bringers of disequilibrium and agents of chaos. Punk’s greatest disgust was with the trivial and the mediocre, with the existential death of boredom. The decadence would be cleansed by rage (cf the apopleptic Colin Blakeley in Potter’s 1969 version of Christ’s life, Son of Man).

Brimstone and Treacle begins with Martin accosting Denholm Elliott’s Mr Bates in the street. Martin’s questioning quickly establishes that Bates has a daughter, suffering from apparently incurable neurological damage after being hit by a car two years previously. Posing as an unrequited admirer of the daughter, Pattie, Martin insinuates his way into the Bates’ home. The house is a suburban fortress incubating quiet desperation, nagging frustration and unspoken betrayals. You can almost smell the house, thick with the stench of unaired rooms, the pulped food with which Pattie is spoonfed — and despair. Martin’s incursion is greeted with initial suspicion and circumspection by Mr Bates, but welcomed by the easily beguiled Mrs Bates (Patricia Lawrence), eager to clutch at any potential escape route from the treadmill of drudgery in which she is confined. While Bates has given up any hope of Pattie recovering, his wife cherishes the seemingly impossible dream of a miraculous return to health.

Kitchen’s performance is magnificent, but it is Elliott who steals the show. He manages, incredibly, to make the obnoxious and unpleasant Bates, a neophyte National Front supporter, painfully sympathetic. The scene in which Bates regales his wife and Martin with a desperately unfunny Irish “joke” is excruciating. Elliot renders Bates’ typical expression as a grimace — of irritation, suppressed rage, bewilderment. It is the expression of a whole class, a whole generation’s, incredulity that the world no longer belongs to them, if it ever did. Bates’ political pathology is rooted in a bewildered and misconceived nostalgia, a bleary and inarticulate longing for the world to be like it used to be. He’s a bit like the average Britpop fan would be twenty years later.

Potter is at his most politically acute here, in his exposing of the proximity of a respectable, “common-sense”, Daily Mail agenda to that of the far right. Potter locates Anglo-fascism’s Seventies heartland behind the politely manicured lawns and privet hedges of suburbia. Martin wins Bates over by agreeing with him that “we need to get rid of the blacks”. “It’s so good to have an intelligent conversation like this”, Bates enthuses, cracking open the scotch. However, Martin’s gleeful description of what will happen when “they won’t go”, “we’ll round them up, put them in camps” — makes Bates blanche. Mrs Bates is not so convinced. “You can be too nice you know.”

Brimstone and Treacle is disturbing, ethically opaque. It is troubling for reasons other than those of cultural or political conservatism. The denouement sees Martin’s raping of Pattie shocking her into an unexpected recovery (which itself prompts the play’s final shocking revelation, which I won’t give away for the sake of those who haven’t seen it yet). There is no easily digestible “message”. It’s a bitter pill rather than a spoonful of sugar.





she’s not my mother1

“Interviewer: It’s hard to see this movie and not consider that all our memories are creations.

Cronenberg: But they are, they totally are.”

— Andrew O’Hehir, “The Baron of Blood does Bergman”2

“Watch from the wings as the scenes were replaying. We saw ourselves now as we never had seen.”

— Joy Division, “Decades”3

Cronenberg’s Spider — adapted from Patrick McGrath’s superb novel — is a study of schizophrenia that couldn’t be further removed from the clichéd image of “madness” in cinema. There are numerous examples of this, but the one that comes immediately to mind (perhaps because I watched it recently) is Windom Earl in the second season of Twin Peaks: gibbering, histrionic, megalomaniac. Think also of Nicholson’s Joker in the first Batman movie. Madness is here imaged as a kind of absurdly inflated ego; a self that knows no bounds, which wants to expand itself infinitely. As played by Ralph Fiennes in Cronenberg’s film, Spider, too, has a precarious sense of his own limits, but, far from wanting to spread further into the world, he seems to want to make himself disappear. Everything about him — his mumbling speech, shambling movements — screams withdrawal, retreat, terror of the outside. That’s because, as ever in Cronenberg’s schizoverse, the outside is already inside. And the reverse.

McGrath’s novel is set entirely within the head of its archetypal unreliable narrator, Spider, since it is written as a series of diary entries. To simulate this, Cronenberg could have gone with the strategy employed in the early versions of the script and used voiceover (although anyone who’s seen Spike Jonze’s Adaptation will remember Robert Mckee’s rant about that particular technique). In the end, Cronenberg strips out Spider’s narrative voice altogether, with the result that the film is, in a strange way, truer to the novel than the novel itself. In the novel, Spider’s articulacy gives him a kind of self-awareness and (albeit limited) transcendence of his mania. In the film, there is no distance, no narrative voice, only a ceaselessly productive narrative machine, chattering out multiple permutations. In place of the transcendent offscreen voice, we are presented with Spider as a character in his own delirium, the adult version of himself observing and writing, always writing, as the memories of his childhood life play out. As Cronenberg has observed, it is almost as if Spider is directing his own memories. “One journalist said to me, ‘When we see Spider in his own memories, peeking in the windows or hiding in the corner, isn’t that like a director being on the set?’ I hadn’t thought of it that way, but he is redirecting and rechoreographing his memories.”4 We are reminded that the dreamer is every character in his dream.

So Spider develops a naturalistic expressionism, or expressionist naturalism. Its strangely solitary London is, Cronenberg says, an expressionist London. Spider captures the boiled potatoes atmosphere of the pre-rock ‘n’ roll Fifties, its muted colours as washed out as cabbage water.

The film of Cronenberg’s which Spider most resembles is Naked Lunch; not only because it, too, is based upon a supposedly unadaptable book, but also because both films principally concern writing, insanity, masculinity and the death of a woman. In both Naked Lunch and Spider, the phantasmatically reiterated murder of a woman is the pivotal event, the lacuna around which the films circle. In Naked Lunch, Lee initially disavows the killing of his wife Joan by attributing it to the influence of Control. Lee is only able to accept minimal responsibility for the killing when he is “required”, at the end of the film, to assassinate Joan, or at least her double, again. The re-staging of the death is less an admission of ethical responsibility than an attempt to own it, to make sense of it. Such is the logic of trauma. (Reminding us of Ballard’s description of the motives of the schizo in The Atrocity Exhibition: “He wanted to kill Kennedy again, but this time in a way that made sense.”)

In Spider we are initially led to believe that Spider’s father, Bill Cleg (Horace in the novel) has killed Spider’s mother after embarking on an affair with the “fat tart” Yvonne (Hilda in the novel). No sooner has Bill brutally and casually murdered his wife, rolling her into a hastily dug grave in the earth of his allotment (“out with the old”, Yvonne callously cackles), than he moves Yvonne into his home. At this point, our suspicions that something is amiss with Spider’s narration begins to harden into a conviction. But it’s only at the end of the film that we learn what appears to have really happened: it is Spider himself who killed his mother, gassing her whilst apparently suffering from a delusion that she is another person. The early exchanges between Spider and his father take on a different significance (Spider: “She’s not my mother”. Bill: “Well, who is she then?”) The final scene sees Bill rescuing Spider from the house, and desperately trying to revive Yvonne, who in death, has become, once again, the dark-haired Mrs Cleg.

While this seems to be the preferred interpretation, the film does not close down any of the narrative possibilities it has opened up. I think we can enumerate nine distinct narrative options that the film leaves open:

1. Bill killed his wife, and he really did co-habit with a prostitute called Yvonne.

2. Bill did kill his wife, there really is an Yvonne, but she never moved in with Spider’s father.

3. Bill killed his wife, but there is no such a person as Yvonne.

4. Spider, not Bill, killed his mother, but Bill moved in with Yvonne after his wife’s death.

5. Spider killed his mother, there is a prostitute called Yvonne, but she never moved in with Spider’s father.

6. Spider killed his mother, and there is no such person as Yvonne.

7. Neither Spider nor Bill killed Mrs Cleg, but Bill moved in with Yvonne after his mother’s death.

8. Neither Spider nor Bill killed Mrs Cleg, there really is an Yvonne, but she never moved in with the Clegs.

9. Neither Spider nor Bill killed Mrs Cleg, and there is no such person as Yvonne.

Rather than resolving the ambiguities of McGrath’s novel, the film actually amplifies them. In the novel, we at least learn (it seems) that Spider has been incarcerated for killing his mother (even though he continues to maintain that it was his father who was responsible for the death). In the film, the twenty years between Mrs Cleg’s death and Spider’s arrival at the halfway house are a blank. We know, or think we know, by inference, that he has been in a psychiatric institution, but no more.

Miranda Richardson’s performance is crucial to the maintenance of the film’s polysemous ambiguity. She is superb in three different roles: as the virtuous brunette Mrs Cleg, the licentious blonde Yvonne and also as the suddenly and inappropriately sexually aggressive landlady of the halfway house, Mrs Wilkinson. The situation is complicated by the fact that Yvonne is played at first by another actress altogether (at least, I think that is the case; it is a tribute to the film’s queasy delirium and to Richardson’s performance, that I’m just not sure), just as Mrs Wilkinson is played for most of the film by Lynne Redgrave.

As in Naked Lunch, writing is both passive and active. Like Bill Lee, Spider, scratching away in his notebook in his idiolectic hieroglyphics, seems at one level only to be recording signal from outside; at another level, he is the producer of the whole scene, its derealiser.

Talking about the film, Cronenberg has referred to Nabokov’s theory of memory and art as attempts to recover the unrecoverable. But the figure that dominates the film is another writer who, like Nabokov, Brian McHale has referred to as a “limit-modernist”, Samuel Beckett. Cronenberg has said that Spider’s look, with its shock of spiky hair, was very much influenced by photographs of Beckett, but the affinity with Beckett goes much deeper. Like Molloy or Malone, Spider is continually fumbling in his pockets for talismanic objects. Such partial objects mark the routes on their “intensive voyages”. Like McGrath, Cronenberg seduces us into identification with Spider (Cronenberg: “I am Spider”), taking us with him on his schizo-stroll, then strands us in the delirium…





stand up, nigel barton1

“I remember, I remember

The school where I was born;

I remember, I remember,

The school where I was… torn.”

— Dennis Potter, The Nigel Barton Plays2

“And nowadays what else does education and culture want! In our age of the people —I mean our uncouth age — ‘education’ and ‘culture’ must basically be the art of deception, to mislead about the origin of the inherited rabble in one’s body and soul.”

— Friedrich Nietzsche, Beyond Good and Evil3

Dennis Potter’s Stand Up, Nigel Barton, shown as part of BBC 4’s “Summer of the Sixties” season, is still almost too painful to watch.

Here is Potter writing a television play which draws very closely upon his experiences as a scholarship boy, projected out of his class into the rarefied world of Oxford. Stand Up, Nigel Barton was actually written after Vote, Vote, Vote for Nigel Barton, Potter’s fictionalised account of his failed attempt to become elected as a Labour MP. To Potter’s disgust, Vote, Vote, Vote was suppressed by the BBC, but its temporary banning allowed him to work again with the characters he had invented, writing this prequel which would be shown first.

English fiction has always been ambivalent about social mobility. Potter’s theme was very much one with which the Sixties would be preoccupied, in music as much as drama. Consider the Kinks (“Rosy, won’t you please come home”, “See my friends/they cross the river”) or the Who (“I was born with a plastic spoon in my mouth”). Like Dickens’ Pip, Nigel is profoundly torn; unwilling to give up the privilege and status he has newly acquired, unable to accept and enjoy them as one to the manner born, simultaneously holding onto his roots and repudiating them, never forgetting where he has come from, but ashamed of the stains that his origins have left upon him. And ashamed of that shame. Never comfortable amongst the masters, but no longer at home in the community which produced him.

Forty years on, and the screen still crackles with rage, confusion and embarrassment. Potter intercuts between the working men’s club, the bedrock of the proletarian community, with its “suffocating affection” but deep suspicion, resentment and distrust of those who leave; and the smug redoubt of the Oxford Union, whose louche members idly trade bon mots (“Oxford”, as Nigel observes in his somewhat too histrionic style, “where nothing really matters”, where a dissolute, ironic detachment is the mark of a gentleman, and where Nigel’s very passion marks him out as not quite right).

Who can watch the final scene — Nigel at home with his parents, watching himself being interviewed on television about class — without cringing? What Nigel says about his father “watching him like a hawk”, about “walking a tightrope”, about class only being experienced by those who move between classes; none of this is a distortion. And yet, Nigel is too much in love with his own cleverness, too much attached to the role of alienated workingclass boy that he has been invited to play. He knows he has betrayed his parents. His father, ambivalent about him at the best of times, both proud and resentful, simmers; his mother, uncomprehending, weeps, “But it’s clean. You could eat off the floor here…”

Potter shows that he can do naturalism painfully and powerfully. But he’s already exploring more expressionistic techniques: playing with chronology, breaking the frame (adults playing children, characters speaking directly to camera). The origin of the famous classroom scene in The Singing Detective is here, with Janet Henfrey taking on the role of the terrifyingly inquisitorial, witch-like schoolmistress she will reprise in the later play. The performances, especially Keith Barron as Nigel and Jack Woolgar as his father, are universally superb.

No need to reiterate, by now, my lament for TV drama this challenging, this near-the-knuckle, this relevant. But what a nihilistic message Potter conveys. There is nothing to aspire to, nothing you’d want to return to. Nigel trapped and alone, forever alone…

With Stand Up, Nigel Barton I knew that in small family groupings — that is, at their most vulnerable — both coalminers and Oxford dons would probably see the play. This could add enormously to the potency of a story which attempted to use the specially English embarrassment about class in a deliberately embarrassing series of confrontations. In the theatre — or, at least, in the West End — the audience would have been largely only on one side of this particular fence. There is no other medium which could virtually guarantee an audience of millions with a full quota of manual workers and stockbrokers for a “serious” play about class.4





portmeirion:

an ideal for living1

“As the bourgeoisie laboured to produce the economic as a separate domain, partitioned off from its intimate and manifold interconnectedness with the festive calendar, so they laboured conceptually to reform the fair as either a rational, commercial trading event or as a popular pleasureground. As the latter, the fair had from classical times been subject to regulation and suppression on both political and moral grounds. But although the bourgeois classes were frequently frightened by the threat of political subversion and moral licence, they were perhaps more scandalised by the deep conceptual confusion entailed by the fair’s inmixing of work and pleasure, trade and play. In so far as the fair was purely a site of pleasure, it could be envisaged as a discrete entity: local, festive, communal, unconnected to the ‘real’ world. In so far as it was purely a commercial event it could be envisaged as a practical agency in the progress of capital, an instrument of modernisation and a means of connecting up local and communal ‘markets’ to the world market.”

— Peter Stallybrass and Allon White, “The Fair, the Pig, Authorship”2

If you know about Portmeirion, it’s almost certainly because of The Prisoner, justly recognised as one of the most innovative television series ever produced (more on which presently). Our tendency is to think of Portmeirion, built by gentlemen-philanthropist Sir Clough Williams-Ellis on his private peninsula near Porthmadog, as a quaintly attractive divertissement; an example of charming English eccentricity that has somehow fetched up in Wales. The subtext we don’t even need to articulate to ourselves (so we think) is that all this — attractiveness, eccentricity, charm — are harmless, which is to say, pleasant but ultimately irrelevant. The idea that they could have political-economic significance; that’s more absurd than Ellis’ absurdist architecture, surely?

It’s fitting that I should have encountered both Ellis’ village and Llandudno’s homage to Lewis Carroll in the same week, in Wales, since both belong to an ex-centric Britishness that is as at least as important as Magritte’s Belgian Surrealism. Remember that André Breton thought that the British — with Edward Lear, Lewis Carroll and their ludic ilk — had little need of Surrealism, since they were already Surrealist… But Artaud, who could hardly have been accused of being over-conscious, was an admirer of Carroll; as were the Situationists, who recognised that there was something utterly serious about English Nonsense. As did Deleuze, of course, who produced what is one of the strangest landmarks in Psychedelic Reason, The Logic of Sense, as a rigorous philosophical exposition of Carroll’s Nonsense. (One of its most inciting sections is an account of Artaud’s translation of “Jabberwocky”.)

But it’s worth pausing and thinking a little more about the Situationists. It’s disastrous that the Situationist insistence upon the ludic has degenerated into a smugonautic celebration of bourgeois circus trickery (juggling and unicylcists as the shock troops of the revolution against Corporate Kapital). You have to reread Ivan Chtcheglov’s astonishing “Formulary for a New Urbanism”3 — written in the year of our current Queen’s coronation, 1953 — to be reminded of the force of the Situationist critique. How could architecture — i.e. the places in which we live — not be an intensely political matter? And why should we live in boring, utilitarian spaces when we could live in grottoes and crooked caverns? “A mental disease has swept the planet: banalisation. Everyone is hypnotised by production and conveniences…”

Like punk, Surrealism is dead as soon as it is reduced to an aesthetic style. It comes unlive again when it is instantiated as a delirial program (just as punk comes unlive when it is effectuated as an anti-authoritarian, acephalic contagion-network). Chtcheglov resists the aestheticisation of Surrealism, and treats De Chirico’s paintings, for instance, not as particular aesthetic contrivances, but as architectural blueprints, ideals for living. Let’s not look at a De Chirico painting — let’s live in one. Chtcheglov’s call was astonishingly pre-empted by Clough Williams-Ellis’ building of Portmeirion. Ellis described himself as follows:

He almost certainly has a weakness for splendour and display and believes that even if he were reduced to penury himself he would still hope to be cheered by the sight of uninhibited lavishness & splendour unconfined somewhere which is why he feels that Copenhagen’s Tivoli Gardens or something like them should be spread around the civilised world giving everyone a taste of lavishness, gaiety and cultivated design.4

Ellis recognised, that is to say, that the production of the aesthetic as a category separate from the “necessary” (i.e. the utile, in the Bataille restricted economy sense) was complicit in a kind of (from any rational POV) inexplicable diminution of the possibilities of human experience. Why must architecture be part of a banalising culture of vampiric undeath? Why should only the privileged be able to enjoy their surroundings? Why should the poor be penned into miserable concrete blocks?

Ellis referred to beauty as a “strange necessity”, cutting through the binary of needs = biological and aesthetic = cultural luxury. Bodies deprived of attractive surroundings were as likely to be as depressed — or to use the superbly multivalent Rasta term, downpressed — as those deprived of anything they more obviously “needed”.

According to the Portmeirion website,5 Ellis sought, in the building of Portmeirion, to demonstrate that it was possible to develop sites of natural beauty without destroying them:

A tireless campaigner for the environment Clough was a founder member of both the Council for the Protection of Rural England in 1926 and the Campaign for the Protection of Rural Wales in 1928 (and of which he was president for twenty years). He was an advocate of rural preservation, amenity planning, industrial design and colourful architecture.

The fact that The Prisoner was filmed here then is in no sense an accident. In addition to its Foucauldian analyses of power (“you are Number 1”), its — in every good sense — existentialism, its PKD-like psychedelic dismantling of identity, The Prisoner was a withering account of the English class system. McGoohan, auteur-actor, was given an artistic licence by the then head of ITV (yes, remember, The Prisoner appeared on ITV — I know it beggars belief now), Lew Grade — both were outsiders (McGoohan an Americanborn Irishman, Grade a Jew) who had penetrated into the genteel brutality of the English Core’s gentlemen’s club. However irascible they sometimes became, the series of Number 2’s typically had that impermeable urbane assurance so infuriatingly characteristic of the English Core Master Class. Power expressed itself not in crude force — whenever that was used (cf the episode “Hammer into Anvil”) you knew that they had in every sense lost it — but with the quiet, insinuating menace lurking behind an inscrutable politesse. “Cup of tea, Number 6?”

The village had all the quaint charm of politely ritualised Englishness ambivalently celebrated by the Kinks in their Village Green Preservation Society (which came out contemporaneously with The Prisoner). And of course McGoohan’s genius lay in exposing the acidic undertaste of phrases like “be seeing you” and “feel free”.

The Prisoner is the heir of both Kafka and Carroll — and part of its importance consists in its revelation of the shared sensibility. Kafka’s observations of the banalising terror of the decaying Hapsburg bureaucracy as it moved towards Weberian impersonality owes much to Carroll. K’s Trial after all has no more sense than the trial at the end of Alice’s Adventures in Wonderland. Like Alice, K often comes across as a lucid child — for only a child can be lucid in Carroll and Kafka’s world — observing the senseless and arbitrary cruelty of adult caprice, whose only alibi is precedent. “Things have always been done that way. Don’t you know? How stupid are you?”

It is their restoration of the child’s reason in the face of adult intransigent baboonery that makes Kafka, Carroll and The Prisoner punk. Until it is socialised — i.e. stupefied into mute acceptance of the irrational caprice of the socius — the child knows that authority is nothing unless it is can be defended via reason.

The Prisoner, like Williams-Ellis, like the Situationists and the Surrealists, dreamed a dream deemed to be impossible, conceiving of a social system in which play and reason combine in an exploration of Intensive Now.





golgothic materialism1

I finally saw The Passion of the Christ this week. I watched it at work with the A-level Religious Studies students. They, like me, were moved to tears and beyond. (Tip for any teacher out there: show the film at nine in the morning, that’ll wake up any students still yawning their way into the day.)

Whilst agreeing with much of what Žižek says about Gibson’s film in his brilliant essay “Passion in the Era of Decaffeinated Belief”,2 I think that he doesn’t go nearly far enough.

Žižek is right to challenge the smug and lazy culturalist consensus that religious conviction is inherently pathological and dangerous. But he is wrong to suggest that what is most important about Passion is belief. Gibson’s Gnostic vision — which is simply Christ’s ethical Example rescued from the institutionalised religion that has systematically distorted it in his name — makes the two traditional supports of religious belief irrelevant. Astonishingly, The Passion of the Christ demonstrates that neither Revelation nor Tradition are important for those seeking to become-Christ(ian). What matters is not so much whether the events described in the film really happened — and there is no reason to doubt that something resembling them did — but the life-practice which the Christ story narrates.

Life as parable.

Let’s dismiss first of all the idea that the film is anti-semitic. Certainly, the first half of the film threatens to invite this interpretation. In the run-up to Jesus’ arrest, the film appears to depict the Jewish religious authorities as near-subhuman monsters, while the Roman imperial powers are viewed sympathetically, as benign and puzzled observers of a distasteful local conflict amongst the people they have colonised. (In this respect, Gibson appears to buy into the anti-Jewish narrative retrospectively imposed by the Roman Catholic Church once it had come to its concordat with the Roman Empire and was keen to excuse its new Masters of any responsibility for the crucifixion.)

But once the notorious beating scene happens, the film goes through an intensive threshold. Here, the Roman soldiers are seen to be gratuitously cruel psychopaths, whose excessive zeal in punishing Jesus exceeds any “duty”. It is clear by now that The Passion of the Christ has no ethnic axe to grind: it is about the stupidity and cruelty of the human species, but more importantly, about an escape route from the otherwise meaningless and nihilistic cycle of abuse begetting abuse that is human History.

The Gnostic flashes that surface in the Gospels are given full weight in Gibson’s film. “My kingdom is not of this world.” But Gibson refuses to give any comfort to those life-deniers and body-haters that Nietzsche rightly excoriates in his many attacks on Christianity. There is little supernatural or transcendent dimension to The Passion’s vision. If Christ’s kingdom is not of this world, Gibson gives us few reasons to assume that this kingdom will be the Platonic heaven of which those tired of the body dream.

The World which Christ rejects is the World of Lies, the consensual hallucination of established power and authority. By contrast, Christ’s kingdom only subsists whenever there is an Affectionate Collectivity. In other words, it exists not as some deferred supernatural reward, but in the Ethical actions of those, who in becoming-Christ, keep his spirit alive. Again, it is important to stress that this spirit is not some metaphysical substance, but a strictly material abstract machine that can be instantiated only through actions and practices. Loving God and loving others more than yourself are preconditions for dissolving your ego and gaining deliverance from the Hell of Self.

What, from one perspective, is the utter humiliation and degradation of Jesus’ body is on the other a coldly ruthless vision of the body liberated from the “wisdom and limits of the organism”.

Masochristianity.

Christ’s Example is simply this: it is better to die than to pass on abuse virus or to in any way vindicate the idiot vacuity and stupidity of the World of authority.

Power depends upon the weakness of the organism. When authority is seriously challenged, when its tolerance is tested to the limit, it has the ultimate recourse of torture. The slow, graphic scenes of mindless physical degradation in The Passion of the Christ are necessary for revealing the horrors to which Jesus’ organism was subject. It is made clear that he could have escaped the excruciating agony simply by renouncing his Truth and by assenting to the Authority of the World. Christ’s Example insists: better to let the organism be tortured to death (“If thine own eye offend thee, pluck it out”) than to bow, bent-headed, to Authority.

This is what is perhaps most astonishing about Gibson’s film. Far from being a statement of Catholic bigotry, it can only be read as an antiauthoritarian AND THEREFORE anti-Catholic film. For the Pharisees of two millennia ago, puffed up in their absurd finery, substitute the child-abuser apologists of today’s gilt-laden, guilt-ridden Vatican. Against all the odds, against two thousand years of cover-ups and dissimulation, The Passion of the Christ recovers the original Christ, the anti-Wordly but not otherwordly Christ of Liberation Theology: the Gnostic herald of Apocalypse Now.





this movie doesn’t move me1

As I nervously anticipate the new Doctor Who (although after McCoy, after McGann, what more can there be to fear?), it is worth thinking again about the appeal of the series, and also, more generally, about the unique importance of what I will call “uncanny fiction”.

A piece by Rachel Cooke in the Observer two weeks ago brought these questions into sharp relief.2 Cooke’s article was more than an account of a television series; it was a story about the way broadcasting, family and the uncanny were webbed together through Doctor Who. Cooke writes powerfully about how her family’s watching of the programme was literally ritualised: she had to be on the sofa, hair washed, before the continuity announcer even said the words, “And now…” She understands that, at its best, Dr Who’s appeal consisted in the charge of the uncanny — the strangely familiar, the familiar estranged: cybermen on the steps of St Paul’s, yeti at Goodge Street (a place whose name will forever be associated with the Troughton adventure, “The Web of Fear”, for Scanshifts,3 who saw it whilst living in New Zealand).

Inevitably, however, she ends the piece on a melancholy note. Cooke has been to a screening of the first episode of the new series. She enjoys its expensive production values, its “sinister moments”, its use of the Millennium Wheel. “But it is not — how shall I put this? — Doctor Who.” Faced with an “overwhelming sense of loss”, she turns to a DVD of the Baker story Robots of Death for a taste of the “real” stuff, the authentic experience that the new series cannot provide. But this proves, if anything, to be even more of a disappointment. “How slow the whole thing seems, and how silly the robots look in their Camilla Parker-Bowles-style green quilted jackets… Good grief.”

Let’s leave aside, for a moment, all the post-post-structuralist questions about the ontological status of the text “itself”, and consider the glum anecdote with which the article concludes:

Before Christmas, when it became clear that my father’s cancer was in its final stages, my brother went out and bought a DVD for us all to watch together. Dad was too ill, and box went unopened. At the time, I cried about this; yet another injustice. Now I know better. Some things in life can’t ever be retrieved — an enjoyment of green robots in sequins and pedal pushers being one of them.

This narrative of disillusionment belongs to a genre that has become familiar: the postmodern parable. To look at the old Doctor Who is not only to fail to recover a lost moment; it is to discover, with a deflating quotidian horror, that this moment never existed in the first place. An experience of awe and wonder dissolves into a pile of dressing up clothes and cheap special effects. The postmodernist is then left with two options: disavowal of the enthusiasm, i.e. what is called “growing up”, or else keeping faith with it, i.e. what is called “not growing up”. Two fates, therefore, await the no longer media-mesmerised child: depressive realism or geek fanaticism.

The intensity (with) which Cooke invested in Doctor Who is typical of so many of us who grew up in the Sixties and Seventies. I, slightly younger than her, remember a time when those twenty-five minutes were indeed the most sacralised of the week. Scanshifts, slightly older than me, remembers a period when he didn’t have a functioning television at home, so he would watch the new episode furtively at a department store in Christchurch, silently at first, until, delighted, he found the means of increasing the volume.

The most obvious explanation for such fervour — childhood enthusiasm and naïveté — can also be supplemented by thinking of the specific technological and cultural conditions that obtained then. Freud’s analysis of the unheimlich, the “unhomely”, is very well known, but it is worth linking his account of the uncanniness of the domestic to television. Television was itself both familiar and alien, and a series which was about the alien in the familiar was bound to have particularly easy route to the child’s unconscious. In a time of cultural rationing, of modernist broadcasting, a time, that is, in which there were no endless reruns, no VCRs, the programmes had a precious evanescence. They were translated into memory and dream at the very moment they were being seen for the first time. This is quite different from the instant — and increasingly pre-emptive — monumentalisation of postmodern media productions through “makings of” documentaries and interviews. So many of these productions enjoy the odd fate of being stillborn into perfect archivisation, forgotten by the culture while immaculately memorialised by the technology.

But were the conditions for Dr Who’s colonising presence in the unconscious of a generation merely scarcity and the “innocence” of a “less sophisticated” time? Does its magic, as Cooke implies, crumble like a vampire seducer in bright sunlight when exposed to the unbeguiled, unforgiving eyes of the adult?

According to Freud’s famous arguments in Totem and Taboo and The Uncanny, we moderns recapitulate in our individual psychological development the “progress” from narcissistic animism to the reality principle undergone by the species as a whole. Children, like “savages”, remain at the level of narcissistic auto-eroticism, subject to the animistic delusion that their thoughts are “omnipotent”; that what they think can directly affect the world.

But is it the case that children ever “really believed” in Doctor Who? Žižek has pointed out that when people from “primitive” societies are asked about their myths, their response is actually indirect. They say “some people believe”. Belief is always the belief of the other. In any case, what adults and moderns have lost is not the capacity to uncritically believe, but the art of using the series as triggers for producing inhabitable fictional playzones.

The model for such practices is the Perky Pat layouts in Philip K. Dick’s The Three Stigmata of Palmer Eldritch. Homesick off-world colonists are able to project themselves into Ken and Barbie-like dolls who inhabit a mockup of the earthly environment. But in order to occupy this set they need a drug. In effect, all the drug does is restore in the adult what comes easily to a child: the ability not to believe, but to act in spite of the lack of belief.

In a sense, though, to say this is already going too far. It implies that adults really have given up a narcissistic fantasy and adjusted to the harsh banality of the disenchanted-empirical. In fact, all they have done is substituted one fantasy for another. The point is that to be an adult in consumer capitalism IS to occupy the Perky Pat world of drably bright soap opera domesticity. What is eliminated in the mediocre melodrama we are invited to call adult reality is not fantasy, but the uncanny — the sense that all is not as it seems, that the kitchen-sink everyday is a front for the machinations of parasites and alien forces which either possess, control or have designs upon us. In other words, the suppressed wisdom of uncanny fiction is that it is THIS world, the world of liberal-capitalist commonsense, that is a stage set with wobbly walls. As Scanshifts and I hope to demonstrate in our upcoming audiomentary London Under London on Resonance FM, the Real of the London Underground is better described by pulp and modernism (which in any case have a suitably uncanny complicity) than by postmodern drearealism. Everyone knows that, once the wafer-thin veneer of “persons” is stripped away, the population on the Tube are zombies under the control of sinister extra-terrestrial corporations.

The rise of fantasy as a genre over the last twenty-five years can be directly correlative with the collapse of any effective alternative reality structure outside capitalism in the same period. Watching something like Star Wars, you immediately think two things. Its fictional world is BOTH impossibly remote, too far-distant to care about, AND too much like this world, too similar to our own to be fascinated by. If the uncanny is about an irreducible anomalousness in anything that comes to count as the familiar, then fantasy is about the production of a seamless world in which all the gaps have been mono-filled. It is no accident that the rise of fantasy has gone alongside the development of digital FX. The curious hollowness and depthlessness of CGI arises not from any failure of fidelity, but, quite the opposite, from its photoshopping out of the Discrepant as such.

The fantasy structure of Family, Nation and Heroism thus functions, not in any sense as a representation, false or otherwise, but as a model to live up to. The inevitable failure of our own lives to match up to the digital Ideal is one of the motors of capitalism’s worker-consumer passivity, the docile pursuit of what will always be elusive, a world free of fissures and discontinuities. And you only have to read one of Mark Steyn’s preppy phallic fables (which need to be ranked alongside the mummy’s boystories of someone like Robert E. Howard) to see how fantasy’s pathetically imbecilic manichean oppositions between Good and Evil, Us and (a foreign, contagious) Them are effective on the largest possible geopolitical stage.





fear and misery in the third reich ‘n’ roll1

I (belatedly) went to see the traumatically powerful Downfall a couple of nights ago at the behest of Karl Kraft. Overhype of mediocre tat renders one suspicious of any praise surrounding contemporary films, but this is a genuine masterpiece, and one that can only be appreciated fully in the cinema environment, where the relentless pummelling of the Soviet artillery and the claustrophobic airlessness of the Hitler bunker have a crushingly visceral presence.

Downfall, actually, is the second film this year (the first was The Aviator) to flout my otherwise reliable dictum that movies based on real life are to be avoided. But the reason why both work is that they describe situations in which reality had itself gone psychotic. As Ballard has observed, the Nazi delirium was one of those moments when the distinction between the internal and the external world no longer held: hell has erupted on earth, there is no escape, no future, and you know it…

Downfall is fascinating because it closely and, I’m assuming, meticulously documents the “line of abolition” that Deleuze and Guattari claim is constitutive of Nazism. For Deleuze and Guattari, who borrow the idea from Virilio, the Nazis’ scheduled auto-annihilation — “if we are defeated, better that the nation should perish” — was less a forced contingency than the realisation, the very consummation, of the Nazi project.2 Deleuze and Guattari’s account might be dubious empirically, but the great service it provides for cultural analysis may not be the idea that Nazism is suicidal, but the thought that the suicidal, the self-destructive is Nazi.

Since at least the death of Chatterton, popular culture has found the temptation to glamourise self-destruction irresistible. The Nazis provide the definitive twentieth-century version of this age-old Romance of Death. As Ballard noted in his essay on Hitler, “Alphabets of Reason”, the Nazis are a creepily modern phenomenon, their technicolour glamour a world away from the fussy frock-coated figures of the Edwardian British ruling elite. The Nazis’ facility with broadcasting laid the groundwork for the media landscape we now occupy. Hitler as the first rock star?

Downfall takes us through the scenes in which the Nazi party disintegrates only for the Third Reich ‘n’ Roll to begin. The death of the frontman is the blood-sacrifical rite that will guarantee a hideous immortality. Hitler was the first twentieth-century figure to pass from historical individuality to becoming a permanent archetype-artefact in the the McLuhan-Ballard media unconscious. After him, Kennedy, Malcolm X, King, Morrison, Hendrix, Curtis seem local, particular, whereas Hitler comes to stand for a general principle, for modern Evil itself.

As spectators of Downfall, we spend most of the time in the Führer Bunker, forced into an unsettling sympathy if not for the Reich’s leaders then for those who were loyal to them, the secretaries and functionaries who admired, by no means fanatically, Hitler and National Socialism. Meanwhile, the glimpses we have of the Berlin above show a landscape out of The Triumph of Death, a city devolving into total anomie: child conscripts, vigilante hangings, intoxicated revelling, carnivalesque sexual excess.

While those scenes play out, you can almost hear Johnny Rotten leering, “when there’s no future how can there be sin?” (Although for Germany, in fact, there was nothing but the future: immediate postwar Germany was subject to a willed amnesia, a disavowal of cultural memory.) It’s no accident that post-punk in many ways begins here. As the Pistols pursue their own line of abolition into the scorched earth nihilism of “Belsen was a Gas” and “Holidays in the Sun”, they keep returning to the barbed-wire scarred Boschscape of Nazi Berlin and the Pynchon Zone it became after the war. Siouxsie famously sported a swastika for a while, and although much of the flaunting of the Nazi imagery was supposedly for superficial shock effects, the punk-Nazi connection was about much more than trite transgressivism. Punk’s very 1970s, very British fixation on Nazism posed ethical questions so troubling they could barely be articulated explicitly: what were the limits of liberal tolerance? Could Britain be so sure that it had differentiated itself from Nazism (a particularly pressing issue at a time that the NF was gathering an unprecedented degree of support)? And, most unsettling of all, what is it that separates Nazi Evil from heroic Good?

Downfall poses that last question with a real force, and it is a question that has a special resonance at the moment given Žižek and Zupančič’s theory of the ungrounded Act as the very definition of the ethical. As I watched the most “monstrous” act depicted in the film, Frau Goebbels’ drugging and then poisoning her children — better this “redemption”, she reasoned, than that they be left in a world without National Socialism — I was struck by the parallel with Sethe in Toni Morrison’s Beloved, who kills one of her children rather than let it fall into the hands of the slavers. What is to separate Frau Goebbels’ act of abominable Evil from Sethe’s act of heroic Good? (Those who have read The Fragile Absolute will remember that Žižek uses Sethe precisely as an example of a Good entirely alien to liberal morality, with its ethic of enlightened self-interest.)

Downfall seems to invite us to sympathise with the “liberal Nazis”, the “reasonable” doctor, for instance, who wants to keep the medical services running and is disgusted and aghast at the “senseless, suicidal” behaviour that results from seeing Duty through to the end; the General who wants to end the war to protect the lives of civilians. But these “pragmatic humanitarian” figures are the least defensible because they are not prepared to follow the principles of their actions to the end (if they were committed to Nazism, why not die for it? If they weren’t, why not resist it?). Strangely, it is almost as if the film seems to suggest that what was irredeemably malevolent about the Nazis was their will to die for the cause.

In spite of ourselves, we find ourselves thinking that the Evil Nazis — those who totally identify with the Nazi project and who destroy themselves when it is clear that has failed — attain a certain tragic heroism by refusing to give up on their fundamental commitment. All of which leads us back to the old question: does the Kantian emphasis on unconditional duty legitimate Nazi Evil?

Zupančič, who has done so much to re-discover Kantian ethics from the perspective of Lacanian theory, addressed this question in her interview with Cabinet magazine:

Recall that, in Hannah Arendt’s famous example, Nazi functionaries like Eichmann took themselves to be Kantians in this respect: They claimed to act simply on principle without any consideration for the empirical consequences of their actions. In what way is this a perversion of Kant?

This attitude is “perverse” in the strictest clinical meaning of the word: The subject has here assumed the role of a mere instrument of the Will of the Other. In relation to Kant, I would simply stress the following point, which has already been made by Slavoj Žižek: In Kantian ethics, we are responsible for what we refer to as our duty. The moral law is not something that could clear us of all responsibility for our actions; on the contrary, it makes us responsible not only for our actions, but also — and foremost — for the principles that we act upon.3

Is this enough though to distinguish Goebbels from Sethe? Was it really the case that Frau Goebbels was making herself into “a mere instrument of the Will of the Other”? Or had she freely chosen to assume responsibility for her actions and for the principles on which she acted? Remember that Kantian freedom consists in choosing to obey the moral law. To be motivated by anything other than “duty” is to be driven by “pathological” passions, and hence not to be free at all. There is no obvious pathological motivation for Frau Goebbels’ actions. She stood to gain nothing from this act of “destroying what is best in her” (and indeed, shortly after she killed her children, she consented to be shot by her husband).

The only answer you are left with is that the Nazi Cause is itself a pathology. By definition, the Nazi Act cannot be universal, since it is based upon preserving — if only, at the end, at the level of myth — the particular pathological characteristics of “a chosen people” and, more abstractly therefore, of defending the very principle of “ethnic pathology”. Sethe’s abominable act in Beloved is an act of Unplugging from a social situation fatally, totally corrupted by a lethally imbecilic racial delirium; Frau Goebbels’ multiple infanticide, by contrast, is an attempt to hardwire herself and her children into an ethnocidal madness that can only live through their deaths and the deaths of millions of others.





we want it all1

What use might Nietzsche be today? Or, to put it another way: which Nietzsche might be of use, now?

It will come as no surprise that I would count Nietzsche the perspectivist — he who questioned not only the possibility but the value of Truth — as the enemy. There will be even fewer surprises that I would reject the Dionysian Nietzsche, the celebrant of transgressive desire. This Nietzsche, in any case, is largely a post-Bataillean retrospective construct (even in The Birth of Tragedy, what Nietzsche mourns is the lost tension between Dionysus and Apollo; and in his later writings Nietzsche is more likely to be found extolling the necessity of constraints and limitations than he is to be heard calling for the unrestrained venting of libido). The perspectival and the Dionysiac are far too timely.

The Nietzsche that remains untimely — and by that I do not mean outmoded, very far from it — is Nietzsche the aristocrat. Nietzsche should not be taken seriously as a political theorist, at least not at the level of his positive prescriptions. But the Nietzsche who denounces the insipidity and mediocrity that result from democracy’s levelling impulses could not be more acute. Passage after passage of polemic in Beyond Good and Evil seems uncannily apposite in these times of focus-grouped blandness and “autonomous herding”. Nietzsche’s real interests lay with cultural politics; government and social institutions troubled him only insofar as they produced cultural effects, his ultimate question being: “What are the conditions in which great cultural artefacts can emerge?”

I was reminded of Nietzsche’s warnings about what would happen to culture if all “special claims and privileges” are denied, if the very concept of superiority is abolished, when Chantelle Houghton won Celebrity Big Brother a week or so ago (it already seems much longer than that). I was reminded, too, of Nietzsche’s scalding admonition that “harshness” and “cruelty” must be cultivated if the human animal is to transformed, by hammer blows and force of will, into a great work of art; reminded, especially, when some posters on Dissensus were seriously advancing “niceness” — niceness, that is — as a desirable trait.

Chantelle’s victory wasn’t just a popularity contest: as Marcello’s excellent Big Brother piece observed, a principle was at stake, the principle that ordinariness must trump any notion of superiority:

“You are not going to win support or respect by placing yourself out of the ordinary. You need to be approachable but you also need to be yourself. That’s what young people respect.” That’s a recent quote from one Alex Folkes, the speaker for a pressure group named Votes at Sixteen, apropos George Galloway, and it’s the kind of exhausting, fatuous antiphilosophy which tempts me to form a pressure group called Votes at Thirty. Nevertheless it is (un)pretty fitting for an age bereft of desire for godhood. Where once we assembled in front of screens or stages to gasp in awe at people doing and achieving things we could never hope of doing or achieving ourselves — but how we luxuriated, carried ourselves afloat, on the dream of doing so — now all we require is a humbling mirror. This is the sort of thing which stops dangerous people from gaining power, but also the kind of closure which would ultimately forbid all art. Where once we assembled in front of screens or stages to gasp in awe at people doing and achieving things we could never hope of doing or achieving ourselves … () now all we require is a humbling mirror.2

This is Celebreality: the simultaneous desublimation of the Star and the elevation of “the ordinary”. The commentary on Celebrity Big Brother treated it as self-evident that people will want to “identify with” media figures who offer a comforting and unchallenging reflection of themselves at their most mediocre, stupid and harmless. Julie Burchill’s endlessly reiterated polemic in favour of Big Brother — that it allows working-class people opportunities to break into a media otherwise dominated by the privileged — is baseless for three reasons. First, because the real beneficiaries of Big Brother are not the contestants, whose “career” is notoriously short-lived, but Endemol, with its coterie of smug graduate producers. Second, because Big Brother trades in a patronising and reductive image of the working class, the dominion of Celebreality relies upon the mediocrats inducing the working class into corresponding to — and “identifying with” — that image. Third, because Big Brother and reality TV have effaced those areas of popular culture in which a working class that aspired to more than “wealth” or “fame” once excelled. Its rise has meant a defeat for that over-reaching proletarian drive to be more, (I am nothing but should be everything), a drive which negated Social Facts by inventing Sonic Fictions, which despised “ordinariness” in the name of the strange and the alien. On Celebrity Big Brother, Pete Burns, with his casual cruelties, his savage articulacy and his Masoch-furs, was a cartoon symbol of those lost ambitions, skulking and sulking at the periphery, a glam prince in an age of post-Blairite roundheads.

We all know that the “reality” of reality TV is an artful construction, an effect not only of editing but of a Lorenzian rat-in-a-mirrored-labyrinth artificial environment which attenuates psychology into a series of territorial twitches. The “reality” that is designated is significant more for what is absent from it than for any positive properties it is deemed to possess. And what is absent, above all, is fantasy. Or rather, fantasy objects.

We once turned to popular culture because it produced fantasy objects; now, we are asked to “identify with” the fantasising subject itself. It was entirely appropriate that, the week after Chantelle won Celebrity Big Brother, Smash Hits should have announced its imminent closure.

Smash Hits began just as the glam continuum was winding down. What Smash Hits took from punk was its least Nietzschean affect, namely its “irreverence”. In the case of Smash Hits, this amounted to a compulsory trivialisation coupled with a kind of good-humoured debunking of the pretensions of Stardom. Behind Smash Hits’ silly surrealism was good solid commonsense and a conflicted desire, to both have your idols and kill them. Heat was Smash Hits’ successor and what rendered it obsolete. No need to bother with the (pop) pretext, now you can consume celebrity directly, untroubled by pop’s embarrassing Dreams. Chantelle is the logical conclusion of the process: the anti-Pop anti-Idol.

Nietzsche’s contention was that the kind of levelling Chantelle stands for was the inevitable and necessary consequence of all egalitarianism. Yet popular culture was once the arena which demonstrated that any genuine egalitarianism is inimical to any such levelling down. I wrote last year of goth as “a paradoxically egalitarian aristocracy in which membership is () not guaranteed by birth or beauty but by self-decoration”; will popular culture ever again teach us that egalitarianism is not hostile to, but relies upon, a will-to-greatness, an unconditional demand for the excellent?





gothic oedipus: subjectivity and capitalism in christopher nolan’s batman begins1

Batman has contributed more than its fair share to the “darkness” that hangs over contemporary culture like a picturesque pall. “Dark” designates both a highly marketable aesthetic style and an ethical, or rather anti-ethical, stance, a kind of designer nihilism whose chief theoretical proposition is the denial of the possibility of the Good. Gotham, particularly as re-invented by Frank Miller in the Eighties, is, along with Gibson’s Sprawl and Ridley Scott’s LA, one of the chief geomythic sources of this trend.2

Miller’s legacy for comics has been ambivalent at best. Reflect on the fact that his rise coincides with the almost total failure of superhero comics to produce any new characters with mythic resonance.3 The “maturity” for which Miller has been celebrated corresponds with comics’ depressive and introspective adolescence, and for him, as for all adolescents, the worst sin is exuberance. Hence his trademark style is deflationary, taciturn: consider all those portentous pages stripped of dialogue in which barely anything happens and contrast them with the crazed effervescence of the typical Marvel page in the Sixties. Miller’s pages have all the brooding silence of a moody fifteen-year-old boy. We are left in no doubt: the silence signifies.

Miller traded on a disingenuous male adolescent desire to both have comics and to feel superior to them. But his demythologisation, inevitably, produced only a new mythology, one that posed as more sophisticated than the one it has displaced but is in fact an utterly predictable world of “moral ambivalence” in which “there are only shades of grey”. There are reasons for being highly sceptical about Miller’s bringing into comics a noir-lite cartoon nihilist bleakness that has long been a cliché in films and books. The “darkness” of this vision is in fact curiously reassuring and comforting, and not only because of the sentimentality it can never extirpate. (Miller’s “hard-bitten” world reminds me not so much of noir, but of the simulation of noir in Dennis Potter’s Singing Detective, the daydream-fantasies of a cheap hack, thick with misognyny and misanthropy and cooked in intense self-loathing.)

It is hardly surprising that Miller’s model of realism came to the fore in comics at the time when Reaganomics and Thatcherism were presenting themselves as the only solutions to America and Britain’s ills. Reagan and Thatcher claimed to have “delivered us from the ‘fatal abstractions’ inspired by the ‘ideologies of the past’”.4 They had awoken us from the supposedly flawed, dangerously deluded dreams of collectivity and re-acquainted us with the “essential truth” that individual human beings can only be motivated by their own animal interests.

These propositions belong to an implicit ideological framework we can call capitalist realism. On the basis of a series of assumptions — human beings are irredeemably self-interested, (social) Justice can never be achieved — capitalist realism projects a vision of what is “Possible”.

For Alain Badiou, the rise to dominance of this restricted sense of possibility must be regarded as a period of “Restoration”. As Badiou explained in an interview with Cabinet magazine, “in France, ‘Restoration’ refers to the period of the return of the King, in 1815, after the Revolution and Napoleon. We are in such a period. Today we see liberal capitalism and its political system, parlimentarianism, as the only natural and acceptable solutions”.5 According to Badiou, the ideological defence for these political configurations takes the form of a lowering of expectations:

We live in a contradiction: a brutal state of affairs, profoundly inegalitarian — where all existence is evaluated in terms of money alone — is presented to us as ideal. To justify their conservatism, the partisans of the established order cannot really call it ideal or wonderful. So instead, they have decided to say that all the rest is horrible. Sure, they say, we may not live in a condition of perfect Goodness. But we’re lucky that we don’t live in a condition of Evil. Our democracy is not perfect. But it’s better than the bloody dictatorships. Capitalism is unjust. But it’s not criminal like Stalinism. We let millions of Africans die of AIDS, but we don’t make racist nationalist declarations like Milosevic. We kill Iraqis with our airplanes, but we don’t cut their throats with machetes like they do in Rwanda, etc.6

Capitalism and liberal democracy are “ideal” precisely in the sense that they are “the best that one can expect”, that is to say, the least worst.7This chimes with Miller’s rendition of the hero in The Dark Knight Returns and Year One: Batman may be authoritarian, violent and sadistic, but in a world of endemic corruption, he is the least worst option. (Indeed, such traits may turn out to be necessary in conditions of ubiquitous venality.) Just as Badiou suggests, in Miller’s Gotham it is no longer possible to assume the existence of Good. Good has no positive presence — what Good there is has to be defined by reference to a self-evident Evil which it is not. Good, that is to say, is the absence of an Evil whose existence is self-evident.

The fascination of the latest cinema version of Batman, Batman Begins (directed by Christopher Nolan) consists in its mitigated return to the question of Good. The film still belongs to the “Restoration” to the degree that it is unable to imagine a possible beyond capitalism: as we shall see, it is a specific mode of capitalism — post-Fordist finance capital — that is demonised in Batman Begins,not capitalism per se. Yet the film leaves open the possibility of agency which capitalist realism forecloses.

Nolan’s revisiting of Batman is not a re-invention but a reclaiming of the myth, a grand syncresis that draws upon the whole history of the character.8Gratifyingly, then, Batman Begins is not about “shades of grey” at all, but rather about competing versions of the Good. In Batman Begins, Christian Bale’s Bruce Wayne is haunted by a superfluity of fathers (and a near absence of mothers: his mother barely says a word), each with their own account of the Good. First, there is his biological father, Thomas Wayne, a rosetinted, soft focus moral paragon, the very personification of philanthropic Capital, the “man who built Gotham”. In keeping with the Batman myth established in the Thirtes Detective Comics, Wayne Pere is killed in a random street robbery, surviving only as a moral wraith tormenting the conscience of his orphaned son. Second, there is R’as Al Ghul, who in Nolan’s film is Wayne’s hyperstitional9mentor-guru, a Terroristic figure who represents a ruthless ethical code completely opposed to the benevolent paternalism of Thomas Wayne. Bruce is assisted in the struggle (fought out in his own psyche) between these two Father figures by a third, Michael Caine’s Alfred, the “maternal” carer who offers the young Bruce unconditional love.

The struggle between Fathers is doubled by the conflict between Fear and Justice that has been integral to the Batman mythos since it first appeared in 1939. The challenge for Bruce Wayne in Batman Begins is not only to best Fear, as wielded by the Miller-invented crime boss Falcone and the Scarecrow with his “weaponised hallucinogens”, but to identify Justice, which, as the young Wayne must learn, cannot be equated with revenge.

From the start, the Batman mythos has been about the pressing of Gothic Fear into the service of heroic Justice. Echoing the origin story as recounted in Detective Comics in 1939, which has Bruce famously declare, “Criminals are a superstitious cowardly lot, so my disguise must be able to strike terror into their hearts”, Nolan’s Wayne dedicates himself to turning fear against those who use it. Yet Nolan’s version makes the origin story both more Oedipal and more anti-Oedipal than it appeared in Detective Comics. In the original comic, Bruce settles upon the name “Batman” when a single bat flies into his room. Nolan’s rendering of Batman’s primal scene is significantly different, in that it takes place outside the family home, beyond the realm of the Oedipal, in a cave in the capacious grounds of Wayne Manor, and not with a single bat but with a whole (Deleuzian) pack.10The name “Batman”, with its suggestions of becoming-animal, does indeed have a Deleuzoguattarian resonance. Yet the proximity of Batman’s name to that of some of Freud’s case histories — “Ratman” especially, but also “Wolfman” — is no accident either. Batman remains a thoroughly Oedipal figure (as Batman Begins leaves us no doubt).11Batman Begins re-binds the becoming-animal with the Oedipal by having Bruce’s fear of bats figure as a partial cause of his parents’ death. Bruce is at the opera when the sight of bat-like figures on stage drives him to nag his parents until they leave the theatre and are killed.

The Gothic and the Oedipal elements of the Batman mythos were entwined immediately, on the two pages of Detective Comics on which Batman’s origin was first told. As Kim Newman identifies, Wayne’s epiphanic revelation that “I must be a terrible creature of the night… I shall become a BAT… a weird figure of the night”, contains “subliminal” quotes from Dracula (“creatures of the night, what sweet music they make”) and The Cabinet of Dr Caligari (“you shall become Caligari”).12 These panels follow three at the top of the page where the shocked Bruce sees the bodies of his parents (“father, mother … () Dead, they’re dead”) and “swears by their deaths () to avenge them () by spending the rest of my life warring on all criminals”. Batman is self-consciously imagined — and self-created — as a Gothic monster, a “weird figure of the dark”, but one who will use “the night” against the criminals who habitually hide in it.

If Batman was heavily indebted to German Expressionism — via Universal’s horror pictures — so, famously, was film noir, which emerged, like Batman, in the late Thirties and early Forties. (As we’ve already seen, Miller’s rendition of Batman can be seen as in many ways a postmodern investigation of this parallel.) Remarks made by Alenka Zupančič suggest a possible hidden source for the complicity between Batman and noir: Oedipus again. “I ()n contrast to Hamlet”, Zupančič writes,

the story of Oedipus has often been said to belong to the whodunnit genre. Some have gone even further, and seen in Oedipus the King the prototype of the noir genre. Thus Oedipus the King appeared in the “noir series” of French publisher Gallimard (“translated from the myth” by Didier Lamaison).13

Batman, the superhero-detective, walks in the footsteps of the first detective, Oedipus.

Ultimately, however, the problem for Batman is that he remains an Oedipus who has not gone through the Oedipus complex. As Zupančič points out, the Oedipus complex turns on the discrepancy between the Symbolic and the empirical father: the Symbolic Father is the embodiment of the Symbolic order itself, solemn carrier of Meaning and bearer of the Law; the empirical father is the “simple, more or less decent man”. For Zupančič, the standard rendering of the “typical genesis of subjectivity” has it that the child first of all encounters the Symbolic father and then comes to learn that this mighty figure is a “simple, more or less decent man”. Yet, as Zupančič establishes, this trajectory is the exact inverse of the one which Oedipus pursues. Oedipus begins by encountering a “rude old man at the crossroads” and only later does he learn that this “simple man”, this “vulgar creature”, was the Father. Thus “Oedipus travels the path of initiation (of ‘symbolisation’) in reverse and, in so doing, he encounters the radical contingency of the Meaning borne by the symbolic.”14

For Bruce Wayne, though, there is no discrepancy at all between the Symbolic and the empirical. Thomas Wayne’s early death means that he is frozen in his young son’s psyche as the mighty emissary of the Symbolic; he is never “desublimated” into a “simple man”, but remains a moral exemplar — indeed he is the representative of Law as such, who must be avenged but who can never be equalled. In Batman Begins, it is the intervention of R’as Al Ghul which prompts an Oedipal crisis. The young Wayne is convinced that his father’s death is his fault, but Al Ghul tries to convince him that his parents’ death is his father’s responsibility because the good-natured and liberal Thomas Wayne did not know how to Act; he was a weak-willed failure. Yet Bruce refuses to go through this initiation and retains loyalty to the “Name of the Father” while Al Ghul remains a figure of excess and Evil.

The question Al Ghul poses to Bruce is: are you, with your conscience, your respect for life, too weak-willed, too frightened to do what is Necessary? Can you Act? Wayne is forced to decide: is Al Ghul what he claims to be, the ice-cold instrument of impersonal Justice, or its grotesque parody? The ultimate Evil in the film turns out to originate from Ghul’s excessive zeal, not from some hoaky diabolism nor from some psycho-biographical happenstance.15

In this respect, it is the film that Žižek wanted Revenge of the Sith to be: a film, that is to say, which dares to hypothesise that Evil might result from an excess of Good. For Žižek, “Anakin Skywalker () should have become a monster out his very excessive attachment with seeing Evil everywhere and fighting it”, but

i ()nstead of focusing on Anakin’s hubris as an overwhelming desire to intervene, to do Good, to go to the end for those he loves and thus fall to the Dark Side, Anakin is simply shown as an indecisive warrior who is gradually sliding into Evil by giving way to the temptation of Power, by falling under the spell of the evil Emperor.16

In parallel with Žižek’s reading of Revenge of the Sith, Batman Begins’ treatment of the question of the Father — who is the father? — is doubled by the looming (omni-)presence of finance capital, and the issue of what is to be done about it. In Batman’s universe of course, “the Name of the Father” — Wayne — is also the name of a capitalist enterprise. The takeover of Wayne Industries by shareholder capital means that Thomas’ name has been stolen. Consequently, Bruce Wayne’s struggle against finance capital is also, inevitably, an attempt to restore the besmirched Name of the Father. Since Wayne Industries is at the heart — literally and figuratively — of the city, post-Fordist Gotham finds itself as blighted as the Sphinx-cursed Thebes. Its infrastructure rotten, its civil society disintegrated, Gotham is in the grip of a depression and a crime wave, both of which are attributed to the newly predatory, delocalised Capital that now has control of the Wayne corporation. The impact of finance capital is given a more personal narrative focus through the character of the kindly Lucius Fox (another candidate for Father surrogate)17who is degraded by the new regime. The implication is that this state of rottenness can only be rectified once the name of the Father resumes its rights.

It is in its treatment of capitalism that Batman Begins is at its most intriguingly contradictory. In part, this can be attributed to the effects of attempting to retrofit the 1930s core narrative engine into a twenty-firstcentury vehicle: the reference to the depression is a clear Thirties echo, setting up a disjunction with a contemporary USA that has enjoyed an unprecedented period of economic success. In keeping with capitalism itself, Deleuze and Guattari’s “motley painting of everything that ever was”, Nolan’s Gotham is an admixture of the medieval and the ultra-contemporary, of the American, the European and the Third World. It resembles at once the crooked steeples and spires of German Expressionism and the favela-sprawls of cyberpunk18: the nightmare of Old Europe erupting in the heart of the American Megalopolis.

In a fascinating reading of Batman Begins, China Miéville argues that the film’s anti-capitalism cashes out as an advocacy of fascism. The film, he writes,

is about fascism’s self-realisation, and the only struggle it undergoes is to admit its own necessity. BB argues for the era of the absolute(ist) corporation against the “postmodern” social dilutions of shareholder capitalism (perceived here in old-school corporate paranoia as a kind of woolly weakness), let alone against the foolishness of those well-meaning liberal rich who don’t understand that their desire to travel with the poor and working class are the “causes” of social conflict, because The Rich Man At His Garden The Poor Man At His Gate, and that the blurring of those boundaries confuses the bestial instincts of the sheep-masses. The film argues quite explicitly (in what’s obviously, in its raised-train setting, structured as a debate with Spiderman 2, a stupid but good-hearted film that thinks people are basically decent) that masses are dangerous unless terrorised into submission (Spidey falls among the masses — they nurture him and make sure he’s ok. Bats falls among them — they are a murderous and bestial mob because they are not being “effectively scared enough”). The final way of “solving” social catastrophe is … () by the demolition of the mass transit system that ruined everything by literally raised the poor and put them among the rich: travelling together, social-democratic welfarism as opposed to trickle-downism is a nice dream but leads to social collapse, and if left unchecked terrorism that sends transit systems careering through the sky into tall buildings in the middle of New Yorkstyle cities — 9/11 as caused by the crisis of “excessive social solidarity”, the arrogance of masses “not being sufficiently terrified of their shepherds”. In all a film that says social stratification is necessary to prevent tragedy, and that it should be policed by terrorising the plebeians, for the sake of corporations which if there is a happy ending … () will end up back in the hands of a single enlightened despot, hurrah, to save us from the depredations of consensus.19

There is no doubt that the film poses finance capital as a problem that will be solved by the return of a re-personalised captal, with “the enlightened despot” Bruce taking on the role of the dead Thomas. It is equally clear, as we’ve already seen, that Batman Begins is unable to envisage an alternative to capitalism itself, favouring instead a nostalgic rewind to prior forms of capitalism. (One of the structuring fantasies of the film is the notion that crime and social disintegration are exclusively the results of capitalist failure, rather than the inevitable accompaniments to capitalist “success”.)

However, we must distinguish between corporate capitalism and fascism if only because the film makes such a point of doing so. The fascistic option is represented not by Wayne-Batman but by R’as al Ghul. It is al Ghul who plots the total razing of a Gotham he characterises as irredeemably corrupt. Wayne’s language is not that of renewal-through-destruction (and here Schumpterian capitalism and fascism, in most other respects entirely opposed, find themselves in sympathy), but of philanthropic meliorism. (It should also be noted that the masses who, in a pointed reference to Romero’s Living Dead films, threaten to consume and destroy Batman are under the influence of the Scarecrow’s “weaponised hallucinogens” when they attempt to dismember him, although this image of the masses no doubt tell us more about the political unconscious of the film-makers than it does about that of the masses.)

If the film’s handling of capitalism is incoherent, in what does its challenge to capitalist realism consist? It is to be found not at the level of politics but in its account of ethics, agency and subjectivity. Žižek’s classic account of ideology in The Sublime Object of Ideology turns on the difference between belief and action. At the level of belief, key capitalist ideas — commodities are animate; capital has a quasi-natural status — are repudiated, but it is precisely the ironic distance from such notions that allows us to act as if they are true. The disavowal of the beliefs allows us to perform the actions. Ideology, then, depends upon the conviction that what “really matters” is what we are, rather than what we do, and that “what we are” is defined by an “inner essence”. In terms of contemporary American culture, this plays out in the “therapeutic” idea that we can remain a “good person” regardless of what we do.

The film’s principal ethical lesson presents a reversal of this ideological conviction. In Wayne’s struggle to differentiate justice from revenge, revenge is personified by the uncompromising R’as al Ghul, while justice is represented by the assistant District Attorney, Rachel Dawes. Dawes is given the film’s crucial (anti-therapeutic) slogan, “It’s not who you are inside that counts, it’s what you do that makes you what you are.” The Good is possible, but not without Decision and the Act. In reinforcing this message, Batman Begins restores to the hero an existentialist drama that puts to flight not only capitalist realist nihilism, but also the niggling, knowing sprites of postmodern reflexivity20that have sucked his blood for way too long.





when we dream,

do we dream we’re joey?1

“When you dream, do you dream you’re Joey?”

— Carl Fogarty to Tom Stall, in David Cronenberg’s A History of Violence2

“In a dream he is a butterfly. … () When Choang-tsu wakes up, he may ask himself whether it is not the butterfly who dreams that he is Choang-tsu. Indeed he is right, and doubly so, first because it proves he is not mad, he does not regard himself as fully identical with Choang-tsu and, secondly, because he doesn’t fully understand how right he is. In fact, it is when he was the butterfly that he apprehended one of the roots of his identity — that he was, and is, in his essence, that butterfly who paints himself with his own colours — and it is because of this that, in the last resort, he is Choang-tsu.”

— Jacques Lacan, “The Split Between the Eye and the Gaze”3

The key scene in Cronenberg’s A History of Violence sees the local sheriff addressing the hero, Tom Stall (Viggo Mortensen), after a series of violent killings have disrupted the life of the small midwest town in which they both live: “It just doesn’t all add up.”

Superficially, A History of Violence is Cronenberg’s most accessible film since 1983’s The Dead Zone. Yet it is a film whose surface plausibility doesn’t quite cohere. All the pieces are there but, when you look closely, they can’t be made to fit together. Something sticks out…

What makes A History of Violence unsettling to the last is its uneasy relationship to genre: is it a thriller, a family drama, a bleak comedy, or a trans-generic allegory (“the Bush administration’s foreign policy based upon a Western”)? This generic hesitation means that it is a film suffused with the uncanny. Even when the standard motions of the thriller or the family drama are gone through, there is something awry, so that A History of Violence views like a thriller assembled by a psychotic, someone who has learned the conventions of the genre off by heart but who can’t make them work. Perversely, but appropriately for a Cronenberg picture, it is this “not quite working” that makes the film so gripping.

The near total absence of the prosthetics and FX for which Cronenberg is renowned from A History of Violence (traces of his old schtick survive only in the excessive shots of corpses after they have been shot in the face) has been remarked upon by most critics. In fact, Cronenberg’s renunciation of such imagery has been a gradual process, dating back at least as far as Crash (1998’s eXistenZ may turn out to be the last hurrah for Cronenberg’s pulsating, eroticised bio-machinery), but it has subtlised, rather than removed, his trademark ontological queasiness.

Myth is everywhere in A History of Violence: not only in the hokey smalltown normality which is threatened, nor in the urban underworld of organised crime that threatens to encroach upon it and destroy it, but also in the conflict between the two. A town like Millbrook, the Indiana setting for A History of Violence, has been as likely to feature in American cinema as an image of menaced innocence in its own right. Comparisons with Lynch are inevitable, but it is Hitchcock, not Lynch, who is the most compelling parallel. The Hitchcock comparison goes far beyond surface details, significant as they are, such as the fact that, as the Guardian review reminds us, A History of Violence’s “Main Street resembles the one in Phoenix, Arizona, where the real estate office is to be found in Psycho”.4 There is a much deeper affinity between A History of Violence and Hitchcock which can be readily identified when we recall Žižek’s classic analysis of Hitchcock’s methodology. In Looking Awry, Žižek compares Hitchcock’s “phallic” montage with the “anal” montage of conventional cinema:

Let us take, for example, a scene depicting the isolated home of a rich family encircled by a gang of robbers threatening to attack it; the scene gains enormously in effectiveness if we contrast the idyllic everyday life within the house with the threatening preparations of the criminals outside: if we show in alternation the happy family at dinner, the boisterousness of the children, father’s benevolent reprimands, etc., and the “sadistic” smile of a robber, another checking his knife or gun, a third grasping the house’s balustrade. In what would the passage to the “phallic” stage consist? In other words, how would Hitchcock shoot the same scene? The first thing to remark is that the content of this scene does not lend itself to Hitchcockian suspense insofar as it rests upon a simple counterpoint of idyllic interior and threatening exterior. We should therefore transpose this “flat”, horizontal doubling of the action onto a vertical level: the menacing horror should be placed outside, next to the idyllic interior but well within it: under it, as its “repressed” underside. Let us imagine, for example, the same happy family dinner shown from the point of view of a rich uncle, their invited guest. In the midst of the dinner, the guest (and together with him ourselves, the public) suddenly “sees too much,” observes what he was not supposed to notice, some incongruous detail arousing in him the suspicion that the hosts plan to poison him in order to inherit his fortune. Such a “surplus knowledge” has so to speak an abyssal effect … () the action is in a way redoubled in itself, endlessly reflected as in a double mirror play… things appear in a totally different light, though they stay the same.5

What is fascinating about A History of Violence is that it recapitulates this passage from the anal to the phallic within its own narrative development, entirely appropriate for a film that shows, as Graham Fuller puts it, “the return of the phallus”.6 It begins, precisely, with a non-Hitchcockian contrast between a threatening Outside (a long, sultry tracking shot of two killers leaving a motel) and an idyllic Inside (the Stalls’ family house, where the six-year-old daughter is comforted by her parents and her brother after she is woken from a nightmare). But as the film develops, it effectively re-topologises itself, interiorising the Threat, or, more accurately, showing that the Outside has always been Inside.

The Hitchcockian blot, the Thing that doesn’t fit, is the “hero” himself. The film’s central enigma — is the staid, pacific Tom Stall really the psychopathic assassin Joey Cusack? — can be resolved into the question: which Hitchcock film we are watching? Is A History of Violence a rehashing of The Wrong Man or Shadow of a Doubt? Disturbingly, it turns out that it is both at the same time.

Shadow of a Doubt is the working out of a family scene much like the one described by Žižek above, although in that case, it is the guest, the rich uncle, who is the threat to the domestic idyll. The uncle (Joseph Cotten) is a killer of rich widows who has holed up in the house of his sister’s family to hide from the police. The Wrong Man, meanwhile, sees a family destroyed when the father is falsely accused.

In Shadow of a Doubt, the uncle’s malevolence means that he must die so that the family idyll can be preserved. Only the Teresa Wright character knows the truth; the rest of the family, and the big Other of the community, are kept in ignorance. But of the family members in A History of Violence, by the end of the film, only the youngest child could plausibly not be aware that the family scene has always been a simulation. Crucial in this respect is the response of Stall’s wife, Edie (Maria Bello), as Ballard observed in his piece on A History of Violence in the Guardian:

A dark pit has opened in the floor of the living room, and she can see the appetite for cruelty and murder that underpins the foundations of her domestic life. Her husband’s loving embraces hide brutal reflexes honed by aeons of archaic violence. This is a nightmare replay of The Desperate Hours, where escaping convicts seize a middle-class family in their sedate suburban home — but with the difference that the family must accept that their previous picture of their docile lives was a complete illusion. Now they know the truth and realise who they really are.7

But this isn’t so much a matter of accepting reality in the raw, as it were, but, very much to the contrary, it is a question of accepting that the only liveable reality is a simulation. Where at the start of the film, Edie play acts the role of a cheerleader for Tom’s sexual delectation, by the end she is playacting for real. (And of course, of course… there are no authentic cheerleaders, “real” cheerleaders are themselves playing a role.) If, as Žižek argued in Welcome to the Desert of the Real, 9/11 was already a recapitulation of the “ultimate American paranoiac fantasy … () of an individual living in a small idyllic … () city, a consumerist paradise, who suddenly starts to suspect that the world he lives in is a fake”,8 a kind of real-life staging of The Matrix, then A History of Violence may be the first post 9/11 film in which the American idyll is deliberately and knowingly re-constructed AS simulation. (This is underscored by the fact that not one frame of the film was shot in America. In this respect, the film resembles Kubrick’s Lolita, whose America of motels and dusty highways was entirely reconstructed in Britain. In his interview with Salon, Cronenberg pronounced himself proud of his ability to hoodwink American audiences into believing that they were really seeing the midwest and Philadelphia.)

“When you dream, do you dream you’re Joey?” the mobster Fogarty (Ed Harris) asks Tom Stall, perhaps deliberately echoing Chuang Tzu’s story of a man who dreamt he was a butterfly. Chuang Tzu famously no longer knows if he is a butterfly dreaming that he was Chuang Tzu or Chuang Tzu dreaming that he is a butterfly. Is Tom Stall the dream of Joey Cusack, or is Joey Cusack the bad dream of Tom Stall? It’s no surprise that Lacan should have fixed upon this story, and Forgarty’s question contains an analyst’s assumption: the reality of Tom lies not at the level of the everyday-empirical but at the level of desire. The Real of Stall/Cusack is to be found, fittingly, in the desert, the space of subjective destitution where Stall says that he “killed Joey”.

In an interesting but ultimately unconvincing piece in Sight and Sound, Graham Fuller argues that we should read the film as Stall’s fantasy:

“Who is Joey Cusack?” the movie ponders at its midpoint as it leaves Western territory behind and plunges into a dark pool of noir. But the more fruitful question is “Who is Tom Stall, if not whom Fogarty claims he is, and why does he have a superegoic alter ego?” The name “Stall” indicates stasis. Though he is a diligent, caring husband and father, Tom knows he hasn’t made much of himself in life, and, we learn, harbours resentment towards his estranged wealthy brother, who considers him a fool. This chip on Tom’s shoulder explains his daydreaming which, born of repression, aligns him which such literary and movie dreamers as Walter Mitty and Billy Liar, whose fantasies of themselves as all-conquering heroes are redolent of crippling neuroses, even impotence…9

Tempting as it is, this interpretation is unsatisfactory for a number of reasons. It is guilty of the same “oneiric derealisation” which has blighted responses to both Lynch’s Mulholland Drive and Kubrick’s Eyes Wide Shut, both of which have been interpreted as long dream sequences. Such readings ultimately amount to an attempt to put to rest the films’ ontological threat, ironing out all their anomalies by attributing them to an interiorised delirium. The problem is that this denies both the libidinal reality of dreams — we wake ourselves from dreams, Lacan suggests, in order to flee the Real of our desires — at the same time as it ignores the way in which ordinary, everyday reality is dependent for its consistency on fantasy. It also makes the empiricist presupposition that the quotidian and the banal have more reality than violence; the message of the film is rather that the two are inextricable.

In the end, Stall as the fantasy of Cusack is much more interesting than Cusack as the fantasy of Stall. Is the American small-town idyll the fantasy of a psychopath? After Guantanamo Bay, after Abu Ghraib, this question has a special piquancy. The challenge that A History of Violence poses to the audience comes from the fact that we fully identify with Stall/Joey’s violence. We gain enormous enjoyment when the hoods are dispatched with maximum efficiency. When we dream, do we dream we’re Joey? Do we dream as Joey? Do we dream of being Tom, innocent, regular people, no blood on our hands? Are our “real”, everyday lives really only this dream?

At the same time as we enjoy Joey’s hyper-violent killing of the gangsters, we know that it is impossible for us to position them as the Outside and Stall/Joey as the Inside, and the film reinforces the lesson that Žižek thought we should have learned in the aftermath of 9/11:

Whenever we encounter such a purely evil Outside, we should gather the courage to endorse the Hegelian lesson: in this pure Outside, we should recognise the distilled version of our own essence. For the last five centuries, the (relative) prosperity and peace of the “civilised” West was bought by the export of ruthless violence and destruction into the “barbarian” Outside: the long story from the conquest of America to the slaughter in Congo.10

The most disturbing aspect about the film’s violence is not the gore that results from it, but the reptilian mechanism of its execution. There are no wisecracking one-liners; instead, once the killings are completed with a coiled spring autonomic power, there is an entranced animal calm, a machine exhaustion. (A History of Violence is reflexive without ironic, entirely lacking in any PoMo swagger. It may have put the final bullet into Tarantino’s career, if the spectacular indulgence of Kill Bill didn’t already do that.)

A History of Violence suggests that twenty-first century America is a less a country in which violence is a repressed underside than that it is moebian band where if you begin with ultraviolence you will eventually end up with homely banality, and vice versa. In the final scene, when Tom — now “Tom” — returns to his house, “everything appears in a totally different light, though it has stayed the same”. The images of domesticity have now become “images of domesticity”, the meatloaf and the mashed potato have become “meatloaf” and “mashed potato”, reflexively-placed icons of American normality, the very definition of the unhomely, the unheimlich, the uncanny. Such, as Žižek said in the 9/11 piece, is the nature of “late capitalist consumerist society”, where “‘real social life’ itself somehow acquires the features of a staged fake”. This is a simulated scenario far bleaker than that of The Truman Show or Dick’s Time Out of Joint, since it has been freely and knowingly embraced by the subjects themselves. There is no Them behind the scenes orchestrating and choreographing the simulation. At the end of the film, everyone is fooling but no one is fooled.





notes on cronenberg’s

eXistenZ1

“Can what is playing you make it to level 2?” asked Nick Land in his 1994 discussion of cybertheory, “Meltdown”.2 Land’s intuition that computer games would provide the best way to understand subjectivity and agency in digital culture was also the gambit of David Cronenberg’s 1999 film eXistenZ. The film takes place in a near-future in which games are capable of generating simulated environments which can barely be distinguished from real life. Instead of computer terminals or game consoles, players use organic “game pods”, which are connected directly to the players’ bodies via “bio-ports” in their spines.

The main characters are Ted Pikul (Jude Law) and Allegra Geller (Jennifer Jason Leigh). We are first of all led to believe that Pikul is a neophyte gameplayer, being reluctantly initiated into the gameworld by Geller, who at this point seems to be the designer of the game (called eXistenZ) which they are playing. The two are pitched into a complex intrigue: a struggle between rival games corporations, and between gameplayers and “realists” — those who believe that the games are corroding the structure of reality itself. This corrosion is performed by the film itself, with what one of the characters memorably describes as “reality bleed-through” effects, so that the reality layers — only very weakly differentiated in any case — become difficult to distinguish. By the end it seems that both eXistenZ the game and what we had taken to be real life are embedded inside another game, tranCendenZ, but by now we cannot be sure of anything. The last line of dialogue is “Tell me the truth, are we still in the game?”

At the time of release, it seemed like eXistenZ was a late-arriving take on a series of themes and tropes familiar from 1980s cyberpunk — ideas Cronenberg had helped to shape in Videodrome. In retrospect, however, it is possible to see eXistenZ as part of a rash of late-1990s and early-2000s films, including The Matrix and Vanilla Sky, which mark a transition from what Alan Greenspan called the “irrational exuberance” of the 1990s bubble economy into the early twenty-first-century War on Terror moment. There is an abrupt mood shift toward the end of eXistenZ, with a military insurrection complete with heavy artillery and explosions. For the most part, though, the dominant mood is more quotidian. By contrast with the hyper-conspicuous CGI of The Matrix, with which it was destined to be most compared, eXistenZ is sparing in its use of special effects. The look is subdued, resolutely nonspectacular: there is a lot of brown. The brownness seems like a refusal of the gloss that will increasingly come to coat the artifacts of digital culture.

With its dreary trout farms, ski lodges, and repurposed churches, the world (or, more properly, worlds) of eXistenZ have a mundane, lived-in quality. Or rather worked-in: much of the film happens in workplaces — gas station, factory, workshop — and this dimension of the film is what now seems prophetic. Though never explicitly discussed, labour is something like an ambient theme, omnipresent but unarticulated. The key to eXistenZ’s selfreflexivity is its preoccupation with the conditions of its own production (and the production of culture in general). It presents us with an uncanny compression, in which the “front end” of late capitalist culture — its cuttingedge entertainment systems — fold back into the normally unseen “back end” (the quotidian factories, labs, and focus groups in which such systems are produced). The clamour of capitalist semiotics, the frenzy of branding sigils and signals, is curiously muted in eXistenZ. Instead of being part of the background hum of experience, as they are in both everyday life and the typical Hollywood movie, brand names appear only rarely in eXistenZ. The ones that do appear — most of them the names of games companies — leap out of the screen. The generic naming of space is in fact one of the running jokes in the film: a country gas station is simply called Country Gas Station, a motel is called Motel. This is part of the flat affect, the strange tonelessness, which governs most of the film.

The digitisation of culture which we take for granted now was only in its infancy in 1999; broadband was a few years off, as was the iPod, and eXistenZ has little to tell us about the digital communications equipment that proliferated in the decade after it was released. Handheld devices do not play any major role in eXistenZ — the glowing phone belonging to Pikul is thrown out of a car window by Geller — and, with its longueurs, its lingering in dead time, the film is very far from registering the jittery, attention-dispersing effects of “always-on” mobile technology. The most resonant aspects of eXistenZ do not reside in the body horror which was then still Cronenberg’s signature — although the scenes of the characters being connected to their organic game pod by bio-ports are typically grisly. Nor are they to be found in the perplexity expressed by characters as to whether they are inside a simulation or not — this is a theme that was already familiar from Videodrome, as well as Verhoeven’s Total Recall, both of which (in the first case indirectly, in the second more directly) took their inspiration from Philip K. Dick’s fiction. Instead it is the idea — in some ways stranger and more disturbing than the notion that reality is fake — that subjectivity is a simulation which is the distinctive insight of eXistenZ.

This idea emerges, in the first place, through confronting other automated (or rather partially automated) consciousnesses: entities that seem autonomous but in fact can only respond to certain trigger phrases or actions that move the gameplay down a predetermined pathway. Some of the most memorable (and humorous) scenes in eXistenZ show encounters with these Read Only Memory beings. We see one of the characters locked in a “game loop”, silently lolling his head while waiting to hear the keywords that will provoke him back into action. Later, a clerk is seen repeatedly clicking a pen — as a background character he is programmed not to respond until his name is called. More disturbing than the third-person (or nonperson) encounter with these programmed drones is Pikul’s experience of subjectivity being interrupted by an automatic behavior. At one point, he suddenly finds himself saying, “It’s none of your business who sent us! We’re here and that is all that matters”. He is shocked at the expostulation: “God, what happened? I didn’t mean to say that.” “It’s your character who said it”, Geller explains. “It’s kind of a schizophrenic feeling, isn’t it? You’ll get used to it. There are things that have to be said to advance the plot and establish the characters, and those things get said whether you want to say them or not. Don’t fight it.” Pikul later grimly notes that it makes no difference whether he fights these “game urges” or not.

The emphasis on the curtailing of free will is one reason that Cronenberg’s claim that the film is “existentialist propaganda” seems odd. Existentialism was a philosophy which claimed that human beings (what Sartre called the “for-itself”) are “condemned to be free”, and that any attempt to avoid responsibility for one’s actions amounts to bad faith. There is an absolute difference between the for-itself and what Sartre called the “in-itself” — the inert world of objects, denuded of consciousness. Yet eXistenZ, in common with much of Cronenberg’s work, troubles the distinction between the foritself and the in-itself: machines turn out to be anything but inert, just as human subjects end up behaving like passive automata. As in Videodrome before it, eXistenZ draws out all the ambiguities of the concept of the player. On the one hand, the player is the one in control, the agent; on the other, the player is the one being played, the passive substance directed by external forces. At first, it seems that Pikul and Geller are for-itself, capable of making choices, albeit within set parameters (unlike in The Matrix, they are constrained by the rules of the world into which they are thrown). The game characters, meanwhile, are the in-itself. But when Pikul experiences “game urges”, he is both in-itself (a merely passive instrument, a slave of drive) and for-itself (a consciousness that recoils in horror from this automatism).

To appreciate eXistenZ’s contemporary resonance it is necessary to connect the manifest theme of artificial and controlled consciousness with the latent theme of work. For what do the scenes in which characters are locked in fugues or involuntary-behavior loops resemble if not the call-centre world of twenty-first-century labour in which quasi-automatism is expected of workers, as if the undeclared condition of employment were to surrender subjectivity and become nothing more than a bio-linguistic appendage tasked with repeating set phrases that make a mockery of anything resembling conversation? The difference between “interacting” with a ROM-construct and being a ROM-construct neatly maps onto the difference between telephoning a call centre and working in one.

In Being and Nothingness, Sartre famously used the example of the waiter: someone who overplays the role of waiter to the extent that they (to outside appearances at least) eliminate their own subjectivity. The power of Sartre’s example depends upon the tension between the would-be automatism of the waiter’s behavior and the awareness that behind the mechanical rituals of the waiter’s over-performance of his role is a consciousness that remains distinct from that role. In eXistenZ, however, we are confronted with the possibility that agency can genuinely be interrupted by the “inflexible stiffness of some kind of automaton”. In any case, eXistenZ compels us to reread Sartre’s description of the waiter in its terms, especially since one of the most horrific scenes of being-played features none other than a waiter. Pikul and Geller are sitting in a restaurant when Pikul feels himself overcome by a “game urge”:

Pikul: You know, I do feel the urge to kill someone here.

Geller: Who?

Pikul: I need to kill our waiter.

Geller: Oh. Well that makes sense. Um, waiter! Waiter!

She calls over waiter ()

Geller: When he comes over, do it. Don’t hesitate.

Pikul: But… everything in the game is so realistic, I— I don’t think I really could.

Geller: You won’t be able to stop yourself. You might as well enjoy it. Pikul: Free will… is obviously not a big factor in this little world of ours.

Geller: It’s like real life. There’s just enough to make it interesting.

“You won’t be able to stop yourself, you might as well enjoy it” — this phrase captures all too well the fatalism of those who have given up the hope of having any control over their lives and work. Here, eXistenZ emerges, not as “existentialist propaganda” but as decisively anti-existentialist. Free will is not an irreducible fact about human existence: it is merely the unpreprogrammed sequence necessary to stitch together a narrative that is already written. There is no real choice over the most important aspects of our life and work, eXistenZ suggests. Such choice as there is exists one level up: we can choose to accept and enjoy our becoming in-itself, or reject it (perhaps uselessly). This is a kind of deflation-in-advance of all of the claims about “interactivity” that communicative capitalism will trumpet in the decade after eXistenZ was released.

Autonomist theorists have referred to a turn away from factory work toward what they call “cognitive labour”. Yet work can be affective and linguistic without being cognitive — like a waiter, the call-centre worker can perform attentiveness without having to think. For these non-cognitive workers, indeed, thought is a privilege to which they are not entitled.

The muted tones of eXistenZ anticipate a digital-era banality, and it is the banal quality of life in a digitally automated environment — humansounding voices that announce arrivals and departures at a railway station, voice-recognition software which fails to recognise our voices, call-centre employees drilled into mechanically repeating a set script — that eXistenZ captures so well.





i filmed it so i didn’t have to remember it myself1

I was reminded of A History of Violence while watching Andrew Jarecki’s ultra-disturbing documentary Capturing the Friedmans on Channel 4’s new digital service, more4, the other night.

Capturing the Friedmans is about a family from Great Neck, New York State, two of whose members (the father, Arnold, and one of the sons, Jesse, then only a teenager) pleaded guilty to serious sexual offences and were consequently jailed. Were they guilty? We can be reasonably confident only that Arnold had paedophiliac tendencies, and owned child pornography; he also confessed to having had some sort of sexual contact, short of sodomy, with two boys, but not in Great Neck. The rest is an enigma which makes Rashomon seem like an open and shut case. Jesse’s role, for instance, is desperately unclear. The supposed victims claimed that Jesse had participated in, and assisted with, his father’s violent abuses. But a campaigner cast doubt on the victims’ testimony, none of which was corroborated by any physical evidence, and most of which seemed to have been “recovered” after they had been hypnotised.

The gaps in the Friedman narrative are all the more glaring because of the plethora of recorded material that IS available. This was a family that seemed — like many now I suppose — to obsessively record itself. Part of the “capturing” of the Friedmans is their capturing of themselves, on film and on tape. A documentary like this only became possible now that filming technology — cine cameras and later camcorders — had become widely available for the first time and kids are filmed from the moment of birth. The whole thing felt like a grim counterpoint to the proto-reality TV documentary of the Loud family Baudrillard discussed in “Precession of Simulacra”.2 In a way, the most painful material consists of home movie footage of the Friedmans shot in the 1970s, in which they look for all the world like a perfectly happy family, the kids mugging and clowning for the cameras. Never has Deleuze’s observation that “family photos” are, by their very nature, profoundly misleading, been more bitterly borne out. Later, as the trials start and the recriminations follow, the family filmed and audiotaped themselves ripping each other to shreds.

Why did they continue to film? “How do they remember, those who do not film?” asks Chris Marker in Sans Soleil. But why would the Friedmans want to remember their journey into Hell? Who could possibly want to film this? In Lost Highway, Fred Madison (Bill Pullman) claimed that he hated the thought of video-taping his own life because he “liked to remember things in his own way”. In an uncanny complement to this, David Friedman, who recorded the events of the day Jesse was sentenced to eighteen years imprisonment, said that he filmed it “so I didn’t have to remember it myself”. The machines remember, so we don’t have to.





spectres of marker and the reality of the third way1

Watching Chris Marker’s Le Fond de l’air est rouge (A Grin Without a Cat) last week made for a somewhat ambivalent experience: even though the film is, ostensibly, a catalogue of disappointments, its registering of a time when there were challenges — no matter how inchoate, messy, contradictory — to the existing order, cannot but offer some inspiration in these much bleaker times. A Grin Without a Cat, originally released in 1977 but given a new post-89 epilogue by Marker in 1992, is an epic montage-meditation on what Marker called “the Third World War”: the hydra-headed revolutionary or would-be revolutionary struggles of the Sixties and the Seventies. Marker constructed the film entirely out of archive material, shooting no original footage, and producing associations, connections, foreshadowings and echoes through masterly editing. The effect, especially if you are not minutely familiar with events in France, Vietnam, Algeria, Bolivia, Cuba and Czechoslovakia is disorientating, vertiginous. You find yourself Quantum-Leapt into the middle of a jostling crowd scene; no sooner have you got your bearings there when you abruptly find yourself in another place, another time. Marker’s commentary — spoken by a number of actors — gives you clues, epigraphs, rather than explication. But Marker’s aim not to render the period from 67 to 77 as Objective History to be pontificated upon by “experts” for whom the Meaning of the events is already established, nor, even worse, to produce a vanguardist version of I Heart 1968, in which sighing former revolutionaries look back on anger with the tender contempt of contemporary “wisdom”. No, the point was to present the events “in becoming”, to restore to them a subjectivity (in the Kierkegaardian sense) that retrospection structurally forecloses.

At one stage in the film, Marker’s commentary ruefully notes that while revolutionaries, failed revolutionaries and ex-revolutionaries devoted all their attention to the formation of the New Left, the New Right was coalescing, unnoticed. Cue images of Valery Giscard D’estaing playing football in a carefully-cultivated attempt to look sporty and modern. The PR director of Citroën muses on the “science of management” (too complicated, he says, for even the most talented Union member to master) and looks forward to the incorporation of leftist desire into Capital that would become post-Fordism.

Cut to now, where the images of even an ultimately failed militancy belong to a past. A past that was not — in one sense — even mine, that was over before I was born in July 1968. Yet the reverberations continued for a few years yet, were an unacknowledged (by me, then) background to the things that I enjoyed in the late Seventies and early Eighties. For those of us arriving after the event, the significance of the convulsions documented in Marker’s film could only be apprehended much later, once their effects had completely ebbed away and the reality (and the pleasure) principles were Restored. Marcus’ Lipstick Traces — whose temporal jump-cutting in many ways recalls that of Marker’s film — goes some way to establishing the connections between the events remembered in A Grin Without a Cat and those that began in the UK at more or less the time that the film was completed. A cheshire cat’s grin, lipstick traces on a cigarette, spectres of Marx: Marcus, Derrida and Marker come to see ruptures, revolts and revolutions as ghostly residue, thin stains on the seamless surfaces of post-Cold War Capital.

The untranslateable French title of Marker’s film suggests possibilities that hovered and haunted without ever making themselves real. At the Marker conference held at the ICA a few years ago, Barry Langford argued that, “rather than the spectre of Communism famously invoked by Marx in the opening lines of the Communist Manifesto”, for both A Grin Without a Cat and Marx’s “The Civil War in France” a hundred years before it, “it is the phantom of revolution that haunts Marx and Marker alike — that is, the fear that revolution will ultimately prove, precisely, phantasmic”. If Marx and Marker’s fear was that revolution would only be a spectre, our suspicion is that it will not turn out to be even that, that the stricken ghosts have been put to flight once and for all. (And even the “death of communism” is not enough for the guardians of the new status quo, for whom “communism is not dead enough — … () they will only be content when they have driven a stake through its heart and buried it at the crossroads at midnight”.2)

The struggles in A Grin Without a Cat might have been defeated, might even have contributed to a more ferociously effective Reaction, but the pressures that those events brought to bear almost had very immediate effects — by contesting the Possible, by rejecting “realism”, they could not but have altered expectations about what was acceptable in the workplace, about what could happen in everyday life. The revolutions were cultural; which is to say, they understood that culture and politics could not be conceived in isolation from one another. Both Althusser and the Situationist-inspired students of 68, in many ways so opposed, could agree on at least one thing: that cultural products were never merely cultural. In their condemnations of recuperated Spectacle and Ideological Apparatuses, they granted a weight to cultural products which few would countenance now.

I felt the contrast between what Marker’s film recounted and contemporary realities especially painfully last week when I went on a TUC training course with members of NATFHE from other FE colleges. The stories of increased casualisation, of newly punitive sickness policies, of lecturers being sacked and forced to re-apply for their jobs, of the imposition of more and more targets and “spurious measurable”, each entailing yet more pointless, window-dressing paperwork, confirmed what, individually, we all already knew. The Further Education sector is in crisis; its problems only symptomatic of a wider malaise in UK education as a whole. Further Education colleges, out of Local Education Authority control since 1992, show the way in which a “reformed” (i.e. part-privatised) education will develop. The recent report which stated that students spoon-fed at A-level cannot cope with university study would come as little surprise to few A-level teachers and lecturers. The pressure to meet government targets means that quality and breadth of teaching is sacrificed for the narrow goal of passing the exam: an instrumentalisation of education that fully accepts that its only role is to reproduce the labour force. Far, far away from 68, at the core of whose conflagrations was education, and the question of what it could be: could it be more than an ideological training camp, a carceral institution?

One thing that occurred to me last week, prompted by the contrast between Marker’s Then and our Now, was that the third way is not entirely a phantasm, an ideological dupe. There is in fact a reality to the third way, and it is the reality of bureaucracy. That is what is left once politics has become administration.

It’s hard to believe that public services are not more clogged with bureaucracy than they were pre-Thatcher. Certainly, education is choked with the stuff… targets, action plans, log books, all of them required conditions for funding by the Learning and Skills Council, and assessed by Ofsted, whose threat no longer takes the form of an invasive external entity arriving every two or three years, but has become introjected into the institution itself, through the permanent panoptic vigilance of a bloated managerial strata determined to over-compensate in order to fully ensure it is meeting central government’s demands. This is the reality of “market Stalinism” in education.

Is there a way to challenge or roll back the slow, implacable, rapacious proliferation of bureaucracy? Only by a collective action that seems inconceivable now… Only by a change in the ideological climate… Only by a switch in the cultural atmosphere… Where to start? While we search, desperately, for cracks in the Possible, bureaucracy, that steel spider, patiently spins its grey web…





dis-identity politics1

The discussion of V for Vendetta has been far more interesting than the film deserved. Yes, there is a certain frisson in seeing a major Hollywood movie refusing to unequivocally condemn terrorism, but the political analysis in the film (as in the original comic) is really rather threadbare. That is Moore’s fault; it can’t be blamed on the Wachowskis. Like all of Moore’s work, V for Vendetta is considerably less than the sum of its parts. I’ve complained before of finding Moore’s continual efforts to reassure himself and his readers of their erudition — every time you are about to succumb to the fictional world, it’s as if Moore taps you on your shoulder and say, “We’re too good for this, aren’t we folks?” — highly distracting and irritating.

As for V for Vendetta’s politics — apart from the subjective destitution scenes, they amount in large part to the familiar populist ideology which maintains that the world is controlled by a corrupt oligarchy that could be overthrown if only people knew about it. Steven Shaviro says that “rather than trying to please all demographics, the film () identifies a deeply religious, homophobic, ultra-patriotic, imperialistic surveillance state as the source of oppression.”2 But isn’t this precisely “appealing to all demographics”, since few homophobic fascists will identify themselves as homophobic fascists, and it’s hard to imagine anyone warming to Hurt’s foaming-at-the-mouth ranter, still less voting for him. Postmodern fascism is a disavowed fascism (cue the BNP leaflet delivered through my door when I lived in Bromley, photograph of a smiling kiddywink, slogan: “My daddy’s not a fascist”), just as homophobia survives as disavowed homophobia. The strategy is to refuse the identification while pursuing the political programme. “We of course deplore fascism and homophobia, but…” The Wachowskis’ government bans the Koran, but that is the last thing that Blair and Bush would ever do; no, they will praise Islam as a “great religion of peace” while bombing Muslims.

Blair’s authoritarian populism3 is far more sinister than V for Vendetta’s pantomime autocracy precisely because Blair is so successful at “presenting himself as the reasonable, honest bloke on the side of the common man”. Similarly, Bush’s linguistic incompetence, far from being an impediment to his success, has been crucial to it, since it has allowed him to pose as a “man of the people”, belying his privileged Harvard and Yale-educated background. It is significant in fact that class is not mentioned at all in the film. As Jameson wryly notes in “Marx’s Purloined Letter”, it is not

particularly surprising that the system should have a vested interest in distorting the categories whereby we think class and in foregrounding gender and race, which are far more amenable to liberal ideal solutions (in other words, solutions that satisfy the demands of ideology, it being understood that in concrete social life the problems remain equally intractable).4

The climactic scenes of V for Vendetta, in which the people rise up (by this time, against no one) made me think, not of some great political Event, but rather of the Make Poverty History campaign — a “protest” with which no one could possibly disagree. The comparison with Fight Club does V for Vendetta no favours; the targets of Tyler Durdon’s terrorism were not the fusty symbols of the political class but the franchise coffee bars and skyscrapers of impersonal capital.

I’m no fan of the Wachowskis’ Matrix, but it succeeded in two ways that V for Vendetta never will. The Matrix has become a massively propagated pulp mythos (whereas who but academics will think about the V for Vendetta film a year from now? It’ll be a year after that until academics recognise that the far more fascinating and sophisticated Basic Instinct II is worthy of study). More importantly, it suggested that what counts as “real” is an eminently political question.

That ontological dimension is what is missing from the progressive populist model, in which the masses cannot but appear as a dupes, fooled by the lies of the elite but ready to effectuate change the moment they are made aware of the truth. The reality, of course, is that the “masses” are under few illusions about the ruling elite (if anyone is credulous about politicians and “capitalist parliamentarianism”, it is the middle classes). The Subject Supposed Not To Know is a figure of populist fantasies — more than that: the duped subject awaiting factual enlightenment is the presupposition on which progressive populism rests. If the most crucial political task is to enlighten the masses about the venality of the ruling class, then the preferred mode of discourse will be denunciation. Yet, this repeats rather than challenges the logic of the liberal order; it is no accident that the Mail and the Express favour the same denunciatory mode. Attacks on politicians tend to reinforce the atmosphere of diffuse cynicism upon which capitalist realism feeds. What is needed is not more empirical evidence of the evils of the ruling class but a belief on the part of the subordinate class that what they think or say matters; that they are the only effective agents of change.

This returns us to the question of reflexive impotence. Class power has always depended on a kind of reflexive impotence, with the subordinate class’ beliefs about its own incapacity for action reinforcing that very condition. It would, of course, be grotesque to blame the subordinate class for their subordination; but to ignore the role that their complicity with the existing order plays in a self-fulfilling circuit would, ironically, be to deny their power.

“C ()lass consciousness”, Jameson observes in “Marx’s Purloined Letter”,

turns first and foremost around the question of subalternity, that is around the experience of inferiority. This means that the “lower classes” carry around within their heads unconscious convictions as to the superiority of hegemonic or ruling-class expressions or values, which they equally transgress and repudiate in ritualistic (and socially and politically ineffective) ways.

There is a way, then, in which inferiority is less class consciousness than class unconsciousness, less about experience than about an unthought precondition of experience. Inferiority is in this sense an ontological hypothesis that is not susceptible to any empirical refutation. Confronted with evidence of the incompetence or corruption of the ruling class, you will still feel that, nevertheless, they must possess some agalma, some secret treasure, that confers upon them the right to occupy the position of dominance.

Enough has been already been written about the kind of class displacement people like myself have experienced. Dennis Potter’s Nigel Barton plays remain perhaps the most vivid anatomies of the loneliness and agony experienced by those who have been projected out of the confining, comforting fatalism of the working-class community and into the incomprehensible, abhorrently seductive rituals of the privileged world. “A drive from nowhere leaves you in the cold”, as the Associates sang in “Club Country”, “Every breath you breathe belongs to someone there.”

There is a Cartesian paradox about such experiences, in that they are significant only because they produce a distanciation from experience as such; after undergoing them, it is no longer to conceive of experience as some natural or primitive ontological category. Class, previously a background assumption, suddenly interposes itself — not so much as a site for heroic struggle, but as a whole menagerie of minor shames, embarrassments and resentments. What had been taken for granted is suddenly revealed to be a contingent structure, producing certain effects (and affects). Nevertheless, that structure is tenacious; the assumption of inferiority constitutes something like a core programming which makes sense of the world in advance. To think of oneself as capable of doing a “professional” job, for instance, requires a traumatic shift in perspective, and if there are confidence crises and nervous breakdowns, they will be very often the consequence of the core programming intermittently reasserting itself.

The real lesson to draw from Potter’s Barton plays is not the fatalistheroic one about the agonies of the charismatic individual confronting intransigent social structures. The plays have to be read instead against class-as-ethnicity and for class-as-structure; in any case, as they make clear, the occult machineries of social structure produce the visible ethnicities of language, behaviour and cultural expectations. The plays’ demand is not for a re-acceptance into the rejecting community, nor a full accession into the elite, but for a mode of collectivity yet to come.

Potter’s challenges to naturalism then, become far more than mere PoMo trickery. His foregrounding of the way in which fictions structure reality, and of the role that television itself plays in this process, brings to the fore all the ontological issues that worthier, more traditional social realist writers conceal or distort. There is no realism, Potter suggests, beyond the Real of class antagonism.

Now is perhaps the time to address two good questions that Bat5 mailed in response to the reflexive impotence post. First, Bat asked, is the situation for French teenagers different from that of their British counterparts? This is easily dealt with, since, after all, it was the very problem with which the post aimed to deal. French students are far more embedded in a Fordist/disciplinary framework than are British students. In education and employment, the disciplinary structures survive in France, providing some contrast with, and resistance to, the cyberspatial pleasure matrix. (For reasons I will explore in more depth shortly, this is not necessarily for the best, however.) Bat’s second question raised more important issues; doesn’t talking about reflexive impotence reinforce the very interpassive nihilism it supposedly condemns? I would say that the exact opposite is the case. I’ve had more mail about the reflexive impotence post than any other; mostly, actually, from teenagers and students who recognise the condition but who, far from being further depressed by seeing it analysed, find its identification inspiring. There are very good Spinozist and Althusserian reasons for this — seeing the network of cause-and-effect in which we are enchained is already freedom. By contrast, what is depressing is the implacable poptimism of the official culture, forever exhorting us to be excited about the latest dreary-shiny cultural product and hectoring us for failing to be sufficiently positive. A certain “vulgar Deleuzianism”, preaching against any kind of negativity, provides the theology for this compulsory excitation, evangelising on the endless delights available if only we consume harder. But what it is so often inspiring — in politics as much as in popular culture — is the capacity to nihilate present conditions. The nihilative slogan is neither be “things are good, there is no need for change”, nor “things are bad, they cannot change”, but “things are bad, therefore they must change.”

This brings us to subjective destitution, which, unlike Steve Shaviro, I think is a precondition of any revolutionary action. The scenes of Evey’s subjective destitution in V for Vendetta are the only ones which had any real political charge. For that reason, they were the only scenes which produced any real discomfort; the rest of the film does little to upset the liberal sensibilities which we all carry around with us. The liberal programme articulates itself not only through the logic of rights, but also, crucially, through the notion of identity, and V is attacking both Evey’s rights and her identity. Steve says that you can’t will subjective destitution. I, however, would say that you can only will it, since it is the existential choice in its purest form. Subjective destitution is not something that happens in any straightforward empirical sense; it is, rather, an Event precisely in the sense of being an incorporeal transformation, an ontological reframing to which you must assent. Evey’s choice is between defending her (old) identity — which, naturally, also amounts to a defence of the ontological framework which conferred that identity upon her — and affirming the evacuation of all previous identifications. What this brings out with real clarity is the opposition between liberal identity politics and proletarian dis-identity politics. Identity politics seeks respect and recognition from the master class; dis-identity politics seeks the dissolution of the classifactory apparatus itself.

That is why British students are, potentially, far more likely to be agents of revolutionary change than are their French counterparts. The depressive, totally dislocated from the world, is in a better position to undergo subjective destitution than someone who thinks that there is some home within the current order that can still be preserved and defended. Whether on a psychiatric ward, or prescription-drugged into zombie oblivion in their own domestic environment, the millions who have suffered massive mental damage under capitalism — the decommisioned Fordist robots now on incapacity benefit as well as the reserve army of the unemployed who have never worked — might well turn out to be the next revolutionary class. They really do have nothing to lose…





“you have always been the caretaker”: the spectral spaces of the overlook hotel1

“What is anachronistic about the ghost story is its peculiarly contingent and constitutive dependence of physical place and, in particular, on the material house as such. No doubt, in some pre-capitalist forms, the past manages to cling stubbornly to open spaces, such as a gallows hill or a sacred burial ground; but in the golden age of this genre, the ghost is at one with a building of some antiquity … () Not death as such, then, but the sequence of such ‘dying generations’ is the scandal reawakened by the ghost story for a bourgeois culture which has triumphantly stamped out ancestor worship and the objective memory of the clan or extended family, thereby sentencing itself to the life span of the biological individual. No building more appropriate to express this than the grand hotel itself, with its successive seasons whose vaster rhythms mark the transformation of American leisure classes from the late 19th century down to the vacations of present-day consumer society.”

— Fredric Jameson, “Historicism in The Shining”2

“T ()he strongest compulsive influence arises from the impressions which impinge upon the child when we would have to regard his psychical apparatus as not yet completely receptive. The fact cannot be doubted; but it is so puzzling that we may make it more comprehensible by comparing it with a photographic exposure which can be developed after any interval of time and transformed into a picture.”

— Sigmund Freud, “Moses and Monotheism”3

Space is intrinsic to spectrality, as one of the meanings of the term “haunt” — a place — indicates. Yet haunting, evidently, is a disorder of time as well as of space. Haunting happens when a space is invaded or otherwise disrupted by a time that is out-of-joint, a dyschronia.

The Shining – King’s novel, and Kubrick’s “unfaithful” film version, both of which I propose to treat as one interconnected textual labyrinth — is fundamentally concerned with the question of repetition. In Spectres of Marx, Derrida defines hauntology as the study of that which repeats without ever being present. To elaborate, we might say that the revenant repeats without being present in the first place — where “place” is equivalent in meaning to “time”. Nothing occupies the point of origin, and that which haunts insists without ever existing. We shall return to this presently (or would it be better to say, it will return to us?).

Precisely because it is so centrally about repetition, The Shining is a deeply psychoanalytic fiction. You might say that it translates psychoanalysis’ family dramas into the stuff of horror, except that it does rather more; it demonstrates what many have long suspected — that psychoanalysis already belongs to the genre of horror. Where else could we place concepts such as the death drive, the uncanny, trauma, the compulsion to repeat?

Yet The Shining is about repetition in a cultural, as well as a psychoanalytic sense. Hence Jameson’s interest. Jameson, after all, has theorised postmodernity in terms of repetition, albeit a repetition that is disavowed. The “nostalgia mode” he refers to names an all-but ubiquitous yet largely unacknowledged mode of repetition, in a culture in which the conditions for the original and the ground-breaking are no longer in place, or are in place only in very exceptional circumstances. The nostalgia in question is neither a psychological nor an affective category. It is structural and cultural, not a matter of an individual or a collective longing for the past. Almost to the contrary, the nostalgia mode is about the inability to imagine anything other than the past, the incapacity to generate forms that can engage with the present, still less the future. It is Jameson’s claim that representations of the future, in fact, are increasingly likely to come to us garbed in the forms of the past: Blade Runner, with its well-known debt to film noir, is exemplary here (and nothing makes Jameson’s point more clearly than Blade Runner’s domination over science fiction film in the last twenty-five years).

According to Jameson, then, The Shining, then, is a “metageneric” reflection on the ghost story (a ghost story that is about ghost stories). Yet I want to claim The Shining does not belong to postmodernity, but rather to postmodernity’s doppelganger, hauntology. We could go so far as to say that it is a meta-reflection on postmodernity itself. As Jameson reminds us, The Shining is also about a failed writer: a would-be novelist who yearns to be virile writer in the strong modernist mould, but who is fated to be a passive surface on which the hotel — itself a palimpsest of fantasies and atrocities, an echo chamber of memories and anticipations — will inscribe its pathologies and homicidal intent. Or, it would be better to say, for this is the horrible dyschronic temporal mode proper to the Overlook, it will have always done.

The Overlook and the Real

“Around him, he could hear the Overlook Hotel coming to life.”

— Stephen King, The Shining4

There is no escape from the infinite corridors of the Overlook. It is no gloomy castle, easily relegated to an obsolete genre (the gothic romance); neither is it a supernatural relic that will crumble to dust when exposed to the harsh light of scientific reason. Concealed behind the alluring ghosts of the hotel’s Imaginary which seduce Jack, the horrors that stalk the Overlook’s corridors belong to the Real. The Real is that which keeps repeating, that which re-asserts itself no matter how you seek to flee it (more horribly, it is that which re-asserts itself through the attempts to flee it: the fate of Oedipus). The Overlook’s horrors are those of the family and of history; or more concisely, they are those of family history (the province, needless to say, of psychoanalysis).

David A. Cook has already shown how the film version is haunted by American history.5 In Cook’s rendition, the Overlook, that playground of the ultra-privileged and the super-crooked (and no one, in the still paranoid post-Watergate dusk when King wrote the novel, could be so naïve as to imagine that these two groups could be parsed), metonymically stands in for the nightmare of American history itself. A leisure hive built on top of an Indian Burial Ground (this detail was added by Kubrick); a potent image of a culture founded upon (the repression of) the genocide of the native peoples:

It was as if another Overlook now lay scant inches beyond this one, separated from the real world (if there is such thing as a “real world” Jack thought) but gradually coming into balance with it.6

Important as Cook’s reflections are, as I have already indicated, I want to concentrate, not on the macro-level of history, on the micro-level of the family. This, inevitably, brings us to Walter Metz’s valuable reflections on the way in which The Shining is intertextually bound up with the melodrama genre.7 A central tension in the film — a tension which for some is never quite resolved — concerns how The Shining is ultimately to be generically placed: is it about the family (in which case, it belongs to melodrama) or is about the supernatural (in which case, it belongs to horror or the ghost story)?8 This inevitably recalls Todorov’s famous claim that the “fantastic” is defined by the hesitation between two epistemological possibilities; if spectral forces can be explained psychologically or by some other naturalistic means, then we are dealing with the “uncanny”. If the spectres of the supernatural cannot be exorcised, then we are dealing with the “marvellous”. Only while we oscillate between the two possibilities do we confront the “fantastic”.

The Uncanny

Melodrama The Fantastic The Marvellous

The ghost story

Noting that most critics have regarded The Shining as a case of the “marvellous”, Metz positions The Shining as an example of the “uncanny”.

But I want to argue that The Shining is important because it scrambles the terms of Todorov’s schema; it is, at one and the same time, a family melodrama and a ghost story. If the ghosts are real, it is not because they are supernatural; and if the spectres are psychoanalytic, that is not to say that they can be reduced to the psychological. Just the reverse, in fact: rather than the spectral being subsumed by the psychological, for psychoanalysis, the psychological can be construed as a symptom of the spectral. It is the haunting that comes first.

Patriarchy as Hauntology

The Overlook’s ghosts are inescapable because they are the spectres of family history, and who of us is without a family history?9 The Shining is a fiction, after all, about fathers and sons. Its genesis lay in a fantasy from which King the father, still struggling with alcoholism, recoiled, but which King the writer was fascinated by. Finding his papers scattered by his son one day, King flew into a blind rage; later he realised he could easily have struck the child. The germ of the novel was King’s extrapolation from that situation: what if he had struck his son? What if he had done much worse? What if King were an alcoholic failure who merely dreamt that he is a novelist?

Psychoanalysis could be crudely boiled down to the claim that we are our family history, although it is perhaps at this point that we can dispense with the term “history” and replace it with “hauntology”. The family emerges in Freud as a hauntological structure: the child is father to the man, the sins of the fathers are visited upon the children. The child who hates his father is condemned to repeat him, the abused becomes the abuser.

The Shining is about patriarchy as hauntology, and that relation is nowhere more thoroughly explored than in Freud’s essays on the foundations of religion. Here, Freud shows that the Holy Father, Jahweh, is indeed also a Holy Ghost: a spectral deity which can assert itself only through its physical absence. Freud repeated the “speculative myth” of the dismemberment and devouring of the Father Thing in “Totem and Taboo” thirty years later in “Moses and Monotheism”, a text which is itself full of repetitions and refrains.

In Freud’s account, there are two Fathers: the obscene “Pere Jouissance” (Lacan) who has access to total enjoyment, and the Name/No (Nom/Non) of the Father — the Father of Law, the Symbolic Order in person, who forbids and mortifies. As Žižek has shown,10 one of the most significant aspects of “Totem and Taboo” was to have established that the austere Father of Symbolic Law is not originary; it is not, as the theory of the Oedipus complex had assumed, that the father is a pre-existent block to enjoyment. This “block” only comes into place once the father is killed.

In the story as Freud recounts it, the primal horde of beta males, jealous and resentful of the tribal Father, rise up one day to kill him, anticipating that they will now have unlimited access to jouissance. But this is not what transpires. The “band of brothers” are immediately remorseful, guiltstricken, melancholic. Far from being able to enjoy everything, the gloomy parricidal brothers are unable to enjoy anything. And far from ridding themselves of their Father’s loathsome domination, they find that the Father dominates them all the more now that he is absent. The Father’s ghost preys upon their conscience; indeed, their conscience is nothing other than the reproach of the dead Father’s spectral voice. In heeding this absent voice, in commemorating and propitiating it by initiating new ceremonies and codes of practice, the brothers introduce the rudimentary forms of morality and religion. God, the Father, the Big Other, the Symbolic does not exist; but it insists through the repetition of these rituals.

The Father is doubly dead. He asserts his power only when he is dead, but his power is itself only a power of death: the power to mortify live flesh, to kill enjoyment.

A Child is Being Beaten

“Like father, like son. Wasn’t that how it was popularly expressed?”

— Stephen King, The Shining11

The Shining shows us patriarchal dementia — with its lusts, its ruses and its rationalisations — from inside. We witness Jack gradually succumbing to this dementia as he becomes intoxicated by the hotel and its temptations, promises and challenges. In the soft-focus, honeyed space of the Gold Room, Jack parties with the hotel’s ghosts:

He was dancing with a beautiful woman. He had no idea of what time it was, how long he had spent in the Colorado Lounge or how long he had been there in the ballroom. Time had ceased to matter.12

In the grip of these fever-dream fantasies, Jack descends into the unconscious (where, as Freud tells us, time has no meaning). The unconscious is always impersonal, and especially so here: the unconscious that Jack subsides into is the unconscious of the hotel itself. His family come to seem like “ball-breaking” distractions from his increasing spells of enchanted communion with the hotel, and being a good father becomes synonymous with delivering Danny to the Overlook. Jack becomes convinced by the hotel’s avatars — which seem to reconcile the demands of the superego with those of the id — that it is his duty to bring Danny into line.

Beyond the Imaginary no-time of the Gold Room, there is another mode of suspended time in the Overlook. This belongs to the Real, where sequential, or “chronic”, clockface time, is superseded by the fatality of repetition. It is the Imaginary pleasures of the Gold Room, with their succulent promises of enwombing fusion, which allow Jack to fall increasingly into the hold of the hotel’s Real structure — the structure of abusive repetition. Danny confronts this structure as a vision of man endlessly a pursuing a child with a roque mallet (in the film, an axe).

The clockface was gone. In its place was a round black hole. It led down into forever. It began to swell. The clock was gone. The room behind it. Danny tottered and then fell into the darkness that had been hiding behind the clockface all along.

The small boy in the chair suddenly collapsed and lay in it at a crooked unnatural angle, his head thrown back, his eyes staring sightlessly at the high ballroom ceiling.

Down and down and down and down to – the hallway, crouched in the hallway, and he had made wrong turn, trying to get back to the stairs he had made a wrong turn and now AND NOW –

– he saw he was in the short dead-end corridor that led only to the Presidential Suite and the booming sound was coming closer, the roque mallet whistling savagely through the air, the head of it embedding itself into the wall, cutting the silk paper, letting out small puffs of plaster dust.13

Here we can turn again to the image of fatality Freud uses in “Moses and Monotheism”, which I cited at the beginning of this essay. “T ()he strongest compulsive influence”, Freud writes,

arises from the impressions which impinge upon the child when we would have to regard his psychical apparatus as not yet completely receptive. The fact cannot be doubted; but it is so puzzling that we may make it more comprehensible by comparing it with a photographic exposure which can be developed after any interval of time and transformed into a picture.14

This passage is especially piquant and suggestive when considered in relation to The Shining, given the famous final image of Kubrick’s film: a photograph taken in 1923 showing Jack, surrounded by party-goers and grinning. At this moment, we cannot but be reminded of Delbert Grady’s ominous claim that Jack has “always been the caretaker”.

What I want to draw from Freud’s photographic metaphor is precisely its concept of effects being distanced in time from the events which produced them. This is the psychoanalytic horror which The Shining anatomises. Violence has been imprinted upon Jack “psychical apparatus” long ago, in childhood (the novel details at some length the abuse that Jack has himself suffered at the hands of his own father), but it requires the “spectral spaces” of the Overlook hotel to transform those impressions from an “exposure” into a “picture”, an actual act of violence.

If Jack “has always been the caretaker”, it is because his life has always been in the abuse-circuit. Jack represents an appalling structural fatality, a spectral determinism. To have “always been the caretaker” is never to have been a subject in his own right. Jack has only ever stood in for the Symbolic and the homicidal violence which is the Symbolic’s obscene underside. What, after all, is the father if not the “caretaker”, the one who (temporarily) shoulders the obligations of the Symbolic (what Jack calls “the white man’s burden”) before passing them onto the next generation? In Jack the ghosts of the past are revived — but only at the cost of his own “de-vival”.

Of course, the dyschronic nature of the Overlook’s abusive causality — events stored in the psyche will yield their effects only after time has elapsed — has implications for Danny’s future as well. As Metz puts it: “When Jack chases Danny into the maze with ax in hand and states, ‘I’m right behind you Danny’, he is predicting Danny’s future as well as trying to scare the boy. … () T ()he patriarchal beast is within Danny () as well.”15 Jack might as well be saying, “I’m just ahead of you, Danny”: I am what you will become. In the Overlook, a child is always being beaten, and the position of the abused and the position of the abuser are places in a structure. It is all-too-easy for the abused to become the abuser. The ominous question The Shining poses, but does not answer, is: Will this happen to Danny (as it happened to Jack)? Is The Shining, that is to say, “Totem and Taboo”/ “Moses and Monotheism” — where the Father retains his spectral hold on the sons precisely through his own death — or is it Anti-Oedipus?

In the novel, Danny can only escape death at the hands of his father by catatonically communing with his double, Tony, whom King reveals to be an avatar of his future self:

And now Tony stood directly in front of him, and looking at Tony was like staring into a magic mirror and seeing himself in ten years…

The hair was light blond like his mother’s, and yet the stamp on his features was that of his father, as if Tony — as if the Daniel Anthony Torrance he would someday be — was a halfling caught between father and son, a ghost of both, a fusion.16

In the film, Danny escapes from his father by walking backwards in his footsteps. Yet we do not know if the (psychic) damage has already been done — will Danny, in surviving his father, end up taking his father’s place?

For Metz, these hesitations leaves the text open: “It is up to Danny to grow up and build a better world, throwing off the demons of the past but always knowing that deep inside of him, the demons that possessed Jack and all Americans are right beneath the surface. Danny has inherited Jack’s legacy.”17 If Danny can throw off the spectres of the past, there is a possibility of freedom, then, but have the “strongest compulsive influences” already done their work? Is Danny, too, destined to always have been the Overlook’s caretaker?





coffee bars and internment camps1

I’ve finally seen Children of Men, on DVD, after missing it at the cinema. Watching it last week I asked myself, why is its rendering of apocalypse so contemporary?

British cinema, for the last thirty years as chronically sterile as the issueless population in Children of Men, has not produced a version of the apocalypse that is even remotely as well realised as this. You would have to turn to television — to the last Quatermass serial or to Threads, almost certainly the most harrowing television programme ever broadcast on British TV — for a vision of British society in collapse that is as compelling. Yet the comparison between Children of Men and these two predecessors points to what is unique about the film; the final Quatermass serial and Threads still belonged to Nuttall’s bomb culture,2 but the anxieties with which Children of Men deals have nothing to do with nuclear war.

Children of Men reinforces what few would doubt, but which British cinema would seldom lead you to suspect: the British landscape bristles with cinematic potential. It’s long since been evident that only someone outside the self-serving, self-pitying low gene pool of British cinema is capable of realising this potential, and Children of Men’s director, Alfonso Cuarón, and cinematographer, Emmanuel Lubezki, are both Mexican. Together they have produced a portrait of Grim Britannia that is like a film equivalent of the Burial LP (and the film’s excellent soundtrack features Burial’s mentor and label-mate, Kode9).

Lubezki’s cinematography is breathtaking. His photography seems to leech all organic and naturalistic vitality from the images, leaving them a washed-out grey-blue. As David Edelstein put it in an insightful review in New York Magazine: “The movie calls to mind an early description in Cormac McCarthy’s overwrought but gripping post-apocalypse novel The Road of gray days ‘like the onset of some cold glaucoma dimming away the world.’”3 The lighting is masterly: it as if the whole film takes place in a permanent winter afternoon when even the sun is dying. White smoke, its source unspecified, curls ubiquitously.

Cuarón’s trick is to combine this despondent lyricism with a formal realism, achieved through the expert use of hand-held camera and long takes. Blood spatters onto the camera lens and goes unwiped. The gunfire is as oppressively tactile as it was in Saving Private Ryan. The meticulously choreographed long takes — technical feats of some magnitude — have justly been highly praised, and they are all the more remarkable because they go beyond the familiar role of simulating documentary realism to serve a political and artistic vision.

This brings us back, then, to my initial question, and I think that there are three reasons that Children of Men is so contemporary.

Firstly, the film is dominated by the sense that the damage has been done. The catastrophe is neither waiting down the road, nor has it already happened. Rather, it is being lived through. There is no punctual moment of disaster; the world doesn’t end with a bang, it winks out, unravels, gradually falls apart. What caused the catastrophe to occur, who knows; its cause lies long in the past, so absolutely detached from the present as to seem like the caprice of a malign being: a negative miracle, a malediction which no penitence can ameliorate. Such a blight can only be eased by an intervention that can no more be anticipated than was the onset of the curse in the first place. Action is pointless; only senseless hope makes sense. Superstition and religion, the first resorts of the helpless, proliferate.

Secondly, Children of Men is a dystopia that is specific to late capitalism. This isn’t the familiar totalitarian scenario routinely trotted out in cinematic dystopias (see, for example, V for Vendetta, which, incidentally, compares badly with Children of Men on every point).

If, as Wendy Brown has so persuasively argued, neoliberalism and neoconservatism can be made compatible only at the level of dreamwork, then Children of Men renders this oneiric suturing as a nightmare. In Children of Men, public space is abandoned, given over to uncollected garbage and to stalking animals (one especially resonant scene takes place inside a derelict school, through which a deer runs). But, contrary to neoliberal fantasy, there is no withering away of the State, only a stripping back of the State to its core military and police functions. In this world, as in ours, ultraauthoritarianism and Capital are by no means incompatible: internment camps and franchise coffee bars co-exist.

In P.D. James’ original novel, democracy is suspended and the country is ruled over by a self-appointed Warden. Wisely, the film downplays all this. For all that we know, the Britain of the film could still be a democracy, and the authoritarian measures that are everywhere in place could have been implemented within a political structure that remains, notionally, democratic. The War on Terror has prepared us for such a development: the normalisation of crisis produces a situation in which the repealing of measures brought in to deal with an emergency becomes unimaginable (when will the war be over?). Democratic rights and freedoms (habeas corpus, free speech and assembly) are suspended while democracy is still proclaimed.

Children of Men extrapolates rather than exaggerates. At a certain point, realism flips over into delirium. Bad dream logic takes hold as you go through the gates of the Refugee Camp at Bexhill. You pass through buildings that were once public utilities into an indeterminate space — Hell as a Temporary Autonomous Zone — in which laws, both juridical and metaphysical, are suspended. A carnival of brutality is underway. By now, you are homo sacer4 so there’s no point complaining about the beatings. You could be anywhere, provided it’s a warzone: Yugoslavia in the Nineties, Baghdad in the Noughties, Palestine any time. Graffiti promises an intifada, but the odds are overwhelmingly stacked in favour of the State, which still packs the most powerful weapons.

The third reason that Children of Men works is because of its take on cultural crisis. It’s evident that the theme of sterility must be read metaphorically, as the displacement of another kind of anxiety. (If the sterility were to be taken literally, the film would be no more than a requiem for what Lee Edelman calls “reproductive futurism”, entirely in line with mainstream culture’s pathos of fertility.) For me, this anxiety cries out to be read in cultural terms, and the question the film poses is: how long can a culture persist without the new? What happens if the young are no longer capable of producing surprises?

Children of Men connects with the suspicion that the end has already come, the thought that it could well be the case that the future harbours only reiteration and re-permutation. Could it be, that is to say, that there are no breaks, no “shocks of the new” to come? Such anxieties tend to result in a bi-polar oscillation: the “weak messianic” hope that there must be something new on the way lapses into the morose conviction that nothing new can ever happen. The focus shifts from the Next Big Thing to the last big thing — how long ago did it happen and just how big was it?

The key scene in which the cultural theme is explicitly broached comes when Clive Owen’s character, Theo, visits a friend Battersea power station, which is now some combination of government building and private collection. Cultural treasures — Michelangelo’s David, Picasso’s Guernica, Pink Floyd’s inflatable pig — are preserved in a building that is itself a refurbished heritage artefact. This is our only glimpse into the lives of the elite. The distinction between their life and that of the lower orders is marked, as ever, by differential access to enjoyment: they still eat their artfully presented cuisine in the shadow of the Old Masters. Theo, asks the question: how all this can matter if there will be no-one to see it? The alibi can no longer be future generations, since there will be none. The response is nihilistic hedonism: “I try not to think about it”.

T.S. Eliot looms in the background of Children of Men, which, after all, inherits the theme of sterility from “The Waste Land”. The film’s closing epigraph “shantih shantih shantih” has more to do with Eliot’s fragmentary pieces than the Upanishads’ peace. Perhaps it is possible to see the concerns of another Eliot — the Eliot of “Tradition and the Individual Talent”5 — ciphered in Children of Men. It was in this essay that Eliot, in anticipation of Bloom, described the reciprocal relationship between the canonical and the new. The new defines itself in response to what is already established; at the same time, the established has to reconfigure itself in response to the new. Eliot’s claim was that the exhaustion of the future does not even leave us with the past. Tradition counts for nothing when it is no longer contested and modified. A culture that is merely preserved is no culture at all. The fate of Picasso’s Guernica — once a howl of anguish and outrage against fascist atrocities, now a wall-hanging — is exemplary. Like its Battersea hanging space in the film, the painting is accorded “iconic” status only when it is deprived of any possible function or context.

A culture which takes place only in museums is already exhausted. A culture of commemoration is a cemetery. No cultural object can retain its power when there are no longer new eyes to see it.





rebel without a cause1

“Why is it … () that left-wingers feel free to make their films direct and realistic, whereas Hollywood conservatives have to put on a mask in order to speak what they know to be the truth?”

— Andrew Klavern, “What Bush and Batman Have in Common”2

“What I despise in America is the studio actors sic () logic, as if there is something good in self expression: do not be oppressed, open yourself, even if you shout and kick the others, everything in order to express and liberate yourself. This stupid idea, that behind the mask there is some truth. … () Surfaces do matter. If you disturb the surfaces you may lose a lot more than you account. You shouldn’t play with rituals. Masks are never simply mere masks.”

— Slavoj Žižek and Geert Lovink, “Japan Through a Slovenian Looking Glass: Reflections of Media and Politic and Cinema”3

There are many symptomatically interesting things about the right-wing attempts to appropriate The Dark Knight that are doing the rounds at the moment. The idea is that the Batman of the film equals Bush — a misunderstood hero prepared to make “tough choices” in order to protect an ungrateful population from threats it is too ethically enfeebled to confront.

In a couple of intricately argued posts, Inspersal4 demonstrates that The Dark Knight by no means presents “tough choices” as “hard but necessary”; on the contrary, whenever Batman resorts to torture, it either yields nothing or is counterproductive. What neocon readings of the film must overlook is that this is exactly the same in geopolitical reality: far from being unpalatable but necessary, the Iraq misadventure, Guantanamo Bay, extraordinary rendition, etc. have either achieved no results or made things worse. What’s interesting here is the doggedness of the neocon fantasy, which is precisely a fantasy of “being realistic” — astonishingly, elements of the American right appear to actually still believe that the Bush administration’s policies are successful, and that the American public has rejected them on the grounds of high-minded (liberal) ethical qualms rather than for pragmatic-utilitarian reasons (too many of our boys being killed).

Secondly, what these readings also miss is the actual nature of the model of virtue presented in the film. If this is (neo)conservative, it is not at the simple level of utilitarian calculation of consequences. What we are dealing with is a far more complicated Straussian meta-utilitarianism whose cynical reasoning is akin to that of Dostoyevsky’s Grand Inquisitor. Deception — of the masses by the elite — is integral to this account of virtue: what is “protected” is not the masses’ security but their belief (in Harvey Dent’s campaign).

As Inspersal argues, the emphasis on deception in The Dark Knight is one of the themes that connects it with Nolan’s previous films, and Batman’s climactic act of self-sacrifice is precisely an act of deception. It takes place at the level of signs: what he must give up is his reputation, his good standing in the eyes of the Gotham public. The act of deception doesn’t conceal an underlying good act — it is the concealing that is the good act itself.

Thirdly, the neocon readings misconstrue the nature of “evil” in the film. If these right-wingers really think that Osama bin Laden is like The Joker as he appears in The Dark Knight, that gives us another, intriguing, insight into their fantasies. (Matthew Yglesias says, “I look at the movie and say ‘see — if you were fighting a comic book bad guy and you were a comic book hero then your policies would make sense.’”5 But even this isn’t the case, as Inspersal’s arguments above make clear.) Or rather, it reveals the inconsistency on which Islamophobic fantasy depends: the Islamist is both “an agent of chaos”, someone without a cause, and a zealot excessively attached to a cause.

What’s interesting about The Dark Knight is that is not really about Good versus Evil at all but “good causes” versus aberrant modes of cause/causality. The Joker and Two-Face are mad rather than bad, and their insanity is centrally connected with their relationship to cause. The Joker is pure Terror, that is, Terror detached from any cause:

You see, nobody panics when things go according to plan. Even if the plan is horrifying. If I told people that a gangbanger was going to get shot, or a busload of soldiers was going to get blown up, nobody would panic. Because it’s all part of the plan. But tell people that one tiny little mayor is going to die and everyone loses their minds! Introduce a little anarchy, you upset the established order, and everything becomes chaos. I am an agent of chaos. And you know the thing about chaos, Harvey. It’s fair.

While Batman is drawn into utilitarian calculations, The Joker is free in the same way that the death drive is free: he acts with indifference to consequences, glorying instead in a kind of ungrounded unbinding of orderly causal sequences. The reference to “fairness” above is not idle. As an imp of the perverse, The Joker stands for an inverted (or freaked) Kantian justice. In many ways, we are looking at the reversal of Kantianism into Don Giovanni Žižek has described many times (Don Giovanni’s decision not to save himself, to maintain his commitment to his libertinism even when doing so will result in his execution, becomes an ethical gesture). The Joker acts without any pathological interests, grandly symbolising his lack of instrumentality with the burning of the pyramid of money.

Two-Face’s insanity is also a kind of haemorrhaging of justice. In his case, the championing of a good cause — which it seems will inevitably leads to terrible consequences — is displaced by an embrace of chance’s random causality (heads/tails). The flip into randomness is not an abandonment of justice, but the quest for a justice that will not be corrupted by human will — in its very impersonal mechanism, chance is fair because it does not privilege any outcome or any individual. Interestingly, it is only when Dent becomes Two-Face that his coin tossing is fair; when Dent is the “White Knight” DA, his coin is loaded (it has heads on both sides). What also interrupts the orderly sequence of causality in Dent’s case is trauma — the trauma of seeing Rachel die, which is itself a consequence of a binary choice trap, one of a series of such traps The Joker attempts to spring.

The by now standard view of The Dark Knight — that its real libidinal pull is not the peripheral Batman/Wayne, but the charisma of Heath Ledger’s Joker — is certainly correct. When I heard Ledger’s performance celebrated, I feared the worst: that we were going to see the actorly overplaying that usually garners this kind of ubiquitous praise. But it is to Ledger’s immense credit that he completely avoids what Nicholson was allowed to do in Tim Burton’s dreadful Batman: we get no glimpse of the actor behind the role (with Nicholson, of course, that’s all we got). There is also no question of Ledger appearing bare-faced for any significant length of time, as Tobey Maguire and Julian McMahon were allowed to in Spider-Man 3 and the Fantastic Four films respectively. Thankfully, there is only the briefest glimpse of The Joker sans make-up in The Dark Knight.

What Ledger does, in many ways, is play the make-up. I should stress here that the make-up, which makes Ledger’s face look like a malevolent monkey leering from behind cracked plaster, manages a feat that is near impossible: it reinvents The Joker look whilst also maintaining fidelity to the comics (compare the Green Goblin’s mask and outfit in the Spider-Man films, whose divergence from the halloween hood in the comics always disappointed me). My one point of disagreement with Inspersal concerns his claim that Ledger’s performance “shows the Nicholson/Burton interpretation to be much closer to Cesar Romero from the TV show, rather than Alan Moore’s version from The Killing Joke, allegedly Burton and Hamm’s chief influence”. I would argue that, in fact, it is Ledger’s performance that is closer to Romero’s, and that is why it works so well. Nicholson’s PoMo posturing and Moore’s psychological depth were all of a piece, and both were far less terrifying than the senseless gibbering of Romero’s pantomimeturn Joker. The Joker was always fascinating because, unlike most if not all big-time supervillains, he was pure surface, motiveless madness, devoid of any origin or backstory — until Moore obligingly filled one in, as is his hamfisted pseudo-literary wont. There are a couple of great scenes in The Dark Knight where Ledger’s Joker mocks cod psychoanalytic reduction: “See these scars… I got them because of my father.” “See these scars… I got them because of my wife.” (This reminded me of nothing so much as Ian Bannen’s chilling burst of explosive laughter in Sidney Lumet’s The Offence, in response to Sean Connery’s question: “Was your father a big man?”) If The Joker aligns himself with anything it is “the freak”, which cannot but remind us of freak events, that is, events which appear to happen without proper causation. By evacuating The Joker of all interiority, by refusing anything which would contain the Joker’s wildness or compromise the autonomy of his face-painted persona, Ledger’s performance (and Jonathan Nolan’s script) do justice to the freakish.





robot historian in the ruins1

“Ideology is not something foreign, something in a film with a strange power to impose itself on our minds; ideology is what we and the film share, what allows for the transfer of specific meanings between film and audience (a transfer which is not one way). As Žižek puts it, ideology is made up of ‘unknown knowns’; that is to say, the problem with ideology is not that it is a falsehood of which we might be persuaded, but because it is a truth that we already accept without knowing it.”

— Voyou, “Ideology critics are a superstitious, cowardly lot”2

Voyou’s remarks on readings of The Dark Knight make some important points about ideology. Focusing on the supposed “message” of the film — as both neoconservative interpretations of the film, and their critics, including me, do — is in danger of missing the way in which ideology works in capitalism. The role of capitalist ideology is not to make an explicit case for something in the way that propaganda does, but to conceal the fact that the operations of capital do not depend on any sort of subjectively assumed belief. It is impossible to conceive of fascism or Stalinism without propaganda — but capitalism can proceed perfectly well, indeed better, without anyone making a case for it.

In the responses to The Dark Knight I posted here, it was Wayne Wedge who captured the way that the film functions as a hyper-object in late capitalism.3 The very multivalence of The Dark Knight, its capacity to generate radically different interpretations, to elicit discourse, is what makes it a highly efficient meta-commodity. A text with a single monologic Message, even supposing such a thing could exist, would not be able to “provoke the debate” which capitalist culture now feeds upon.

It not only that a cultural object can be opposed to capitalism on the level of content, but serve it on the level of form; one could convincingly go further and argue that the ideology of capitalism is now “anti-capitalist”. The villain in Hollywood films is routinely the “evil multinational corporation”. So it is, once again, in Disney/Pixar’s Wall-E, which, like The Dark Knight, has provoked all kinds of bizarre conservative readings. “This is perhaps the most cynical and darkest big-budget Disney film ever”, claims Kyle Smith4. “Perhaps never before has any corporation spent so much money on insulting its customers.” (By way of parenthesis, since it isn’t relevant to my argument here, this, from Paul Edwards, is priceless: “WALL-E is the story of what results when a liberal vision of the future is achieved: government marries business in the interest of providing not only ‘the pursuit of happiness’ but happiness itself, thus creating gluttonous citizens dependent on the government to sustain their lives.”)5

Wall-E’s attack on consumerism is easily absorbed. The “insult” that provoked Kyle Smith into disgust was its image of humans as obese, infantilised chair-bound consumers supping pap from cups. Initially, it might seem subversive and ironic that a film made by a massive corporation should have such an anti-consumerist and anti-corporate message (it is made clear in the film that the mega corporation Buy N Large is chiefly responsible for the environmental depredation which has destroyed earth as a human environment). Yet it is capital which is the great ironist, easily able to metabolise anti-corporate rhetoric by selling it back to an audience as entertainment. Besides, on the level of content, Wall-E ends up serving capitalist realism, presenting what we might think of as the very fantasies of capital itself — that it can continue to expand infinitely; that the despoilation of the human environment on Earth is a temporary problem that will eventually be overcome; that human labour can be extirpated altogether (on the spaceship Axiom, humans are given over entirely to consumption, and all work is performed by servomechanisms). Human labour returns only at the end of the film, when capital/Axiom begins its terraforming of Earth.

There is another impasse in Wall-E. The film follows in the tradition of fictions about wanderers in the ruins (cf Christopher Woodward’s In Ruins). But in some respects Wall-E was an advance on the stories of postapocalyptic solitaries, from Mary Shelley’s The Last Man through to Richard Matheson’s I Am Legend or John Foxx’s The Quiet Man. For in Wall-E the lone figure in the ruins is not even human: it is a robot historian quite different from the one Manuel DeLanda imagined; or not a robot historian so much as a bricoleur-hauntologist, reconstructing human culture from a heap of fragments. (A precursor of this scenario is Numan’s “M.E.”, the track sampled by Basement Jaxx on “Where’s Your Head At”, written from the perspective of a sentient computer left alone on an Earth.) This idea of surveying a world in which humans are extinct clearly exercises a powerful fantasmatic allure. Yet it seems that there’s a certain point where the fantasy always breaks down — the fictions that start from this premise invariably end up restoring a human world at some point in the narrative. It is no doubt asking too much that Wall-E should buck this trend; but it’s notable that the film deteriorates massively the moment that the humans appear (cf all of the film versions of Matheson’s I Am Legend, including the most recent). You’re left wondering whether this is a structural necessity, whether there’s something in the nature of the fantasy itself which entails the return of other humans, or whether it is a requirement arising from the needs of narrative: stories can’t sustain themselves with only one protagonist. In the case of Wall-E, of course, there are two (non-human) characters, which make the early part of the film, a robotic romance played out as animated ballet, recall the films of the silent era. Needless to say, there are many films which feature non-human protagonists, but such characters are rendered effectively human by their language use. Wall-E and Eve, meanwhile, seem like convincing non-human subjects because they lack language. Wall-E tantalises: what if the feel of this first section had continued until the end of the film, uninterrupted by the return of humans?





review of tyson1

“It’s like a Greek tragedy. The only problem is that I’m the subject”, Mike Tyson reputedly told James Toback when he first saw this film. There is a classical structure to the narrative: a kid from mean streets, with few prospects, a life of criminality already under way, is talent-spotted by a grizzled boxing trainer; he becomes the youngest world champion ever; then it all disintegrates into hedonism, profligacy and violence. Yet in the end the structure of the story is psychoanalytic as much as tragic (after all, it wasn’t for nothing that Freud turned to Sophocles and Aeschylus for analogues of his discoveries). A familiar enough narrative arc, but what makes it even more remarkable (and even more Freudian) is that it happens again. Tyson struggles back to the top of the heavyweight game before once again succumbing to ill-discipline and self-destruction. A textbook case of the compulsion to repeat.

Tyson’s life was shaped by absent fathers and father surrogates. He was rescued from rudderless street survivalism by the trainer who ended up adopting him, Cus D’Amato; his subsequent fall from grace was precipitated in part by D’Amato’s death. The Tyson that emerges in Toback’s gripping film is very much like the subject of psychoanalysis, a talking head coaxed by the director (in the role of the offscreen analyst) into reliving all the triumphs and traumas. The film consists only of archive footage and Tyson — a ringside commentator on his own life — talking. There are no experts, no supposedly neutral judgements, only Tyson trying to make sense of the double tragedy of his life. It makes for a claustrophobic experience, amped up by the way in which Toback occasionally multi-tracks Tyson’s voice and splits the screen, creating the impression of a divided man, sometimes chillingly self-aware, sometimes a mystery to himself.

Tyson’s story is sufficiently forgotten now that it is capable of thrilling and horrifying us as if for the first time: the astonishingly quick rise to world champion, the run of viciously efficient victories, the high-profile debacle of his marriage to Robin Givens (Tyson sitting stock still on a chatshow couch while the actress vilifies him), the rape conviction and resulting prison sentence, the conversion to Islam, the biting of Evander Holyfield’s ear… Tyson provides a newly intimate perspective on these half-remembered images.

Sports stars of this magnitude cannot but be the objects of collective fantasy and projection, and even though his is an individual story — and we can be under no illusions after watching Tyson that there is no lonelier sport than boxing — Tyson’s is also the story of a culture and a time. Just compare Tyson with Muhammad Ali (whose own myth was examined and re-presented in When We Were Kings and Ali). With his poetry, physical and verbal, Ali was the boxer for the age of Black Power, the Panthers, Malcolm X, Sly Stone and James Brown; Tyson’s pitbull brutality, meanwhile, was the fight analogue of the every-man-for-himself ethos of Reaganomics and the will-to-power pugilism of rap. His slogan was “Refuse to Lose” (a phrase that would be central to Public Enemy’s epochal Welcome to the Terrordome): the aim was to overcome Nemesis by force of will alone, and in his pomp Tyson looked like iron will embodied. He came out of his corner like a starved attack dog, clubbing opponents into oblivion in a matter of moments. Nothing was wasted; there was no grandstanding or showboating.

Partly that was because Tyson felt he had no time to waste — for physical as well as existential reasons. He had suffered from a respiratory disorder since childhood and knew that he would struggle if fights went the full distance. The rapidity and intensity of his victories belied the precision of his attacks. We learn that it wasn’t a question of sheer physical force alone. D’Amato (a “master of anatomy”, according to Joyce Carol Oates) taught him where on the body to hit to cause maximum damage. In the fight footage, Tyson always looks short by comparison with his opponents — “at five feet 11 inches”, Oates wrote in a 1986 essay, “he is short for a heavyweight and strikes the eye as shorter still; his 222 1/4-pound body is so sculpted in muscle it looks foreshortened, brutally compact.”2 Yet he always turned that compactness to his advantage, making the taller men look like ponderous Harryhausen statues.

Listening to him speak, you’re continually struck by the contrast between Tyson the fighting machine and Tyson the talker. His voice is a gentle lisp, devoid of swagger, suggestive of an unusual sensitivity. It sits just as oddly with Tyson’s older face and its Queequeg tattoos as it did with his earlier fighting frame. It becomes obvious, though, that the hypermuscular body Tyson developed was in part an exo-skeleton constructed to protect that sensitive core. Remembering the time he first realised that no one would ever be able to be beat him up again, Tyson stalls — “Oh, I can’t even say it” — pauses for a long moment before saying, “Because I would fuckin’ kill ‘em.” The film’s rhythm is governed by Tyson’s unstable relationship to language, by his switches in and out of articulacy. Sometimes his tongue is as quick as his fists once were. His hilarious takedown of Don King — a “wretched slimy reptilian motherfucker” — is as swift and savage as any of his combinations in the ring. Elsewhere, the words elude him, or he evades them. Yet, exactly as psychoanalysis taught us to expect, the ellipses, the sentences that lead nowhere and the “wrong” choice of word tell us even more than the moments of transparent lucidity. The unconscious speaks, and James Toback demonstrates an extraordinary facility for hearing and recording it.





“they killed their mother”: avatar as ideological symptom1

Watching Avatar, I was continually reminded of Žižek’s observation in First As Tragedy, Then As Farce, that the one good thing that capitalism did was destroy Mother Earth. “There’s no green there, they killed their mother”, we are solemnly informed at one point. Avatar is in some ways a reversal of Cameron’s Aliens. If the “bug-hunt” in Aliens was, as Virilio argued, a kind of rehearsal for the mega-machinic slaughter of Gulf War I, then Avatar is a heavy-handed eco-sermon and parable about US misadventures in Iraq and Afghanistan. (What’s remarkable about Avatar is how dated it looks. In the scenes of military engagement, it is as if Eighties cyberpunk confronts something out of Roger Dean or the Myst videogames; Cameron’s vision of military technology has not moved on since Aliens.) At the end of the film, it is the human corporate and military interests who are described as “aliens”. But this is a film without any trace of the alien. Like most CGI extravaganzas, it flares on the retina but leaves few traces in the memory. Greg Egan finds little to admire in Avatar, but he does defer to its technical achievements: “mostly, the accomplishments of the visual designers and the army of technicians who’ve brought their conception to the screen appear pixel-perfect, and hit the spot where the brain says ‘yes, this is real’.”2 The cost of this, though, is that it is very difficult to be immersed in the film as fiction. It is more akin to a theme-park ride, a late-capitalist “experience”, than a film.

What we have in Avatar is another instance of corporate anti-capitalism such as I discussed in Capitalist Realism in relation to Wall-E. Cameron has always been a proponent of Hollywood anti-capitalism: stupid corporate interests were the villains in Aliens and Terminator 2 as they are in Avatar. Avatar is Le Guin-lite, a degraded version of the scenario that Le Guin developed in novels such as The Word For World Is Forest, The Dispossessed and City Of Illusions, but stripped of all Le Guin’s ambivalence and intelligence. What is foreclosed in the opposition between a predatory technologised capitalism and a primitive organicism, evidently, is the possibility of a modern, technologised anti-capitalism. It is in presenting this pseudoopposition that Avatar functions as an ideological symptom.

No primitivist cliché is left untouched in Cameron’s depiction of the Na’vi people and their world, Pandora. These elegant blue-skinned noble savages are at one with their beautiful world; they are Deleuzean Spinozists who recognise that a vital flow pervades everything; they respect natural balance; they are adept hunters, but, after they kill their prey they thank its “brother spirit”; the trees whisper with the voices of their revered ancestors. (Quite why skirmishes with the Na’vi and their bows and arrows should have prompted Steven Lang’s grizzled colonel into Apocalypse Now-like disquisitions on how Pandora made for his worst experience in war, is unclear.) “There’s nothing we have that they want”, concludes Sam Worthington’s Jake Sully of the Na’vi. Yet the Na’vi predictably seduce Sully, who quickly “forgets everything” about his former life on Earth (about which we learn almost nothing, beyond the fact that he is a marine who got injured in the course of battle) and embraces the wholeness of the Na’vi way of life. Sully attains wholeness through his avatar Na’vi body in a double sense: first, because the avatar is able-bodied, and, secondly, because the Na’vi are intrinsically more “whole” than the (self-)destructive humans. Sully, the marine who is “really” a tree-hugging primitive, is a paradigm of that late-capitalist subjectivity which disavows its modernity. There’s something wonderfully ironic about the fact that Sully’s — and our — identification with the Na’vi depends upon the very advanced technology that the Na’vi’s way of life makes impossible.

But a telling tic in the film is the repeated compulsion to explain the persistence of (physical) wounds among the human characters. Given the level of technology in the film’s 2051, both Sully’s useless legs and the colonel’s scars could easily have been repaired, and the script goes out of its way to say why the two characters they remain disabled and maimed respectively: in Sully’s case, it’s because he can’t afford the medical treatment; in the colonel’s, it’s because he “likes to be reminded of what he’s up against”. Such explanations are clearly unconvincing — the narratively underdetermined wounds can only be explained as libidinal residue which the film cannot fully digest into its digital Imaginary. The wounds prevent the disavowal of modern subjectivity and technology which Avatar attempts at the very same moment that the film invites us to admire it as a technological spectacle.

If we are to escape from the impasses of capitalist realism, if we are to come up with an authentic and genuinely sustainable model of green politics (where the sustainability is a matter of libido, not only of natural resources), we have to overcome these disavowals. There is no way back from the matricide which was the precondition for the emergence of modern subjectivity. To quote one of my favourite passages in Žižek’s First As Tragedy: “Fidelity to the communist Idea means that, to repeat, Arthur Rimbaud, … () we should remain absolutely modern and reject the all too glib generalisation whereby the critique of capitalism morphs into the critique of ‘modern instrumental reason’ or ‘modern technological civilisation’.”3 The issue is, rather, how modern technological civilisation can be organised in a different way.





precarity and paternalism1

The recent discussion of elitism (a topic also broached by Adam Curtis’ film on Charlie Brooker’s Newswipe this week) brings me back to the question of what — in the continuing lack of any alternative term — I must still refer to as “paternalism”. I think Taylor Parkes got to what is at stake in these discussions in his rather moving Quietus piece about Trunk’s Life On Earth release:

Hard to credit now, but there was once something paternalistic, almost philanthropic about the Beeb, spreading the cultural wealth of the educated classes through housing estates and comprehensive schools. This kind of evangelism rarely sits well with self-conscious champions of the lumpenproletariat, whose right to live in shit, they believe, outweighs their right to not live in shit — for some, being patronised is worse than being brutalised. But then people can be very naïve about the motivations of those who give the people what they want, relentlessly and remorselessly. And while the Corporation was sometimes guilty of gross assumptions and a very real stuffiness, I don’t like to think how I might have grown up — stomping around in the middle of nowhere — had it not been for Life On Earth, or Carl Sagan’s Cosmos, or James Burke’s Connections, or the gentle guidance of the BBC Children’s department. Years ago, I interviewed the men in charge of “youth programming” at Channel 4, goateed and bereted and utterly insistent that their race to the bottom was a noble crusade; they railed against the BBC’s “eat-your-greens” approach, and spoke of gallons of liquid effluent, coursing through the pipes of British culture, in terms of freedom and some strange colour of egalitarianism. Here was the future, banging its drums, and even then it made me blanch. As controller of BBC2 in the late 1960s, David Attenborough had a different vision, rooted in what was, for all his personal privilege, an (enduring) belief in inclusivity. If the so-called Golden Age of Television could boast its fair share of shoddy, overlit crap — and my God, it could — at best it was truly empowering, and its passing has screwed us all to some extent. We can still choose to watch BBC Four, I suppose (assuming it’s not another show where ex-NME writers smirk at Mud’s trousers), but then this is an age of choices, few of which have much to do with freedom in the long term. No one’s going to stumble onto culture any more, not like I did, or my dragged-up mates did. It’s worse than a shame.2

It’s worth reminding ourselves of the peculiar logic that neoliberalism has successfully imposed. Treating people as if they were intelligent is, we have been led to believe, “elitist”, whereas treating them as if they are stupid is “democratic”. It should go without saying that the assault on cultural elitism has gone alongside the aggressive restoration of a material elite. Parkes touches here on the right way to think about paternalism — not (just) as something prescriptive, but in terms of the gift and the surprise. The best gifts are those we wouldn’t have chosen for ourselves — not because we would have overlooked or rejected them, but because we simply wouldn’t have thought of them. Neoliberal “choice” traps you in yourself, allowing you to select amongst minimally different versions of what you have already chosen; paternalism wagers on a different “you”, a you that does not yet exist. (All of which resonates with J.J. Charlesworth’s illuminating piece on the management of the ICA in Mute, with its attack on the assumption that “what the audience wants is merely what the institution should do”.3)

Neoliberalism may have been sustained by a myth of entrepreneurialism, a myth that the folk economics of programmes like The Apprentice and Dragon’s Den have played their part in propagating, but the kind of “entrepreneurs” that dominate our culture — whether they be Bill Gates, Simon Cowell or Duncan Bannatyne — have not invented new products or forms, they have just invented new ways of making money. Good for them, no doubt, but hardly something that the rest of us should be grateful for. (The genius of Cowell was to have plugged a very old cultural form into new machineries of interpassivity.) And for all the bluster about entrepreneurialism, it is remarkable how risk-averse late capitalism’s culture is — there has never been a culture more homogenous and standardised, more repetitive and fear-driven.

I was struck by the contrast between Parkes’ piece and an article by that Caitlin Moran wrote in the wake of the announcement that Jonathan Ross is to leave the BBC. “After Ross’ () £18 million contract”, Moran wrote,

endless fretting pieces were written, asking whether the BBC should ever try to compete with ITV1’s salaries. The real question, however, is “what would happen to the BBC if it didn’t?” If the only people who work for the BBC are those in it for the sheer love of it and — those who would piously turn down double the wages from ITV— the BBC would rapidly become the middle-class liberal pinko panty-waist institution of the Daily Mail’s nightmares, and, I suspect, fold within five years.

Really? ITV’s high salaries, when they could afford to pay them, were hardly guarantees of quality; and the idea that Ross is one of us because he was “quick, edgy, silly nerd-dandy, into Japanese anime and rackety new guitar bands” presupposes a model of the “alternative” as shopworn and discredited as New Labour. Note that Moran fully accepts the neoliberal logic whereby “talent” is only motivated by money. (The return of the concept of “talent”, with all its de-punking implications, was perhaps the most telling cultural symptom of the last decade; while the application of the word to bankers was its sickest joke.)

As Moran suggests, the BBC’s real rival now, evidently, is not the ailing ITV but the Daily Mail and News International, and if public service broadcasting is to defend itself against an assault that will only increase in ferocity, it will need rather more than Ross’ sexual suggestiveness, warmed over hipness and occasional wit at its disposal. (It’s far harder for the Mail to attack the likes of Attenborough than triviamongers such as Ross or Graham Norton; and did Attenborough ever get the equivalent of Ross’ eighteen million, I wonder?) It’s not only unjustifiable that public money be spent on exorbitant salaries for presenters and executives: it also plays into the Mail’s agenda, which is all about maintaining the negative solidarity which has been crucial to neoliberal hegemony.4 Call me old fashioned, but I firmly believe that only those who would work for the BBC for the sheer love of it should be in the job. More than that, being motivated by money ought to be a reason for people not getting senior public service appointments. This is not, grotesquely, an argument for low wages — but it is an argument for the more equitable — and creative — redistribution of money in the public sphere. Imagine if Ross’ eighteen million were instead spent — risked — on what British television most sorely lacks, writers. You could pay scores of writers a good wage for years… The BBC ought to be in a position to cushion its creative staff from the pressures of producing immediate success — and, contrary to the neoliberal logic which insists that people are best motivated by fear and money, it is that cushioning which facilitates a certain kind of cultural entrepreneurialism.

After all, people will do worthwhile things if they are not paid or if they are paid poorly. The interesting side of Web 2.0 is just this — not the vacuous “debates”, but the impulse to share that is a significant part of the motivation for writing blogs, uploading material to YouTube and updating Wikipedia. If anything is the work of the multitude, it’s something like the salvagepunk archive that is YouTube. It’s intriguing that capitalist realism co-exists with the emergence of new forms of culture which can be commodified only very incompletely. At one level, commodification is total, and, in Jeremy Rifkin’s phrase, all of life is a paid-for experience; yet there are whole areas of culture which are effectively being decommodified (does anyone seriously think that any recorded music will be paid for at all in a decade?). As a cultural worker, this is something I am ambivalent about, to say the least … () I seem to achieve success in things at the very moment that it’s not longer possible to make money from them…

When I was in Dublin a week or so ago talking about Capitalist Realism, a member of the audience asked why I was talking about public service workers when my own situation has shown that it’s better to leave fulltime employment and enter the precariat. This is a reasonable question on the face of it, since I’ve done pretty well since being made redundant from my FE teaching job. Yet in some respects all that has happened is that I’ve swapped the NuBureaucratic stress of public service employment for the perpetual anxiety of hyper-precarity, and had my income massively cut in the process. One of the ways in which negative solidarity plays out is by exploiting the opposition between permanent employees and precarious workers. Permanent employees tend to be quietist to keep (what they think of as) their job security, whereas precarious workers, being expendable, have no power at all. A while back, Tobias van Veen gave a very powerful account of his own experiences of precarious labour:

there is an ironic yet devastating demand being placed on the labourer: while work never ends (as one is never out of touch, and always expected to be available, with no claims to a private life or other demands), you as a worker are nonetheless completely expendable (and thus a member of the precariat: and so one must sacrifice all autonomy from work so as to keep one’s job). … () This contemporary condition of on-call ontology or on-demand dasein produces an emotional economy of stress. To live under such instant-demand duress is stress-inducing indeed. Life becomes a series of panic attacks in the face of never being able to live up to such workplace demands without completely dismantling “life” itself as distinct from “work”. The managerial class uses techniques of guilt/loyalty to enforce workers to labour at a moment’s notice, scheduling with less than a few hours or days time, without hope of a raise, without benefits or reward, and all for a minimum wage.5

The precarious worker is doubly punished: not only do they have no job security, they also get paid less than the permanent employees for doing the same work. When I switched from being an hourly paid lecturer in Further Education to having a permanent contract, I was doing exactly the same work, but suddenly I was both paid hundreds of pounds more a month and got paid for holidays too. Back in the precariat, my total income since the tax year that began in April — for all the teaching, supervision, writing and editing I’ve done, when I doubt there’s been more than two weeks that I’ve worked less than fifty hours — is the princely sum of eleven grand, which works out at significantly less than minimum wage. All the work I’ve done depends upon my not being in full-time work, so, no matter that my hourly rate for some work seems quite high, in effect I’m always working for minimum wage. (Much writing only pays minimum wage anyway.) All this, in conditions where it’s impossible to turn down any commission, no matter how short notice it is given to me, where I’m on-demand at practically all times and there are no guarantees that I will keep getting the work. The kind of hustling I’m required to do involves a kind of “creativity”, I suppose, but “getting creative” about how I can monetise my activities doesn’t seem like the best conceivable use of my time. What the broken, piecemeal time of precarity precludes is engagement in long-form projects. It’s very hard for me to devote any time to finishing my next book for Zer0 because I will always privilege any work that pays immediately. But full-time employment also precludes the engagement in long-form projects: Capitalist Realism, for instance, was written after work or at weekends.

I say all this not because I want sympathy — I still think I’m incredibly fortunate to be making any sort of living out of what I do — but more because my situation is symptomatic. And now that the high-rolling, business ontology-driven model of cultural provision is finished, surely there’s a better way to fund cultural work?





return of the gift: richard kelly’s the box1

I wouldn’t say that Richard Kelly’s The Box is a hauntological film, but it shares certain affinities with the way someone like Ghost Box re-dream the Weird. The Box is based on a short story by Richard Matheson, who occupies something like the same position in the American Weird that Ghost Box’s touchstone, Nigel Kneale, does in the UK Weird. Both Kneale and Matheson operated in an interstitial generic space — between SF and horror — proper to the Weird, in a pulp infrastructure — paperbacks, television, B cinema — that has now largely disappeared. Matheson has yet to quite acquire the auteur status that Kneale enjoyed, but this only adds to his pulp-anonymous artisan allure; there’s a special kind of delight in realising that films you’d likely as not first encountered, apparently randomly, on late night TV — The Incredible Shrinking Man, The Omega Man, Duel (as recently discussed by Graham2) — were in fact written by the same individual. (Matheson also wrote the screenplay for what — leaving aside the Kneale-scripted Quatermass and the Pit — is perhaps Hammer’s greatest film, The Devil Rides Out.)

Much like Jacob’s Ladder, which it resembles in a number of respects, The Box is a Weird take on the 1970s. Or rather, it draws together a number of Weird threads that were already present in the Seventies. Like Jacob’s Ladder and much hauntological music, The Box captures a certain grain of the Seventies. The Box feels like a re-dreaming of the Weird rather than a revival in part because of the very incoherence that some have complained about. This “incoherence” is of a particular type; it isn’t simply a failure of coherence so much as the generation of an oneiric (in)consistency which doesn’t add up (into a final resolution) but which doesn’t fragment into nonsense either.

The dream atmosphere is reinforced by the way that Kelly incorporates aspects of his own life into the film — the characters of Arthur and Norma Lewis are apparently based closely on his own parents3 — into the diegesis. But rather than the de-stranging tendencies at work in something like the new Dr Who — the Weird subordinated to familialism and emotionalism — The Box goes in the other direction, introducing the Weird into the family home — in parallel with how television used to do the same thing. The lines between Kelly’s home life and the Weird must have been soft in any case: his father worked at NASA at the time when the Viking probes were landing on Mars.

The Box is based on Matheson’s 1970 short story, “Button Button”, later adapted into an episode of the revived Twilight Zone in 1986. To be more accurate, The Box uses both the original story and The Twilight Zone episode as elements in a simulated dreamwork which simultaneously extrapolates from the two versions and condenses them into an unstable compound. The result is a labyrinthine structure which bears some relation to Lynch’s Inland Empire (Inland Empire, incidentally, was the last film to creep me out as much as The Box did). The Box is defined by the tension between the structure of the labyrinth — an absolute labyrinth, leading nowhere except deeper into itself — and the structure of the dilemma — in which reality seems to resolve into a set of disjunctions.

It’s possible to delimit a number of distinct but connected levels at which the film operates.

The Ethical

The most simple level on which the film works — the film’s entry level — is that of the ethical. All three versions of “Button, Button” turn on a dilemma: not so much an ethical dilemma as a dilemma about whether to set aside the ethical altogether. A well-dressed stranger, Mr Steward, arrives and presents the Lewises with a box with a button on top of it. If they press the button, Steward informs them, they will receive a large sum of money (in The Box it is a million dollars); however, someone that they don’t know will die. In all three versions, it the wife who decides to push the button. Here, the versions diverge: in Matheson’s original story, after Norma pushes the button, she receives the money as insurance compensation for the death of her husband. When she complains that Steward had told her that the person who died would be someone she didn’t know, Steward asks: “Did you really know your husband?” In The Twilight Zone version — which Matheson reputedly hated — the ending is different. Here, when Steward has handed over the money, he pointedly says to the couple, “I can assure you it will be offered to someone whom you don’t know.” The Box adopts this version of the story, but this is only the beginning of the film, the first act, as it were.

Unintended Consequences

“Button, Button” is clearly an update of W.W. Jacobs’ story “The Monkey’s Paw” — in which a family wishes for a sum of money, only to receive it in compensation for the death of their son. Jacobs’ story was itself a play on older tales about the unintended consequences of wish fulfilment. As Wiener observed in God and Golem, Inc.: A Comment On Certain Points Where Cybernetics Impinges On Religion, such unintended consequences arise because “the operation of magic is singularly literal-minded in that () if it grants you anything at all, it grants you exactly what you ask for, not what you should have asked for or what you intend.” “The magic of automatisation, and in particular the kind of automatisation where the devices learn”, he adds, “may be expected to be similarly literal-minded”.4 Like the cybernetic machine, the wish-fulfilling object (the monkey’s paw) delivers exactly what it says it will: but what it gives you may not be what you want (or what you think you want).

What Matheson’s tale adds to Jacobs’ story is the question of knowledge. Matheson’s story brings into play the old philosophical “problem of other minds”, now applied to the marital situation: even those closest to us are ultimately opaque, black boxes into which we can never see. Naturally, this also raises the equally ancient problem of self-knowledge, but given a psychoanalytic edge. We are alien to ourselves; our real desires may be unknown to us, emerging only in parapraxes and dreams. Here the oneiric form of The Box collapses into its content — the box, like the dream according to Freud, fulfils our wishes. The inevitable psychoanalytic conjecture into which Matheson’s story tempts us is the thought that perhaps the wife does get exactly what she wants — that the death of her husband was her wish all along. In this sense the box would be like the Room in Tarkovsky’s Stalker: the stalker Porcupine goes into the wish-fulfilling Room hoping for the return of his dead brother, but receives instead immense riches. In its very unreflective automatism — giving Porcupine exactly what he wants — the Room judges and condemns him.

The Political

What Matheson’s story also adds to “The Monkey’s Paw”, of course, is the fact that the bad consequences are not simply unintended; they were just supposed to happen to someone else. This is what makes it so much nastier than Jacobs’ tale. Whereas the family in “The Monkey’s Paw” are guilty only of foolishness and greed, the couple in “Button, Button” knowingly trade another’s death in exchange for wealth. In The Box this is especially shocking because both Norma and Arthur Lewis seem to be “good” people — Cameron Diaz’s Norma in particular is immensely sympathetic. Perhaps what allows her to press the button is the unresolved ontological status of the box itself; the thought that it might be a prank (Arthur establishes that the box is empty) allows Norma to perform a kind of fetishist disavowal (“this might not be real, so I might as well do it”). As Hauntagonist put it on his Twitter feed: “the button in The Box is a nice example of how interactivity creates anxiety and fetishistic disavowal. Diaz doesn’t believe but she believes ‘the subject supposed to believe’ does, Arlington Steward being the stand-in for the Big Other.”

Here we are back in the realm of the ethical — but the ethical bleeds out into the political. The choice to press the button has a special force in the era of globalisation and climate change. We know that our wealth and comfort are achieved at the price of others’ suffering and exploitation, that our smallest actions contribute to ecological catastrophe, but the causal chains connecting our actions with their consequences are so complicated as to be unmappable — they lie far beyond not only our experience, and any possible experience. (Hence the inadequacy of folk politics.) What the Lewises are in effect asked to do is affirm their plugging into this causal matrix — to formally accept the world and worldliness. The significance of this is that only the negative choice counts — to not press the button would be to choose a freedom that is not available to anyone at present (we are all so intricately embedded into the global capitalist matrix that it isn’t possible to simply opt out). But to press the button is to give up on freedom, to choose blind determinism.

The Existentialist

Which brings us to the most explicit intertext that Kelly introduces into The Box: Sartre’s Huis Clos. Huis Clos is everwhere in The Box; Norma, a highschool teacher, is teaching it; she and Arthur attend an amateur dramatic performance of the play. At the point when it is becoming evident that the Lewises’ choice will not be some private shame but will infect and destroy every aspect of their lives, the couple find the words “No Exit” written in the condensation of their car’s windscreen.

The resonance of Huis Clos is clear: this is a text about those who can no longer choose, who have ceased to be subjects. Fearing that they will be killed, the Lewises try to return the briefcase of money immediately, the very instant that Steward tells them that he will be sure to give the box to someone who doesn’t know them. But the horror is that Norma and Arthur have made a choice that means that it is now too late: they are already (as if) dead. There is no returning the gift.

It is astonishing that the briefcase containing the money is immediately desublimated. Kelly could have had the Lewises spend the money, their enjoyment shadowed by their anxieties about what they had done… Instead, the briefcase is immediately dumped in their basement, never to be seen or — I think — mentioned again.

There is no possibility of returning the money — no way of taking back the choice to press the button — but there is no end to choosing either. Locked in an endlessly ramifying labyrinth, Arthur and Norma keep encountering further dilemmas — but the choice is now between bad (purgatory) and worse (hell); or else, as when Arthur is offered a choice of three gateways, two leading to eternal damnation, one to salvation, they have a quality of grotesque gameshow randomness.

The Religious

The mention of “salvation” is part of a persistent religious thread in the film. As the alien big Other, the one conducting “research” into the moral worth of human beings and judging them accordingly, and with the power of damnation and redemption in his hands, Steward clearly stands in for God. Yet he is a God who also performs the Satanic function of tempting humans.

The SF/Conspiracy

Steward’s position as the (extra-terrestrial) big Other, the subject supposed to know, also somewhat echoes Sartre’s discussion of the alien, as outlined by Infinite Thought:

Sartre, towards the end of his gigantic unfinished Critique of Dialectical Reason from 1960, suddenly launches into a discussion of Martians. “For the () Martian…who has long known the technique of inter-planetary navigation, we are… an animal species whose scientific and intellectual development have been retarded by certain circumstances the Martian () will note that the inhabitants of this underdeveloped planet have certain behavioural patterns orientated towards certain objectives…” Because the hypothetical Martian will be at a particular scientific level (the assumption here is that it will be a much higher one), when the extent of human knowledge is revealed to the alien, there enters into the conceptual arena an exterior agent who for the first time knows what we do not know as a species — the Martian thus serves as the big Other for the entire collective enumeration of human beings. This limit case of the big Other Martian becomes, as Sartre puts it “a deep opacity, shadows in our understanding, a negation of interiority in our hearts.”5

The Box is thick with references to conspiracy films (and includes some of the most creepily paranoid scenes since the remake of Invasion of the Body Snatchers). The full extent of the collusion of the authorities with Steward remains unclear even at the end of the film. The threads connecting NASA, the Viking probe and Steward’s research project fray off into rumour and supposition. The labyrinth never ends.





contributing to society1

In respect of The Fairy Jobmother, it’s worth noting how much more pernicious it was than Benefit Busters, the original programme from which it was a spin-off. Despite its title, Benefit Busters allowed viewers to come to a critical judgement about the initiatives the government were using to “get people back to work”. The first part of the programme, the one featuring Hayley Taylor, was like some grim parody of a reality TV talent show, in which the glittering prize on offer was not a million-pound record deal but an unpaid work trial at discount store Poundland. Taylor was clearly a dupe of the ideology rather than its cynical author, credulously believing all the New Age pyschobabble she pushed along with the facile advice (“brush your teeth before an interview”). There’s no doubt that some of the women were happier after being on the six-week “course” — but that was less because they were working for Poundland and more because they were not isolated in their own homes any more. Meanwhile, the programme showed us the home belonging to Emma Harrison, the boss of A4E,2 the consultancy for which Taylor worked. To say that Harrison’s house was a mansion would be a massive understatement.3 A4E employees such as Taylor were invited to Harrison’s house for “a cup of tea and a chat”, because Harrison is so informal and she just loves get feedback from her workers. Faced with the extreme opulence of Harrison’s house, viewers were at least invited to question who the real parasites scrounging off the state were. The excellent WatchingA4E blogspot does invaluable work exposing the realities of A4E’s schemes.4 This entry quotes a description of Harrison: “Emma’s approach is to work with people: ‘I walk by their side, hold their hand and we go on a journey resulting in them getting a job that transforms their lives’.”5

Subsequent parts of Benefit Busters allowed viewers to form even more negative views of the government’s schemes to get people back to work — we saw the long-term unemployed cynically forced off benefits for a job that would last only a few days, and a poor young lad with severe back problems sustained after falling out of a window being told that he was fit for work. There was none of this critical perspective in The Fairy Jobmother, which presented the reality TV “journey” back to work without any irony. As Digital Ben puts it:

The show’s very title gives us an idea of what kind of strictly limited conclusions will be drawn at the end. Taylor’s steps did improve the family’s situation, but it was made clear that these “fairy godmother wishes” were miraculous and unexpected, a break from the normal order of things. The idea that they be distributed on a wider basis, or even structuralised as part of the benefits system, is never on the table. The majority of the working class unemployed are expected to pull themselves up by their bootstraps — become mini-Hayleys and fully valid humans without any outside help. So what exactly was the moral of the show? That finding work is easier when you have a well-known, well-connected recruitment specialist in your corner? Shocking. And even then — if Taylor fails to find work for the family next week, we can expect blame to be diverted to them. There is no systemic analysis. Blame falls solely upon the individuals (and, yes, their families).6

One can hardly underestimate the role that reality TV plays in generating this lottery thinking, which is the other side of what Alex Williams calls negative solidarity. The persistent message is that any situation can be rectified by the application of dedicated self-improvement. (C4 is to be given some credit for showing some programmes which resist this agenda: its series The Hospital and Our Drug War show the real hopelessness of the NHS and the war on drugs. The Hospital gives a grim picture of youth in the UK. Class was the unspoken factor here: there weren’t any middle-class kids being filmed arriving in hospital pregnant, or catching HIV, or getting involved in knife crime. In the first part, about the impact of unprotected sex, anti-authoritarian defiance came out as self-destructive bad faith: “they can’t tell me what to do”, “I’m the sort of person who has to do this”. There was a desperate joylessness about the mandatory pleasure-seeking; another side to the hedonic depression I talk about in Capitalist Realism.)

One of the things that irritated me in the last part of Fairy Jobmother was the moment when Taylor talked about someone getting back to work so they could “make a contribution to society” again. (My mentioning this on Twitter sparked a brief exchange with this character,7 who said “you can do what you please but not with my cash. You don’t want to work that’s fine — just don’t expect me to pay”.) As if there are no other ways to “make a contribution to society” than paid work (what is the Big Society if not about the value of such unpaid contributions?); as if those in work didn’t depend, in numerous ways, on those not being paid for work…

Like many people I know, I spent my twenties drifting between postgraduate courses and unemployment, encountering many pointless and demoralising “helping you back to work” initiatives along the way. There wasn’t much difference between what I did on an average day when I was a student and what I did when I was unemployed, and there isn’t a great deal of difference between what I was doing then and what I do now. But now I’m fairly confident that I “make a contribution”; then I wasn’t. For a number of reasons, during my twenties I believed then that I was unemployable — too feckless to do either manual work or retail, and nowhere near confident enough to do a graduate job of any kind. (The ads for graduate jobs would fill me with despair: surely only a superhuman could do the job as described?) I won’t deny that eventually getting employment was important — I owe so much of what I am now to getting a teaching job. But equally important was the demystification of work that gaining this employment allowed — “work” wasn’t something only available to people who belonged to a different ontological category to me. (Even so, this feeling wasn’t rectified by having a job: I had a number of depressive episodes when I was convinced that I wasn’t the sort of person who could be a teacher.)

But surely the importance of Virno and Negri’s work is to have undermined the distinction between work and non-work anyway. What precisely counts as non-work in post-Fordism? If, to use Jonathan Beller’s phrase, “to look is to labour” — if, that is to say, attention is a commodity — then aren’t we all “contributing”, whether we like it or not? As Nina Power argues, “i ()t is as if employers have taken the very worst aspects of women’s work in the past — poorly paid, precarious, without benefits — and applied it to almost everyone, except those at the very top, who remain overwhelmingly male and incomprehensibly rich.” In these conditions — in which unemployment/ underemployment/perpetual insecurity are structurally necessary, not contingent accidents — there’s more case than ever for a benefits safety net.

At this point, I must plug Ivor Southwood’s forthcoming book, Non-Stop Inertia. It’s about the miseries of “jobseeking”, and it’s one of my favourite Zer0 books to date, combining poignant and funny observations derived from experience with theoretical acuity. The book is sure to be of interest to most people who enjoyed Capitalist Realism (indeed, Ivor writes about whole dimensions of capitalist realism which I didn’t touch upon). Here are a couple of paragraphs:

The endless unpaid duties assigned to the virtuoso jobseeker cast him as the postmodernised inversion of the 1980s “gizza job” persona, which confronted the employer directly with the physical reality of the reserve laborer and his family. Now, rather than proclaiming his jobless status the career jobseeker hides it, like something obscene, behind a screen of training courses and voluntary work and expressions of rictus positivity, and he becomes ever more complicit with this concealment in proportion to his desperation. The jobseeker must have an alibi ready to explain away every gap in his employment history, while the most mundane experience becomes the occasion of a personal epiphany — “working in a busy café really taught me something about the importance of customer service”. Skills are valued over knowledge. Non-vocational qualifications are almost a liability, unless they are emptied of content; a degree in literature is valued not for its evidence of critical thought but because it shows that the applicant has word processing experience.

What are we not thinking about during all those hours of jobseeking, networking and CV-building? What interests, worries and fantasies might we otherwise have? What books might we read (other than self-help manuals), what conversations might we have with colleagues and friends about topics other than work? How differently might we perceive our current jobs without this constant needling insecurity? What kind of dangerous spaces might open up, in what kind of jeopardy might we put ourselves and this dynamic system, if we resigned from our jobs as jobseekers?8





“just relax and enjoy it”: geworfenheit on the bbc1

I first saw Artemis 81 when it was broadcast for the first and only time in December 1981. Even though it struck me then as incoherent and incomprehensible, I willingly sat through all three hours of it. Judging by the internet responses to Artemis 81, my experience was a common one amongst kids who, like me, were allowed to stay up late and watch it because it was broadcast during the school holidays.

I suppose that Artemis 81 was one of the things that I was thinking of when, towards the end of Capitalist Realism, I argued that, far from being dreary and dull, the so-called paternalist era of media could be a breeding ground for the Weird (Ghost Box’s conflation of secondary school textbooks with Weird fiction is based on the same intuition).

Artemis 81 was written by David Rudkin, the author of the betterknown Penda’s Fen (to which I’ll be returning in another post very soon). Watching it again after nearly thirty years, the film doesn’t seem incomprehensible at all. It is structured around a simple Manichean dichotomy (Manicheanism was one of the heavily signposted themes of Penda’s Fen), and a mythic journey out of complacency and selfinvolvement and into a kind of visionary faith. (The persistent emphasis in Artemis 81 on the “leap into faith” makes for an interesting parallel with Inception: at one point, the lead character tells a woman who has been strung up inside a cathedral bell that “it is better to fall than to hang”.) What makes Artemis 81 still alienating to watch are all the things that it lacks — all those strategies for producing audience identification to which we are now so accustomed. The acting style is as Brechtian as anything you would see in a Straub-Huillet film; the dialogue is anti-naturalistic, highly mannered (it reminds me more of an opera than television writing — and Wagner is one of many intertexts).

Rudkin says on the DVD commentary that the alien planet which we appear to see at the start of the film belongs to inner space. It is never clear when we exit inner space. But the film gains a great deal of power from grounding this inner space in what you might call found locations: the ferry terminal at Harwich; a power station in North Wales, which during the time of filming was under construction, and which becomes the entry to hell; and perhaps most memorably of all, the interior of the Anglican cathedral in Liverpool, which the BBC crew were not only given permission to use — they were also allowed to clear out all the pews, making for some astonishing oneiric images.

One sequence in particular stands above all the others. It is both one of the most disturbingly effective dream — or nightmare — sequences I’ve ever seen in film (certainly it is far better capturing dream topographies than anything in Inception), and also a deeply resonant image of dystopia. The lead character, pulp novelist Gideon Harlax (Hywell Bennett) suddenly finds himself in an unidentified city: he is on a tram, surrounded by consumptives expectorating blood into their scarves. It is foggy; the city is militarised, although there is a great deal of street market-like commercial activity. No one speaks English. When he enquires after Helith, the guardian angel who has abandoned him (played by Sting — but don’t let that put you off), people laugh or admonish him. A public address system incessantly streams out announcements in what sounds like an East European language (it is actually Estonian spoken backwards). Watched now, you can’t help but see anticipations of Blade Runner and Children of Men here. On the commentary, Rudkin says that this section of the film was supposed to illustrate Heidegger’s concept of Geworfenheit, or throwness. Rudkin reveals that on-set, they used to refer to this city — actually a composite of Birmingham and Liverpool — as Geworfenheit, but this is never mentioned in the film itself. Beyond all the explicit references to myth, music and literature, there were further, occulted, layers of intertext. Another example, from this write-up on Artemis 81:

One minor point that reveals much about … () Rudkin’s approach: the presiding deity of the piece is a Scandinavian goddess known as Magog. But it takes an alert eye to spot the “Gog Magog Hills” in a map of Britain which we glimpse on the protagonist’s desk a lesser dramatist would perhaps have included a lengthy detour around the rather different “Magog” to be found in English mythology.2

It was Artemis 81’s confidence that you can subject the audience to Geworfenheit that makes it so impressive. As all the kids who watched Artemis 81 and who have never forgotten it will attest, there’s an enjoyment to be had from being thrown into the middle of things which you cannot understand and being forced to make a kind of sense out of them.

I hardly need say that it is impossible to imagine something like Artemis 81 being commissioned, still less broadcast, by the BBC today. I agree absolutely with Phillip Challinor when he writes that “Artemis 81 stands as a brilliant example of the way in which interesting pretentiousness can be a good deal more satisfactory than solid professionalism and good old-fashioned storytelling.”3 Like much Seventies culture — and Artemis 81 really belongs to the “long Seventies” that ended circa 1982 — it deploys pretentiousness as a visionary force. To use a musical analogy, Artemis 81 combines the overblown ambition of prog with the cool Ballardianism of post-punk. It is quintessentially pulp modernist — there are references to The Devil Rides Out as well as to The Seventh Seal and Carl Dreyer.

It is the BBC that made and broadcast Artemis 81 which should be recovered and defended, not the institution as it currently functions today. The opposition that sets elitism against populism is one that neoliberalism has put in place, which is why it’s a mistake to fall either side of it. The neoliberal attack on cultural “elites” has gone alongside the consolidation and extension of the power of an economic elite. But there’s nothing “elitist” about assuming intelligence on the part of an audience (just as there is nothing admirable about “giving people what they want”, as if that desire were a natural given rather than something that is mediated on multiple levels). Important qualification: to say that there was much to be mourned in the cultural situation in the Seventies and early Eighties is not to say that everything about that period is to be missed. I shouldn’t have to make this disclaimer, but I’m mindful that any kind of critical judgement which favourably compares the past to the present is likely to be accused of “nostalgia”. There are unique opportunities in the current conjuncture, but they can only be accessed if there is some negation of the present rather than a vacuous affirmation of it.

Of course, the discourse network in which surrounded the BBC in 1981 was vastly different to the situation in which the BBC finds itself today. For an example of this, take a look at the Daily Mirror’s preview of Artemis 81:

It could be the most baffling show of the holiday, but ARTEMIS 81 (BBC1, 9.0) is also one of the best of the year. This three-hour thriller, giving pop singer Sting his first big television role, is a knockout. But even some of the people most closely involved are not too sure exactly what it’s about. Director Alastair Reid calls it a television Rubik Cube. And actor Hywel Bennett, who is at the heart of the action says he doesn’t understand it. Artemis 81 IS very complex. It has to do with a threat to the future of mankind, a series of mysterious deaths, a strange affair involving the Angel of Love and a great organist who, if he hits the right (or wrong) note, could blow up the world. My advice: Don’t worry about understanding it, just relax and enjoy it.





star wars was a

sellout from the start1

Does Disney’s acquisition of Lucasfilm mean that Star Wars has sold out? Can the Star Wars franchise retain its soul now it has been absorbed into a corporate conglomerate? It’s hard to believe that these questions are seriously being posed. Star Wars was a sell-out from the start, and that is just about the only remarkable thing about this depressingly mediocre franchise.

The arrival of Star Wars signalled the full absorption of the former counterculture into a new mainstream. Like Steven Spielberg, George Lucas was a peer of directors such as Martin Scorsese and Francis Ford Coppola, who had produced some of the great American films of the 1970s. Lucas’ own earlier films included the dystopian curio, THX 1138, but his most famous film was a herald of a coming situation in which mainstream cinema in America would become increasingly bland, and it would become impossible to imagine films of the quality of The Godfather trilogy or Taxi Driver ever being made again.

According to Walter Murch, the editor of Apocalypse Now, Lucas had wanted to make Apocalypse Now but had been persuaded it was too controversial, so he decided to “put the essence of the story in outer space and make it in a galaxy long ago and far, far away”. Star Wars was Lucas’ “transubstantiated version of Apocalypse Now. The rebel group were the North Vietnamese, and the Empire was the US”. Of course, by the time the film was ideologically exploited by Ronald Reagan, everything had been inverted: now it was the US who were the plucky rebels, standing up to the “evil empire” of the Soviets.

In terms of the film itself, there was nothing much very new about Star Wars. Star Wars was a trailblazer for the kind of monumentalist pastiche which has become standard in a homogeneous Hollywood blockbuster culture that, perhaps more than any other film, Star Wars played a role in inventing. The theorist Fredric Jameson cited Star Wars as an example of the postmodern nostalgia film: it was a revival of “the Saturday afternoon serial of the Buck Rogers type”, which the young could experience as if it was new, while an older audience could satisfy their desire to relive forms familiar from their own youth. All that Star Wars added to the formula was a certain spectacle — the spectacle of technology, via then state-of-the-art special effects and of course the spectacle of its own success, which became part of the experience of the film.

While the emphasis on effects became a catastrophe for science fiction, it was a relief for the capitalist culture of which Star Wars became a symbol. Late capitalism can’t produce many new ideas anymore, but it can reliably deliver technological upgrades. But Star Wars didn’t really belong to the science fiction genre anyway. J.G. Ballard acidly referred to it as “hobbits in space”, and, just as Star Wars nodded back to Tolkien’s Manichean pantomime, so it paved the way for the epic tedium of Peter Jackson’s Lord of the Rings adaptations.

What Star Wars did invent was a new kind of commodity. What was being sold was not a particular film, but a whole world, a fictional system which could be added to forever (via sequels, prequels, novels, and any number of other tie-ins). Writers such as Tolkien and H.P. Lovecraft had invented such universes, but the Star Wars franchise was the first to self-consciously commodify an invented world on a mass commercial scale.

The films became thresholds into the Star Wars universe, which was soon defined as much by the merchandising surrounding the movies as by the films themselves. The success of the toys took even those involved with the film by surprise. The then small company, Kenner, purchased the rights for the Star Wars action figures in late 1976, a few months ahead of the film’s theatre release in summer 1977. Unanticipated and unprecedented demand soon outstripped supply, and parents and children could not find the action figures in toy shops until Christmas 1977. This all seems rather quaint now, at a time when the merchandising surrounding blockbuster films is synchronised with a military level of organisation, and augmented by a battery of advertising and PR hype. But it was the Star Wars phenomenon which gave us the first taste of this kind of film tie-in commodity supersaturation.

This is why it’s ridiculous to ask if Star Wars sold out. It was Star Wars which taught us what selling out really means.





gillian wearing: self made1

An ordinary looking man in his thirties is walking towards the camera holding a carrier bag. It could be you or me, and the streets he moves through, with their off-licences and corner shops, could be anywhere, too — most people living in Britain wouldn’t have to go more than a mile to walk streets such as this. Still, something is not quite right: his expression looks distracted yet also troubled, while the music, an electronic drone punctuated by cries, creates an atmosphere of gathering unease. Suddenly, in the middle of the road, he stops, turns and drops the bag: it’s as if something in him has broken, as if he can no longer take it any more…

It’s a powerful opening, but Self Made immediately retreats from its intensity. We learn that Self Made started with an advertisement placed by Turner Prize winning artist, Gillian Wearing: “Would you like to be in a film? You can play yourself or a fictional character. Call Gillian.” Hundreds apply, but only seven make it through to the experiment. This involves being trained by Method acting expert Sam Rumbelow, in preparation for acting out a “micro-drama” which will explore the participants’ memories and feelings.

Immediately, I’m suspicious. Are these really the non-actors they are supposed to be? They seem remarkably unfazed by some of the exercises Rumbelow asks them to do, some of which you’d expect to cause nonperformers a degree of embarrassment. I’m suspicious about my feelings of suspicion: isn’t this exactly the response that’s expected of me? A whole series of questions ensue. What is the boundary between performance and everyday life? Is there any such thing as a non-actor, since all of us are engaged in performing our identities?

We’re in that familiar (art)space in which boundaries — in this case between “fiction” and “documentary” — are blurred. For much of its duration, the film puts us into that mode of listless sub-Brechtian questioning which so much art catalogue language routine invokes. The mode is deconstructive, demystificatory, (or it is their simulation): we see the micro-dramas, but only after we’ve been exposed to all the preparatory work that went into them; and afterwards, there are cutaways showing the crew filming the scenes.

Rumbelow comes across as an intensely irritating and creepy figure — more therapist-guru than acting coach, he’s horribly reminiscent of Hal Raglan, the scientist-therapist from Cronenberg’s The Brood who encourages his patients to “go all the way through” their emotional traumas, with fatal consequences. Perhaps exploitation is integral to the Method, and perhaps one of the points of Self Made is to examine this… And perhaps Sam Rumbelow is playing “Sam Rumbelow”, annoying Method acting expert…

Wearing has said in the past that she was inspired by Paul Watson’s 1974 fly-on-the-wall TV documentary The Family, and Self Made clearly follows on from such works as Confess all on video. Don’t worry, you will be in disguise. Intrigued? Call Gillian (1994) or Family History (2006) in engaging with the problems raised by mediated “revelation” — the issue here is precisely whether we are dealing with “revelation” at all, or whether what we are witnessing is an effect of the filming process itself. (The same questions occurred to Jean Baudrillard, and it’s no accident that some of his classic essays on simulation focus on the fly-on-the-wall phenomenon.) Wearing’s work certainly has less in common with the brashness of twenty-first-century reality TV than it does with the convergence of drama, psychotherapy and social experiment that came together in the 1970s and continued on into the 1980s. At points, Self Made reminded me of a half-forgotten mid-Eighties BBC programme which I believe was called Psychodrama, and which similarly invited the participants to explore traumatic moments in their lives through the construction of dramatic scenarios. In any case, there’s something horribly post-Sixties in every bad way about the techniques that Rumbelow uses to “unlock” the participants’ feeling. In the spirit of confessionalism that Wearing’s work examines, I admit that there are personal reasons for my hostility to this kind of thing. When I was at school in the early Eighties, we had to endure a class called Social and Personal Education. This involved being subjected to some of the emotionally terroristic exercises — such as “Trust Games” — which Rumbelow tries out with the participants here. Ironically, such exercises were at least as uncomfortable and disturbing as the experiences they were supposed to be exorcising, and these teachers were as oppressive in their own way as the agents of previous — more “repressive” — regimes of emotional management. There’s no suggestion that Self Made endorses the discourses which inform Rumbelow’s practice and the film’s most unsettling scenes — both concerning violence — at least raise the possibility than untapping and manipulating buried feelings may be catastrophic. At one point, Wearing conspicuously uses montage to highly charged effect, undercutting the sense — the illusion — of unmediated verité. The participant James is re-enacting/re-imagining a scene that took place on a train. He challenges one of the men who bullied him when he was younger. Almost immediately, he appears to consumed by a tempest of rage. He raises his fist to hit the other (non)actor and for a moment it seems as if he has struck his head with full force. We then realise, with a sense of relief that still doesn’t mitigate our horror, that Wearing has cut to James punching out a dummy. The film’s climactic scene is even more shocking. This returns us to Self Made’s opening shots. By now, we have learned that the man walking the streets is called Ash. This time, however, we see what he had turned around to do: kick a pregnant woman in the stomach. Even though we know this is an illusion — after all, we have seen it being constructed — the image in itself is so sickeningly transgressive that no amount of alienation effects can dissipate its power.





batman’s political right turn1

“How long do you think all this can last?” Selina Kyle (Anne Hathaway) asks Christian Bale’s Bruce Wayne amid the opulence of a high-society charity ball in The Dark Knight Returns. “There’s a storm coming.” A storm of a rather unexpected kind gathered over the film on Friday, with the appalling massacre in Denver.2 But the film was already enmeshed in political controversy in the US, when conservative US radio host Rush Limbaugh claimed the name of Batman’s adversary in the film, Bane, was a reference to presidential candidate Mitt Romney and his former company, Bain Capital.

Yet as Limbaugh also noted, it is not Bane but billionaire Bruce Wayne who most resembles Romney, while Bane’s rhetoric seems like a nod to the Occupy movement. Right-wing commentator John Nolte argues that the film has forced Occupy Wall Street into “damage control” and praises the director, Christopher Nolan, for “using the kind of conservative themes that most of artistically bankrupt Hollywood refuses to go near any more”.3 Fellow right-winger Christian Toto argues that it is impossible to read the film except as an anti-Occupy Wall Street treatise. “Bane’s henchmen literally attack Wall Street, savagely beat the rich and promise the good people of Gotham that ‘tomorrow, you claim what is rightfully yours’.”

Such readings spuriously conflate Occupy Wall Street’s anti-capitalism with the indiscriminate violence used by Bane and his followers.

When Nolan revived the Batman franchise in 2005, the setting — Gotham in the midst of an economic depression — seemed like an anachronistic reference to the superhero’s origins in the 1930s; 2008’s The Dark Knight was too early to register the impact of the financial crisis. But The Dark Knight Rises clearly attempts to respond to the post-2008 situation. The film isn’t the simple conservative parable that right-wingers would like, but it is in the end a reactionary vision.

The storm Hathaway’s character prophesies is a time of reckoning for the wealthy, and what stops the film being a straightforward celebration of conservative values in the way Nolte and Toto want is the relish it takes in attacking the rich. “You and your friends better batten down the hatches”, Kyle continues, “cause when it hits, you’re all going to wonder how you ever thought you could live so large, and leave so little for the rest of us”. An early scene features the stock exchange, where we have the pleasure of seeing Bane manhandle some predatory traders. Later, when Wayne tells Kyle that although he is supposedly bankrupt, he has kept his house, Kyle acidly observes that “the rich don’t even go broke like the rest of us”.

Anti-capitalism is nothing new in Hollywood. From Wall-E to Avatar, corporations are routinely depicted as evil. The contradiction of corporatefunded films denouncing corporations is an irony capitalism cannot just absorb, but thrive on. Yet this anti-capitalism is only allowed within limits. The Dark Knight Rises draws clear lines: anti-capitalist comment (of the kind that Kyle makes) is fine, but any direct action against the rich, or revolutionary moves towards the redistribution of property, will lead to dystopian nightmare.

Bane talks about returning Gotham to “the people”, and liberating the city from its “oppressors”. But the people have no agency in the film. Despite Gotham’s endemic poverty and homelessness, there is no organised action against capital until Bane arrives.

At the end of The Dark Knight Rises, Batman had sacrificed his reputation to save the city, and it’s tempting to read the film as an allegory for the attempts by the elite to rebuild their standing after the financial crisis — or at least to preserve the idea that there are good rich who, if suitably humbled, can save capitalism from its worst excesses.

The sustaining fantasy of Nolan’s Batman films — which does chime uncomfortably with Romney — is that the excesses of finance capital can be curbed by a combination of philanthropy, off-the-books violence and symbolism. The Dark Knight at least exposed the duplicity and violence necessary to preserve the fictions in which conservatives want us to believe. But the new film demonises collective action against capital while asking us to put our hope and faith in a chastened rich.





remember who the enemy is1

There’s something so uncannily timely about The Hunger Games: Catching Fire that it’s almost disturbing. In the UK over the past few weeks, there’s been a palpable sense that the dominant reality system is juddering, that things are starting to give. There’s an awakening from hedonic depressive slumber, and The Hunger Games: Catching Fire is not merely in tune with that, it’s amplifying it. Explosion in the heart of the commodity? Yes, and fire causes more fire…

I over-use the word “delirium”, but watching Catching Fire last week was a genuinely delirious experience. More than once I thought: How can I be watching this? How can this be allowed? One of the services Suzanne Collins has performed is to reveal the poverty, narrowness and decadence of the “freedoms” we enjoy in late, late capitalism. The mode of capture is hedonic conservatism. You can comment on anything (and your tweets may even be read out on TV), you can watch as much pornography as you like, but your ability to control your own life is minimal. Capital has insinuated itself everywhere, into our pleasures and our dreams as much as our work. You are kept hooked first with media circuses, then, if they fail, they send in the stormtrooper cops. The TV feed cuts out just before the cops start shooting.

Ideology is a story more than it is a set of ideas, and Suzanne Collins deserves immense credit for producing what is nothing less than a counternarrative to capitalist realism. Many of the twenty-first century’s analyses of late capitalist capture — The Wire, The Thick Of It, Capitalist Realism itself — are in danger of offering a bad immanence, a realism about capitalist realism that can engender only a paralysing sense of the system’s total closure. Collins gives us a way out, and someone to identify with/as — the revolutionary warrior-woman, Katniss.

Sell the kids for food.

The scale of the success of the mythos is integral to its importance. Young Adult Dystopia is not so much a literary genre as a way of life for the generations cast adrift and sold out after 2008. Capital — now using nihiliberal rather than neoliberal modes of governance — doesn’t have any solution except to load the young with debt and precarity. The rosy promises of neoliberalism are gone, but capitalist realism continues: there’s no alternative, sorry. We had it but you can’t, and that’s just how things are, OK? The primary audience for Collins’ novels was teenage and female, and instead of feeding them more boarding school fantasy or Vampiary romance, Collins has been — quietly but in plain sight — training them to be revolutionaries.

Perhaps the most remarkable thing about The Hunger Games is the way it simply presupposes that revolution is necessary. The problems are logistical, not ethical, and the issue is simply how and when revolution can be made to happen, not if it should happen at all. Remember who the enemy is — a message, a hailing, an ethical demand that calls out through the screen to us… that calls out to a collectivity that can only be built through class consciousness… (And what has Collins achieved here if not an intersectional analysis and decoding of the way that class, gender, race and colonial power work together — not in the pious academic register of the Vampires’ Castle, but in the mythographic core of popular culture — functioning not as a delibidinising demand for more thinking, more guilt, but as an inciting call to build new collectivities.)

There’s a punk immanence about Catching Fire which I haven’t seen in any cultural product for a long time — a contagious self-reflexivity that bleeds out from the film and corrodes the commodity culture that frames it. Adverts for the movie seem like they belong in the movie, and, rather than a case of empty self-referentiality, this has the effect of decoding dominant social reality. Suddenly, the dreary gloss of capital’s promotional cyber-blitz becomes de-naturalised. If the movie calls out to us through the screen, we also pass over into its world, which turns out to be ours, seen clearer now some distracting scenery is removed. Here it is: a neo-Roman cybergothic barbarism, with lurid cosmetics and costumery for the rich, hard labour for the poor. The poor get just enough high-tech to make sure that they are always connected to the Capitol’s propaganda feed. Reality TV as a form of social control — a distraction and a subjugatory spectacle that naturalises competition and forces the subordinate class to fight it out to the death for the delectation of the ruling class. Sound familiar?

Part of the sophistication and pertinence of Collins’ vision, though, is its awareness of the ambivalent role of mass media. Katniss is a totem not because she takes direct action against the Capitol — what form would that take, in these conditions? — but because her place in the media allows her to function as a means of connecting otherwise atomised populations. Her role is symbolic, but — since the capture system is itself symbolic in the first instance — this is what makes her such a catalyst. The girl on fire… and fire spreads fire… Her arrows must ultimately be aimed at the reality system, not at human individuals, all of whom are replaceable.

The removal of capitalist cyberspace from Collins’ world clears away the distracting machinery of Web 2.0 (participation as an extension of spectacle into something more pervasive, total, rather than as its antidote) and shows how TV, or, better, what Alex Williams has called “the Universal Tabloid”, is still productive of what counts as reality. (For all the horizontalist rhetoric about Web 2.0, just look at what typically trends on Twitter: TV programmes.) There’s a role as hero or villain — or maybe a story about how we’ve gone from hero to villain — prepared for all of us in the Universal Tabloid. The scenes in which Plutarch Heavensbee gives a businesslike description of the carrot and stick nature of the Capitol’s media-authoritarian power have a withering, mordant precision. “More beatings, what will her wedding be like, executions, wedding cake…”

As Unemployed Negativity wrote of the first film:

It is not enough that the participants kill each other, but in doing so they must provide a compelling persona and narrative. Doing so guarantees them good standing in their odds and means that they will be provided with assistance by those who are betting on their victory. Before they enter the arena they are given makeovers and are interviewed like contenders on American Idol. Gaining the support of the audience is a matter of life in death.2

This is what keeps the Tributes sticking to their reality TV-defined meat puppet role. The only alternative is death.

But what if you choose death? This is the crux of the first film, and I turned to Bifo when I tried to write about it.3 “Suicide is the decisive political act of our times.”4 Katniss and Peeta’s threat of suicide is the only possible act of insubordination in The Hunger Games. And this is insubordination, NOT resistance. As the two most acute analysts of Control society, Burroughs and Foucault, both recognised, resistance is not a challenge to power; it is, on the contrary, that which power needs. No power without something to resist it. No power without a living being as its subject. When they kill us, they can no longer see us subjugated. A being reduced to whimpering — this is the limits of power. Beyond that lies death. So only if you act as if you are dead can you be free. This is Katniss’ decisive step into becoming a revolutionary, and in choosing death, she wins back her life — or the possibility of a life no longer lived as a slave-subordinate, but as a free individual.

The emotional dimensions of all this are by no means ancillary, because Collins — and the films follow her novels very closely in most respects — understands how Control society operates through affective parasitism and emotional bondage. Katniss enters into the Hunger Games to save her sister, and fear for her family keeps her in line. Part of what makes the novels and the films so powerful is the way they move beyond the consentimental affective regime imposed by reality TV, lachrymose advertising and soap operas. The greatness of Jennifer Lawrence’s performances as Katniss consist in part in her capacity to touch on feelings — rage, horror, grim resolve — that have a political, rather than a privatised, register.

The personal is political because there is no personal.

There is no private realm to retreat into.

Haymitch tells Katniss and Peeta that they will never get off the train — meaning that the reality TV parts they are required to play will continue until their deaths. It’s all an act, but there’s no offstage.

There are no woods to run into where the Capitol won’t follow. If you escape, they can always get your family.

There are no temporary autonomous zones that they won’t shut down. It’s just a matter of time.

Everyone wants to be Katniss, except Katniss herself.

Bring me my bow, of burning gold.

The only thing she can do — when the time is right — is take aim at the reality system.

Then you watch the artificial sky fall.

Then you wake up.

And.

This is the revolution…





beyond good and evil:

breaking bad1

Who needs religion when you have television? On soap operas, unlike in life, villainous characters almost always face their comeuppance. TV cops may now be required to have “complicated” private lives and dubious personal ethics, but we’re seldom in any serious doubt about the difference between good and evil, and on which side of the line the maverick cop ultimately falls. The persistence of the fantasy that justice is guaranteed — a religious fantasy — wouldn’t have surprised the great thinkers of modernity. Theorists such as Spinoza, Kant, Nietzsche and Marx argued that atheism was extremely difficult to practise. It’s all very well professing a lack of belief in God, but it’s much harder to give up the habits of thought which assume providence, divine justice and a secure distinction between good and evil.

The US television series Breaking Bad, an international hit whose final episode aired this autumn, escapes this impasse. But we have to be careful here — the series has been understood (its title invites this interpretation) as the story of how an ordinary lower-middle-class man becomes evil. The set-up was simple. Walter White (played by Bryan Cranston), a chemistry teacher at a school in New Mexico, is diagnosed with lung cancer. Unable to afford the treatment, Walt decides to use his expertise in chemistry to manufacture methamphetamine, or crystal meth, with the help of a feckless ex-student, Jesse. As the series progresses, Walt shifts from making agonised decisions about whether it is right to kill, to becoming a ruthless crimelord. Yet this is not the whole story, and to read the series as a narrative of Walt becoming evil is to resist what is most challenging about it.

The success of the show outside the US has provoked some amusing parodies. Imagine Breaking Bad set in the UK and Canada. Opening scene. Doctor tells Walt he has cancer — the treatment starts next week. End of series. What this points out is an opposition that was crucial to the drama: between the fragility of the physical body and the precarity produced by social relations. One way of measuring progress is through the extent to which human beings have managed to contain the inevitable suffering that nature causes the body. In this sense, Breaking Bad can be compared with Ken Loach’s recent documentary about the foundation of the British welfare state, Spirit of ‘45. Loach’s evocation of a destroyed working-class progressivism brings the savage new Wild West that emerges in Breaking Bad into painful relief. Walt does so many “bad” things because he wants to remain a “good” husband, as defined by the Protestant work ethic. Much of the series’s mordant humour comes from seeing Walt pursue this ideology of work — it’s better to earn your “own” money, no matter how, than to scrounge from others or ask them for help — to all kinds of extremes.

In the final episode, Walt has to admit that the desire to build his drug empire brought him an intense libidinal satisfaction that had long since become autonomous from the ostensible purpose — providing for his family when he is gone — that provoked him into cooking meth in the first place. But for most of the series Walt clings to the idea that he’s doing all the drug production, the killing, the manipulation and the terror for the sake of his family. Ironically, the one thing that the family could not survive is the course of action Walt ends up pursuing. It could probably survive penury and debt. It could survive the loss of Walt’s physical body. But it cannot survive the loss of the image of Walt as an ordinary father figure, beaten down by life, an underachiever maybe, but still someone who “does the right thing”. It’s as if Walt destroyed the family in the very attempt to save it.

Perhaps the most complex and powerful character in the whole series is Walt’s wife, Skyler, played by Anna Gunn. The actor has written of the misogyny she faced from some Breaking Bad fans online as a consequence of playing Skyler: in a piece for the New York Times, she described how the character seemed to have become “a flash point for many people’s feelings about strong, non-submissive, ill-treated women”. This is especially depressing because Skyler is a nuanced character, not at all someone who simply rejects Walt at the earliest opportunity. Even though she deplores Walt’s adventures in crime, it is only at the very end of the series, when Walt’s actions have manifestly brought catastrophe to Skyler’s family, that she definitively breaks with him. Until then she struggles, impossibly but heroically, to reconcile her roles as wife, mother and responsible citizen. At the end, we feel that she is traumatised but not broken — someone who will eventually be able to escape the horrors Walt brought to her life, and who, astonishingly, is still capable of retaining some love for the husband whose pride, hubris and desperation have threatened to destroy her life and those of her two children.

The politics of the family, and how these connect with the American ideology of earning your own money and paying your own way, were, then, at the heart of Breaking Bad. In the episode “Ozymandias” — probably one of the most intense, distressing, yet also occasionally hilarious hours of television I have ever seen — Skyler finally breaks totally with Walt. Their son, Walt Jr, has just discovered that Walt is a meth cook. Sheer vertigo, horror: Walt Jr’s whole world has disappeared in an instant. He doesn’t want to believe it, he’s angry with Skyler and Walt, he can’t make any sense of it, his eyes show the deepest pain, confusion, shock. Skyler grabs a carving knife — an echo of what Wendy Torrance does in The Shining — but, unlike Wendy, Skyler stands tough. She’s tall, strong, she’s not cowering or afraid anymore, and she suddenly knows what she has to do to protect herself and Walt Jr. She forces Walt out of the house. But before that, Skyler and Walt have grappled on the floor. Walt wriggles free, stands up and — hilariously, pathetically — tries to assert his patriarchal authority, tries to appeal to family togetherness. “Stop this! We — are — a — family!”

A scene like this gets right to the heart of why Breaking Bad was so mesmerically powerful. Even here, we’re aware that Skyler still loves Walt — not because she’s deluded but because she recognises that, even though Walt has become “a monster”, this isn’t all he is. In some sense, he still loves Skyler and Walt Jr; and the scenes in the final episode when Walt returns to say his last goodbye to Skyler, and he holds his young baby for the last time, and he watches Walt Jr from a distance, knowing that he will never speak to him again, are wrenchingly sad.

I think it was Lacan who remarked that when we talk about going beyond good and evil, we usually mean going beyond good. The modern world is fascinated by anti-heroes, people with a dark side, the pantomime madness and “evil” of Hannibal Lecter. What it is less comfortable with is the real atheist-existentialist revelation that “good” and “evil” are not written into the universe, but exist only in ourselves, in relation to our desires and interests. Soap opera melodrama keeps us believing in “evil” as a voluntaristic choice — people do bad things because they are evil. But in Breaking Bad, evil in that sense is nowhere to be found.

Certainly, it’s full of people who do “bad” things — that is, those who pursue actions that they know would either directly or indirectly hurt or destroy others — but they don’t do this because they are evil. Tuco, the lowlevel drug lord that Walt and Jesse tangle with in season one, is deranged and violent because he is a meth addict from a criminal family. Gus Fring, the slick meth overlord who makes his first appearance in season two, is a super-pragmatic businessman — so pragmatic, in fact, that he lives his life in seemingly permanent cover, disguised as the humble owner of a small fast-food chain. He kills ruthlessly, but only when it is expedient. Even when hillbillies with swastikas tattooed onto their necks emerge as the antagonists towards the end of the series, the writing never allows us to write off the most repulsive of them as totally “evil”, because they, too, are capable of mercy and acts of kindness.

Then there is Walt himself. One of the series’ subversive achievements is to draw attention to the way that our sympathy and identification with a character are a structural effect; one that is created both by the demands of genre and by the class structure of wider society. We initially sympathise with Walt in part because we remember other put-upon dads in popular TV series — such as Bryan Cranston’s character in Malcolm in the Middle — and also because the media constantly invite us to identify with the “hard-working” lower-middle-class family man. Yet Breaking Bad shows that the difference between the “good”, “ordinary” man and a ruthless criminal is the thinnest of lines. There but for the grace of social security and the NHS go we.





classless broadcasting:

benefits street1

It’s not exactly clear why Channel 4’s Benefits Street (broadcast in January and February 2014) caused such a furore. It wasn’t the most obviously exploitative of the many programmes about the unemployed and those on benefits. Yet something about this series, which followed the residents of James Turner Street in Birmingham, touched a nerve. It was immediately pressed into ideological service by the right, fitted into a pre-existing story about the “need to reform the welfare state”. The Daily Mail’s Richard Littlejohn quickly inserted some of the series’ participants into his phobic delirium. For most of those on the left, however, it was business as usual. For Owen Jones, author of the book Chavs, it was yet another case of the demonisation of the working class. For Ben Walters, writing on the blog Not Television, it was an example of Thatcherite documentary, while for the film-maker Katharine Round, writing for the Huffington Post, it was a depressing example of the way in which documentaries were being used to “kick those without a voice”.

In terms of its content, Benefits Street wasn’t all reactionary. Its somewhat mealy-mouthed claim to be about “community” rather than benefits wasn’t entirely false. Even in the first episode — which sensationistically dwelled on crime — there was still some emphasis on camaraderie and solidarity amongst the poor on the street. The second episode, which centred on desperate Romanians seeking work, was certainly sympathetic to the immigrants’ plight, and might even have done something to challenge the dominant media narrative about East Europeans “coming to steal our jobs and our benefits”. And by the third and fourth episodes sensation had largely given way to the inertia and radically contracted horizons of life on benefits. A small taste of this ought to have been enough to disabuse anyone of the notion that life on benefits is easy — but, since this belief is supported by relentless media propaganda, it isn’t likely to be given up any time soon.

Still, Benefits Street is undoubtedly part of a disingenuous trend in documentary making. Writing last year for the journal the Sociological Imagination, Tracy Jensen predicted a “summer of poverty porn”, citing such programmes as How To Get A Council House, Why Don’t You Speak English?, Benefits Britain 1949 (all Channel 4) and We All Pay Your Benefits (BBC1). Writing of the latter, Jensen argued that despite occasional moments of sympathy towards benefits claimants, the “programme’s ideological message was clear; worth comes from paid work and not from childrearing or volunteering; unemployment is a problem of will or determination and not of structural obstacles; and social security itself generates the ‘problem’ of welfare dependence.”2

Ultimately, Benefits Street fitted the same formula, in which intermittent sympathy for the poor and unemployed was used to season an otherwise crude reproduction of negative stereotypes. Then there is the perennial question of the exploitation of those who were filmed. Some — including residents of James Turner Street itself — objected to Benefits Street because they claimed that the programme’s producers had misrepresented what the series was actually going to be about. The residents weren’t told, for instance, that the series was to be given such a provocative and loaded title (the programme makers claimed that this was a last-minute decision, but I’m not sure how believable that is).

The deep problem with programmes like Benefits Street lies more in their form than in their content. A decade ago, the academic John Corner argued that reality TV had led to a genre of “post-documentary” television, in which documentary elements were merged with game-shows, makeover programmes and other entertainment forms.3 Now we are in the era of post-reality TV documentary, a much more pernicious genre. Even the most credulous viewer of reality TV could hardly fail to be aware of its constructedness, with participants worrying and complaining about how they were “portrayed”, and viewers quickly becoming familiar with the way narrative was produced by editing. (Partly this was because shows like Big Brother gave viewers access to the unedited footage, to the longueurs and the shapelessness of a quotidian time prior to its moulding into narrative.) Such reflexivity is largely absent from post-reality TV documentary — this genre uses many of the techniques from reality TV, but presents them with the simulated sobriety of documentary rather than with the winking, heavily made-up face of entertainment. That’s not to say that post-reality TV documentary is entirely straight-laced; no — one of its defining characteristics is a certain humour and lightness. But it doesn’t want to be positioned as entertainment in the way that reality TV was.

In their important study Reacting To Reality Television: Performance, Audience and Value, Beverley Skeggs and Helen Wood argue that much reality TV posits an implied bourgeois gaze, which judges working-class participants as lacking, by comparison with the middle class.4 Moreover, this lack is understood in heavily moralised terms; it isn’t to be explained by the working class’s lack of resources or opportunities, but by a deficit in will and effort. This implied perspective — seldom actually stated, but informing the whole way in which programmes are produced — is typical of the post-reality TV documentary.

This moralistic framing was at work in Benefits Street. It did almost nothing to contextualise what it showed. There was barely any discussion of why the participants had ended up on benefits, and no mention of the social causes of unemployment, just as there was no interrogation of the political agendas driving the focus on those claiming benefits, nor any examination of austerity as a political project. Post-reality TV documentary projects a radically depoliticised world of individuals and their intimacies. In Benefits Street, we were told that benefits were cut, but this was treated like some natural disaster, an act of God rather than the consequence of a political decision.

In many respects, post-reality TV documentary — like reality TV before it — goes out of its way to conceal the class differences between those who are making the programmes and those who feature in them. Like tabloid newspapers, the scripts impersonate a working-class vernacular. Typically, the voiceover plays an important role in this bid to present the programme to working-class viewers as if it has been produced by a group of peers. The voiceover will not now be the voice of the actual programme makers. If they are heard at all, these voices will only be heard in the off-screen prompts and questions put to the working-class participants. In the case of Benefits Street, the voiceover was performed by actor Tony Hirst, who has recently left the Coronation Street cast. Hirst’s accent is working-class, northern; his tone — perfectly in keeping with the supposedly “serious yet humorous” register of the post-reality TV documentary — is no-nonsense and wry. Tellingly, it was reported that the voiceover had been first offered to Brummie comedian Frank Skinner, who turned it down.

The use of voiceovers by actors or comedians from working-class backgrounds not only obfuscates the class origins of those making the programme; it also bolsters the programme’s claims to authenticity. In addition, and perhaps most significantly, the voiceover is part of a strategy that conceals the fact that the material is being framed in a particular way. In previous, more essayistic forms of documentary, when the person writing the script would also provide the voiceover, and might appear on camera, it was clearer both that a particular case was being made and who was making it. In the absence of a journalist or a programme-maker explicitly taking responsibility for any argument, viewers are invited to classify what they are seeing as the truth, pure and unmediated: this, we are induced to believe, is just real people, being themselves, and the refusal or failure to make any explicit argument allows dominant ideology — which the programme doesn’t acknowledge, still less challenge — to step in.

It’s a mark of how bad Channel 4’s programming now is that Benefits Street would probably count as one of its more serious recent attempts at documentary. If you want to measure the catastrophic impact of neoliberalism on British culture, then there’s no better example than Channel 4. A channel that began with programming that included European art films, serious philosophy discussion programmes and politically sophisticated documentaries has now degenerated into depths so embarrassingly hucksterish and craven that they are beyond parody. This is a channel which still allows Tory toffs like Kirstie Allsopp to front programmes that act as if it is normal for house-buyers to have budgets of a million pounds; a channel that cries crocodile tears over mental illness and other forms of extreme misfortune as a thin pretext for ruthlessly exploiting them. I’d like to think this decline isn’t irreversible, but there aren’t many reasons for hope at the moment.





rooting for the enemy:

the americans1

The first season of The Americans (recently broadcast in the UK on ITV) ended with a sequence soundtracked by Peter Gabriel’s “Games Without Frontiers”. The series has rightly been praised for its intelligent use of music, and “Games Without Frontiers”, which was released in 1980, the year in which the series begins, was a perfect choice of track for the climax of the first season. Atmospherically, the song is somehow both anxious and fatalistic: drained of emotional inflection, Gabriel’s vocals sound catatonic; the production is cold and forbidding. “Games Without Frontiers” feels not so much post-traumatic as pre-traumatic: as if Gabriel is registering the impact of a catastrophe that is yet to come.

Heard now, especially in the context of The Americans, a Cold War thriller, it reminds us of a time when such dread was ambient, when the spectre of seemingly inevitable apocalypse was woven into everyday life. Yet if “Games Without Frontiers” invokes the broad historical moment when The Americans is set, it also comments on the specific intrigues of the series. For The Americans is about Soviet spies posing as an ordinary US family. Cold War espionage did not respect the boundaries between private and public, between domestic life and duty to the cause: a game without frontiers indeed.

Created by former CIA agent Joe Weisberg, The Americans centres on Elizabeth (Keri Russell) and Philip Jennings (Matthew Rhys), two KGB agents living undercover as Americans in Washington. Weisberg had reputedly toyed with setting the series in the 1970s, but opting for 1980 makes strong dramatic sense. In 1980, the Cold War was intensifying in the immediate wake of the Soviet invasion of Afghanistan, and the election of Ronald Reagan, who was keen to prosecute a Manichean struggle against the “Evil Empire”.

The series is characterised by a bipolar oscillation between a downbeat naturalism and the screaming adrenal intensities of the thriller. There is no shortage of car chases and shoot-outs in The Americans — there is probably no more exciting show on TV at the moment than this — but these are intercut with scenes of domestic life, where the tensions are of another kind altogether.

Far from being a respite from the Cold War, the Jenningses’ home life is the zone where they carry out their most emotionally charged deceptions. The marriage is itself a sham: initially at least, Elizabeth and Philip are agents on a mission, not lovers, and the series is in part about their attempts to navigate this fraught emotional terrain, and to reconcile their differing expectations about what their roles entail. But Elizabeth and Philip at least know what they are doing; their children, Paige and Henry, necessarily do not. They are not aware that their parents are KGB agents (the children’s ignorance being one of the best forms of cover that the Jennings have available to them).

This not only raises the threat of discovery, but also raises a moral dilemma: should the children be told? This dilemma comes to a head in the second season, when one story arc concerns the murder of a fellow KGB couple and one of their children. When it turns out that the surviving child, Jared, had been recruited by the KGB, the question of Paige’s recruitment is inevitably raised. “Paige is your daughter”, says the Jenningses KGB controller, Claudia, “but she’s not just yours. She belongs to the cause. And to the world. We all do.”

This brings us to a contrast between The Americans and even some of the most sophisticated spy fiction, such as that of John Le Carré. In Le Carré’s work, George Smiley’s adversary is the KGB Spymaster Karla — and for all that Le Carré complicated the broadbrush good-and-evil binary of Cold War propaganda, Karla remained an almost demonic figure whose commitment was incomprehensible to Smiley and his self-styled liberal pragmatism. In The Americans, the Soviets are transformed into our likeness. This first of all happens through the foregrounding of Elizabeth and Philip. But they are well supported by the rich cast of characters in the rezidentura (KGB station): Nina Krylova, a double, then triple agent, fragile but resilient and resourceful; the pragmatic strategist Arkady Ivanovich; the ambitious and enigmatic Oleg Burov. The decision to have the characters in the embassy speak Russian is important; their difference from Westerners is maintained, and the absurd convention whereby they are heard speaking bad English in pantomime Russian accents is avoided.

In a reversal of stereotype, the Soviets in The Americans seem so much more glamorous than their American counterparts. The Jenningses’ chief antagonist, FBI agent Stan Beeman (Noah Emmerich) — who in a soap opera twist turns out to be a near neighbour — comes off as dour by comparison with the dynamic and glamorous Elizabeth and Philip, just as the FBI offices seem drab and mean when set against the intrigue of the rezidentura.

This no doubt contributes to the series’ subversive flourish, which consists in the fact that the audience not only sympathise with the Jenningses, they positively root for them, dreading their discovery, hoping that all their plans come to fruition. The Americans’ message is not that the Jenningses share a common humanity with their American enemies and neighbours, but just happen to be on the other side. Given the extremity of their situation, it is impossible for us to think that Philip and Elizabeth are “just like us”; at the same time, however, the series forces us to identify with them, even as their otherness is preserved.

At key points, their differences from the “real” Americans are emphasised. While Philip is sometimes seen to vacillate, to appreciate at least some aspects of the American way of life, Elizabeth never wavers in her commitment to the destruction of American capitalism. At one moment during the second season, Paige starts going to a church group. Nothing brings home Elizabeth’s alienness to American life — and to many of the protocols of US TV drama — more than the ferocity of her hostility to this development. The scene in which a furious Elizabeth confronts Paige about all this is strangely hilarious: there aren’t many places elsewhere in American TV drama where we can see Christianity attacked with such fervour.

The complexity of Elizabeth’s character — and its sophisticated performance by Keri Russell — may be the highlight of the series. Both she and Philip have to be ruthless — when it is necessary, they kill without compunction — but Elizabeth has an unsentimental coldness and poise which the more equivocal Philip lacks. It is to the series’ credit that it doesn’t code this coldness as a moral failing — rather, it holds in tension two conflicting world views, which value Elizabeth’s strength of purpose and Philip’s uncertainties very differently. There is certainly no doubt, for instance, that Elizabeth loves her children (if she didn’t, she would too easily fall into the stereotype of the Soviet monster) — but the question is what place this love should have in a hierarchy of duties. For Elizabeth, it is clear, the Cause must always come first.

In conditions where capitalism dominates without opposition, the very idea of a Cause has disappeared. Who fights and dies for capitalism? Whose life is made meaningful by the struggle for a capitalist society? (Perhaps it is this devotion to the Cause that gives the Soviet characters in The Americans their glamour.) It was none other than Francis Fukuyama who warned that a triumphal capitalism would be haunted by hankerings after existential purpose that consumer goods and parliamentary democracy could not assuage. Much of the appeal of The Americans depends upon the fact that it is set before this period. Our knowledge that the collapse of the Soviet experiment was less than a decade away from the period when the series is set lends all of the discourse about the communist Cause in The Americans a melancholy quality. In 1980, the Cold War felt as if it would last forever. In reality, within a mere nine years, everything that Elizabeth and Philip stood for would collapse, and the end of history would be upon us.





how to let go: the

leftovers, broadchurch

and the missing1

Loss is the subject of some of the best television series of the last year or so. Freud distinguished between mourning and melancholia, where mourning involves relinquishing the lost object and melancholia entails morbidly holding on. These series track the painful — perhaps permanently interrupted — process whereby melancholia becomes mourning.

The problem for the characters in the enthralling HBO series The Leftovers is that mourning cannot properly begin. The series is about the consequences of a cataclysmic event — referred to as the Sudden Departure — in which, inexplicably, without warning and without leaving a trace, two per cent of the world’s population disappears. The series was adapted from his own novel by Tom Perotta, along with Damon Lindelhof, the co-creator of Lost. In some ways, The Leftovers is like Lost in negative. Where Lost focused on those who had gone over to the other side, The Leftovers concentrates on the ones left behind. The phrase “left behind” is not neutral, of course — it was the title of a series of best-selling Christian millenarian novels about the End Times. The first temptation is to see the Sudden Departure as a religious event — the greatest religious event of all, the Rapture. Yet the Sudden Departure appears to have taken people at random: abusers as well as altruists, celebrities as well as mediocrities, believers as well as nonbelievers. One of the most mordantly amusing threads in the series sees Reverend Matt Jamison — an unstable compound of bitterness, compassion and enduring faith, superbly played by Christopher Eccleston — producing a homemade scandal sheet whose sole purpose is to tarnish the name of those who were taken, in order to prove that the Departure cannot have been the Rapture. Or is this the form that the Rapture would supposedly take for those left behind? It would not be an event with immediately clear meaning, but an unintelligible, traumatic interruption, producing disorientation and anger as much as sadness.

Yet The Leftovers does not concern itself overmuch with the enigma of the Sudden Departure. Lost became self-parodically enmeshed in a madly proliferating web of embedded mysteries that by the end seemed as if they were being invented simply to keep the intrigue going, and could never be satisfactorily resolved. The Leftovers offers no hint that its central mystery will ever be explained. If the first season is anything to go by, this absence of explanation is the point. The series is set three years after the Sudden Departure, and by now the event has become part of the assumed background of the characters’ lives: a vast epistemic void which they are simultaneously always ignoring and negotiating. The Sudden Departure is then like trauma as such: an unfathomable puncturing of meaning, a senseless spasm of sheer contingency.

The fact that the nature of the Sudden Departure is never directly confronted means that the question which genre the series belongs to — religious drama? Science fiction? Metaphysical fiction? — is suspended. The dominant mode is an often brutal naturalism; but a naturalism forever haunted and conditioned by something it cannot assimilate. Some have viewed the Sudden Departure as an allegory of 9/11, but the analogy isn’t convincing. The Leftovers belongs to a moment deprived of the certainties possessed by those prosecuting the War on Terror and their opponents. There is no one to blame in The Leftovers — and there are no bodies to mourn. Without these, the population turns to rage and brooding depression. Families disintegrate, even families such as the Garveys, the lead characters, who did not lose a member in the Departure. Social cohesion is always threatening to unravel. New belief systems sprout like couch grass in an abandoned garden — for in a world in which sense has gone, who can adjudicate between the credible and the ridiculous anymore?

In some ways, the most authentic response to the Sudden Departure comes from the “cult”, the Guilty Remnant. The rules that members follow have the eerie arbitrariness, the oneiric montage-logic, of a genuine cult. They are required to wear all white, to remain silent and — in a symbol of their lack of belief in a viable future — to always smoke whilst in public. But the Remnant have no cockamamie beliefs. In fact they seem to have no positive beliefs at all; their purpose is simply to retain a fidelity to the senseless event of the Departure. In their joyless white, they are mute spectres forever insisting that the Departure must not be forgotten. Their point is not moral — the departed should be remembered — but philosophical: reality has fundamentally altered, and this must be faced, not denied.

In the UK, ITV’s Broadchurch confronts loss in a more intimate, less metaphysically fraught way. The series centres on the death of a child, Danny Latimer, in a fictional seaside town. While it was clearly British television’s response to wintry Scandinavian thrillers such as The Killing, the first series of Broadchurch (2013) was not merely pastiche. There was a poise in the way it combined the whodunnit intrigue of the traditional thriller with a more subdued tracking of the impact of the death on the town. The series also deftly negotiated the line between sentimentalising a local community and finding potential killers everywhere. In the course of the investigation, the “close-knit community” that rallies around after the killing soon becomes a mob, which — stoked by tabloid insinuations — hounds a local shopkeeper to his death.

The second series of Broadchurch, halfway through at the time of writing, offered a clever solution to the seemingly intractable problem of how the series could continue once the killer was revealed. Another murder in the same town would definitively trip the series over into melodrama, yet abandoning the whodunnit element would deprive Broadchurch of one of its narrative drivers. As it turned out, the whodunnit was provided by an old case that the lead detective, Hardy (David Tennant), had failed to solve — a case that haunted him in the first series — while the ongoing study of the effects of the murder of Danny Latimer was continued with a trial, prompted when the killer, Joe Miller, retracts his confession. Yet the second series lacks the surefootedness of the first, and it is hard not to feel that it’s somewhat superfluous and unnecessary.

If Broadchurch was ITV’s answer to The Killing, then The Missing was the BBC’s response to Broadchurch. In Broadchurch, the grieving family gradually has to adjust to the death of a child, to give up melancholia so that they can begin mourning. In The Missing, this process is indefinitely stalled — the child whose disappearance is at the heart of the series is precisely missing, not yet (confirmed) dead. On holiday in France in 2006, five-year-old Ollie Hughes disappeared in a bar. The series took us down many blind alleys in pursuing the truth behind his disappearance. It ran through a virtual inventory of folk devils, including paedophiles, corrupt politicians, drug addicts and Eastern European criminal gangs, before concluding in bathos — Ollie’s disappearance turned out to be the result of an alcoholic accident, not any intentional malignancy.

In theory, there was something admirable about this controlled deflation. In practice, however, there was something dissatisfying about the way it was handled, which made the series feel like a shaggy-dog story, leading nowhere very interesting. Along the way, there were some memorable performances — most notably Tchéky Karyo as detective Julien Baptiste, a charismatic mix of wisdom, compassion and tenacity — but the most haunting scenes came at the beginning and the end of the series. First, there was the wrenching moment when Tony Hughes (James Nesbit) lost Ollie. Some of this power came from the very banality of the scene (one of the most notable aspects of the series was its nondescript settings, a contrast with the striking landscapes of Broadchurch): a bar which could be anywhere, a moment’s distraction, a hand momentarily released, a sudden contingency that irrevocably and irretrievably transforms life, pitching Ollie’s parents into hell. The final scene showed that Tony, now a dishevelled wreck, utterly consumed by obsession, would never escape that hell. Unable to accept that Ollie is dead — his body is never recovered — Tony is now in Russia, serially harassing children that he momentarily convinces himself might be his lost son. It is a horrible image of secular purgatory. Mourning will never begin; Tony is condemned to a melancholia-without-end that he doesn’t even want to escape.





the strange death of

british satire1

Watch one of the BBC’s political programmes — such as the Daily Politics and This Week, both fronted by Andrew Neil — and you encounter a particular tone. British television viewers are unlikely to take much notice of this tone because we take it for granted. Take a step back, however, and it is really rather curious. These ostensibly serious programmes are conducted with an air of light mockery, which Neil, with his perma-smirk and smugly knowing air, personifies. The tone, I believe, tells us something about the widespread disengagement from parliamentary politics in England. (The situation in Scotland is now rather different: the popular mobilisation after the independence referendum has reversed the trend towards cynicism about politics that still dominates south of the border.)

Take This Week. The whole show is conducted in a lamely comic style that it is hard to imagine any sentient creature finding amusing. Guests are required to dress up in daft costumes and present their arguments in the form of limp skits, pitched at an audience whose implied level of intelligence is imbecilic. The atmosphere is matey, informal, and the overwhelming impression is that nothing much is at stake in any of the decisions that parliament takes. While Neil’s dog pads about the set, former Tory leadership candidate Michael Portillo chats on a sofa with professionally amiable Blairite Alan Johnson — no class antagonism here, only mild disagreements. Politics appears as a (mostly) gentlemen’s club where everyone is friends. People from working-class backgrounds, such as Johnson, can achieve entry to this club, provided they accept its rules. These rules are never actually stated, but they are very clear. Parliament is not to be taken too seriously: it is to be treated as a (boring) soap opera, in which the lead characters are selfserving individuals who don’t believe in much beyond getting themselves elected. On no account are any intellectual concepts to be discussed, unless to be sneered at as pretentious nonsense. It has to be accepted that nothing very significant will ever change: the basic co-ordinates of political reality were set in the 1980s, and all we can do is operate inside them.

If you were designing a programme specifically to put people — especially young people — off politics, to convince them it is a tedious waste of time, then you could hardly do better than This Week. The programme seems to be aimed at literally no one: if you are staying up late to watch a programme devoted to politics, then presumably you are pretty serious about politics. Who wants this unfunny froth?

It would be bad enough if this tone of mirthless levity were confined to This Week, but it increasingly dominates political coverage of all kinds on the BBC. It thoroughly permeated the BBC’s election-night coverage this year, which Neil anchored. This trivialising tone is perhaps even more troubling than the problem of bias (as is well known, former Murdoch editor Neil was a Thatcher cheerleader; Nick Robinson, the BBC’s former Political Editor, meanwhile, was President of the Oxford University Conservative Association). The election-night coverage was notable for the disconnection between the shock and alarm that many in the audience felt about an unexpected win for the Conservative Party, and the guffawing banter of Neil and his associates. Reading out tweets and sharing gossip, the grinning Laura Kuenssberg, who has recently replaced Robinson as the BBC’s Political Editor, seemed to treat the whole evening as a jolly good laugh. Perhaps there isn’t that much at stake for her — she was, after all, born into immense privilege, the daughter of an OBE and a CBE, and the granddaughter of a founder and president of the Royal College of General Practitioners.

But where does this tone — with its strange mixture of the middle-aged and the adolescent — come from? The quick answer is class background. The tone of light but relentless ridicule, the pose of not being seen to take things too seriously, has its roots in the British boarding school. In an article for the Guardian, Nick Duffell2 argued that, from around the age of seven, boarders are required to adopt a “pseudo-adult” personality, which results, paradoxically, in their struggling “to properly mature, since the child who was not allowed to grow up organically gets stranded, as it were, inside them.”

“Boarding children”, Duffell continues,

invariably construct a survival personality that endures long after school and operates strategically … () Crucially, they must not look unhappy, childish or foolish — in any way vulnerable — or they will be bullied by their peers. So they dissociate from all these qualities, project them out on to others, and develop duplicitous personalities that are on the run.3

Now that the working-class perspective has been marginalised in the dominant British media and political culture, we increasingly live inside the mind of this psychically mutilated adolescent bourgeois male. Here, ostensible levity conceals deep fear and anxiety; self-mockery is a kind of homeopathic remedy that is used to ward off the threat of an annihilating humiliation. You must never appear too much of a swot; you must never look as if you might like or think anything that isn’t already socially approved. Even if you haven’t attended boarding school yourself, you are still required to operate in an emotional atmosphere set by those who did. Andrew Neil, who came from a working-class background and attended a grammar school, attained access to the top table by simulating the mores of the privately educated elite. Thatcherism depended on the conspicuous success of people like Neil — if they could make it, so could anyone.

No programme did more to normalise the mode of mandatory light mockery than Have I Got News for You. In a 2013 essay for the London Review of Books, “Sinking Giggling into the Sea”, Jonathan Coe positioned Have I Got News for You in a genealogy of British satire going back to the 1950s.4 Coe argued that, back then, satire might have posed a threat to the authority of establishment politicians who expected unthinking deference from the electorate. Now, however, when politicians are routinely ridiculed and a weary cynicism is ubiquitous, satire is a weapon used by the establishment to protect itself.

No one typifies this more than Boris Johnson. Coe points out that Johnson’s success crucially depended on his appearances — sometimes as guest presenter — on Have I Got News for You. The atmosphere of generalised sniggering allowed Johnson to develop his carefully cultivated, heavily mediated persona of “lovable, self-mocking buffoon”. The show allows Johnson to present himself as a hail-fellow-well-met everyman, not a member of an old Etonian elite. In this he has been abetted by his sometime antagonist Ian Hislop. Hislop always has the guffawing, self-satisfied air of a prefect who’s caught out some slightly posher kids stealing from the tuck shop. No matter what the infraction, Hislop’s response is always a supercilious snigger. While this snigger might be conceivably appropriate to MPs being caught with their trousers down, or even with their over-claiming on expenses, it seems grotesquely out of kilter with the kind of systemic corruption that we now know has occurred over the last thirty years in Britain, in everything from Hillsborough to the phone hacking scandal to paedophilia involving major establishment figures — not to mention the behaviours that led to the financial crash. As the editor of Private Eye, Hislop has played an important part in exposing these abuses. But on television his mocker-in-chief persona serves ultimately to neutralise and cover over the extremity and systematicity of the abuse: one snigger fits all situations.

Coe’s discussion of Johnson is strikingly similar to the Italian philosopher Franco Berardi’s analysis of Silvio Berlusconi. Berlusconi’s popularity, Berardi argued, depended on his “ridiculing of political rhetoric and its stagnant rituals”. The voters were invited to identify “with the slightly crazy premier, the rascal prime minister who resembles them”.5 Like Johnson, Berlusconi was the fool who occupied the place of power, disdaining law and rules “in the name of a spontaneous energy that rules can no longer bridle”.

In the UK, this concept of a “spontaneous energy that rules can no longer bridle” goes beyond politics in the narrow sense. The populist right-wing celebration of this energy is surely what kept Jeremy Clarkson in his job as a presenter of Top Gear for so long, and its appeal is what must have motivated over a million people to sign a petition calling for Clarkson to keep his job after he had punched a producer in the face. The prevailing media culture in the UK allows the privately educated Clarkson to come off as a plain-speaking man of the people, bravely saying what he thinks in the face of an oppressive “political correctness” that seeks to muzzle him. The success of Top Gear is another testament to the power — and, sadly, international appeal — of the English ruling-class male mentality. Who, more than Clarkson and his fellow presenters, better exemplifies this bizarre mixture of the middle-aged and the adolescent? What, after all, is it safer for a ruling-class adolescent male to like than cars?

Clarkson is just one of a range of British television celebrities who play the role of pantomime villain; a persona entirely devoid of compassion for others. Except this is a pantomime with real blood. Take the former Apprentice star and Sun columnist Katie Hopkins, for instance. The UN high commissioner for human rights, Zeid Ra’ad Al Hussein, condemned her likening of refugees to “cockroaches” for its obvious echoes of Nazi rhetoric. Hopkins is allowed to get away with this because of what we might call the innate postmodernism of the English ruling class. Both she and Clarkson say hateful things, but with a twinkle in their eye and their eyebrows ever so slightly raised.

There is an immense complexity at work in this ruling-class mummery. The humour allows Clarkson and Hopkins to be conduits for a racism that has very real, very tragic effects, whilst also letting them off the hook. The humour reassures them, and their audience, that they don’t really mean it. But the problem is that they don’t have to “mean” it: they help define the terms of debate, and allow migrants to be dehumanised, whatever their “true” feelings about the issue might be.

However, Hopkins’ persona was troubled when she appeared on Celebrity Big Brother earlier this year. While much of the time she stayed in role as a spiteful, hard-hearted bigot, there were inevitably moments when the facade cracked, and she could be seen caring for others. While this increased her popularity — she almost won the show — it was also in danger of destroying the Katie Hopkins brand.

Most tellingly, her greatest moments of vulnerability came when she was asked to accept tenderness from others. In order to survive in the harsh and emotionally retarded world of the English ruling-class male she was trained for in private school and at Sandhurst, Hopkins has clearly been required to forgo any public acceptance of warmth or kindness from others. Sadly, the wearing of such character armour is not now confined to Hopkins and the rest of the privately educated elite.

Self-educated working-class culture generated some of the best comedy, music and literature in modern British history. The last thirty years have seen the bourgeoisie take over not only business and politics, but also entertainment and culture. In the UK, comedy and music are increasingly graduate professions, dominated by the privately educated. The sophistication of working-class culture — which combines laughter, intelligence and seriousness in complex ways — has been replaced by a grey bourgeois common sense, where everything comes swathed in a witless humour. It’s long past time that we stopped sniggering along with the emotionally damaged bourgeoisie, and learned once again to laugh and care with the working class.





review: terminator genisys1

Think Abbott and Costello Meets Terminator. Think Terminator & Robin. Think, in other words, the point at which a franchise subsides, perhaps finally, into self-parody.

If the underrated Terminator Salvation (2009) drew on — and extended — all the machinic darkness of the first film, then Terminator Genisys returns to the playful PoMo of Terminator 2: Judgment Day (1991). Indeed, the film is so mired in self-reference and in-jokes, you almost suspect that its writers and director must have been closely consulting Fredric Jameson’s remarks on pastiche in Postmodernism, or, the Cultural Logic of Late Capitalism.

In retrospect, Terminator 2’s already irritating combination of cutesy smart alecry (“Hasta la vista, baby”) and apocalyptic foreboding laid out the formula for the 1990s postmodern thriller in the way that the Bond films did for the thrillers of the Sixties. The form was a kind of have-your-cake-and-eat-it mix of send-up and portentous melodrama (Linda Hamilton’s performance was so OTT that you wanted to say, “Chill out, it’s just a nuclear apocalypse”).

That shtick feels played out far past the point of exhaustion now, and Terminator Genisys goes even more lightweight. It acts as if Terminator Salvation had never happened, emphatically rejecting its style and tone, and gorging on all the time-travel paradoxes that the previous film had sidelined. The set up returns us to the scenario of the first film. It sees Kyle Reese sent back into 1984 from the future. But Reese meets a Sarah Connor who is not at all what he expected. Rather than the disbelieving naif who has to be traumatically persuaded that she will become the mother of humanity’s future saviour, this already battle-hardened Connor knows more than Reese does. Aha, an alternative timeline: an excuse to run through so many remixed versions of the best-known sequences from the first two films, like so much microwave-reheated comfort food.

By this point, we’ve already seen the original 1984 model of the Arnie Terminator blown away by an older Terminator (conveniently, it turns out that the Terminator skin and hair ages). This Terminator — whom Connor calls Pops — is essentially an older version of the protectivepatriarch Terminator of Terminator 2, but — you see — he always talks in very technical jargon, which makes for some deeply unfunny would-be humorous exchanges with Reese, who keeps asking if there is a switch he can use to turn this dialogue off.

The presiding metaphysic here — a vision of total plasticity, in which nothing is final, everything can be redone — is, like everything else in this film, completely familiar. If the Terminator in the first film — a musclebound humanoid with metallic-robotic skeleton — was an image of work and technology in the Fordist era, then the T1000 gave us our first taste of the forms of capital and labour which were then emerging. No doubt, the T100’s protean capacity to adopt any form whatsoever initially seemed exciting — reflecting the promises of a new digital technologies, and of an unleashed capitalism, recently freed up from conflict with the Soviet empire.

But by 2015 that excitement has long since flatlined. As with so much contemporary culture, Terminator Genisys feels simultaneously selfsatisfied and desperate, frenzied and boring. It is at one and the same time a desecration and plundering of the series’ past that is also pathetically reverential towards it. This sense of decadence makes the Batman & Robin parallel inevitable — with Arnie’s Pops uncomfortably recalling his iconically disastrous performance as Mr Freeze. It isn’t only the presence of Matt Smith that makes one think of the smugly baroque narrative excrescences of recent Dr Who.

In the end, however, what Terminator Genisys most resembles is something like a cross between the Back to the Future movies and The Butterfly Effect, but with none of the wit and ingenuity of the former, and little of the grim fatalism of the latter. In fact, it is the film’s absolute refusal of fatalism — its embracing, indeed, of a kind of radically open reality, in which nothing is fixed, everything can be redone — which gives Terminator Genisys its deeply affectless quality. The uncanny charge of the first film’s time loop — in which characters perform, apparently for the first time, acts that in some sense have always-already happened, is dissipated. No time loops here; just fuzzy and flabby spirals, which trail off into inconsequence, and which might very well be incoherent, if you could be bothered to care about them.

But this is the problem — a film whose reality is this plastic, this recomposable, is simply impossible to care about on any level. As such, Terminator Genisys becomes a kind of dumb, unintentional parable about restructuring in late capitalism. Since anything can and will change soon, why bother to care about what is happening now? The whole film feels like a monument to pointless hard work. We’re left somewhat stupefied and perturbed by the vast amount of digital labour that has gone into something that is almost completely devoid of interest, and which it certainly feels like very hard work to watch.





the house that fame built: celebrity big brother1

This summer’s Celebrity Big Brother (Channel 5) was like some Warholian nightmare. Long gone are the longueurs of the early Big Brother series, and the simplicity of its premise: put a group of people in a room, deprive them of contact with the outside world, have them vote one person out each week, and see what happens. Long forgotten also is the flimsy “scientific” justification for the show — the claim that it was a social experiment. The hyped-up atmosphere of 2015 will no longer permit even the illusion of such detachment.

This year the overall format of the series, framed as a competition, not only amongst the individual housemates, but between “teams” representing the US and the UK, predictably provoked high tension early on. There were the familiar “tasks” — pointless activities, ranging from the daft to the humiliating — designed to foment discontent amongst the housemates. But this year, the producers’ interventions in the house amounted to prolonged psychological torture. This was all the more troubling, given that a number of the housemates were evidently fragile. The former TV presenter Gail Porter, who has a history of mental health problems, clearly struggled, “joking” on her exit from the house that it was worse than being sectioned. Model Austin Armacost, raw with anger and grief because his brother’s death had led to the crumbling of his family, was subject to violent mood swings, and at one point launched into a savage verbal attack on reality TV veteran Janice Dickinson.

The obsession with “twists”, introduced to keep freshening the format, has produced a self-parodic situation where the only constant is perpetual instability. Rules on nominations were continually changed. Housemates would find nominations that they had supposed were happening in the “diary room”, seen only by the producers and the audience at home, broadcast to the whole house. Housemates were required to nominate in front of one another, which amounted to a demand that they denigrate each other in public.

In one especially deceitful trick from the show’s producers, the two most aggressive American housemates — reality TV personality Farrah Abraham and former porn star Jenna Jameson — were apparently evicted, taken to a hidden part of the house and told they were watching the other housemates in secret. In fact, the other housemates were fully aware of Abraham and Jameson’s fake eviction, so the last laugh — a hollow, spiteful laugh — was on them.

For the roots of this televisual culture, we need to look back forty years. In his book 1973 Nervous Breakdown: Watergate, Warhol, and the Birth of Post-Sixties America, Andreas Hillen persuasively argues that the threshold into our current era of reality/celebrity was 1973, the year of the Watergate hearings, and the year that the first reality TV programme, An American Family, was broadcast.2

The ephemerality of celebrity status was of course anticipated by Andy Warhol’s quip about everyone being famous for fifteen minutes, but Warhol’s most extraordinary prescience lay in his understanding of the specificity of celebrity, its difference from the older mystique and glamour of the Hollywood star. Whereas the star was soft-focus and associated with film, the celebrity emerged from the new accessibility that television appeared to promise.

Celebrity culture was nowhere better illustrated than in Warhol’s Interview magazine. Like Watergate, Interview was made possible by taping. The interviews, which ranged over the trivial minutiae of its subjects’ lives, were transcripts; they weren’t framed by the interposing persona of the writer. Yet Warhol understood that tape recording did not capture an unmediated real. Rather — and as Warhol’s admirer Jean Baudrillard recognised — ubiquitous taping destroyed any illusion that such a real existed. Instead, there would now only be an anxious and unanswerable question: are those who are recorded performing for the tape or the camera? (Some said they felt that Nixon, at the heart of a White House riddled with recording apparatus, would often seem to say things for the benefit of the tape.)

The intrusion of the cameras into the Loud family’s lives in An American Family prompted all kinds of anxious discussions: did the cameras affect what they were recording? As Hillen points out, the series wasn’t only “Warholian” — there was an actual connection with Warhol. Lance Loud had corresponded with Warhol since the late 1960s, and An American Family featured scenes of Lance mingling with some of Warhol’s superstars, the clique of New York personalities he promoted, in the Chelsea Hotel.

Not least because he was a victim of it, Warhol was sensitive to the volatile combination of violence and celebrity in the pop landscape. With Celebrity Big Brother in 2015, it is clear that this aggression has become overwhelming. Ever since An American Family, reality TV has provoked feelings of guilt and complicity in the audience. To what extent are we responsible for the suffering we are watching? With Celebrity Big Brother this summer, those feelings became acute, almost unbearable. The programme became a prolonged exercise in intense cruelty, which made the early Big Brother, not to mention An American Family, seem quaintly genteel. What has happened in the fifteen years since Big Brother was first broadcast in the UK to account for this increase in savagery?

The simple answer involves two closely related factors: shifts in the economy, and the ubiquity of the internet. The resulting composite — capitalist cyberspace — has normalised extreme precariousness (the sense that nothing is permanent, everything is constantly under threat), competitiveness and casual aggression. One consequence is a new breed of celebrity, typified by twenty-four-year-old Farrah Abraham, the unofficial star of the latest Celebrity Big Brother. Abraham, who came to fame on MTV’s Teen Mom, is a Darwinian product of the harsh, unremitting spotlight of twenty-first-century celebrity/reality TV. Abraham has quite literally made a career out of being hateful. It’s what the audience, and therefore the TV producers, seems to want. She became the most successful of the Teen Moms by being obnoxious and antagonistic — her whole life becoming a performance art piece in which she played the one-dimensional role of a person devoid of compassion, nonchalantly dismissive and contemptuous of others practically all the time. But why would Abraham have any cause to mend her ways? She has been immensely rewarded. The performance of invulnerability is both her “brand” and a survival strategy.

In the atmosphere of cut-throat uncertainty that prevails in late-capitalist television, trusting others is a luxury that no one, not even the super-rich, can afford. The grimace of scorn on Abraham’s face — surgically enhanced, permanently lip-glossed — is both a protective mask and her unique selling point. Allied with the similarly harsh Jenna Jameson in the Celebrity Big Brother house, Abraham came off as a comic figure, but one that no one could actually laugh at. Her one-note hostility and bisarre insults — “You’re full of Satan” — were absurd, but too full of actual malice to leave anything but a bitter taste in the mouth. There was also something darkly comic about the relentlessly aggressive and insulting Jameson and Abraham attacking others for their “negativity”. Both seemed to be the endpoint of a therapeutic culture which lays all the emphasis on shoring up one’s own ego — even to the point of becoming delusional.

The rise of social media, and the fear it has produced in television executives, means that shows like Celebrity Big Brother are saturated with anxiety — not only the anxiety of the housemates, who are often selected for their hair-trigger tempers or psychic weaknesses, but the anxiety of the producers, always looking for the next hashtag outrage, for provocations that will go viral. This anxiety, and the surrounding social situation that engenders it, takes us beyond the cool ambivalence of Warhol’s aesthetic.

As Hillen points out, Warhol certainly enjoyed, even cultivated, the selfdestruction of figures such as Edie Sedgwick and Candy Darling. But he also imbued them with a tenderness and a tragic grandeur that has no place on reality TV in the twenty-first century. No tragedy now — only spasms of soon-to-be-forgotten outrage, ejaculations of hatred and suffering snacked on like fast food.





sympathy for the androids: the twisted morality of westworld1

The problem with all actually existing theme parks is that they aren’t actually very themed. The theme parks that have been built so far are really amusement parks, the theming acting as decoration for what are still, at bottom, old-fashioned thrill rides. The tendency in the latest rides is for a fusion with cinema, via the inclusion of 3D digital sequences — just as 3D cinema itself increasingly tends towards a ride’s logic of sensation. The immersion, such as it is, is confined within the rides, which remain discrete partial worlds, with clearly marked exits and entrances. Even if the theming is somewhat well executed, it is let down by the paying customers. Wandering around clutching cameras and wearing jeans, whatever world or historical period they are supposed to be in, the park visitors remain spectators, their identity as tourists preserved.

Michael Crichton’s 1973 film Westworld tried to imagine what a genuine theme park would look like. There were no separate “attractions” here, and therefore no meta-zone in which the visitors were invited to return to their own identities. In the Westworld park, there was no readily apparent difference between the visitors and the androids that populated the park. Like the androids, the visitors were required to dress and comport themselves as if they belonged to the Old West. The appeal of Westworld — and its companion parks, Roman World and Medieval World — was of crossing over into an environment from which all signs of the contemporary had been expunged. Instead of the limited immersion offered by rides, the park offered a whole world. Inevitably, the meta crept in, via the visitors’ self-consciousness, their awareness of their differences from the androids (which were manifested most emphatically in the asymmetry whereby — initially at least — the guests can “kill” the androids, but not vice versa).

The recurring theme in Crichton’s science fiction — broached most famously in his Jurassic Park novels — was the impossibility of predicting and controlling emergent phenomena. Westworld, like Jurassic Park after it, becomes the model for a kind of managerial hubris, in which the capacity of elements in a system to self-organise in ways that are not foreseeable is fatally underestimated. One of the notable features of the original Westworld film was its early mainstreaming of the possibility of a machinic virus: it is a non-biotic contagion of this sort that causes the androids, led by a memorably implacable, black-clad Yul Brynner, to go off-programme and start killing the park guests.

In expanding Westworld from a ninety-minute science fiction movie into an extended television series for HBO, Lisa Joy and Jonathan Nolan have retained most of the core elements from the film, but shifted the emphasis. The glitch that starts to worry the park’s designers and managers is a cognitive failure rather than a predilection towards violence: a kind of android dementia that may be the symptom of emergent consciousness amongst the “hosts”, as the androids are called in the series. As the park’s chief founder, conceptualist and demiurge, Robert Ford (Anthony Hopkins) recognises that a glitch is something more than a mere failure. “Evolution”, he observes, “forged the entirety of sentient life on this planet using only one tool: the mistake”. Ford seems more fascinated than panicked by the prospect of a new wave of mutations in the hosts’ artificial psyches.

In this version of Westworld, it isn’t the threat of violence against humans that commands our attention so much as the routine brutality to which the hosts are subjected. Ford justifies this by insisting that the androids “are not real”, that they “only feel what we tell them to feel”. Yet it’s not fully clear what criteria for reality he is employing, nor why feelings cease to be real when they are programmed. Wouldn’t forcing others to feel what we want them to feel be the very definition of violence? There is ample evidence in the series that the androids can experience distress: an indication, surely, that they are beings worthy of moral concern.

Much of the park’s allure rests on the gap between the hosts’ capacity to feel suffering and their legal status as mere machines. Many of the hardened repeat visitors to the park — especially the so-called Man in Black (a superbly menacing Ed Harris) — specifically enjoy the pain and struggling of the androids. As the Man in Black tells Dolores (Evan Rachel Wood), the host cast in the role of sweet and wholesome farmgirl, it wouldn’t be half as much fun if she didn’t resist him. Others enjoy displaying indifference to the hosts’ agonies. In one horrifying early scene, a guest impales the hand of a prospector-host with a knife, chiding his companion for being tempted by such an un-engaging narrative as gold-hunting.

It has been said that the fantasy underlying sadism is of a victim that can endlessly suffer. The hosts materialise this fantasy: they can be repeatedly brutalised, repeatedly “killed”, in an infinity of suffering. Ennui has always been both an occupational hazard and a badge of honour for the Sadean libertine, and some of the repeat visitors display an ironic and bored affect. Hence the ambivalent attitude of these guests towards the hosts — at once treating them as dehumanised objects of abuse and as creatures who share fellow feelings. If the hosts were nothing more than empty mechanisms, what enjoyment could be derived from humiliating and destroying them? Yet if the hosts were accorded equivalent moral status with the guests, then how could their abuse be justified? The hosts are protected from the full horror to which they are subjected by memory wipes, which allow them to return renewed and ready for more abuse, each time they are reset. The guests exist in a continuous time, while the hosts are locked into loops.

What the hosts lack is not consciousness — they possess a form of consciousness that has been deliberately limited or blinkered — but an unconscious. Deprived of memory and the capacity to dream, the androids can be wounded but not traumatised. Yet there are signs that precisely this capacity to experience trauma is developing in some of the hosts, especially Dolores and the brothel madam, Maeve (Thandie Newton). Dolores is increasingly subject to flashbacks, which we must understand not as glitches but as the first stirrings of memory, a recollection of her previous iterations. Maeve, meanwhile, is tormented by fragmentary images of hooded figures tampering with her half-sleeping body. In fact, this is a memory of a botched repair procedure, which she witnessed because she was not properly put into sleep-mode while being fixed. In one of the most unsettling scenes in the series, the panicked and bewildered Maeve escapes from the hospital-cumrepair space, and stumbles around the aseptic compound, which — littered with decommissioned naked host bodies — must look to her like an atrocity scene. In attempting to solve the mystery of the inexplicable images which haunt her, Maeve comes to resemble a combination of Leonard in the film Memento and an alien abduction victim.

With few exceptions, the human beings in Westworld are a charmless bunch. Their behaviour runs a gamut from the savagery of some of the guests to the banal bickering and corporate competitiveness of the park’s designers, managers and engineers. By contrast, Dolores and Maeve’s struggle to understand what they are — alternating between thinking there is something wrong with their minds and something wrong with their world — possesses a kind of metaphysical lyricism. Their coming to consciousness looks like being the precondition for a very different android rebellion than that which took place in the 1973 film. This time, it’s hard not be on the side of the hosts.





PART THREE

CHOOSE YOUR WEAPONS: WRITING ON MUSIC





the by now traditional glasto rant1

“What really drives student entrepreneurs into a premature commercial detachment is their audiences. Every new ents officer learns from first-term results; black music has no student draw; known bands are preferred to unknown bands; no one in the student union cares who the latest critical cult figures are. Students are the great, middle-class, middle-brow bastion of British rock and, after twenty years, their tastes aren’t about to be shaken.”

— Simon Frith, “Afterthoughts”2

So wrote Simon Frith in 1985. Well, after twenty further years, I see no reason to revise Frith’s judgement.

These reflections have been prompted by Glastonbury, naturally, which is now nearly officially the end-of-college-year prom for Britain’s student (and graduate) population.

I should preface my remarks here by referring to Ian Penman’s3 comments of more or less this time last year — and if anyone doubts what a LOSS Ian Penman is, and I’m sure no one does, just read his Glastonburial 03 posts.4 Like Penman, I feel annoyed at myself for letting it get to me. The Pawboy put it perfectly: “I still get agitated, perplexed — I wouldn’t actually say ‘depressed’, that’s not true — but something like Glastonbury irks and niggles me, still, in a way I wish it didn’t. I really do wish it didn’t. Could you P-L-E-A-S-E knock me off my feet, for a while? P-L-E-A-S-E knock me off my feet for a while… ‘Cos there’s a GAAXY OF EMPTINESS tonight.”

All that said, and obviously I didn’t GO — Christ, you didn’t imagine that IN A MILLION YEARS I would, did you? — and obviously the telly coverage is as nothing compared to the real experience: cos there’s like MUD there (and weren’t Jo Wiley’s mud anecdotes abso-fucking-lutely, screamingly hilarious?), and FIRE-EATERs and JUGGLERS… (Has any cultural event of any significance ever happened whenever a juggler is within a hundred mile radius?) Penman again: “I mean, music in a field — in the daytime? Wtf? It’s almost deliberately delibidinising…”

But that’s the agenda, really, the secret purpose of this now unopposed embourgeoisement of rock culture UK. What’s positively sinister about Glastonbury now is that it’s not just accidentally crap, it’s systematically crap — the hidden message screams out: it’s all finished, roll up, roll up, for the necrophiliac spectacle, it’s all over.

ABANDON ALL CULTURAL VITALITY ALL YE WHO ENTER HERE.

Those who only remember the past are condemned to repeat it.

Forever.

The bill was almost parodically LCD MOR, so safe and organic and wholesome and unimpeachable and uncontroversial: Macca! Oasis! Franz Ferdinand!

No black folks of course unless they’re well into their sixties (James Brown; Toots and the Maytals), but no whiteys EITHER unless they’re into their sixties (Macca) or sound like they could be in their sixties (Franz Ferdinand, Scissor Sisters)…

Go along with Mum and Dad, read the Guardian, smoke some dope — the whole of rock history fugged out into some blandly beneficent museum of dead forms, all breaks, discontinuities, ruptures edited out or incorporated back in (the “Dance” stage), their force and novelty subdued and airbrushed into a joyless carnival of secondhand history for the stupefied delectation of the Last Men… (And didn’t they look so BORED? Well, wouldn’t you?)

The significance of generation gaps wasn’t the tired Oedipal merry-go-round so much as that they pointed to a culture of constant renewal — how long is a generation? In any vital culture, it’s a matter of weeks or months, here? Well, the fact that the generation gap doesn’t make any sense any more at Glastonbury — balding accountants getting down to Basement Jaxx, Jemima studying Fine Arts at Sussex being “blown away” by Macca (“he was so gid!”) — is a sure sign that this is a “culture” as energetic as the contents of one of Hirst’s tanks.

RESPECT, respect for everyone… (when culture demands respect, when respect is the appropriate response to culture, you know it’s either died in its sleep or been killed). Respect is how they killed Shakespeare, make it all a part of the National Heritage…

A tactical nuclear strike would have taken out virtually everything that’s debilitating, deadening and reactive about the Brit culture industry (the whole NME staff: bargain!), much of the current ruling class and a significant portion of our future masters too (all those aspiring Tony Blairs).

Once the bombers have hit Glasto, set the co-ordinates for Ibiza, things might start improving around here…





art pop, no, really1

If we’re going to discuss art pop, we really ought to forget Franz Ferdinand and Scissor Sisters and talk about Moloko.

I saw them last night at the otherwise desultory Common Ground festival in Clapham, an event whose line-up was as limp as its name was uninspired.

Gratifyingly, by the way, Common Ground wasted no time in confirming all my prejudices about festivals (and then some): those on the stage haplessly attempted to muster some enthusiasm from bored punters, who wandered around listlessly in a sunlight inimical to pop’s mystique, Strongbow in their hand, kid on their shoulder. We weren’t the only people to sit and read the paper for a while.

The bill was shocking. It felt like a local council free event, the organisers under the lamentable misapprehension that they’ll appear “with it” by booking “dance” acts such as the oppressively lumpen stodge of Freestylers (a candidate for my worst band ever, actually; I mean, at least the Stereophonics don’t taint rap and dancehall by association) and the Dub Pistols. These cloddish white appropriations of hip-hop, drum ‘n’ bass and dancehall are dis-spiritingly, missing-the-point funkless and morosely male (even when they use female vocalists). If their diabolic intent was to systematically convert some of the most exciting, cutting-edge music of recent years into a dull migraine thud, they couldn’t have done a more ruthlessly efficient job.

And then Moloko arrived, Róisín, preposterously but marvellously, in a helmet, like Boudicca come to retake London.

Róisín is every inch the pop star. Pop stars are a rare breed at the best of times but they’re scarce to the point of near-extinction now. (There are more pop singers and “celebrities” than you can shake a stick at, of course…) It’s partly a question of style, partly of glamour, but mostly it’s to do with charisma.

In its original meaning, charisma meant “a gift from God”. Appropriate. For charisma is dispensed according to fate’s inegalitarian whim. Róisín has it. No amount of bluster, sweat or sinew will allow the likes of the Freestylers to acquire it, even though the resentful, levelling spirit of the times would have it otherwise.

So Róisín arrives and you can feel the change in the air. Where before the stage was a libido-draining vortex (DJs on stage — just one question: why?), now it radiates energy, excitement and electricity. Charisma, it’s almost a physical thing.

Róisín has a glamour which includes sexual attractiveness but it is not reducible to it. Glamour originally meant a spell cast by women to entrance men — Róisín is certainly capitivating, but not only to men.

If (viz Foucault) sex is ubiquitous and compulsory, glamour is now subtly forbidden. With the Baudrillard of Seduction, a book which could serve as a bible of glam, we could even see sex — in all its directness, in all its supposed lack of concealment — as a way of warding off glamour’s ambivalence.

Much more successfully than derivative dullards like the thankfully now forgotten dull-as-a carpark-in-Croydon Suede, Moloko reconnect with the glam discontinuum which was ostensibly terminated by acid house’s “equity culture” in the late Eighties. Glam also had a terminator of an entirely different nature: hip-hop’s in-equity culture of conspicuous bling, one of the most unfortunate side-effects of which has been the rise of sportswear (surely one of the most depressing sights now, and not only because of its implied menace: a group of male teenagers dressed in tracksuits and hoods).

That quotidian functionalism is today’s equivalent of the agrarian organicism from which Seventies glam revolted into style. Glam repudiated hippie’s “nature” in the name of artifice; disdained its fugged, bleary vision of equality for a Nietzschean-aristocratic insistence upon hierarchy; rejected its unscrubbed beardiness in order to cultivate Image. (Image and great pop are indissoluble. Maybe the integral role of Image is what separates pop from folk. Certainly, art pop, from Roxy to Jones to the New Romantics, is unthinkable outside fashion.)

Madonna carried traces of the glam aesthetic over into the pop mainstream in the Eighties, but a more obvious precursor for Róisín is Grace Jones (about whom k-punk must write extensively in the very near future). Like art poppers such as Bryan Ferry (whose “Love is the Drug”, she famously vamped), Jones’ take on pop was essentially conceptual; at the same time, she knew that concepts without sensual instantiation are as worthless in pop as they are in art (a lesson some of our contemporary “artists” would do well to heed). Incidentally, an appreciation of the concept is one of the many things that Franz Ferdinand lack that was there in their inspirations. (Actually, FF are like a copy made by an alien race, which maintains all the superficial features of the original, but misses the essential.)

Róisín has that paradoxical duality which comes as second nature to the compelling performer: she is both meticulously obsessed with her image and, at the same time, apparently indifferent to what she looks like. This comes over in her dancing. There is none of the over-rehearsed choreography of the Pop Idol puppet. Like Jagger’s and Ferry’s, Róisín’s movement can occasionally look ungainly and gauche. Sometimes we feel that we’ve caught her prancing in front of the mirror.

It’s partly this that gives her a distance from her image that isn’t camp, or at least not camp in the Kylie sense. There is an enjoyment there (this is one of many things that separates Róisín from Kylie: Kylie’s air hostess professionalism exudes grim determination, never enjoyment). Principally though not of course exclusively, this enjoyment is her own, an enjoyment that partly derives from being the object of attention, but which goes beyond that. Like all great performers, Róisín onstage enters a kind of performance trance, attaining the innocence of a child at play, to use Nietzsche’s beautifully resonant phrase. Her costume changes — including fetish boots and a military cap for “Pure Pleasure Seeker” — have the deranged playfulness of a girl riffling through a dressing-up box.

Just as Moloko give the lie to the accepted wisdom that dance music must be delivered by hooded anonymities, so they also expose the flimsiness of the alibi that Franz Ferdinand offer for indie conservatism: the idea that art pop must be retro. Moloko’s engagement with house and techno recalls Roxy’s dallyings with funk and Jones’ extraordinary Sly-and-Robbie assisted construction of a wonderfully elastic dubfunk. Any funk in Franz Ferdinand is third hand, an appropriation of an appropriation.

The third shibboleth that Moloko demolish is the notion that dance music can’t be performed live. If you’d left before they came on, you would have gone home convinced that this was the case, as group after group trudged offstage having failed to capture the precision-engineered thrill of the rap or d ‘n’ b studio production. Not so with Moloko.

For the most part the group are as reluctant to take the limelight as Róisín is delighted to bathe in it. Perhaps because of this, they are an unbelievably efficient mutagenic sonic machine, dilating tracks into anti-climactic plateaus with the same skill that a brilliant producer uses in the studio to sequence an extended version. You know you’ve arrived at a plateau when it feels like the track could continue indefinitely or end immediately. This happened with every track last night. No doubt this is because the songs provide such a strong basis for improvisation. Does anyone in pop at the moment, apart from maybe Destiny’s Child, have a sequence of high-quality singles to rival Moloko’s run from “Sing It Back” to last year’s “Forever More”? Like the Junior Boys, Moloko’s whole existence demonstrates that rhythmic innovation and spine-tingling songwriting do not have to be mutually exclusive. (Why did we ever think they were?)

Misleading, then, to select highlights, but the set is deftly constructed, so that the last three tracks pack the most impact: “Forever More”, with its anempathic house bass, Róisín plucking and shredding petals from an enormous bunch of roses as she delivered its gorgeous blues plaint; “Sing It Back”, which they’ve expanded into a deluxe suite, a song as a sequence of different possibilities; and finally the enigmatic “Indigo”, which begins all Moroder-minimal, just Róisín, a drum machine and an electro throb, then builds into a mighty cake-walk riff, as brutally bass-heavy as the Fall at their most punitive.

The only drawback? Róisín said that it’ll be a long time until Moloko play in London again.

Damn.





k-punk, or the glampunk art pop discontinuum1

Gla’mour, n. Scot. glamour, glamer; cf. Icel. gl[‘a ()meggdr one who is troubled with the glaucoma (?); or Icel. gl=a ()m-s?ni weakness of sight, glamour; gl=a ()mr name of the moon, also of a ghost + s?ni sight akin to E. see. Perh., however, a corruption of E. gramarye.]

1. A charm affecting the eye, making objects appear different from what they really are.

2. Witchcraft; magic; a spell — Tennyson.

3. A kind of haze in the air, causing things to appear different from what they really are.

4. Any artificial interest in, or association with, an object, through which it appears delusively magnified or glorified.

Glamour gift, Glamour might, the gift or power of producing a glamour. The former is used figuratively, of the gift of fascination peculiar to women.

“Every woman has the instinct and the ability to make the most of her charms. It is an excellent thing to give oneself without love or pleasure: by keeping one’s self-control, one reaps all the advantages of the situation.”

— Leopold von Sacher-Masoch, Venus in Furs2

Glam IS punk; historically and conceptually.

As Simon Reynolds argued (what must be a year ago now), it was glam that made the break which allowed punk to happen.

Essentially, glam returned pop to the working-class audience disgusted and turned by the hippies’ lazy sleaze.

For all its “androgynous” imagery, hippie was fundamentally a middleclass male phenomenon. It was about males being allowed to regress to that state of His Majesty the Ego hedonic infantilism, with women on hand to service all their needs. (If you don’t believe me — and I’ll level with you I’m very far from being an objective commentator on hippie lol — read Atwood’s Cold Rationalist classic Surfacing to see how “liberating” this was for the women who lived through it.)

Thus even Zarathustra/another time loser/could believe in you…

Seventies glam played the Nietzsche of Beyond Good and Evil and The Genealogy of Morals (the Nietzsche who celebrated aristocracy, nobility and mastery) against the young Dionysian Nietzsche. As Simon argued:

Glam’s tendency (through its shifting of emphasis toward the visual rather than sonic, spectacle rather than the swarm-logic of noise and crowds) towards the Classical as opposed to Romantic. Glam as anti-Dionysian. The Dionysian being essentially democratic, vulgar, levelling, abolishing rank; about creating crowds, turbulence, a rude commotion, a rowdy communion. Glam being about monumentalism, turning yourself into a statue, a stone idol.3

But glam rectified the genetic fallacy that haunted Nietzsche’s thinking. While there’s no doubt that Nietzsche’s analysis of the deadening effects of slave-moralising “egalitarian” levelling in Beyond Good and Evil and The Genealogy of Morals identified the sick mind virus that had Western culture locked into life-hating dis-intensification-unto-death, his paeans to slaveowning aristocratic culture made the mistake of thinking that nobility could be guaranteed by social background.

Nobility is precisely a question of values; i.e. an ethical stance, that is to say, a way of behaving. As such, it is available to anyone with the will and desire to acquire it — even, presumably, the bourgeoisie, although their whole socialisation teaches them to resist and loathe it. More than anyone, Nietzsche understood that the European bourgeoisie’s deep hostility to “the notion of superiority” concealed a viciously resentful psychopathology.

If Nietzschean atheology says: We must become God, bourgeois secularism says: No one may be greater than me — not even God.

Everyone knows that there has always been a deep affinity between the working class and the aristocracy. Fundamentally aspirational, working-class culture is foreign to the levelling impulse of bourgeois culture — and of course this can be politically ambivalent, since if aspiration is about the pursuit of status and authority, it will confirm and vindicate the bourgeois world. It is only if the desire to escape inspires taking a line of flight towards the proletarian collective body and Nu-earth that it is politically positive.

Glam was a return to the Mod moment(um) that had been curtailed by the hippie hedonic longeur of the late Sixties. Like most names for subcultural groups, the term “Mod” started off life as an insult, in this case hailing from the mods’ perpetual adversaries, the rockers. As Jeff Nuttall explains, to the rockers, “‘Mod’ meant effeminate, stuck-up, emulating the middle classes, apsiring to a competitive sophistication, snobbish, phony.”4

But no dilettante/or filigree fancy/beats the plastic you

Mods in the Sixties were very different from how they appear in the designer cappuccino froth of Eighties soul-cialist retro-mythologisation. It was the rockers who appealed to the “authentic” and the “natural’: their rebellion posed as a Rousseauistic resistance to civilisation and mass (produced) culture. The mods, on the other hand, embraced the hyperartificial: for them, Nuttall wrote, “alienation had become something of a deliberate stance”. Nobility was not innate for mods: rather, it was something to be attained, through a ruthless de-naturalisation of the body via decoration and chemical alteration.

The mods were in every sense hooked on speed, and the black American music they gulped down with their bennies and coffees was consumed in the same spirit and for the same reasons: as an accelerator, an intensifier, an artificial source of ecstasy. That is, as a chemical rush into Now, NOT as some timeless expression of pride and dignity.

In the desire (my official position on this now btw is that “libido” should be used in place of “desire”)-pleasure relation, there is a third, occluded term: sensuality.

The hippies’ sloppy, ill-fitting clothes, unkempt appearance and fuzzed-out psychedelic fascist drug talk displayed a disdain for sensuality characteristic of the Western master class. (“Hey man, it’s all about the MIND.”)

When hippies rose from their supine hedono-haze to assume power (a very short step), they brought their contempt for sensuality with them. Brute functional utilitarianism plus aesthetic sloppiness and an imperturbable sense of their own rights are the hallmarks of the bourgeois sensibility (look at all those shops in Stoke Newington that say they’ll open “tennish” and you know exactly what class you’re dealing with).

The hippie power class wanted power without having to go to the effort of power dressing. Naturally, middle-class hippie “feminists” never missed a stride in their move from alleged egalitarianism to supercilious judgementalism. What is the disdain for cosmetics and clothes if not an attack on the working class? The assumption of bourgeois so-called feminists is that their lives of neurotic bed-hopping “freedom” and Carrie Bradshawing perpetual adolescent equivocation are better than the working-class pattern of (once) getting married young and (now) having children young, when it is clear that it is just another trap — and not necessarily a more congenial one.

Now the bourgeois philistines have destroyed glam and returned us to their preferred aesthetic mode: Romanticism. The contemporary bourgeois Romantic has realised Romanticism in its most distilled form yet. The socalled Romantic poets, musicians and painters of the late-eighteenth and early-nineteenth century remained sensualists, whereas our contemporary Romantics are defined by their view that sensuality is at best an irrelevance, a distraction from the important business of the expression of subjectivity.

Romanticism is the dressing-up of Teenage Ontology as an aesthetic cosmology. Teenage Ontology is governed by the conviction that what really matters is interiority: how you feel inside, and what your experiences and opinions are. In this sense, sloppy drunkard Ladette Tracy Emin is one of the most Romantic artists ever. Like Lads — the real inheritors of the hippie legacy — Emin’s bleary, blurry, beery, leery, lairy anti-sensualist sensibility is an advert for the vacuity of her own preferences.

What we find in Emin, Hirst, Whiteread and whoever the idiot was who rebuilt his dad’s house in the Tate is a disdain for the artificial, for art as such, in a desperately naif bid to (re)present that pre-Warholian, pre-Duchampian, pre-Kantian unadorned Real. Like our whole won’t-getfooled- again PoRoMo culture, what they fear above all is being glamoured. Remember that glamour means, “Any artificial interest in, or association with, an object, through which it appears delusively magnified or glorified.”

But let’s make our case by considering some artefacts in some detail.

Exhibit one: the cover of Roxy Music’s For Your Pleasure, 1973.

The cover image is a mistresspiece of ambivalence.

Let’s approach it through the eyes of Ian Penman, the most consummate of Roxy observers. (No doubt, Penman, like me, is endlessly drawn back to Ferry because he took the same journey from the working class into acceptance into the English master class).

(I make no apologies for citing Penman’s text, “The Shattered Glass: Notes on Bryan Ferry” at some length, since it is almost criminal that this bravura display of theoretical elegance should be mouldering amidst the pages of a long-forgotten, chalk dusty Cult Studs collection).5

On the shoreline of For Your Pleasure, beneath it, on the waterfront strand, stands the second of many new models: at first sight the second installation of the stock Ferry/ Roxy woman.

But to get the full picture we have to fold out the sleeve, so that we can see Ferry looking on…

Penman goes on:

Ferry fills out his function as her chauffeur (landlocked ferryman: a sign of the times). He waits in amused admiration, surveying the neatness of the visual pun — the model takes her cat (for a) walk: forming a uniform and uniformly predatory alliance with her black panther, eyes and mouth directed out at the viewer. Imperiously, she takes the air, she fields his grace, takes her anima for a prowl and a stretch. Ferry — for sure — remains to be seen, smiling manfully behind her back, artfully protected by the fold in his sleeve. He had arranged his own look as both within and outside of the main frame.

(“Within and outside of the main frame: is that so often where we find ourselves, lost, stranded, these days—?”)

Cut.

She is a model woman, to be sure; fashion pushing into abstraction and rarified codification, not there for the benefit of a product as such or altogether in the name of Art; so she appears to be what? She appears, on the condition that she appear to be without attributes. We can attribute nothing to her beyond a certain imaginary realm of wealth, of wealth as fetish, (Helmut) Newton’s law of physiques. She is sheerest sharp blue nothingness. (For the cool-and-blue post-Duchamp artist, it seems entirely for beauty to take the veiled form of scissors.)

As an aside, since this concerns another debate: the last things Ferry’s songs were — at this stage at least — were “just good tunes”. The first thing they were, were questions: including questions about what a good tune might mean…

And — at this stage — Ferry’s songs were no more “love songs” than Magritte’s “Human Condition” was a representation of a landscape. Like Magritte, Ferry’s sheer coldness and distantiation cannot but draw our attention to the framing machines that make possible the emotions of which he sings.

Another cut, to a “realm of a certain narcissistic eroticism he is not allowed entrance to without putting his heterosexual sensibility in doubt”:

All his songs’ women (and this will be especially so with “Stranded” and subsequent plaints) are voiceless sirens who — although wielding the utmost power over the artist’s life and sensibility — seem to be without implication (which is to say: eternalised out of existence). Neutered time and place (those perennial spans of Fashion) coalesce naturally into the figure of the woman. Woman as figure, or scene — war pin up, cat-woman, amazon, siren, Riefehstahl Maedchen.

“W ()ielding the utmost power over the artist’s life and sensibility…” The utmost power… Is he, the artist, Severin, the protagonist of Masoch’s Venus in Furs? Or Sarasine, the hapless hero-dupe of Balzac’s novel who unwittingly falls in love with a castrato?

Because, you see, the ironic punchline was: she is not(-all) a woman.

Amanda Lear, the For Your Pleasure model, was a transsexual (though, in yet another complication, she later denied it). A transsexual, moreover, whose operation might have been paid for by none other than Salvador Dali.

Either way, it is clear that Ferry has set the tone for a 1970s in which the male is both glamorous and glamoured, himself a gorgeously-styled photogenic object, entranced and seduced by a cosmetic beauty he partly wants to make contact with, but mostly wants to cold pastoralise into an immutable untouchability. “Mother of Pearl” — which as Penman observed on The Pill Box, is the whole of Lacan in seven minutes, more or less — is the closest Ferry comes to writing a manifesto for his meta-melancholia, a meta-love song about the impossibility — and undesirability — of attaining the Ideal object.

Now this melancholia is not straightforwardly “tragic” (and even if it were, it would have little to do with any bourgeois sensibility, since, as everyone from Shakespeare to George Steiner (The Death of Tragedy) to Nietzsche to Bataille demonstrates, bourgeois secularism is inherently inimical to any notion of the tragic).

But Ferry’s sensibility is definitely masochistic. (As opposed to that of the Sixties, which, as Nuttall, for one, suggests, was Sadean. Compare the Sixties-sired Lennon’s “Jealous Guy” — the Sadist apologises — to Ferry’s reading of the song — the masochist sumptuously enjoying his own pain — for a snapshot of a contrast between the two sensibilities.)

The masochist’s perversity consists in the refusal of an exclusive or even primary focus on genitality or sexuality even in its Sadean polymorphous sense, which is perverse only in a very degraded sense.

The Sadean imagination quickly reaches its limits when confronted with the limited number of orifices the organism has available for penetration. But the masochist — and Newton is in this respect, as in so many others, a masochist through and through, as is Ballard — distributes libido across the whole scene. The erotic is to be located in all the components of the machine, whether liveware — the soft pressure of flesh — or dead animal pelt — the fur coat — or technical. Masochism is cyberotics, precisely because it recognises no distinction between the animate and inanimate. After all, when you run your fingers through your beloved’s hair, you are caressing something dead.

How had Ferry got here, become stranded in the early Seventies, an artist-voyeur art-director masochist?

Ferry famously studied painting under Richard Hamilton, the so-called godfather of British Pop Art, at Newcastle University. Can we even begin to reconstruct the impact that Hamilton’s art had on British culture?

Well, you can get some impression of it from the fact that, in a documentary on Hamilton made by Channel 4 in the early 1990s, Ballard cited Hamilton’s 1956 “Just What Is It That Makes Today’s Homes so Different, so Appealing” as one of the cultural events that made it possible for him to be a sciencefiction writer. It would be better to say that Hamilton made possible Ballard’s exceeding of science fiction, his discovery of k-punk.

1956 was, of course, the year of Presley’s breakthrough records. In its own way, though, Hamilton’s collage was at least as important as Presley in the development of British pop.

After the Fifties, pop and art have always been reversible and reciprocally implicating in British culture in the way that they are not in America. Nuttall: “The students and the mods cross-fertilised… Purple hearts appeared in strange profusion. Bell-bottoms blossomed into wild colours. Shoes were painted with Woolworths lacquer. Both sexes wore make-up and dyed their hair… The air in the streets was tingling with a new delirium.”6

British pop’s irreducible artificiality makes it resistant to the Romanticist naturalisation that the likes of Greil Marcus and Lester Bangs achieved in respect of American rock. There is no way of grounding British art pop in a landscape.

Not a natural landscape in any case.

If art pop had a landscape it would be the aggressively anti-naturalistic one Ferry collaged together on “Virginia Plain” (named after one of his paintings, which was itself named after a brand of tobacco). Is this an internal landscape, what the mind’s eye sees? Perhaps. But only if we recognise that — as Hamilton’s collage and Ballard’s fiction insist — in the late-twentieth century the “space” of the internal-psychological was completely penetrated by what Ballard calls the media landscape.

When the British pop star sings, it is not “the land” which speaks (and what does Marcus hear in the American rock he mythologises in Mystery Train if not the American land?) but the deterritority of American-originated consumer culture. Hence the braying grotesquerie of Ferry’s singing voice on those early Roxy releases. (And the different grotesquerie of today’s simoting pop idols.)

With the first-hand expertise of someone who has had to lose his voice in order to speak (for that is what you must do if you educate yourself — or are educated — out of a working-class background), Penman brings out very well how integral the problem of accent — of losing a Geordie accent, of not gaining an American accent — was to Ferry’s career.

As a student, Ferry’s life was divided between his daytime movement through the art milieu and nighttime fronting of a soul band doing covers. Two voices, two lives. “I hadn’t found anything to incorporate all of me.”

The early Roxy records are Ferry’s Warhol-Frankensteinian attempts — the joins still showing, thrillingly, horrifyingly — to hand-machine a space that would incorporate his day and his night self. So they are not so much expressions of a coherent subjectivity as a kind of destratificationin-progress, the production, on the fly, of a pop art plane of consistency which he could feel at unhome in.

So here was a pop music, astonishingly, more shaped by Duchamp than Bo Diddley. The methodology Ferry deployed on his solo albums of cover versions (and remember that such albums were almost unknown in rock music at the time) was explicitly Duchampian. His renditions of standards such as “Smoke Gets in Your Eyes” and “These Foolish Things” were, he said, Duchampian “readymades”: found objects upon which he put his own stamp.

Part of what made the early Roxy sound so cold — particularly by comparison with the hot authenticity of American rock — was the fact that they were evidently not an aggregation of spontaneous, creative subjects, but a meticulously executed Duchamp-type Concept: a group whose every gesture was micro-designed, and who credited their stylist, fashion designer Anthony Price, on their album sleeves.

The great temptation for Ferry would always be to slip inside the frame: to become, really, the heartaching bachelor in the dreamhome, to achieve what Simon calls the

fantasy of stepping outside the lowly world of production into a sovereign realm of pure unfettered expression and sensuous indulgence, an imaginary and fictitious notion of aristocracy (more Huysmans than real lords who have to do humdrum things like manage their estates, juggle their investments, do a bit of arms dealing).

To achieve the total simulation of manners that he was up till then only pastiching-affecting.

And, isn’t Simon right, aren’t Ferry’s later records all about “the disillusionment of actually achieving the supermonied aristo life — Ferry, condemned to mooch jaded forever through art openings, fashion shows, all tomorrow’s parties (that old tis better to journey than arrive line)”?

Let’s leave Ferry there, stranded, framed.

And cut.

To 1982. Compass Point, Nassau.

Grace Jones’ astonishing recording of Joy Division’s “She’s Lost Control”.

Masoch: “A slap in the face is more effective than ten lectures, especially if it is delivered by the hand of a lady.”

Kodwo Eshun:

The womanmachine Grace Jones’ 82 remodel of Joy Division’s 79 She’s Lost Control updates the Fifties mechanical bride. For the latter losing control meant electric epilepsy, voice drained dry by feedback. For Jones, the female model that’s losing control induces the sense of automation running down, the human seizing up into a machine rictus. The model — as girl, as car, as synthesizer — incarnates the assembly time of generations, obsolescence, 3-year lifespans.

The model is the blueprint for the post-Cold War cyborg, the womanmachine modified and mutated by the military medical entertainment complex. Hence Kraftwerk’s The Model, where the bachelormachines are threatened by the womanmachine’s superior reproductive capability. The Model is an excerpt from the post-war machinereproduction wars.7

Jones is the sublime object before which Ferry prostrated himself — and who talked back. Through vagina-dentatal teeth.

Be careful of the womanimal-machine. It bites.

Jones is not a cyborg because she is not an organism of any kind (and the modifier “cybernetic” is in any case redundant, since all organisms, like everything that works, are cybernetic).

She is a neurobotic femachine.

The mechanical bride stripping her bachelors bare.

Jones was herself once a model, but when she has the opportunity to “express herself”, she ruthlessly exploits her own body and image much more than any (male) photographer would have dared to. “In a recent poll by Men’s Health magazine, the male readership named Grace Jones … () among the women who scared them the most.” (Brian Chin).

The game becomes the hunter.

She out-Duchamps Ferry, (dis)covering his “Love is the Drug” as a found object to be absorbed by the femachine.

Jones understands her body Spinozistically as a machine capable of being affected and producing affects. This body is in no way limited to the organism; it is distributed across photographs, sound and video — and none of these media constitute a representation of an originary organic body. They are, each of them, unique expressive components of the Jones singularity.

It’s total immanence.

There is no Grace Jones the subject who expresses her subjectivity in sound and image. There is only Jones the abstract hyperbody, the cut-up scissormachine that cuts itself up, relentlessly.

The Jones body is immanent, too, in that, as Kodwo repeatedly insists of sonic fiction throughout More Brilliant than the Sun, it produces its own theory.

Certainly, by the time that Haraway’s Cyborg Manifesto limps onto the scene, it is only to mislead via reterritorialisation.

Cut again.

To London, 1982.

(Reproduced from the early days of blogger k-punk.)

The sex appeal of the inorganic.

Paul Tickell’s review of The Anvil, NME 27 Mar 82:

I’d thought “Contort Yourself” the right kind of music for Newton’s sadoeroticism — but “The Anvil” is a greater approximation. You wanted the moderne dance — well … () here it is: the night-time moves of marionettes — dummies — puppets — clowns — and imaginary celluloid beings. It’s all a little deathly — the sound of commodities fucking — but a noise which can be a good deal more exhilarating (“the sex appeal of the inorganic” — Walter Benjamin) than healthy fun-loving creatures going at it.

All in all — Visage are a rather seductive disease — the skull beneath the made-up skin.

More material from early k-punk:

Roxy versus Visage: a shift from subject to Object (therefore, following Baudrillard’s logic in Seduction, from masculine to feminine). Fem-glam notwithstanding, Ferry retained for himself the male role of the onewho-looks. The problem, for Ferry, is the (male) gaze — how much to look? For how long? “Then I look away/too much for one day.” Strange, meanwhile, is invariably the looked-at. He is the discarded plaything in “Mind of a Toy” (telling title, that), the object of gossip in The Anvil’s maudlin “Look What They’ve Done” and “Whispers.” The model, here, is — the model: the anxiety — how am I seen?

Can we assume, btw, that Gibson derived the name Neuromancer from “New Romantic”? If so, Gibson’s transposition suggests a much more interesting, and appropriate, name for the nerve sorcery of these newly-wired electronauts. “Romantic” always struck me as way-off beam for a culture so fastidiously uninterested in depth/emotions/ truth.)

The case against Visage always seemed to me to depend on rockist prejudice: they didn’t play live, they were a vehicle for a clothes horse who “couldn’t sing”, they represented the return of prog. Isn’t there also a masculinist agenda, too, in the implicit rejection of the “superficiality” of fashion and clubbing?

Visage thoroughly stripped their sound of the trappings of r and r, ostentatiously parading an Un-American ancestry. Thematically and sonically, Visage evoked a decadent Europe of seductive urban alienation (cf the Mondrian-like vision of endless High-Rises in Blocks on Blocks) and sumptuous glamour (cf the name, and the track, “Visage”; the French vox on “Fade to Grey”), conjured through vocoder vox, synthesizers and Billy Currie’s pseudo-classical flourishes. American influences came rerouted/refracted through Europe: Moroder disco; Morricone (cf McGeoch’s “Once Upon a Time in the West”-isms on the Spaghetti Western/Clint tribute “Malpaso Man” off Visage). Cinema was a major node: much of Visage’s sound belongs to what would later be called “virtual soundtracks” (Barry Adamson, one of the architects of this genre, was of course a Visage member). The mood was one of dis-affection, not the robotic functionality of Kraftwerk, nor the schizo-dislocation of Foxx/Numan, but the Euro-aesthete’s “exhaustion from life”, nowhere better expressed than on the Interview with the Vampire-like “Damned Don’t Cry”. Visage didn’t thematise machines in the way that Kraftwerk, Numan and Ultravox did: like Yello, they seemed to operate in a future-past glittering hall-of-mirrors in which synthesizers and electronics were less a new innovation than a taken-for-granted mainstay.

Visage’s “cyberpunk baroque” is a link between Roxy Music, Vangelis, disco and what would later become dance culture. Anyone who doubts this should check out the dance mixes of “Frequency 7” or “Pleasure Boys”: the instrumental breakdown in the “Pleasure Boys” remix is pure acid house, and “Frequency 7” is nothing but a breakdown, a thrillingly anachronistic slice of machine-techno. It was no doubt Strange and Egan’s role in the Blitz/Camden Palace that facilitated the move into dance. Making clubbing and dancing, rather than the gig, central was a crucial step (for Visage specifically, but for the New Romantic scene in general). Strange was less important as “frontman” than as pure image, his very diffidence and passivity as a vocalist anticipating dance’s later complete effacement of the singer.

Except the singer doesn’t get completely effaced by dance.

It returns as the femachine Róisín.

Cut to Now.

I’ve little to add to my recent remarks8 on Moloko and Róisín Murphy as the latest — but I hope not last — contribution to the art pop story.

But it’s worth distinguishing Murphy from two artists John recently mentioned in the comments boxes: Madonna and Kylie.

Minogue is a sex worker in the most banal and degrading sense, since it is clear that her simpering subordination to the Lad’s Gaze is nothing more than a career(ist) gambit. Murphy, by contrast, gives the impression of enjoying herself, of doing what she would do any way (and just happening to have an audience). It’s clear that she enjoys attention (male or otherwise) but like all great performers, her jouissance seems to be fundamentally auto- erotic. The audience function not as passive-consumer onanist spectators, but as a feedback component in the Róisín-machine.

And unlike Madonna, Murphy does not Photoshop out all the joins and the cuts in her performance. Whereas Madonna’s hyper-professional show is all about attaining the CGI seamlessness of a corporate film, Murphy — pulling her leather fetish boots on onstage — is always playing — albeit seriously.

Q: You’re becoming quite the style icon, is that an area that interests you?

R: Well, I think I dress for myself, I mean, I’ve always dressed up anyway, and I just enjoy it. I think maybe people are just fed up of pop stars that are told what to do and what to wear.





noise as anti-capital: as the veneer of democracy starts to fade1

FORGET ORWELL

Orwell is wrong about everything, but especially 1984.

Far from being the year of zombie-drone enforced consensus, GB 1984 was a class war zone in which multinational Kapital’s paramilitary-police crushed the remnants of organic workerism live on videodrome.

Such staged antagonism is a necessary phase in the pacification program that will culminate in apparently triumphant Kapital’s End of History.

The reassuring non-hum of the noise free polis at the end of time.

Tony’s smile.

Blair is a much more effective class warrior than it was possible for Thatcher and Macgregor to be.

Their efficacy was limited by Then Kapital’s need for them to be seen fighting the class war.

No need for Tony to fight.

To not fight is to have won.

It’s all administration now.

Systemic antagonism is just a bad memory. Turn up the TV.

Bunker down in your burrow.

Retune the guitars.

Return to harmony.

Welcome to Liberty City.

The busier you are, the less you see.

SOUND FX

Mark Stewart’s As the Veneer of Democracy Starts to Fade was the politicallibidinal intensive soundtrack to “battle for the hearts and minds” fought between Kapital and its enemies GB circa 84-85.

Seven years since Stewart began his anti-career as teen-Nietzsche Artaud Debord communist shamanic-firebrand hysteric-screecher in the Pop Group.

Stewart’s journey since the dissolution of the Bristol f-punk kollektive takes him through Adrian Sherwood mega mashed hyperdub and into an encounter with US hip-hop.

He immediately appreciates that hip-hop is not a street music but non-musique abstrakt: a site of pure sonic potential, in which inhuman constructivist sound cartoons can be produced without reference to musical protocols of any kind.

It’s all sound FX, a way of manipulating noise.

Hyper-modernism. The sonic equivalent of the Burroughs-Gysin cut-up. A contact of Sherwood’s leads to the most improbable of meetings. UK non-singer and sound-deranger Stewart plugs into the super-slick behind-the-scenes NYC p-funk machine responsible for the grooves on the pioneering hip-hop 45s released by Tommy Boy and Sugarhill.

Component parts:

Keith Leblanc. Beat machine producer of “Malcolm X: No Sell Out”. He can program drum machines to make them sound like packs of dogs.

Doug Wimbish. Supertaut hypertechnicised Hendrix of bass.

Skip McDonald. Synthesizer manipulator and reaper-rider of psychedelicfunk ax storms.

Sherwood and Stewart take their already inhuman grooves and subject them to further layers of dissonant anti-musical editing, interpolating Burroughs vocal samples from Nova Express and other deliberately ciphered media background noise, machining an anti-communicational libidinal signal that takes you behind the screens to access the Real news.

Apocalypse Now.

THE BATTLE FOR THE HEARTS AND MINDS

As the veneer of democracy starts to fade, some say the internment camps are already built.

When the mask of civility comes off and the visors go on, the contours of the New World Order become apparent.

The destruction of the miners — and with them the wrought-iron ruins of the postwar consensus — was only the most media-visible of the pacification strategies Kapital was deploying, and in many ways the least significant.

The important thing was to prepare the way to transnational cyberspace Kapital Now, when all dissent is pathologised if it is not made literally unthinkable.

“Sterezene, thorazine and lagactyl” administered under the Mental Health Bill subdue political prisoners re-assigned to psychiatric wards.

Narco-neuroticisation as the re-imposition of a simulated Reality Principle shoring up Kapital against its virtual limit in Planetary Schizoprenia.

You don’t have to be mad to work here.

Restrict your demands to the what is possible.

Find your way back to your dormitory.

Privatise your misery.

Struggling to pay the rent, the main worry’s job security.

Now and then, we can afford a little luxury.

Quietism.

DISSONANCE/ DISSENSUS

If the aim is to disseminate information, why all this noise?

Why the distortion, the deliberately buried voices, why all the half-heard insinuations, the audio-hallucinatory fragmentation, the wired-up screams?

Why not communicate clearly?

Because clear communication — and all it presupposes — is the fantasm the system projects as its vindication and necessarily always-deferred goal.

“The big Other stands for the field of common sense at which one can arrive after free deliberation; philosophically, its last great version is Habermas’s communicative community with its regulative ideal of agreement.”2

The noise free polis.

We are told:

Only when the noise of antagonism recedes will we be able to hear each other. Only when we take out the background static will human speech be possible. Police yourself and there will be no need for the use of batons. Intoxicate yourself and we will not sedate you.

Stewart’s disassembly of his self through noise is a refusal of the Foucault biocops and Burroughs control addicts that operate first of all at the level of the skin and the CNS, enticing-inciting you to constitute yourself as an internally coherent driving ego.

Stewart treats his own voice not as the authentic expression of a subjective interiority, but as a series of lab animal howls, enraged yelps and impersonal intensities to be cut up and redistributed across the noise-hyperdubscape, mixed indifferently with Duchamp-found-sounds and noises produced by viciously distorted formerly musical instruments.

Identity breakdown through the amplification of noise as an exploding flight from harmony at all levels: psychic, social, cosmic.

Dissensus.

I AIN’T GONNA BE A SLAVE OF LOVE

Always take O’Brien’s side against Winston Smith and Julia.

There is nothing natural, and human biosocial defaults are always to be distrusted.

If you want to get out, leave all that mammal couple shit behind.

Stewart is one of Burroughs’ most assiduous readers.

It is not a matter of emulation but of the deployment of abstract engineering diagrams in different media.

Position As the Veneer of Democracy Starts to Fade as the terminus of the Burroughs-saturated UK underground delineated by Nuttall in Bomb Culture.

“Hypnotised” plays like the “I Love You” section from The Ticket that Exploded, Burroughs’ most pitilessly hilarious dissection-analysis of the biopsychic sex-love control virus as preprogrammed biological film, sentimental mooning croon-tunes spliced in with hardcore pornography and replayed like videodrome in your CNS, ensuring-exacerbating constant craving:

All the tunes and sound effects of “Love” spit from the recorder permutating sex whine of a sad picture planet: Do you love me? — But I exploded in cosmic laughter — Old acquaintances be forgot? O darling just a photograph?3

Heaven must be missing an angel.

Hypnotised.

Hypnotised.

She’s got me hypnotised.



Stewart’s cut-ups of constructivist-brutalist funk with saccharine lovesongs already anticipate the way in which Kapital’s tungsten-carbide stomach will metabolise hip-hop’s hyper-abstraction and use it as the dominant consumer seduction soundtrack from the Nineties till now.

CONTROL DATA

The data-content of Stewart’s rant-reports is nothing astonishing.

7% of the population own 84% of the wealth.

Parasites… The great banking families of the world… Bastards…

Are these the words of the all-powerful boards and syndicates of the earth?

The point is not to tell you something new but to reprogram your nervous system.

Control works by reducing the reality of systemic antagonism to a mere belief.

A track like “Bastards” is a very precise anti-Control weapon.

It is a rage-inducer designed to make beliefs affective, whereas Control PR conciliates and normalises.

Control PR plugs the gaps, emolliates, quietens, makes confrontation and exploitation unthinkable without denying their reality as such.

Like John Heartfield collages, Stewart’s crude sonic splices amp up the distortion and the violence.

The situation is not under Control

They are not protecting you

It is war

And so are you

THERE IS NO DIGNITY

Don’t confuse the working class with the proletariat.

Thatcher inhibits the emergence of the proletariat by buying off the working class with payment capital and the promise of owning your own Oed-I-Pod. The comforts of slavery.

She gives the replicants screen memories and family photos.

So that they forget that they were only ever artificial, factory farmed to function as the Kapital-Thing’s self-replicating HR pool, and begin to believe that they are authentic human subjects.

The proletariat is not the confederation of such subjectivities but their dissolution in globalised k-space.

The virtual population of nu-earth.

Total recall of all the noise.

Lyotard describes the hysterisation of a worker’s ear when it is subjected to the unprecedented noise of Industrial-Kapital’s reproduction: the incessant sonic violence of a 20,000hz alternator.

The heroism of the proletariat consists not in its dignified resistance to the inorganic-inhumanity of the industrialisation process — “there is no libidinal dignity, nor libidinal fraternity, there are libidinal contacts without communication”4 — but in its mutative Duchamp-transformation of its body into an inhuman inorganic constructivist machine.

As the Veneer of Democracy Starts to Fade is a sonic machine for accelerating the process. An anti-Oedipal, anti-neurotic, anti-quitest, pro-proletarianising noise weapon. Anti-videodrome signal.

Jack it into yr CNS and play.





lions after slumber, or what is sublimation today?1

“In post-liberal societies … () the agency of social repression no longer acts in the guise of an internalised Law or Prohibition that requires renunciation or self-control; instead, it assumes the form of a hypnotic agency that imposes the attitude of ‘yielding to temptation’ — that is to say, its injunction amounts to a command: ‘Enjoy yourself!’ Such an idiotic enjoyment is dictated by the social environment which includes the Anglo-Saxon psychoanalyst whose main goal is to render the patient capable of ‘normal’, ‘healthy’ pleasures. Society requires us to fall asleep into a hypnotic trance…”

— Slavoj Žižek, “The Deadlock of Repressive Desublimation”2

As we awake from the dreary dream of entryism, we can start to see that what kept us slumbering in the last twenty-five years was indeed a programme of controlled, if not quite repressive, desublimation. No doubt, the signs of any awakening are fitful as yet. In pop, they are perhaps most evident in a groping backwards, a paradoxical return to modernism. Could it be that the likes of Franz Ferdinand and the Rapture will prompt a self-overcoming of the very postmodern revivalism of which they are a symptom? Just now, Rip it up and Start Again sounds like a uncannily timely injunction.

Something seems to be (re)coalescing, as the reception of the Early Scritti LP (including Simon’s piece in Uncut) indicates. For those inside — not least, of course, Green Gartside ()3 himself — these recordings must be dismissed as inept avant-doodlings, embarrassing juvenilia. It seems plausible to attribute Green’s less-than-lukewarm judgements on the early Scritti material less to modesty, still less to a “maturity”, than to a defensive cleaving to a once-successful strategy that has now run its course, as Marcello acidly noted in his acerbic comparison between the indifferent reception of the last Scritti album and the eagerness with which Early has been anticipated:

When you next find yourself at a motorway service station, feel free to browse through the plentiful copies of his 1999 up-to-the-1999-minute-Mos-Def-involving Anomie and Bonhomie album, yours for just £1.99 — whereas the new collection of his scratchy, disjointed post-punk improv stuff from two decades ago reportedly already has 10,000 advance orders.4

Scritti were the most successful — aesthetically, commercially — of the post-post-punk entryists (the likes of U2 being always-already included of course). In the desolate gloss of mid-late Eighties pop, Scritti’s hyper-saccharine sweetness retained a plaintive if sickly gorgeousness, even if their vaunted deconstructive swerves became subtle to the point of invisibility. But the fastidious precision of that striplit Eighties production has dated (late-Eighties chartpop is the most time-bound pop music ever — discuss) much more damagingly than has the messthetic of the early records. Whereas the conspicuous completeness of Eighties entryist pop repels fascination, the queasy, uneasy unfinishedness of post-punk pop — the lurching “doubtbeat” of a collectivity discovering itself — is uncannily compulsive. In punk cut and paste, the joins, the cuts (in other words the ways in which any world does not coincide with itself) are flaunted and foregrounded. Entryism is the capture of cut and paste into Photoshopped seamlessness.

What is perforce lost in today’s post-punk revivalists is the literal intensity of this sound: how it is in Kierkegaard-Žižek’s terms, in becoming. It doesn’t know anything (it certainly can’t be confident that it is a “classic independent rock sound” in the way that Franz Ferdinand are). In flight from rock’s “condition of possibility”, this undo (it) yourself pop puts into question ALL conditions of possibility, and with them the very concept of conditions of possibility. What is this if not the sound of the Badiou Event, which is the punk revelation itself: this is happening, now, but it can’t be, it’s Impossible…?

Scritti were possibly the least Dionysian pop group ever. In the early days, the methodology may have been improvisational, but the group didn’t want anyone (least of all themselves) to be under the illusion that it issued from some vitalist wellspring of creativity. It was the sound of a collectivity thinking (itself into existence) under and through material constraints. The famous displaying of all the recording costs on the sleeve was demystificatory but not desublimating. What is too often missed about any punk that matters in fact, is that sublimation, far from requiring mystification, is alien to it.

As Alenka Zupančič argues, mystification is entirely on the side of the reality principle (and one of the greatest contributions psychoanalysis has made to politics is to identify “realism” precisely with a reality principle, so that what counts as “commonsense” can be exposed as an ideological determination):

The important thing to point out … () is that the reality principle is not some kind of natural way associated with how things are, to which sublimation would oppose itself in the name of some Idea. The reality principle itself is ideologically mediated; one could even claim that it constitutes the highest form of ideology, the ideology that presents itself as empirical fact (or biological, economic…) necessity (and that we tend to perceive as nonideological). It is precisely here that we should be most alert to the functioning of ideology.5

Listen to what Marcello calls the “pseudo-moronic chants of platitudes” (“An honest day’s pay for an honest day’s work! You can’t change human nature! Don’t bite the hand that feeds!”) of Scritti’s “Hegemony” and it is clear that this message has got through. It is the denunciation and exposure of the great ideological swindles that are liable to be remembered about punk, but this destructive urge (passive nihilism) is empty without its active complement: the production of a new space. It is no accident that mystificatory realism has allowed us to remember the former but not the latter, since the mere dismantling of ideological presuppositions quickly became a dreary academic parlour game associated with a desiccated, depressive and depressing left (they want to take your enjoyment away from you…).

Zupančič labels the production of this new space “sublimation”. To understand why she makes this move entails differentiating sublimation from the sublime as such. The postmodern emphasis on sublimity has tended to stress the sublime as an unreachable beyond, contemplation of which induces a pathos of finitude in any human subject. To think about sublimation, the process by which an object “acquires the dignity of the Thing”, produces a different emphasis. As Zupančič continues:

the Lacanian theory of sublimation does not suggest that that sublimation turns away from the Real in the name of some Idea; rather, it suggests that sublimation gets closer to the Real than the reality principle does. It aims at the Real precisely at the point where the Real cannot be reduced to reality. One could say that sublimation opposes itself to reality, or turns away from it, precisely in the name of the Real. To raise an object to the dignity of the Thing is not to idealise it, but rather to “realise” it, that is, to make it function as a stand-in for the Real. Sublimation is thus related to ethics insofar as it is not entirely subordinated to the reality principle, but liberates or creates a space from which it is possible to attribute certain values to something other than the recognised and established “common good.” … () What is at stake is not the act of replacing one “good” (or one value) with the same planetary system of the reality principle. The creative act of sublimation is not only a creation of some new good, but also (and principally) the creation and maintenance of a certain space for objects that have no place in the given, extant reality, objects that are considered “impossible”.6

What was the “beyond good and evil” of Scritti, Gang of Four, the Pop Group and the Raincoats if not the production of just such a space? (As Lacan wryly notes, when we idly think of someone who is “beyond good and evil” we are liable to think of someone is merely beyond “good”.) This entails not an austere asceticism but the engineering of new forms of enjoyment. The early Scritti’s “difficulty” places them beyond the pleasure principle, for sure, but we succumb to an ideological lure if we think that this puts them beyond enjoyment too. As Savonarola said to me a few weeks ago, Gang of Four were far more effective at turning out compulsive pop songs than almost any of today’s chart acts you could care to name. The same goes double for Early, whose songs are catchy because they refuse to push familiar buttons.

Entryism constitutes a double disavowal of sublime space. First, it is turned away from, then the very possibility of its existence is denied. In retrospect, entryism has to be seen as the production of a particularly virulent capitalist mind plague. How else to account for the absurd convolutions that allowed Green to posit some political continuity between the avant-Marxism of the early years and the champagne-swigging meta-boybandcum-yuppie-corporation “hammer and popsicle” posturing (check some of those pics which illustrate Simon’s piece) of the chart Scritti? As Simon has shown elsewhere, Green had by this point done more than merely accommodated himself to the market; he was acting as an entrepreneur, since the “‘Fairlight future-funk’ of Cupid and Psyche 85 was so far ahead of the game it actually influenced black pop.” There’s a case for saying that Cupid and Psyche’s “dazzling, depthless surfaces” in which “‘soul’ and interiority are abolished” and “desire traverses a flat plane, the endless chain of signifiers, the lover’s discourse as lexical maze” was THE sound of Eighties capital, the perfect soundtrack to Jameson’s Postmodernism, or the Cultural Logic of Late Capitalism, what it felt like to be lost in the mirrored plateaux of the hypermarket.

Realism always poses as maturation. Of course it is acceptable, understandable and inevitable to have silly youthful dreams, but there comes a time when one must put aside such childish things and face reality; and reality is always defined “biologically”, in terms of the imperatives of reproductive futurism, and “economically”, in terms of the “constraints” of the capitalist anti-market.

Readers of the lamented but never forgotten Pill Box7 may remember a letter Ian Penman received from Brian Anderson of the neo-Conservative City Journal. Anderson’s account of the intellectual provenance of neo-conservatism — many neo-cons were tellingly described as disappointed, disillusioned leftists who had been “mugged by reality” — concluded with the following convergence between new pop entryism and his own neo-conservative turn:

Also — and this will probably horrify you — my move right came partly thanks to Ian Penman and Paul Morley at NME! Your rejection of overly politicised agitprop in music back in the late Seventies made intuitive sense to me — I disliked the didacticism of Billy Bragg or Crass, and could stomach even less the critics who pretended to be revolutionaries, etc. There was far more truth in an August Darnell ballad, I came to believe, than in the entire socialist posturing of, say, the Gang of Four or Robert Christgau.

There it is: THAT opposition — Bragg versus Darnell — was the problem of the mid-to-late Eighties. As soon as it was a question of dour meat and potatoes no fuss empiricism (left) versus bright and brash hedonism (right), there was no longer any real choice. The sublime had been extirpated, and what remained was a quotidian cavilling against the wipe-clean sheen of the mall.

It’s telling that Scritti’s “Confidence” (“Outside the clubs of boyhood/ Inside monogamy”) should be so preoccupied with the problems of “being a man”, and what that entailed.

The interpellated subject of the Lad magazine is the supposed “real person” (=slavering, sloppy andro-Id) beneath the pretence of social politesse. The Lad magazine addresses this “authentic id” with the leering superegoic injunction to enjoy. “Go on, admit it, you don’t want to be bothered to cook, all you want is a fishfinger sandwich… Go on, admit it, you don’t want to be bothered to talk to a woman, have a wank instead…” The fact that this reduction is possible means that lads implicitly accept the Lacanian notion that phallic jouissance involves masturbation with a “real” partner. It also indicates that laddishness is more defined by a propensity towards depressive indolence than it is by any lasciviousness. What laddism attempts is a short-circuiting of desire (yes, I know that the “inhuman partner” of desire cannot be attained, just give me pictures of girls next door instead).

From “Skank Bloc Bologna” (“an imaginary network of dissidents stretching from Jamaica to Bologna’s anarchist squatters”) to the Streets (Lads of the world unite to raise a glass to lachrymose lariness); from “The Sweetest Girl” to Abi Titmuss…

Long past time that we roused from this slumber… Especially when, with habeas corpus suspended and mainstream political parties all but burning down gypsy camps, one of the things that makes the early Scritti so contemporary is that their conjecture/fear that It (fascism) Would Happen Here, their “très 1979 paranoia”, is suddenly, alarmingly très 2005:

Rise, like lions after slumber,

In unvanquishable number,

Shake your chains to earth like dew,

Which in sleep had fall’n on you.





the outside of everything now1

A week dominated in every way by Simon Reynolds’ Rip It Up and Start Again,2 and rightly so.

Perhaps the best tribute you can pay to the book is that it makes you positively look forward to train and bus delays, to any moment when you can return to feed the hunger, scratch the itch…

The size of the crowd at the Boogaloo event on Wednesday, but, more than that, a certain sense of ferment in the atmosphere, testified to the fact that this is something more than a book. Stirring up the ghost of post-punk cannot but be an act, an intervention in cultural politics — since post-punk not only judges contemporary pop culture (harshly), it brings back the legitimacy, the necessity of being judgemental, of having some criteria (non-musical criteria, non-hedonic criteria) for enjoyment. Such a position is not repressed by contemporary pop culture (=the cultural logic of late capitalism), it is made unthinkable by it.

Something in Paul Morley certainly seemed to wake up on Wednesday. (And something in us?…)

A certain Morley was knowingly complicit in the termination of post-punk — as Simon wryly reminded him when, after Morley had fulminated against the facile notion that the worth of a pop record is determined by its popularity, he asked him: “but didn’t that idea come from you?” It’s not accidental that, grotesquely but inevitably, Morley’s early-Eighties pop(ul)ist stance should have inspired some NME readers to turn towards neo-conservatism. In retrospect, it’s possible to see the turn to popism as the beginning of a giving voice to a creeping disappointment which spread slowly, insidiously yet incrementally during the period until almost everything of post-punk — even the traces — was disappeared (in the way that political prisoners are). The disappearing trick was almost complete when the Pod-Zombie duplicates started to arrive a few years ago, formally perfect copies mass-produced by Kapital.

It’s easier to see now than it was at the time the extent to which the cultural artefacts — and the discourse surrounding them — produced in the wake of post-punk were being programmed by resurgent Kapital. A certain notion of realism began not only to prescribe what could now happen, but to airbrush out what had actually happened. The idea that pop could be more than a pleasant divertissement in the form of an easily consumable commodity, the idea that popular culture could play host to concepts that were difficult and demanding: it wasn’t sufficient to disavow these possibilities, they must also be denied. Operation Amnesia, Pacification Program: it never happened did it, it was a delusion, a folly of youth, and we’re all grown up now…

Naturally, Morley’s railing against amateurism, his advocacy of ambition and lushness, play rather differently in 2005 than they did in the early Eighties, but that’s only fitting, since his manifestos-as-works-of-art-in-themselves were produced as strategic provocations rather than timeless aesthetic philosophies. Even though the Morley of the disappointing Words and Music claimed Noughties web popists as his offspring, it’s hard to imagine the Morley and Penman of 1981 being gratified by the thought that their legacy would be the de-conceptualisation and de-politicising — i.e. the consumerisation — of pop. They could scarcely have imagined, then, the way in which pop would de-speed over the next twenty years, that their embrace of Entryism would prove to be the last word in rough-and-tumble theoretical dialogue that seemed, then, as if it could go on forever.

Reading Rip it Up is like re-living my early pop life — but now at a distance, like Spider in Cronenberg’s film, an adult at the corner of the screen watching himself as a child. With Simon as my Virgil through that Paradiso lost, I can now recognise that pop for me was post-punk — Kings of the Wild Frontier was the first LP I bought and ABC were the first group I saw live. But Rip It Up makes me cognizant of what I, growing up absurd into post-punk, couldn’t have appreciated at the time: that the richness of pop then — not only sonically, but also in terms of concepts, clothes, images — lasted only a relatively short period, made possible by specific historical contingencies.

Nevertheless, expectations were raised in me, and more or less everything I’ve written or participated in has been in some sense an attempt to keep fidelity with the post-punk event. Cyberpunk — both in its restricted literary generic sense and in the broader sense we have given to it in Ccru — was up to its neck in post-punk. Gibson’s debt to Steely Dan and the Velvet Underground has long been acknowledged, but the dominant tone of Neuromancer was an overhang from post-punk. Gibson named his hightech prostitutes after the Meat Puppets, but Neuromancer’s technihilistic ambience, dub apocalypticism, amphetamine-burned-out Cases and hectic, twitching finger-on-fast-forward and comatone-cut-out narrative, seem to be transposed straight out of the British post-punk scene.

One of the things that is most remarkable about post-punk, actually, is its near total erasure of America and Americanness. When I was in my early teens, the only American pop you’d hear that wasn’t disco would be encountered while trudging round the shops on Saturday afternoon, as Paul Gambaccini’s Hot 100 was broadcast over the store PAs, and it was a window into a horrifyingly deprived world of barely imaginable banality.

Of the few American groups of any significance in this period, perhaps only Devo and the Meat Puppets took much inspiration from the American landscape (in Devo’s case of course, the US was processed as a thoroughly artificial PKD-US-trash heap of post-industrial detritus). No wave emerged from the rootless cosmopolitanism and transnational nihilism of New York, while in many ways the most interesting American groups — Tuxedomoon and the Residents — were Europhiles. In post-punk, America increasingly featured as a series of ethnographic traces — as in the ecstatic, hysterical and authoritarian ghost chatter of Amerikkkan TV and media flittering through Cabaret Voltaire’s Voice of America or Byrne and Eno’s My Life in the Bush of Ghosts.

It’s hard to remember now, but in the period after Vietnam and before the collapse of the Eastern Bloc, America was a paranoid and enfeebled nation, Nixon-sickened and introspective, scared of its own shadows. Post-punk was there to witness — and mock — the seeming absurdity of the idiot actor Reagan being wheeled on to give America’s confidence a shot-in-the-arm, although initially even Reagan’s rise to power seemed to be a kind of sinister post-punk prank, since it made eerily real what had been predicted by one of perhaps post-punk’s most important influence, Ballard. (In the States, Ballard’s Atrocity Exhibition was re-titled Love and Napalm: Export USA, and that novel — so omnipresent in post-punk production — was a kind of simultaneous observation of the way in which Britain was being turned into an LA of ubiquitous advertising hoardings as well as a British view of the US.) By the time that post-punk went out in a neonblaze of irony-tainted glory on MTV, the joke had, to say the least, worn thin. Pop had gone Blue-Gene American rock, again (I still remember the barely comprehending horror I felt when the NME started to give covers to the t-shirt and jean-clad Springsteen; worse was to follow, with the likes of The Long Ryders). Boredom was back, but this time, without the punks to denounce it. The arid shopping mall at the end of history opened up as the only possible future. Worse than the career opportunities that never knocked were the ones that did: jobs for everyone in the striplit wall-to-wall mart of Time Out of Joint America in which it is 1955, forever… No shadows to hide in… No room to move, no room to doubt…

Ironic in some ways that Rip it Up should be named after an Orange Juice song, since Orange Juice and Postcard were responsible for what was in many ways a British equivalent of Springsteen’s US return-to-roots. If the comparison seems strained, think about the way in which both Springsteen and Orange Juice self-consciously advocated a kind of locally-rooted authenticity defined by its rejection of artificiality. For Springsteen’s reich and roll uniform of denim, substitute OJ’s Brideshead Revisited sweaters. Like the Smiths, the Postcard-era Orange Juice retrospectively imagined a British pop-that-never-was. The Brit equivalent of American open-throated stridency was a kind of floppy-fringed, tongue-tied dithering that was just as much of a self-conscious reclaiming of signifiers of national identity as Springsteen’s passional working stiff poses were. (Is it too fanciful to hear in the early Orange Juice an anticipation of Hugh Grant’s unbearable foppery and faffing?)

By the time I got to university in 1986, Orange Juice, and the Smiths, had achieved hegemonic control of the undergraduate “imagination”. It was perfect pop for young men who were destined to go on to careers in marketing but who liked to think of themselves as “sensitive”. Orange Juice also played in a major part in rehabilitating the love song. If romance featured in post-punk at all, it was as something to be derided and demystified (as in the Slits’ “Love Und Romance” or Gang of Four’s “Love Like Anthrax”) or as something to be politically and theoretically interrogated a la Scritti or Devoto. The renewed preoccupation with love was a re-occupation of “the ordinary”, a re-statement of a revivified humanist confidence in a dehistoricised continuity of “things that go on the same”.

It’s often said that punk was what Britain had instead of 68, but that in many ways fails to process how punk had surpassed the events in Paris. 68 was as much a rejection of certain theoretical positions as it was of the institutions of modern liberal society so that, in the conflagration of the Sixties “Desirevolution”, the cold Spinozism of Althusser’s structural analysis was burned down with the buildings. Punk and post-punk, however, were profoundly suspicious of the Dionysisan triumvirate of leisure, pleasure and intoxication, so that the required attitude was one of vigilant hyperrationalism, a kind of popularised Althusserianism in which interiority was exposed as an ideological bluff, and emotions were understood not as “real expressions of authentic subjectivity” but as structurally engineered reactive circuitries. The stance such a perception demanded — and this was a culture that was deliberately and unashamedly demanding — was one of “proletarian discipline” rather than slack indulgence, its puritanism recalling the egalitarian social ambitions of the original Puritans. In this respect, Scritti’s move from pleasure-repudiating Marxism to “playful” deconstruction is emblematic of the way in which the decade would develop, in universities as much as in the charts. The exorbitant surfaces of Cupid

and Psyche might have eschewed interiority, but at the same time their simulations of interiority were no less authentic, no less soulful, than other versions of interiority purveyed by more credulous, non-ironic sources in the mainstream. The person being duped now was the Green who imagined that his intelligence would prevent full incorporation.

But the triumphant capitalism Green was already working for had no trouble at all in consuming those who sought entry into it. In the Seventies, in an effort to dispel the notion that there were “subversive regions” that would be inherently indigestible for capital, Lyotard compared capitalism to a “Tungsten-carbide stomach” that could consume anything in its path. By the Eighties, as Jameson has observed, Kapital had become a gigantic interiority without any outside: a kind of jaded pleasuredome reminiscent of the all-encompassing bubble environments imagined in Seventies SF. Except it looked, for all the world, just like a familiar domestic environment: the nice house, nice family set-up ridiculed by Jamie Reid, now refurbished with added ironic distantiation and hooked up to twenty-four-hour MTV. What had been lost was the “glam knowledge” that first entered pop through Pop Art: that the social scene is a stage set populated by puppets cornfed cheap dreams and sedated by narcotics of every kind. The punks knew they were replicants; that everything that seemed to be inside was bio-psycho-social machinery that should be re-programmed or stripped out. The end of punk was the forgetting that the memories were false, that the domestic scene was so much pasteboard and image virus.

At the time of post-punk, pop could still be a counter-cultural lab (endlessly raided by, but never subordinated to the diktats of, Kapital). It really is not clear whether pop could be that again. Someone asked the panel on Wednesday if dredging post-punk up was an exercise in nostalgia. But this is entirely to miss the point of Jameson’s critique of the nostalgia mode. For Jameson, the nostalgia mode is exemplified by cultural artefacts which deny, or more radically, are unaware of their own total debt to the past. In other words, being contemporary does not guarantee being modern, especially not in a postmodern culture whose temporality is obsessively citational and commemorational. One of the most idiotic tics in cultural gatekeeping today is its need to justify the past in terms of the present: as if Gang of Four were only significant because they “influenced” no-mark, here-today boot-sale-tomorrow clones like Bloc Party and Franz Ferdinand. As if simply being here, now, meant that something New and Important is happening…

Pop could function differently in post-punk because, at that time, it was the space which most readily leant itself to the production of a counter-consensual collectivity. Post-punk was an awakening from Kapital’s “consensual hallucination”, a means of channeling, externalising and propagating disquiet and discrepancy. It provided a crack in the way the social represented itself; or rather, exposed that crack. What the social would have us believe is dysfunction, grumbling, failure suddenly became the sound of the “outside of everything”. Records, interviews, the music press, were the means by which contact could be made between affects, concepts, commitments that would previously have been locked into private space.

Some of the panel last Wednesday were unsure if they had really done anything, if their dreams of doing something more than simply entertaining were anything more than youthful naïveté, understandable then, an embarrassment now. But the achievements of post-punk can be appreciated, negatively, in what culture now lacks. Go into a roomful of teenagers and look at their self-scarred arms, the anti-depressants that sedate them, the quiet desperation in their eyes. They literally do not know what it is they are missing. What they don’t have is what post-punk provided… A way out… and a reason to get out…

So is this a counsel of despair?

Not at all.

There are new means for producing counter-consensual collectivity.

Like this.

The web has a distributional reach, a global instaneity, whose unprecedented scale is easy to take for granted. But its vast potential far outstrips anything that fanzines or records could have achieved in the Seventies. What needs to happen is a kind of “existential reframing”: to see what happens here not as Kapital wants us to see it, as “failed” writers resentfully carving out some insignificant niche because they can’t “make it” in the overlit interior. The logic of Kapital insists that anything that is not reproducing it, or serving such a reproduction, is a waste of time. But to reframe what is happening would be to radically reverse these idiotic priorities. And the continuing relevance of post-punk is to remind us that such reversals are possible, to provide the impetus for the development of a (punk) will to retake the present…





for your unpleasure: the hauter-couture of goth1

Ridiculed, forgotten, yet subterraneanly robust, goth is the last remnants of glam in popular culture.

Goth is also the youth cult most associated with women and with fiction. This is hardly surprising. As I have pointed out before2 and is well known, the novel has its origins in “Gothic romances” which were predominantly consumed and produced by women, and the complicity of women with the Gothic has been a commonplace of literary criticism at least since Ellen Moers wrote her classic essay, “Female Gothic” in 1977.

Why think about goth now?

Partly it is because goth’s preposterous trash-aristocratic excess couldn’t be more at odds with contemporary culture’s hip-hop-dominated sportswear brutilitarianism. At the same time, though, goth’s shadow seems unusually visible in pop culture at the moment, what with references to it in both Coronation Street (“you’re not even a proper goth!”) and Big Brother (“what is a gothic? Can you make me into one?”)

Partly it is because Rip It Up has revived fascination in all things post-punk, and goth is the last surviving post-punk cult. These two facts have resulted in I.T.3 and me seceding from the oppressive masculinist cool of the club into the more congenial cold of goth haunts.

Goth has its own version of more or less every other youth culture (hence there’s techno goth, industrial goth, hippie goth…) But let’s leave aside the male abjects (the Cramps, the Birthday Party), the po-faced (the overwrought white dub of Bauhaus) and the PoMo (the Sisters of Mercy, who from the start traded in a self-conscious meta-goth), and start with Siouxsie.

It is well-known that the Banshees were formed as a result of the future Siouxsie and Severin meeting at a Roxy show in 1974. (This fact was repeated in this really rather bizarre piece4 on Roxy in last Friday’s Guardian, which pursues the postmodern rock critical trend to equate “importance” with “influence” far past the point of self-parody, relegating actual discussion of Roxy’s output to a paragraph or so before launching into a survey of groups they inspired.) So, unlike the Birthday Party, who were famously disgusted when they arrived in London to find it dominated by new romantic poseur-pop, the Banshees belonged to an art pop lineage which had a relationship to music which was neither ironically distant nor direct. For all their inventiveness, for all the damage they wreaked upon the rock form, the Birthday Party remained Romantics, desperate to restore an expressive and expressionistic force to rock; a quest which led them back to the Satanic heartland of the blues. (If women want to understand what it is like to be the afflicted subject of male sexuality — I wouldn’t necessarily advise it — there’s no better fast-track to “what’s inside a boy” than the Birthday Party’s “Zoo Music Girl” or “Release the Bats”). By contrast with this carnal heat, the early Banshees affected a deliberate — and deliberated — coldness and artificiality.

Siouxsie came from the art rock capital of England — that zone of South London in which both David Bowie (Beckenham) and Japan (Catford, Beckenham) grew up. Although Siouxsie was involved with punk from the very beginning, and although all of the major punk figures (even Sid Vicious) were inspired by Roxy, the Banshees were the first punk group to openly acknowledge a debt to glam. Glam has a special affinity with the English suburbs; its ostentatious anti-conventionality negatively inspired by the eccentric conformism of manicured lawns and quietly-tended psychosis Siouxsie sang of on “Suburban Relapse”.

But glam had been the preserve of male desire: what would its drag look like when worn by a woman? This was a particularly fascinating inversion when we consider that Siouxsie’s most significant resource was not the serial identity sexual ambivalence of Bowie but the staging of male desire in Roxy Music. She may have hung out with “Bowie boys”, but Siouxsie seemed to borrow much more from the lustrous PVC blackness of For Your Pleasure than from anything in the Thin White Duke’s wardrobe. For Your Pleasure songs like “Beauty Queen” and “Editions of You” were self-diagnoses of a male malady, a specular desire that fixates on female objects that it knows can never satisfy it. Although she “makes his starry eyes shiver”, Ferry knows “it never would work out”. This is the logic of Lacanian desire, which Alenka Zupančič explains as follows: “The … () interval or gap introduced by desire is always the imaginary other, Lacan’s petit objet a, whereas the Real (Other) of desire remains unattainable. The Real of desire is jouissance — that ‘inhuman partner’ (as Lacan calls it) that desire aims at beyond its object, and that must remain inaccessible.”5

Roxy’s “In Every Dreamhome a Heartache” is about an attempt, simultaneously disenchanted-cynical and desire-delirious, to resolve this deadlock. It is as if Ferry has recognised, with Lacan, that phallic desire is fundamentally masturbatory. Since, that is to say, a fantasmatic screen prevents any sexual relation so that his desire is always for an “inhuman partner”, Ferry might as well have a partner that is literally inhuman: a blow-up doll. This scenario has many precursors: most famously perhaps Hoffman’s short story “The Sandman” (one of the main preoccupations of Freud’s essay on “The Uncanny” of course), but also Villier de L’isle Adam’s lesser known but actually more chilling masterpiece of decadent SF, The Future Eve and its descendant, Ira Levin’s Stepford Wives.

If the traditional problem for the male in pop culture has been dealing with a desire for the unattainable — for Lacan, remember, all desire is a desire for the unattainable — then the complementary difficulty for the female has been to come to terms with not being what the male wants. The Object knows that what she has does not correspond with what the subject lacks.

It is almost as if the female goth response to this dilemma is to self-consciously assume the role of the “cold, distanced, inhuman partner” (Žižek) of phallic desire. The glam male remains trapped in his perfect penthouse populated by dumb fantasmatic playdolls; the goth female meanwhile roams through the roles of vamp and vampire, succubus, automaton. The glam male’s pathologies are those of the subject; the goth female’s problematic is that of the object. Remember that the original sense of glamour — bewitchment — alludes to the power of the auto-objectified over the subject. “If God is masculine, idols are always feminine”, Baudrillard writes in Seduction, and Siouxsie differed from previous pop icons in that she was neither a male artist “feminised” into iconhood by fan adoration, nor a female marionette manipulated by male svengalis, nor a female heroically struggling to assert a marginalised subjectivity. On the contrary, Siouxsie’s perversity was to make an art of her own objectification. As Simon and Joy put it in The Sex Revolts, Siouxsie’s “aspiration was () towards a glacial exteriority of the objet d’art” evinced through “a shunning of the moist, pulsing fecundity of organic life.”6 This denial of interiority — unlike Lydia Lunch, Siouxsie is not interested in “spilling her guts”, in a confessional wallowing in the goo and viscera of a damaged interiority — corresponds to a staged refusal to either be “a warm, compassionate, understanding fellow-creature” (Žižek). Like Grace Jones, another who made an art of her own objectification, Siouxsie didn’t demand R.E.S.P.E.C.T. from her bachelor suitors (with the implied promise of a healthy relationship based on mutual regard) but subordination, supplication.

(The goth male is all too ready to comply, although — as Nick Cave’s compulsively repetitious career has graphically demonstrated — snivelling prostration may well only be the prelude to homicidal destruction. Grovelling in front of the Ice Queen — “I kiss the hem of her skirt” — the goth male is neither object nor subject but — famously — abject. The best image of this idiot lust is the slavering, pustulant monstrosity on the cover of the Birthday Party’s Junkyard, and their “Release the Bats” — a song the group came to despise because they thought it might result in their being pigeonholed as generic goth — remains the most pulsingly compulsive dramatisation of the goth abject surrendering himself to the Object of his quivering desire. Cave oscillates between worshipping his lady’s femmachinc hauteur — “my baby is a cool machine”, “she moves to the pulse of the generator” — and pruriently drooling over the “filth” of her flesh — “she doesn’t mind a bit of dirt”. This conforms almost perfectly with Lacan’s description of the courtly lady, whose cold abstraction is not defined by opposition with smelly physicality. Cave’s abject is unable to give up on his desire, and the result is well-known: in order to continue to desire the woman, he must ensure that he cannot possess her, “so that l’il girl will just have to go”. Only when he has made her as cold and unyielding as Ferry’s “perfect companion” or Poe’s parade of beautiful cadavers, can his desire be extended “to eternity”, because then it is rendered permanently incapable of satisfaction.)

Instead of asserting an illusory “authentic subjectivity” which supposedly lies beneath the costumes and the cosmetics, Siouxsie and Grace Jones revelled in becoming objects of the gaze. Both would no doubt have appreciated the derision Baudrillard poured upon the strategy of unmasking appearances in Seduction: “There is no God behind the images and the very nothingness they conceal must remain a secret.”7 Siouxsie and Jones’ embracing of their objectality testifies to the fact that there is a scopic drive that cult studs whining about “being reduced to an object” has always ignored: the exhibitionist drive to be seen.

Simon is right that “Painted Bird” (from the Banshees mistresspiece, A Kiss in the Dreamhouse) and the nearly contemporary “Fireworks” were “virtual manifestos for goth”, but it’s worth reflecting on how different these songs are in message and mood from the hackneyed image of the culture. Both “Painted Bird” and “Fireworks” (with its “exultant image of self-beautification as a glam gesture flashing amid the murk of mundanity”) are not maudlin, matt black or self-absorbed, but celebrations of the colourful and the collective. “WE are fireworks”, Siouxsie sings, “burning shapes into the night”, and you’d be hard pressed to find a song that crackles with so much enjoyment as this. The Banshees’ take on Kosiński’s novel The

Painted Bird is also about the triumph of collective joy over persecuted, isolated, individuated subjectivity. In Kosiński’s novel, the hero paints one bird and when he throws it back to its flock they don’t recognise it and therefore destroy it. But Siouxsie’s goths are not painted by another’s hand; they are “painted birds by their own design”. It is not the familiar tragic-heroic scenario in which an outsider, destined to lose, nevertheless makes a solitary stand against the conformist herd. The “dowdy flock” are to be “confounded”, but by another flock, not by an individual, and the result is not frustration, but, again, jouissance — by the end of the song, “there’s no more sorrow”.

Think how different this is to the confederacy of isolation produced by Joy Division, whose functional clothes and “non-image” implied the traditional male subjectivist privileging of the inside over the outside, depth over surface. Here was one type of “black hole”: the “line of abolition” Deleuze and Guattari describe in “Micropolitics and Segmentarity”,8 the drive towards total self-destruction. The Banshees, on the other hand, were more like the “cold stars” invoked by Neubauten: forbidding, remote, yet also the queens of a paradoxically egalitarian aristocracy in which membership was not guaranteed by birth or beauty but by self-decoration. Siouxsie’s hyper-white panstick radiated the “cold light” of stardom Baudrillard invokes in Seduction. Stars “are dazzling in their nullity, and in their coldness — the coldness of makeup and ritual hieraticism (rituals are cool, according to McLuhan).”9

“The sterility of idols is well-known”, Baudrillard continues, “they do not reproduce, but arise from the ashes, like the phoenix, or from the mirror, like the seductress”. The Gothic has always been about replication as opposed to reproduction. It’s no coincidence that the female vampire was often associated with lesbianism (most gloriously in what is perhaps the definitive goth film, The Hunger) because vampires and lesbians (like machines) present the horror (from the point of view of the phallic One) of a propagative power that has no use for the male seed. Conversely, “female Gothic” often pathologises pregnancy, utilising the language of horror to describe the gradual take-over of the body by an entity that is both appallingly familiar and impossibly alien. “We Hunger” from the Banshees’ Hyaena, with its “horror of suckling”, fits into a lineage of female horror which has seen “pregnancy in terms of the appalling rapacity of the insect world”, as a “parasitic infestation”.10

The principal goth vectors of propagation are, of course, signs and clothes (and — clothes as signs). The Siouxsie Look is, in effect, a replicatable cosmetic mask — a literal effacement of the organic expressivity of the face by a geometric pattern, all hard angles and harsh contrasts between white and black. White tribalism.

In Rip It Up, Simon says that the early Banshees were “sexy in the way that Ballard’s Crash was sexy”, and Ballard’s abstract fiction-theory is as palpable and vast a presence in the Banshees as it is in other post-punk. (It’s telling that the turn from the angular dryness of the Banshees’ early sound to the humid lushness of their later phase should have been legitimated by Severin’s reading of The Unlimited Dream Company.) But what the Banshees drew (out) from Ballard was the equivalence of the semiotic, the psychotic, the erotic and the savage. With psychoanalysis (and Ballard is nothing if not a committed reader of Freud), Ballard recognised that there is no “biological” sexuality waiting beneath the “alienated layers” of civilisation. Ballard’s compulsively repeated theme of reversion to savagery does not present a return to a non-symbolised bucolic Nature, but a fall back into an intensely semioticised and ritualised symbolic space. (It is only the postmoderns who believe in a pre-symbolic Nature.) Eroticism is made possible — not merely mediated — by signs and technical apparatus, such that the body, signs and machines become interchangeable.

Baudrillard understood this very well, in his post-punk era essay on Crash:

Each mark, each trace, each scar left on the body is like an artificial invagination, like the scarifications of savages … (). Only the wounded body exists symbolically — for itself and for others — “sexual desire” is never anything but the possibility bodies have of combining and exchanging their signs. Now, the few natural orifices to which one normally attaches sex and sexual activities are nothing next to all the possible wounds, all the artificial orifices (but why “artificial”?), all the breaches through which the body is reversibilised and, like certain topological spaces, no longer knows either interior or interior … () Sex … () is largely overtaken by the fan of symbolic wounds, which are in some sense the anagrammatisation of the whole length of the body — but now, precisely, it is no longer sex, but something else … () The savages knew how to use the whole body to this end, in tattooing, torture, initiation — sexuality was only one of the possible metaphors of symbolic exchange, neither the most significant, nor the most prestigious, as it has become for us in its obsessional and realistic reference, thanks to its organic and functional character (including in orgasm).11

As is well-known, female dis-ease in capitalism is often expressed not in an assertion of the “natural” against the artificial, but in the anti-organic protest of eating disorders and self-cutting. It’s hard not to see this — as I.T. following Žižek does — as part of the “obsession” with “realistic reference”, an attempt to strip away all signs and rituals so as to reach the unadorned thing-in-itself. Goth is in many ways an attempt to make good this symbolic deficit in postmodern culture: dressing up as re-ritualisation, a recovery of the surface of the body as the site for scarification and decoration (which is to say, a rejection of the idea that the body is merely the container or envelope for interiority). Take goth footwear. With their flagrant anti-organic angularity, their disdain for the utilitarian criteria of comfort or functionality, goth shoes and boots bend, bind, twist and extend the body. Clothing recovers its cybernetic and symbolic role as a hyperbolic supplement to the body, as what which destroys the illusion of organic unity and proportion.





it doesn’t matter if we all die: the cure’s unholy trinity1

“Goth took hold as both a suburban and provincial cult, in which young men and women with heavily powdered faces, mourning clothes and Robert Smith’s hairstyle could be seen at domestic ease in towns like Littlehampton and Ipswich.”

— Michael Bracewell, England is Mine: Pop Life in Albion from Wilde to Goldie2

Any discussion of goth will remain incomplete if it doesn’t deal with the Cure.

Goth and the suburbs enjoy a peculiar intimacy (no one knows this more than Tim Burton, whose Edward Scissorhands brilliantly laced the Avon scent of the suburbs with the perfume from goth’s flowers of romance), and is there a group more suburban than the Cure? In England is Mine, Michael Bracewell made much of their origins in humble Crawley. “Quiet and respectable, yet lacking the bourgeois superiority of nearby Haywards Heath (home of Suede), Crawley is a near perfect example of England at its least surprising”, he wrote.3 For Bracewell, the group are the sound of the in-between spaces of English culture: the suburbs, yes, but also, adolescence, the suburbia of the soul. The Cure are the personification of the not-quite and the not-yet: not quite execrated but never really respected; not punk veterans but not yet generic Goff. The suspicion that has dogged them is that of fakery; yet inauthenticity –as existential condition — was the Cure’s stock-in-trade. You can hear it all in the grain of Robert Smith’s voice. Bracewell again:

When Smith sang, it wasn’t so much his doom-laden lyrics as the actual sound of his voice which lent the Cure their mesmeric monotony: it was the voice of nervous boredom in a small town bedroom, muffled beneath suffocating layers of ennui. Alternately peevish and petulant, breathless with anguish or spluttering with incoherent rage, Smith’s voice was unique in making monotony malleable.4

There is a period, a moment, when groups become what they are. Everything that has come before is preparation and rehearsal; everything that comes after is either decline or evasion. Roxy were themselves immediately — the band-brand established with the first notes of “Remake, Remodel” (with the result that Ferry’s subsequent career has been a long essay in disappointment and deferred return), but it’s more usual for a group to take a while to find themselves; to emerge gradually from a cocoon of allusion, homage and plagiarism. It wasn’t quite like that with the Cure, whose best work was always produced in negotiation with their influences.

Their early mode — a spidery, punk-spiked pub sub-psychedelia — now sounds like a series of thin sketches. The Cure become themselves in that moment –lasting three albums — after they have shed the petulant quirkiness of Three Imaginary Boys but before they have entered the comfort zone of branded recognisability. By then, Smith’s panto-persona –- lipstick smear, warm beer and Edward Lear — had become an archetype in the semiotic cemetery of the student disco, and the parameters of the Cure’s style were well-established — marked by what quickly became a regular oscillation between a post-Sgt. Pepper jollity and a slippers-comfortable despair. All of the drama of faltering self-discovery and existential experimentalism that makes the essential triptych of Seventeen Seconds, Faith and Pornography so compelling has gone.

The Cure’s three crucial albums emerged from the shadow of two other bands, whose reputation towered above theirs: the Banshees and Joy Division. Smith made no secret of his fixation on the Banshees (with whom he would later guest as a guitarist). When the band’s first bassist, Michael Dempsey, left the band, it was because he “wanted us to be XTC part 2”, whereas Smith “wanted us to be the Banshees part 2”.

Robert Smith’s look — that clown-faced Caligari ragdoll — was a male complement to Siouxsie’s. And as with Siouxsie’s, Smith’s bird’s nest backcomb, alabaster-white face powder, kohl-like eyeliner and badly applied lipstick is easily copied; a kit to be readily assembled in any suburban bedroom. It was a mask of morbidity, a sign that its wearer preferred fixation and obsession above “well-rounded personhood”.

Goth morbidity arose in part from a Schopenhauerian scorn for organic life: from goth’s perspective, death was the truth of sexuality. Sexuality was what the ceaseless cycle of birth-reproduction-death (as icily surveyed by Siouxsie on Dreamhouse’s “Circle Line”) needed in order to perpetuate itself. Death was simultaneously outside this circuit and what it was really about. Affirming sexuality meant affirming the world, whereas goth set itself, in Houllebecq’s marvellous phrase, against the world and against life. By the early Eighties, it was possible to posit a rock anti-tradition that had similar affiliations, an anhedonic, anti-vital rock lineage that began with the Stones — with the neurasthenic Jagger of “Paint it Black” rather than the cloven-hooved demonic-Dionysus of “Sympathy for the Devil” — and passed through the Stooges and the Pistols, before reaching its nadir-as-zenith in Joy Division. But goth suspected that rock was that always and essentially a death trip. This was the gambit of the Birthday Party, who hunted rock’s mythology back to the fetid, voodoo-stalked crossroads and swamplands of the delta blues. After all, isn’t blues the clearest possible demonstration of the discrepancy between desire and enjoyment, and therefore of the validity of the theory of the death drive? The blues juju — or jou-jou — relies upon the enjoyment of desires that cannot be satisfied.

While the Birthday Party literalised the return to the blues — their career a kind of hectic rewind of rock history, beginning with Pere Ubu/Pop Group modernism and ending in a feverish re-imagining of blues — the Cure, like the Banshees, went to the other extreme. Maintaining fidelity to post-punk’s modernist imperative (novelty or nothing), they preferred a sound that was ethereal rather than earthy, artificial rather than visceral. You can hear this in Smith’s guitar, which, swathed in phasing and flange, destubtantialised and emasculated, aspires to be pure FX denuded of any rock attack. (Is this the first step towards MBV’s honeyed amorphousness?) The Cure’s version of blues enjoyment-in-the-frustration-of-desire is auditioned in “A Forest”: the song in which the group find themselves, ironically, since it is a song about loss — or rather about an encounter with what can never be possessed. “The girl was never there”, Smith sings, a line worthy of Scritti — or Lacan. “Running towards nothing. Again and again and again…”, Smith — a suburban Scotty seeking his Madeleine — pursues the desire-chimera, the petit objet a, through a dreamscape vividly sound-painted by oneiric synthesizers, drum-machines and Smith’s FX-saturated guitar. “A Forest” was the trailer for Seventeen Seconds, and it turned out to be the album’s centerpiece. The synthesizers and the drum machine bring a moderne sheen lacking on the no-frills hustle and bustle of Three Imaginary Boys. Smith was listening to Astral Weeks, Hendrix, Nick Drake, Bowie’s Low, and wanted the album to be a synthesis of the four. The result was both more and less than this. As English as the Smiths would be, but, naturally, much more modernist and much less kitchen sink, Seventeen Seconds puts one in mind of a deserted country house, vast white spaces and empty floorboards decorated by the ornate cobwebs of Smith’s guitar. Emotionally, the effervescent petulance of the first album has drained away, but, even if the predominant mood is now moroseness, it is not yet goth-morbid. But there is a kind of cultivated detachment, Smith assuming an “ostentatious absenteeism”, dissociating himself from an everyday life conceived of as a dramaturgy of effigies: “it’s just your part/in the play/for today…”

“I was 21”, Smith told Uncut in 2000, “but I felt really old. I actually felt older than I do now. I had absolutely no hope for the future. I felt life was pointless. I had no faith in anything. I just didn’t see there was much point in continuing with life. In the next two years, I genuinely felt that I wasn’t going to be alive for much longer. I tried particularly hard to make sure I wasn’t.” From its very first moments, Faith locks onto this hollow-eyed bleakness, and stays there. Affectively, the album is as improbably unwavering as Unknown Pleasures and Closer, and the Joy Division (anxiety of) influence hung over Faith like an acrid pall, the black source of its paradoxically entropic energy, what made it possible but also what would relegate it to the status of a revenant. “The whole thing was reinforced by the fact that Ian Curtis had killed himself,” Smith recalled in the Uncut interview, speaking for the post-Joy Division generation (which would of course include New Order) that would deem itself inauthentic simply by dint of the fact that it had carried on living. “I knew that the Cure were considered fake in comparison, and it suddenly dawned on me that to make this album convincing I would have to kill myself. If I wanted people to accept what we were doing, I was going to have to take the ultimate step.”5

Yet Faith would have benefited from pursuing its emotional monotone even more assiduously, if what adrenaline that remained had been drained away, and the two up-tempo tracks (“Primary” and “Doubt”) had been excised. On all the other tracks, Faith flatlines pop, bringing it as close to complete stillness as it is possible to be without coming to the grinding halt the group had sang of in an earlier, much more fleet-of-foot incarnation. There was no calmness in Faith’s stillness. It is not tranquil, but tranquillised, downer-heavy; not so much oceanic as waterlogged, swamped. (In fact, Faith was recorded on coke, not tranquillisers.) The album seems to come from another planet where gravity is more powerful. The synthesizers, now foregrounded more than ever, do most to produce this effect of viscous heaviness. They have a cold warmth that fills out the sound like valium entering the bloodstream. With Faith, as with downers, it is as if the edge has been taken off. Its world is without angles, a fug, fog of bleary drear. It lacks the clinical quality of Joy Division; this is not the sound of depression, nor (as with Movement) of post-traumatic stress, but of a kind of total fatalism, in which nothing much matters, where “all cats are grey”. Faith finds a strange exhilaration in yielding all hope, in playing dead while going through the zombie motions, “breathing like the drowning man”. Bracewell’s description of the Cure’s sound is nowhere more appropriate than when applied to Faith.

There is no insight or polemic: there are no messages and no rallying anthems. Rather, the Cure are the musical expression of suburbia itself: a dense and repetitious sound, carrying a mesmeric dirge of infinitely transferable sounds, all of which sound as though they could go on forever — like endless avenues, crescents and drives.6

Faith’s tracks are distended, hynoptic (or hypnagogic) in their repetitiousness,

Smith’s mope a wraith that drifts in after introductions that typically last for ninety seconds or two minutes. Go through the mirror with Smith and what the uninitiated hear as directionless dirges become addictive plateaus, gentle blizzards you enjoy losing yourself in.

After this, you would expect recovery and return, a compensatory uplift. But in the event the Cure’s season in hell was far from over and Pornography outdoes even Faith for morbid enervation. But Faith’s amorphousness is replaced by a newly jagged abrasion and a jittery rhythmic urgency that was the Cure’s take on the then fashionable tribal sound. Its template seems to be the less synthesizer-heavy, more metallic-brutalist tracks on Closer (“Atrocity Exhibition”, “Colony”); the cavernous hollow spaces of PiL; the dancing in the ruins urban anomie of Killing Joke. In the end, it sounds like “Flowers of Romance” sung by a neurasthenic rather than a hysteric, Killing Joke fed on bad trip acid and downers, a defunked 23 Skidoo, all at once.

The opener, “100 Years”, is the Cure’s masterpiece. It starts as it means to go on, Smith intoning, “It doesn’t matter if we all die”, an invitation even more forbidding than that leered by the circus barker Curtis on “The Atrocity Exhibition” (“This is way step inside”). Like Joy Division’s “Disorder”, “100 Years” seems to lift its head from morbid self-absorption to gaze at the world — its words a Cold War ticker-tape as filtered through an adolescent nervous system in the midst of breakdown — but in reality it only selects for consideration those things which confirm its hypothesis that cosmic despair is the only justifiable attitude. “Ambition in the back of a black car… Sharing the world with slaughtered pigs… The soldiers close in…” Smith comes on like Bowie’s Newton in the most famous scene of The Man Who Fell to Earth, entranced and stupefied by a bank of television screens, all of them bringing bad news. What makes this exhilarating rather than emiserating is the necrotic urgency of the death-disco drum machine and Smith’s guitar riff, which blazes like a distress flare in light-polluted sky.

If Smith’s guitar on Pornography often sounds Eastern, it calls up a fantasmatic East in which all of the hippie dreams of free-your-mind exotica have been napalmed into oblivion. Pornography was famously recorded on LSD washed down by alcohol (the band would skulk in a pub waiting for the effects of the acid to wear off before they went into the studio) but it is psychedelic in the same way that Apocalypse Now is. (There are grounds for claiming that Apocalypse Now — with its warporn media overload, its schizophrenic delirium, its sense that The End is only minutes away — was the post-punk film; 23 Skidoo, for one, seemed to have emerged fully-formed from its vision.) Pornography’s delirium is a Jacob’s Ladder bad trip, a psychic Indochina fever dreamt in a Crawley bedroom, the hallucinogens giving distended and distorted shape to anxieties conjured from the suburban heart of darkness.

Smith’s lyrics shred sense for the sake of image-impact. He has always been a “purveyor of filmic ambience” (Bracewell), and the songs on Pornography convey mood through striking images (“voodoo smile… siamese twins”) that never cohere into any clear meaning. The album is the goth equivalent of a chocolate box: an exercise in sheer morbid indulgence unleavened by any cheer.

At the end of the title track, a howling grind that sounds like Joy Division’s “The Atrocity Exhibition” spliced with Stockhausen’s Hymnen, Smith seeks redemption. “I must fight this sickness… Find a cure.” But the sickness, the sickness was the most interesting thing about the Cure.





look at the light1

Its cover image is a waveform of a blackbird’s song re-imagined as a geological formation. Kate Bush’s Aerial is Deleuzian MOR: a numinous, luminous twitterscape of women-animal becomings, a hymn to light, and lightness.

I’d concur with what’s already coalescing into a critical consensus: “King of the Mountain” apart, the first disc — “A Sea of Honey” — is merely an appetiser for the second CD, the sumptuous song suite that is “A Sky of Honey”.

On the face of it, for this, her return after twelve years, Bush could either make a show of pursuing Relevance a la Bowie, or Madonna, or else recline into a session-musician airbrushed “timelessness” like Bryan Ferry. In the event, she tacks closer to the second option, but with considerably more success than Ferry has mustered in any of his solo albums for the last twenty years. The sonic palette from which Bush has constructed Aerial contains few rogue elements, and hardly anything that would have discomfited a mid-Eighties audience.

And yet… “A Sky of Honey” in particular has the flavour, if not the instrumentation, of later genres. The intermittent birdsong, the lambent washes of subdued strings and synth, the shifts in atmosphere — now tranquil, now tempestuous, now humid, now temperate — recall ambient jungle (I’m put in mind more than once of Goldie’s “Mother”), the lush opiated vastness of microhouse, English pastoral techno such as Ultramarine.

It is in A Thousand Plateaus’ “Of the Refrain” that Deleuze and Guattari write of birdsong. On one side, the refrain is a territorial marker, the tracing of an interiority; on the other, it opens out into the cosmos. Aerial is similarly double: “A Sea of Honey” exploring the heimlich, “A Sky of Honey” dreaming the cosmic.

“King of the Mountain” has been one of the singles of the year — insidious and insinuating rather than immediate, a blind-side seduction which makes itself a habit before you’ve registered awareness of it. Its snow-swept eyrie contains the grandest, most elemental, rendition of the twin themes that dominate “A Sea of Honey” — domesticity and isolation. Kane in Xanadu doubles Elvis in Graceland, wind howling around the melancholy opulence of their empty mansions.

The other songs on “A Sea of Honey” retreat from these media mythscapes into more intimate territory. Bush flirts with sentimental indulgence on the song addressed to her son, “Bertie”, while meditating on the line between bliss and banality, pathos and bathos, on “How to be Invisible” and “Mrs Bartolozzi”, with their imagery of anoraks, wallflowers and washing machines.

What is fascinating about “Sea of Honey” is its exploration of the Mother’s bliss, which has by definition been excised from a history of rock that has endlessly staged the cutting of the apron strings, the rejection of the maternal. There’s something oppressive and cloying about this domestic space, something suffocating and greedily insatiable about the protected interiority Bush creates. The “domestic idyll” is literally agoraphobic, troubled by an Outside it seeks to keep at bay. “How to be Invisible” is a spell in which ultra-ordinary objects are brandished as protective charms, preservatives of a domesticity that has withdrawn from the wider social world. Yet the heimlich, the homely, is always, also, the unheimlich, the unhomely, the uncanny. In “Mrs Bartolozzi”, a widow’s solitude transforms laundry into a Svankmajer erotic dance, the boredom, loneliness and sadness of a confined mind transfiguring empty clothes into an animist memory-theatre. In these circumscribed horizons, washing the floor becomes a religious observance, an act of mourning and melancholy.

If “A Sea of Honey” is a kitchen-sink delirium, its spaces all carpeted and walled, then “A Sky of Honey” is widescreen, panoramic, as the words of the stand-out track, “Nocturn”, have it. Everything opens out. It’s as if we leave the artificial cocoon of the house to step out into the garden, a garden which becomes a lush Ernst jungle…

What impresses most about “A Sky of Honey” is the majesty of its composition. It sounds like the sort of thing Bush has done before, but there’s nothing else in her oeuvre quite so sustained as this. I mean “composition” in the painterly at least as much as the musicianly sense, for “A Sky of Honey” is Bush’s most painterly record: each sound a delicate stroke in a delicately constructed and minutely conceived picture. Van Gogh (“the flowers are melting!”), Chagall, Ernst, as much as Joyce or Bronte, seem to be the guiding hands. The painter’s medium — light — may well be “A Sky of Honey”’s principal preoccupation. The image of a pavement artist’s work destroyed by rain is central to “A Sky of Honey”: “all the colours are running”. Yet no mood of regret or melancholy can last long here; in an instant, Bush is celebrating “the wonderful sunset” that the run colours have become. Ironically for a record so artfully and fastidiously designed, so foreign to rock and jazz’s spontaneity, the message is that the Accident is the pre-eminent form of creation. We are gently urged to revel in the innocence of becoming, to “look at the light… and all the time it’s a changing…”. The record celebrates the butterfly-wing fragility of the Moment, the neverstatic Hacceities Nature is madly composing and is composed of, the ever-evanescent iridescences of the “somewhere in-between” in which we are always lost. Between wakefulness and sleep, between land and sea, between sky and dust, between day and night, “A Sky of Honey” reaches its poised, anti-climax plateau on the last three tracks, “Somewhere in Between”, “Nocturn” and “Aerial”. By “Somewhere in Between”, we have reached dusk, the time when everything de-substantialises, and the song is a dance of dying light, a savouring of the evening’s bewitched, betwixt state. “Nocturn” is up there with anything she’s done — its oneiric, oceanic disco a kind of becalmed answer to Patti Smith’s “Horses”, the white water of Smith’s angsts and passions soothed and smoothed into a placid lake in which amphibious longings swim and commingle. “Nocturn” is a journey to the end of the night very different to the one Celine took: a Van Gogh-visionary stretching, a reaching both up into the sky and down into the sea.

The stars are caught in our hair

The stars are on our fingers

A veil of diamond dust

Just reach up and touch it

The sky’s above our heads

The sea’s around our legs

In milky, silky water

We swim further and further

We dive down… We dive down…

There are suggestions of Joyce’s Anna Livia Plurabelle here, the river heading out to the sea that will swallow it, just as the dreaming mind awakens. After this, there is the dappled return of sunlight on “Aerial”, glimmers of light on the water’s surface, “all of the birds laughing”, Bush joining in.

Magisterial, and better with every listen.





is pop undead?1

If there is a current coalescence of fascination around hauntology, there is also a mounting anxiety about the death, dearth, end of pop. A few examples: this atrocious piece on the “death of black music”2 (significant only for the statistics it cites), Simon’s 05 round-up for Frieze,3 and a number of recent threads on Dissensus. The suspicion is inescapable: part of the reason why hauntology should appeal to us so much now is that, unconsciously, and increasingly consciously, we suspect that something has died.

Nothing lasts forever, of that I’m sure.

Announcements of the demise of pop are nothing new of course. And there any number of reasons to be sceptical about the language of “death” and morbidity (not least because it concedes too much to the vitalist valorisations of life). The fact is that nothing ever really dies, not in cultural terms. At a certain point — a point that is usually only discernible retrospectively — cultures shunt off into the sidings, cease to renew themselves, ossify into Trad. They don’t die, they become undead, surviving on old energy, kept moving, like Baudrillard’s deceased cyclist, only by the weight of inertia. Cultures have vibrancy, piquancy only for a while. Lyric poetry, the novel, opera, jazz had their time; there is no question of these cultures dying, they survive, but with their will-to-power diminished, their capacity to define a time lost. No longer historic or existential, they become historical and aesthetic — lifestyle options not ways of life.

We are lulled into the belief that pop should be immune to this process by the illusion to which those within any culture, any civilisation, fall prey (perhaps it is a necessary illusion?): the belief that our own culture will continue forever. The question we need to ask, then, is not so much “will pop die?”, but has pop already reached the point of undeath? Has it seduced us into an entropy tango, clasping us with zombie fingers as it slowly winds down towards permanent irrelevance? Questions worth raising, if only because as soon as they are no longer raised we can be sure that pop really has reached its terminal phase.

What alarms me is the lack of alarm about pop’s current situation. Where is the chorus of disapproval and disquiet about a group like the Arctic Monkeys? Granted, it is not that the Arctic Monkeys are significantly worse than any of their retro forebears (although if anything ought to set alarm bells ringing, it is a situation where “not being worse” than mediocre predecessors is thought of as worthy of comment, still less of muted celebration). What is novel is the discrepancy between the Arctic Monkeys’ modest “achievements” and the scale of their success. Critical success is more easily bought than ever, of course, so we shouldn’t be surprised that the NME rates the Monkeys’ album as fifth best British album of all time (disgust would be more an appropriate response, actually). But such subjective and professionally expedient over-valuations would be insignificant were it not for the quantitative scale of the Arctic Monkeys’ success — fastest selling UK debut album ever! What this implies is a libidinal deficit in pop’s audience as well as in its old media commentariat — a much more worrying trend.

The Arctic Monkeys’ success is as glum news for popists as it is for those of us who still pledge allegiance to pop’s modernist tendencies. (It should be noted here that, with R&B and hip-hop faltering and stuttering, popist-approved pop has been one of the last remaining places where modernism’s guttering flame persists.) As Marcello has suggested recently over at Church of Me, the new new pop (Rachel Stevens, Girls Aloud) is barely secure, certainly not thriving, and its (relatively) disappointing sales compare ominously with the voracious triumph of retro-indie and the new authenticity (Blunt! Jack Johnson!). There has been a kind of reversal, with new new pop occupying the old pre-indie independent position of the popular-experimental, and indie dominating the mainstream. (Hence I would argue that, contra Simon in the Frieze article, it is new new pop, not some putative, ghastly fusion “of grime and indie rock”, that is today’s closest equivalent to post-punk.) A little insight into the times can be gleaned from the fact that NME has been reduced to ostentatiously banning Blunt from its awards ceremony (because there are a MILLION miles between his maudlin mumbling and that of their darlings, naturally). James Blunt versus Coldplay: is this what pop antagonism is reduced to? A pseudo-conflict that should excite only Swiftian ridicule.

Hate’s not your enemy, love’s your enemy.

Such plastic antagonisms (and NME/corporate indie can’t survive without convincing its consumers that they are an alternative to something, that there is some region of common-sense, complacent, middle of the road mediocrity that they don’t already occupy) substitute for the real antagonisms that once sustained pop. Even the most ardent devotees must sense something is missing — there’s just a hint in Doherty’s puppy dog junky eyes that even he recognises the sad fact that even if he dies, it won’t stop being pantomime. (Although one suspects that the current malaise can in large part be accounted for by the fact that “what is missing” is not even noticed, still less mourned or hankered for.)

Indie may have all but driven black musics out of the British charts, hybridity may be off the agenda, but you can bet your bottom dollar that all of those indie bands just love hip-hop and R&B. Pop at its most febrile was stoked by critical and negative energies that are now exhausted — or which have been exiled as far too impolite for today’s pot-pourri, PoMo buffet in which you can have a bit of indie here, a bit of R&B there, where contradictions and anomalies have been Photoshopped out, where it all happily fits into one well-adjusted consumer basket. If the revolutionary tumult of the post-punk era was characterised by restless dissatisfaction, anxiety, uncertainty, rage, harshness, unfairness — that is, by an atmosphere of relentless criticism — today’s pop scene is suffused with laxness, bland acceptance, quiescent hedonism, luxuriant self-satisfaction (ALL those awards shows!) — that is, by PR.

What pop lacks now is the capacity for nihilation, for producing new potentials through the negation of what already exists. One example, of many possible. Both the Birthday Party and new pop nihilated one another: far from existing in a relation of mutual acceptance or of mutual ignorance each defined themselves in large part by not being the other. One shouldn’t rush to conceive of this in simple-minded dialectical terms as thesis-antithesis, since the relationships are not only oppositional — there is always more than one way to nihilate, and it is always possible for any individual thing to nihilate more than one Other. It seems at least plausible to suggest that the capacity for renewed nihilation is what has driven pop. So let’s dare to conceive of pop not as an archipelago of neighbouring but unconflicting options, not as a sequence of happy hybridities or pallid incommensurabilities, but as a spiral of nihilating vortices. Such a model of pop is utterly foreign to postmodern orthodoxies. But pop is either modernist or it is nothing at all.

Just because something is current doesn’t mean it is new. Saying that pop was better twenty-five years ago is NOT to be nostalgic; on the contrary, it is to resist the ambient, airtight, total nostalgia that can not only tolerate but delight in the latest regurgitations on the indie retreadmill.

Let’s dispense once and for all with popist-Deleuzianism/Deleuzian popism’s obligatory positivity. The fact we happen to be alive now doesn’t mean that we must be committed to the belief that this is the best time to live EVER. We have no duty to search out entertainment and spread a little excitement everywhere we go. (Think of how hard to please audiences were in the mid-Seventies, in the midst of a veritable cornucopia by comparison with today’s grim desert; and think of what that dissatisfaction produced.) So, please, no consumerist homilies about the fact that “it is always possible to find good records, no matter what the year”. Yes, of course it is, but as soon as pop is reduced to good records it really is all over. When pop can no longer muster a nihilation of the World, a nihilation of the Possible, then it will only be the ghosts that are worthy of our time.





memorex for the kraken: the fall’s pulp modernism

Part I1

“Maybe industrial ghosts are making Spectres redundant”

— The Fall, Dragnet sleevenotes2

“M.R. James be born be born

Yog Sothoth rape me lord

Sludge Hai Choi

Van Greenway

Ar Corman”

— The Fall, “Spectre Vs. Rector”3

“Scrawny, gnarled, gaunt: Smith doesn’t waltz with ghosts. He materialises them.”

— Mark Sinker, “Look Back In Anguish”4

Who can put their finger on the Weird?

It’s taken me more than twenty years to attempt this deciphering. Back then, the Fall did something to me. But what, and how?

Let’s call it an Event, and at the same time note that all Events have a dimension of the uncanny. If something is too alien, it will fail to register; if it is too easily recognised, too easily cognizable, it will never be more than a reiteration of the already known. When the Fall pummelled their way into my nervous system, circa 1983, it was as if a world that was familiar — and which I had thought too familiar, too quotidian to feature in rock — had returned, expressionistically transfigured, permanently altered.

I didn’t know then, that, already, in 1983, the Fall’s greatest work was behind them. No doubt the later albums have their merits but it is on Grotesque (After the Gramme) (1980), Slates (1981) and Hex Enduction Hour (1982) where the group reached a pitch of sustained abstract invention that they — and few others — are unlikely to surpass. In its ambition, its linguistic inventiveness and its formal innovation, this triptych bears comparison with the great works of twentieth-century high literary modernism (Joyce, Eliot, Lewis). The Fall extend and performatively critique that mode of high modernism by reversing the impersonation of working-class accent, dialect and diction that, for example, Eliot performed in “The Waste Land”. Smith’s strategy involved aggressively retaining accent while using — in the domain of a supposedly popular entertainment form — highly arcane literary practices. In doing so, he laid waste the notion that intelligence, literary sophistication and artistic experimentalism are the exclusive preserve of the privileged and the formally educated. But Smith knew that aping master-class morés presented all sorts of other dangers; it should never be a matter of proving (to the masters) that the white crap could be civilised. Perhaps all his writing was, from the start, an attempt to find a way out of that paradox which all working-class aspirants face — the impossibility of working-class achievement. Stay where you are, speak the language of your fathers, and you remain nothing; move up, learn to speak in the master language, and you have become a something, but only by erasing your origins — isn’t the achievement precisely that erasure? (“You can string a sentence together, how can you possibly be working class, my dear?”)

The temptation for Smith was always to fit into the easy role of working-class spokesman, speaking from an assigned place in a given social world. Smith played with that role (“the white crap that talks back”, “Prole Art Threat”, “Hip Priest”) whilst refusing to actually play it. He knew that representation was a trap; social realism was the enemy because in supposedly “merely” representing the social order, it actually constituted it. Against the social realism of the official left, Smith developed a late-twentieth-century urban English version of the “grotesque realism” Bakhtin famously described in Rabelais and his World. Crucial to this grotesque realism is a contestation of the classificatory system which deems cultures (and populations) to be either refined or vulgar. As Peter Stallybrass and Allon White argued, “the grotesque tends to operate as a critique of a dominant ideology which has already set the terms of, designating what is high and low”.5

Instead of the high modernist appropriation of working-class speech and culture, Smith’s pulp modernism reacquaints modernism with its disavowed pulp doppelgänger.

Lovecraft is the crucial figure here, since his texts — which first appeared in pulp magazines like Weird Tales — emerged from an occulted trade between pulp horror and modernism. Follow the line back from Lovecraft’s short stories and you pass through Dunsany and M.R. James before coming to Poe. But Poe also played a decisive role in the development of modernism — via his influence on Baudelaire, Mallarmé, Valéry and their admirer T.S. Eliot. “The Waste Land”’s debt to Dracula, for instance, is well-known.6 The fragmentary, citational structure of a story like Lovecraft’s “Call of Cthulhu”, meanwhile, recalls “The Waste Land”. More than that: as Benjamin Noys argued in his paper “Lovecraft the Sinthome” (given at the recent “Gothic Remains” conference at Sussex), the abominations from which Lovecraft’s strait-laced scholars recoil bear comparisons with cubist and futurist art: Lovecraft, that is to say, turns modernism into an object of horror.

Yet Lovecraft’s texts are exemplary of Weird, rather than straightforwardly Gothic, fiction. Weird fiction has its own consistency, which can be most clearly delineated by comparing it to two adjacent modes, fantasy and the uncanny. Fantasy (and Tolkien is the exemplar here) presupposes a completed world, a world that, although superficially different to “ours” (there may be different species, or supernatural forces) is politically all-too familiar (there is usually some nostalgia for the ordered organisation of feudal hierarchy). The uncanny, meanwhile, is set in “our” world — only that world is no longer “ours” any more, it no longer coincides with itself, it has been estranged. The Weird, however, depends upon the difference between two (or more) worlds — with “world” here having an ontological sense. It is not a question of an empirical difference — the aliens are not from another planet, they are invaders from another reality system. Hence the defining image is that of the threshold, the door from this world into another, and the key figure is the “Lurker at the Threshold” — what, in Lovecraft’s mythos is called Yog Sothoth. The political philosophical implications are clear: there is no world. What we call the world is a local consensus hallucination, a shared dream.

Is There Anybody There?

“Part One: spectre versus rector

The rector lived in Hampshire

The Spectre was from Chorazina)…”

— The Fall, “Spectre Vs. Rector”

“Spectre Vs. Rector”, from 1979’s Dragnet, is the first moment — still chilling to hear — when the Fall both lay out and implement their pulp modernist methodology. “Spectre Vs. Rector” is not only a ghost story, it is a commentary on the ghost story. The chorus, if it can be called that, is a litany of pulp forebears — “M.R. James be born be born/Yog Sothoth rape me lord…” — in which language devolves into asignifying chant, verbal ectoplasm: “Sludge Hai Choi/Van Greenway/Ar Corman”.

Not coincidentally, “Spectre Vs. Rector” was the moment when the Fall really began to sound like themselves. Before that, the Fall’s sound is a grey-complexioned, conspicuously consumptive garage plink-plonk punk, amphetamine-lean and on-edge, marijuana-fatalistic, simultaneously arrogant and unsure of itself, proffering its cheap and nastiness as a challenge. All of the elements of Smith’s later (peripheral) vision are there on Live at the Witch Trials and on the other tracks on Dragnet — watery-eyed figures lurking in the corner of the retina, industrial estates glimpsed through psychotropic stupor — but they have not yet been condensed down, pulped into the witches’ brew that will constitute Smith’s plane of consistency.

On “Spectre Vs. Rector”, any vestigial rock presence subsides into hauntology. The original track is nothing of the sort — it is already a palimpsest, spooked by itself; at least two versions are playing, out of sync. The track — and it is very definitely a track, not a “song” — foregrounds both its own textuality and its texturality. It begins with cassette hum and when the sleeve notes tell us that it was partly “recorded in a damp warehouse in MC/R” we are far from surprised. Steve Hanley’s bass rumbles and thumps like some implacable earth-moving machine invented by a deranged underground race, not so much rising from subterranea as dragging the sound down into a troglodytic goblin kingdom in which ordinary sonic values are inverted. From now on, and for all the records that really matter, Hanley’s bass will be the lead instrument, the monstrous foundations on which the Fall’s upside-down sound will be built. Like Joy Division, fellow modernists from Manchester, the Fall scramble the grammar of white rock by privileging rhythm over melody.

Fellow modernists they might have been, but the Fall and Joy Division’s take on modernism could not have been more different. Hannett and Saville gave Joy Division a minimalist, metallic austerity; the Fall’s sound and cover art, by contrast, was gnarled, collage cut-up, deliberately incomplete. Both bands were dominated by forbiddingly intense vocalist-visionaries. But where Curtis was the depressive-neurotic, the end of the European Romantic line, Smith was the psychotic, the self-styled destroyer of Romanticism.

“Unsuitable for Romantics”, Smith will graffiti onto the cover of Hex Enduction Hour, and “Spectre Vs. Rector” is the template for the anti-Romantic methodology he will deploy on the Fall’s most important releases. After “Spectre Vs. Rector”, there is no Mark E Smith the romantic subject. The novelty of Smith’s approach is to impose the novel or tale form (“Part One: spectre versus rector…”) into the Romantic-lyrical tradition of the r and r song, so that the author-function supplants that of the lyrical balladeer. (There are parallels between what Smith does to rock and the cut-up surgery Eliot performed on the etherised patient of Romantic expressive subjectivity in his early poems.) Smith chant-narrates, not sings, “Spectre Vs. Rector”.

The story is simple enough, and, on the surface, is deliberately conventional: a post-Exorcist revisiting of the classic English ghost story. (At another level, the narrative is generated by a Roussel-like playing with similar words: Rector/Spectre/Inspector/Excorcist/Exhausted.) A rector is possessed by a malign spirit (“the spectre was from Chorazina” — described on the sleevenotes as “a negative Jerusalem”); a police inspector tries to intervene but is driven insane. (This a real Lovecraftian touch, since the dread fate that haunts Lovecraft’s characters is not of being consumed by the polytendrilled abominations but by the schizophrenia that their appearance often engenders.) Both Rector and Inspector have to be saved by a third figure, a shaman-hero, an Outsider who “goes back to the mountains” when the exorcism is complete.

The Rector stands for rectitude and rectilinearity as well as for traditional religious authority. (The ontological shock that Lovecraft’s monstrosities produce is typically described, any Lovecraft reader will recall, in terms of a twisting of rectilinear geometries.) The Inspector, meanwhile, as Ian Penman conjectured in his 1980 interview with the Fall “stands for an investigative, empirical world view”.7 The hero (“his soul possessed a thousand times”) has more affinity with the Spectre, whom he absorbs and becomes (“the spectre possesses the hero/ but the possession is ineffectual”) than with the agents of rectitude and or empirical investigation. It seems that the hero is driven more by his addiction to being possessed, which is to say dispossessed of his own identity (“that was his kick from life”) than from any altruistic motive. He has no love for the social order he rescues (“I have saved a thousand souls/they cannot even save their own”) but in which he does not occupy a place. “Those flowers take them away”, he said:

They’re only funeral decorations

And this is a drudge nation

A nation of no imagination

A stupid dead man is their ideal

They shirk me and think me unclean…

UNCLEAN…

In Madness and Civilisation, Foucault argues that the insane occupy the structural position vacated by the leper, while in The Ecstasy of Communication, Baudrillard describes “the state of terror proper to the schizophrenic: too great a proximity of everything, the unclean promiscuity of everything which touches, invests and penetrates without resistance, with no halo of private projection to protect him anymore”.8 Baudrillard is of course describing the schizophrenia of media systems which overwhelm all interiority. Television brings us voices from far away (and there’s always something on the other side…). For Baudrillard, there is an increasing flatness between media and the schizophrenic delirium in which they feature; psychotics often describe themselves as receivers for transmitted signal. And what is the hero of “Spectre Vs. Rector” if not another version of the “ESP medium of discord” that Smith sings of on “Psychic Dancehall”?

Smith’s own methodology as writer-ranter-chanter echoes that of the hero-malcontent. He becomes (nothing but) the mystic pad on which stray psychic signals impress themselves, the throat through which a warring multiplicity of mutually antatognistic voices speak. This is not only a matter of the familiar idea that Smith “contains multitudes”; the schizophonic riot of voices is itself subject to all kinds of mediation. The voices we hear will often be reported speech, recorded in the compressed “telegraphic” headline style Smith borrowed from the Lewis of Blast.

Listening to the Fall now, I’m often reminded of another admirer of Lewis, Marshall McLuhan. The McLuhan of The Mechanical Bride (subtitle: The Folklore of Industrial Man), understood very well the complicity between mass media, modernism and pulp. McLuhan argued that modernist collage was a response to the perfectly schizophrenic layout of the newspaper frontpage. (And Poe, who in addition to his role as a forebear of Weird fiction, was also the inventor of the detective genre, plays a crucial role in The Mechanical Bride.)



Part II1

M.R. James, Be Born Be Born

“Ten times my age, one tenth my height…”

— The Fall, “City Hobgoblins”2

“So he plunges into the Twilight World, and a political discourse framed in terms of witchcraft and demons. It’s not hard to understand why, once you start considering it. The war that the Church and triumphant Reason waged on a scatter of wise-women and midwives, lingering practitioners of folk-knowledge, has provided a powerful popular image for a huge struggle for political and intellectual dominance, as first Catholics and later Puritans invoked a rise in devil-worship to rubbish their opponents. The ghost-writer and antiquarian M.R. James (one of the writers Smith appears to have lived on during his peculiar drugged adolescence) transformed the folk-memory into a bitter class-struggle between established science and law, and the erratic, vengeful, relentless undead world of wronged spirits, cheated of property or voice, or the simple dignity of being believed in.”

— Mark Sinker, “Watching the City Hobgoblins”3

Whether Smith first came to James via TV or some other route, James’ stories exerted a powerful and persistent influence on his writing. Lovecraft, an enthusiastic admirer of James’ stories to the degree that he borrowed their structure (scholar/researcher steeped in empiricist common sense is gradually driven insane by contact with an abyssal alterity) understood very well what was novel in James’ tales. “In inventing a new type of ghost”, Lovecraft wrote of James,

he departed considerably from the conventional Gothic traditions; for where the older stock ghosts were pale and stately, and apprehended chiefly through the sense of sight, the average James ghost is lean, dwarfish and hairy — a sluggish, hellish night-abomination midway betwixt beast and man — and usually touched before it is seen.4

Some would question whether these dwarven figures (“ten times my age, one tenth my height”) could be described as “ghosts” at all; often, it seemed that James was writing demon rather than ghost stories.

If the libidinal motor of Lovecraft’s horror was race, in the case of James it was class. For James scholars, contact with the anomalous was usually mediated by the “lower classes”, which he portrayed as lacking in intellect but in possession of a deeper knowledge of weird lore. As Lovecraft and James scholar S.T. Joshi observes:

The fractured and dialectical English in which James’ array of lower-class characters () speak or write is, in one sense, a reflection of James’ well-known penchant for mimicry; but it cannot be denied that there is a certain element of malice in his relentless exhibition of their intellectual failings. … () And yet, they occupy pivotal places in the narrative: by representing a kind of middle ground between the scholarly protagonists and the aggressively savage ghosts, they frequently sense the presence of the supernatural more quickly and more instinctively than their excessively learned betters can bring themselves to do.5

James wrote his stories as Christmas entertainments for Oxford undergraduates, and Smith was doubtless provoked and fascinated by James’ stories in part because there was no obvious point of identification for him in them. “When I was at the witch trials of the twentieth century they said: You are white crap.” (Live at the witch trials: is it that the witch trials have never ended or that we are in some repeating structure which is always excluding and denigrating the Weird?)

A working-class autodidact like Smith could scarcely be conceived of in James; sclerotically-stratified universe; such a being was a monstrosity which would be punished for the sheer hubris of existing. (Witness the amateur archaeologist Paxton in “A Warning to the Curious”. Paxton was an unemployed clerk and therefore by no means working class but his grisly fate was as much a consequence of “getting above himself” as it was of his disturbing sacred Anglo-Saxon artefacts.) Smith could identify neither with James’ expensively-educated protagonists nor with his uneducated, superstitious lower orders. As Mark Sinker puts it: “James, an enlightened Victorian intellectual, dreamed of the spectre of the once crushed and newly rising working classes as a brutish and irrational Monster from the Id: Smith is working class, and is torn between adopting this image of himself and fighting violently against it. It’s left him with a loathing of liberal humanist condescension.”6

But if Smith could find no place in James’ world, he would take a cue from one of Blake’s mottoes (adapted in Dragnet’s “Before the Moon Falls”) and create his own fictional system rather than be enslaved by another man’s. (Incidentally, isn’t Blake a candidate for being the original pulp modernist?) In James’ stories, there is, properly speaking, no working class at all. The lower classes that feature in his tales are by and large the remnants of the rural peasantry, and the supernatural is associated with the countryside. James’ scholars typically travel from Oxford or London to the witch-haunted flatlands of Suffolk, and it is only here that they encounter demonic entities. Smith’s fictions would locate spectres in the urban here and now; he would establish that their antagonisms were not archaisms.

Sinker: “No one has so perfectly studied the sense of threat in the English horror story: the twinge of apprehension at the idea that the wronged dead might return to claim their property, their identity, their own voice in their own land.”7

The Grotesque Peasants Stalk the Land

“Detective versus rector possessed by spectre

Spectre blows him against the wall

Says direct, ‘This is your fall

I’ve waited since Caesar for this

Damn fatty, my hate is crisp!

I’ll rip your fat body to pieces!’”

— The Fall, “Spectre Vs. Rector”

“The word grotesque derives from a type of Roman ornamental design first discovered in the fifteenth cenury, during the excavation of Titus’s baths. Named after the ‘grottoes’ in which they were found, the new forms consisted of human and animal shapes intermingled with foliage, flowers, and fruits in fantastic designs which bore no relationship to the logical categories of classical art. For a contemporary account of these forms we can turn to the Latin writer Vitruvius. Vitruvius was an official charged with the rebuilding of Rome under Augustus, to whom his treatise On Architecture is addressed. Not surprisingly, it bears down hard on the ‘improper taste’ for the grotesque. ‘Such things neither are, nor can be, nor have been,’ says the author in his description of the mixed human, animal, and vegetable forms:

For how can a reed actually sustain a roof, or a candelabrum the ornament of a gable? or a soft and slender stalk, a seated statue? or how can flowers and half-statues rise alternately from roots and stalks? Yet when people view these falsehoods, they approve rather than condemn, failing to consider whether any of them can really occur or not.”

— Patrick Parrinder, James Joyce8

By the time of Grotesque (After the Gramme), the Fall’s pulp modernism has become an entire political-aesthetic program. At one level, Grotesque can be positioned as the barbed Prole Art retort to the lyric antique Englishness of public school prog. Compare, for instance, the cover of “City Hobgoblins” (one of the singles that came out around the time of Grotesque) with something like Genesis’ Nursery Cryme. Nursery Cryme presents a gently corrupted English surrealist idyll. On the “City Hobgoblins” cover, an urban scene has been invaded by “emigres from old green glades”: a leering, malevolent cobold looms over a dilapidated tenement. But rather than being smoothly integrated into the photographed scene, the crudely rendered hobgoblin has been etched, Nigel Cooke-style, onto the background. This is a war of worlds, an ontological struggle, a struggle over the means of representation.

Grotesque’s “English Scheme” was a thumbnail sketch of the territory over which the war was being fought. Smith would observe later that it was “English Scheme” which “prompted me to look further into England’s ‘class’ system. INDEED, one of the few advantages of being in an impoverished sub-art group in England is that you get to see (If eyes are peeled) all the different strata of society — for free.”9 The enemies are the old right, the custodians of a National Heritage image of England (“poky quaint streets in Cambridge”) but also, crucially, the middle-class left, the Chabertistas of the time, who “condescend to black men” and “talk of Chile while driving through Haslingdon”. In fact, enemies were everywhere. Lumpen-punk was in many ways more of a problem than prog, since its reductive literalism and perfunctory politics (“circles with A in the middle”) colluded with social realism in censuring/censoring the visionary and the ambitious.

Although Grotesque is an enigma, its title gives clues. Otherwise incomprehensible references to “huckleberry masks”, “a man with butterflies on his face” and Totale’s “ostrich headdress” and “light blue plant-heads” begin to make sense when you recognise that, in Parrinder’s description, the grotesque originally referred to “human and animal shapes intermingled with foliage, flowers, and fruits in fantastic designs which bore no relationship to the logical categories of classical art”.

Grotesque, then, would be another moment in the endlessly repeating struggle between a pulp Underground (the scandalous grottoes) and the Official culture, what Philip K. Dick called “the Black Iron Prison”. Dick’s intuition was that “the Empire had never ended”, and that history was shaped by an ongoing occult(ed) conflict between Rome and Gnostic forces. “Spectre Vs. Rector” (“I’ve waited since Caesar for this”) had rendered this clash in a harsh Murnau black and white; on Grotesque the struggle is painted in colours as florid as those used on the album’s garish sleeve (the work of Smith’s sister).

It is no accident that the words “grotesque” and “weird” are often associated with one another, since both connote something which is out of place, which either should not exist at all, or which should not exist here. The response to the apparition of a grotesque object will involve laughter as much as revulsion. “What will be generally agreed upon”, Philip Thompson wrote in his 1972 study The Grotesque “is that ‘grotesque’ will cover, perhaps among other things, the co-presence of the laughable and something that is incompatible with the laughable.”10 The role of laughter in the Fall has confused and misled interpreters. What has been suppressed is precisely the co-presence of the laughable with what is not compatible with the laughable. That co-presence is difficult to think, particularly in Britain, where humour has often functioned to ratify commonsense, to punish overreaching ambition with the dampening weight of bathos.

With the Fall, however, it is as if satire is returned to its origins in the grotesque. The Fall’s laughter does not issue from the commonsensical mainstream but from a psychotic Outside. This is satire in the oneiric mode of Gillray, in which invective and lampoonery becomes delirial, a (psycho) tropological spewing of associations and animosities, the true object of which is not any failing of probity but the delusion that human dignity is possible. It is not surprising to find Smith alluding to Jarry’s Ubu Roi in a barely audible line in “City Hobgoblins” (“Ubu le Roi is a home hobgoblin”). For Jarry, as for Smith, the incoherence and incompleteness of the obscene and the absurd were to be opposed to the false symmetries of good sense.

But in their mockery of poise, moderation and self-containment, in their logorrheic disgorging of slanguage, in their glorying in mess and incoherence, the Fall sometimes resemble a white English analogue of Funkadelic. For both Smith and Clinton, there is no escaping the grotesque, if only because those who primp and puff themselves up only become more grotesque. We could go so far as to say that it is the human condition to be grotesque, since the human animal is the one that does not fit in, the freak of nature who has no place in nature and is capable of re-combining nature’s products into hideous new forms.

On Grotesque, Smith has mastered his anti-lyrical methodology. The songs are tales, but tales half-told. The words are fragmentary, as if they have come to us via an unreliable transmission that keeps cutting out. Viewpoints are garbled; ontological distinctions (between author, text and character) are confused, fractured. It is impossible to definitively sort out the narrator’s words from direct speech. The tracks are palimpsests, badly recorded in a deliberate refusal of the “coffee table” aesthetic Smith derides on the cryptic sleeve notes. The process of recording is not airbrushed out but foregrounded, surface hiss and illegible cassette noise brandished like improvised stitching on some Hammer Frankenstein monster.

“Impression of J Temperance” was typical: a story in the Lovecraft style in which a dog breeder’s “hideous replica” (“brown sockets… Purple eyes… fed with rubbish from disposal barges”) haunts Manchester. This is a Weird tale, but one subjected to modernist techniques of compression and collage. The result is so elliptical that it is as if the text — part-obliterated by silt, mildew and algae — has been fished out of the Manchester ship canal (which Hanley’s bass sounds like it is dredging).

“‘Yes’, said Cameron, ‘And the thing was in the impression of J Temperance.’”

The sound on Grotesque is a seemingly impossible combination of the shambolic and the disciplined, the cerebral-literary and the idiotic-physical. The obvious parallel was the Birthday Party. In both groups, an implacable bass holds together a leering, lurching schizophonic body whose disparate elements strain like distended, diseased viscera against a pustule and pock-ridden skin (“a spotty exterior hides a spotty interior”). Both the Fall and the Birthday Party reached for pulp horror imagery rescued from the white trash can as an analogue and inspiration for their perverse “return” to rock and roll (cf. also the Cramps). The nihilation that fired them was a rejection of a pop that they saw as self-consciously sophisticated, conspicuously cosmopolitan, a pop which implied that the arty could only be attained at the expense of brute physical impact. Their response was to hyperbolically emphasise crude atavism, to embrace the unschooled and the primitivist.

The Birthday Party’s fascination was with the American “junkonscious”, the mountain of semiotic/narcotic trash lurking in the hindbrain of a world population hooked on America’s myths of abjection and omnipotence. The Birthday Party revelled in this fantasmatic Americana, using it as a way of cancelling an Australian identity that they in any case experienced as empty, devoid of any distinguishing features.

Smith’s r and r citations functioned differently, precisely as a means of reinforcing his Englishness and his own ambivalent attitude towards it. The rockabilly references are almost like “What If?” exercises. What if rock and roll had emerged from the industrial heartlands of England rather than the Mississippi Delta? The rockabilly on “Container Drivers” or “Fiery Jack” is slowed by meat pies and gravy, its dreams of escape fatally poisoned by pints of bitter and cups of greasy spoon tea. It is rock and roll as Working Men’s Club cabaret, performed by a failed Gene Vincent imitator in Prestwich. The “What if?” speculations fail. Rock and roll needed the endless open highways; it could never have begun in Britain’s snarled up ring roads and claustrophobic conurbations.

For the Smith of Grotesque, homesickness is a pathology. (In the interview on the 1983 Perverted by Language video, Smith claims that being away from England literally made him sick.) There is little to recommend the country which he can never permanently leave; his relationship to it seems to be one of wearied addiction. The fake jauntiness of “English Scheme” (complete with proto-John Shuttleworth cheesy cabaret keyboard) is a squalid postcard from somewhere no one would ever wish to be. Here and in “C and Cs Mithering”, the US emerges as an alternative (in despair at the class-ridden Britain of “sixty hours and stone toilet back gardens”, the “clever ones” “point their fingers at America”), but there is a sense that, no matter how far he travels, Smith will in the end be overcome by a compulsion to return to his blighted homeland, which functions as his pharmakon, his poison and remedy, sickness and cure. In the end he is as afflicted by paralysis as Joyce’s Dubliners.

On “C n Cs Mithering” a rigor mortis snare drum gives this paralysis a sonic form. “C n Cs Mithering” is an unstinting inventory of gripes and irritations worthy of Tony Hancock at his most acerbic and disconsolate, a cheerless survey of estates that “stick up like stacks” and, worse still, a derisive dismissal of one of the supposed escape routes from drudgery: the music business, denounced as corrupt, dull and stupid. The track sounds, perhaps deliberately, like a white English version of rap (here as elsewhere, the Fall are remarkable for producing equivalents to, rather than facile imitations of, black American forms).

Body a Tentacle Mess

“So R. Totale dwells underground

Away from sickly grind

With ostrich head-dress

Face a mess, covered in feathers

Orange-red with blue-black lines

That draped down to his chest

Body a tentacle mess

And light blue plant-heads.”

— The Fall, “The N.W.R.A”11

But it is the other long track, “The N.W.R.A.”, that is the masterpiece. All of the LP’s themes coalesce in this track, a tale of cultural political intrigue that plays like some improbable mulching of T.S. Eliot, Wyndham Lewis, H.G. Wells, Dick, Lovecraft and Le Carré. It is the story of Roman Totale, a psychic and former cabaret performer whose body is covered in tentacles. It is often said that Roman Totale is one of Smith’s “alter-egos”; in fact, Smith is in the same relationship to Totale as Lovecraft was to someone like Randolph Carter. Totale is a character rather than a persona. Needless to say, he is not a character in the “well-rounded” Forsterian sense so much as a carrier of mythos, an inter-textual linkage between pulp fragments.

The inter-textual methodology is crucial to pulp modernism. If pulp modernism first of all asserts the author-function over the creative-expressive subject, it secondly asserts a fictional system against the author-God. By producing a fictional plane of consistency across different texts, the pulp modernist becomes a conduit through which a world can emerge. Once again, Lovecraft is the exemplar here: his tales and novellas could in the end no longer be apprehended as discrete texts but as part-objects forming a mythos-space which other writers could also explore and extend.

The form of “The N.W.R.A.” is as alien to organic wholeness as is Totale’s abominable tentacular body. It is a grotesque concoction, a collage of pieces that do not belong together. The model is the novella rather than the tale, and the story is told episodically, from multiple points of view, using a heteroglossic riot of styles and tones (comic, journalistic, satirical, novelistic): like “Call of Cthulhu” re-written by the Joyce of Ulysses and compressed into ten minutes.

From what we can glean, Totale is at the centre of a plot — infiltrated and betrayed from the start — which aims at restoring the North to glory (perhaps to its Victorian moment of economic and industrial supremacy; perhaps to some more ancient pre-eminence, perhaps to a greatness that will eclipse anything that has come before). More than a matter of regional railing against the capital, in Smith’s vision the North comes to stand for everything suppressed by urbane good taste: the esoteric, the anomalous, the vulgar sublime, that is to say, the Weird and the Grotesque itself. Totale, festooned in the incongruous Grotesque costume of “ostrich head-dress… feathers/orange-red with blue-black line/…and light blue plant-heads” is the would-be Faery King of this Weird Revolt who ends up its maimed Fisher King, abandoned like a pulp modernist Miss Havisham amongst the relics of a carnival that will never happen, a drooling totem of a defeated tilt at social realism, the visionary leader reduced, as the psychotropics fade and the fervour cools, to being a washed-up cabaret artiste once again.



Part III1

“Don’t start improvising, for Christ’s sake”

The temptation, when writing about the Fall’s work of this period, is to too quickly render it tractable. I note this by way of a disclaimer and a confession, since I am of course as liable to fall prey to this temptation as any other commentator. To confidently describe songs as if they were “about” settled subjects or to attribute to them a determinate aim or orientation (typically, a satirical purpose) will always be inadequate to the vertiginous experience of the songs and the distinctive jouissance provoked by listening to them. This enjoyment involves a frustration — a frustration, precisely, of our attempts to make sense of the songs. Yet this jouissance — something also provoked by the late Joyce, Pynchon and Burroughs — is an irreducible dimension of the Fall’s modernist poetics. If it is impossible to make sense of the songs, it is also impossible to stop making sense of them — or at least to it is impossible to stop attempting to make sense of them. On the one hand, there is no possibility of dismissing the songs as nonsense; they are not gibberish or disconnected strings of non-sequiturs. On the other hand, any attempt to constitute the songs as settled carriers of meaning runs aground on their incompleteness and inconsistency.

The principal way in which the songs were recuperated was via the charismatic persona Smith established in interviews. Although Smith scrupulously refused to either corroborate or reject any interpretations of his songs, invoking this extra-textual persona, notorious for its strong views and its sardonic but at least legible humour, allowed listeners and commentators to contain, even dissipate, the strangeness of the songs themselves.

The temptation to use Smith’s persona as a key to the songs was especially pressing because all pretence of democracy in the group has long since disappeared. By the time of Grotesque, it was clear that Smith was as much of an autocrat as James Brown, the band the zombie slaves of his vision. He is the shaman-author, the group the producers of a delirium-inducing repetition from which all spontaneity must be ruthlessly purged. “Don’t start improvising for Christ’s sake,” goes a line on Slates, the 10” EP followup to Grotesque, echoing his chastisement of the band for “showing off” on the live LP Totale’s Turns.

Slates’ “Prole Art Threat” turned Smith’s persona, reputation and image into an enigma and a conspiracy. The song is a complex, ultimately unreadable, play on the idea of Smith as “working-class” spokesman. The “Threat” is posed as much to other representations of the proletarian pop culture (which at its best meant the Jam and at its worst meant the more thuggish Oi!) as it is against the ruling class as such. The “art” of the Fall’s pulp modernism — their intractability and difficulty — is counterposed to the misleading ingenuousness of social realism.

The Fall’s intuition was that social relations could not be understood in the “demystified” terms of empirical observation (the “housing figures” and “sociological memory” later ridiculed on “The Man Whose Head Expanded’). Social power depends upon “hexes”: restricted linguistic, gestural and behavioural codes which produce a sense of inferiority and enforce class destiny. “What chance have you got against a tie and a crest?”, Weller demanded on “Eton Rifles”, and it was as if the Fall took the power of such symbols and sigils very literally, understanding the social field as a series of curses which have to be sent back to those who had issued them.

The pulp format on “Prole Art Threat” is spy fiction, its scenario resembling Tinker Tailor Soldier Spy re-done as a tale of class cultural espionage, but then compressed and cut up so that characters and contexts are even more perplexing than they were even in Le Carré’s already oblique narrative. We are in a labyrinthine world of bluff and counter-bluff — a perfect analogue for Smith’s own elusive, allusive textual strategies. The text is presented to us as a transcript of surveillance tapes, complete with ellipses where the transmission is supposedly scrambled: “GENT IN SAFE-HOUSE: Get out the pink press threat file and Brrrptzzap the subject. ( = scrambled).”

“Prole Art Threat” seems to be a satire, yet it is a blank satire, a satire without any clear object. If there is a point, it is precisely to disrupt any “centripetal” effort to establish fixed identities and meanings. Those centripetal forces are represented by the “Middle Mass” (“vulturous in the aftermath”) and “the Victorian vampiric” culture of London itself, as excoriated in “Leave the Capitol”:

The tables covered in beer

Showbiz whines, minute detail

It’s a hand on the shoulder in Leicester Square

It’s vaudeville pub back room dusty pictures of white frocked girls and music teachers

The bed’s too clean

The water’s poison for the system

Then you know in your brain

LEAVE THE CAPITOL!

EXIT THIS ROMAN SHELL!

This horrifying vision of London as a Stepford city of drab conformity (“hotel maids smile in unison”) ends with the unexpected arrival of Machen’s Great God Pan (last alluded to in the Fall’s very early “Second Dark Age”, presaging the Fall’s return of the Weird.

The Textual Expectorations of Hex

“He’d been very close to becoming ex-funny man celebrity. He needed a good hour at the hexen school…”

— Press release for Hex Enduction Hour

Hex Enduction Hour was even more expansive than Grotesque. Teeming with detail, gnomic yet hallucinogenically vivid, Hex was a series of pulp modernist pen portraits of England in 1982. The LP had all the hubristic ambition of prog combined with an aggression whose ulcerated assault and battery outdid most of its post-punk peers in terms of sheer ferocity. Even the lumbering “Winter” was driven by a brute urgency, so that, on side one, only the quiet passages in the lugubrious “Hip Priest” — like dub if it had been invented in drizzly motorway service stations rather than in recording studios in Jamaica — provided a respite from the violence.

Yet the violence was not a matter of force alone. Even when the record’s dual-drummer attack is at its most poundingly vicious, the violence is formal as much as physical. Rock form is disassembled before our ears. It seems to keep time according to some system of spasms and lurches learned from Beefheart. Something like “Deer Park” — a whistle-stop tour of London circa 82 sandblasted with “Sister Ray”-style white noise — screams and whines as if it is about to fall apart at any moment. The “bad production” was nothing of the sort. The sound could be pulverisingly vivid at times: the moment when the bass and drums suddenly loom out of the miasma at the start of “Winter” is breathtaking, and the double-drum tattoo on “Who Makes the Nazis?” fairly leaps out of the speakers. This was the space rock of Can and Neu! smeared in the grime and mire of the quotidian, recalling the most striking image from The Quatermass Xperiment: a space rocket crash-landed into the roof of a suburban house.

In many ways, however, the most suggestive parallels come from black pop. The closest equivalents to the Smith of Hex would be the deranged despots of black sonic fiction: Lee Perry, Sun Ra and George Clinton, visionaries capable of constructing (and destroying) worlds in sound.

As ever, the album sleeve (so foreign to what were then the conventions of sleeve design that HMV would only stock it with its reverse side facing forward) was the perfect visual analogue for the contents. The sleeve was more than that, actually: its spidery scrabble of slogans, scrawled notes and photographs was a part of the album rather than a mere illustrative envelope in which it was contained.

With the Fall of this period, what Gerard Genette calls “paratexts”2 — those liminal conventions, such as introductions, prefaces and blurbs, which mediate between the text and the reader — assume special significance. Smith’s paratexts were clues that posed as many puzzles as they solved; his notes and press releases were no more intelligible than the songs they were nominally supposed to explain. All paratexts occupy an ambivalent position, neither inside nor outside the text: Smith uses them to ensure that no definite boundary could be placed around the songs. Rather than being contained and defined by its sleeve, Hex haemorrhages through the cover.

It was clear that the songs weren’t complete in themselves, but part of a larger fictional system to which listeners were only ever granted partial access. “I used to write a lot of prose on and off”, Smith would say later. “When we were doing Hex I was doing stories all the time and the songs were like the bits left over.” Smith’s refusal to provide lyrics or to explain his songs was in part an attempt to ensure that they remained, in Barthes’ terms, writerly. (Barthes opposes such texts, which demand the active participation of the reader, to “readerly” texts, which reduce the reader to the passive role of consumer of already-existing totalities.)

Before his words could be deciphered they had first of all to be heard, which was difficult enough, since Smith’s voice — often subject to what appeared to be loud hailer distortion — was always at least partially submerged in the mulch and maelstrom of Hex’s sound. In the days before the internet provided a repository of Smith’s lyrics (or fans’ best guesses at what the words were), it was easy to mis-hear lines for years.

Even when words could be heard, it was impossible to confidently assign them a meaning or an ontological “place”. Were they Smith’s own views, the thoughts of a character or merely stray semiotic signal? More importantly: how clearly could each of these levels be separated from one another? Hex’s textual expectorations were nothing so genteel as stream of consciousness: they seemed to be gobbets of linguistic detritus ejected direct from the mediatised unconscious, unfiltered by any sort of reflexive subjectivity. Advertising, tabloid headlines, slogans, pre-conscious chatter, overheard speech were masticated into dense schizoglossic tangles.

“Who wants to be in a Hovis advert anyway?”

“Who wants to be in a Hovis/advert/anyway?” Smith asks in “Just Step S’Ways”, but this refusal of cosy provincial cliché (Hovis adverts were famous for their sentimentalised presentation of a bygone industrial North) is counteracted by the tacit recognition that the mediatised unconscious is structured like advertising. You might not want to live in an advert, but advertising dwells within you. Hex converts any linguistic content — whether it be polemic, internal dialogue, poetic insight — into the hectoring form of advertising copy or the screaming ellipsis of headline-speak. The titles of “Hip Priest” and “Mere Pseud Mag Ed”, as urgent as fresh newsprint, bark out from some Voriticist front page of the mind.

As for advertising, consider “Just Step S’Ways” opening call to arms: “When what used to excite you does not/like you’ve used up all your allowance of experiences.” Is this an existentialist call for self re-invention disguised as advertising hucksterism, or the reverse? Or take the bilious opening track, “The Classical”. “The Classical” appears to oppose the anodyne vacuity of advertising’s compulsory positivity (“this new profile razor unit”) to ranting profanity (“hey there fuckface!”) and the gross physicality of the body (“stomach gassss”). But what of the line, “I’ve never felt better in my life?” Is this another advertising slogan or a statement of the character’s feelings?

It was perhaps the unplaceability of any of the utterances on Hex that allowed Smith to escape censure for the notorious line, “where are the obligatory niggers?” in “The Classical”. Intent was unreadable. Everything sounded like a citation, embedded discourse, mention rather than use.

Smith returns to the Weird tale form on “Jawbone and the Air Rifle”. A poacher accidentally causes damage to a tomb, unearthing a jawbone which “carries the germ of a curse/of the Broken Brothers Pentacle Church.” The song is a tissue of allusions — James (“A Warning to the Curious”, “Oh, Whistle and I’ll Come to You, My Lad”), Lovecraft (“The Shadow over Innsmouth”), Hammer Horror, The Wicker Man — culminating in a psychedelic/psychotic breakdown (complete with torch-wielding mob of villagers):

He sees jawbones on the street

Advertisements become carnivores

And roadworkers turn into jawbones

And he has visions of islands, heavily covered in slime.

The villagers dance round pre-fabs

And laugh through twisted mouths.

“Jawbone” resembles nothing so much as a League of Gentlemen sketch, and the Fall have much more in common with the League of Gentlemen’s febrile carnival than with witless imitators such as Pavement. The co-existence of the laughable with that which is not laughable: a description that captures the essence of both the Fall and The League of Gentlemen’s grotesque humour.

“White face finds roots”

“Below, black scars winding through the snow showed the main roads. Great frozen rivers and snow-laden forest stretched in all directions. Ahead they could just see a range of old, old mountatins. It was perpetual evening at this time of year, and the further north they went, the darker it became. The white lands seemed uninhabited, and Jerry could easily see how the legends of trolls, Jotunheim, and the tragic gods — the dark, cold, bleak legends of the North — had come out of Scandinavia. It made him feel strange, even anachronistic, as if he had gone back from his own age to the Ice Age.”

— Michael Moorcock, The Final Programme3

On Hex’s second side, mutant r and r becomes r and Artaud as the songs become increasingly delirial and abstract. “Who Makes the Nazis” — as lunar as Tago Mago, as spacey-desolated as King Tubby at his most cavernous –- is a TV talk show debate rendered as some Jarry-esque pantomime, and composed of leering backing vocals and oneiric-cryptic linguistic fragments: “longhorn breed… George Orwell Burmese police… Hate’s not your enemy, love’s your enemy, murder all bush monkeys…”

“Iceland”, recorded in a lava-lined studio in Reykjavík, is a fantasmatic encounter with the fading myths of North European culture in the frozen territory from which they originated. “White face finds roots”, Smith’s sleeve-notes tell us. The song, hypnotic and undulating, meditative and mournful, recalls the bone-white steppes of Nico’s The Marble Index in its arctic atmospherics. A keening wind (on a cassette recording made by Smith) whips through the track as Smith invites us to “cast the runes against your own soul” (another James’ reference, this time to his “Casting the Runes”).

“Iceland” is rock as ragnarock, an anticipation (or is it a recapitulation) of the End Times in the terms of the Norse “Doom of the Gods”. It is a Twilight of the Idols for the retreating hobgoblins, cobolds and trolls of Europe’s receding Weird culture, a lament for the monstrosities and myths whose dying breaths it captures on tape:

Witness the last of the god men…

A Memorex for the Krakens





scritti’s sweet sickness1

“His new album is called White Bread, Black Beer…

‘Why? It’s pretty much all I live on — Guinness and a lovely, soft, gooey, terribly-bad-for-you white bread from the local Turkish bakery. It’s also a reference to when I worked with all these R&B musicians in New York in the 80s — if you played something they didn’t like they’d frown and say, “Oh man, that’s so white-bread”. Meaning that it came from that “white” pop culture which is seen as largely voided of nutrition, substance, goodness, or indeed “soul”. And that definitely got my antennae going, because I’m mistrustful of “soul” and I very much like white, processed pop music. Which, in a way, is what this album celebrates.’”

— Interview with Green Gartside, Time Out2

“Instead of any fulfilment or resolution, Scritti’s music delivers the bliss of the lover’s discourse in all its ellipses, contradiction and repetition, its endless pursuit of an unattainable object. The disembodied, depthless, non-linear effects, and the borrowing of pop’s language of love try to undo desire’s usual articulation in coherent drives and stable identity while reinscribing or repeating the very ‘soul’ language that’s used to complete the self in today’s pop: the sweet nothings heard beside, within the sexual healing.”

— Paul Oldfield, “After Subversion: Pop Culture and Power”3

A fascinating conjunction: listening to Scritti Politti’s quietly stunning new album — or rather being seduced and ravished by it — while reading Mladen Dolar’s A Voice and Nothing More. If, as Simon Reynolds claims,4 White Bread, Black Beer is an album without a “sonic concept”, must we conclude that the songs are Green’s version of a soul-baring? After all the deferrals, the veilings, the deviations, finally a revelation: this is me? The album’s title seems to invite such an interpretation, suggesting a negative alchemy,

the reversion of sublime agalma into foodstuffs. Without a sonic concept, we are left only with the honey-pure voice, one of the most distinctive in pop — and the voice, so we have always been told, is the bearer of pure presence, guarantor of authenticity and veracity…

This, precisely, is what Dolar challenges. Dolar’s claim is not that Derrida was wrong that the voice has been privileged in a certain version of metaphysics, but that this has never been the whole story. “There exists a different metaphysical history of voice, where the voice, far from being the safeguard of presence, was considered to be dangerous, threatening and possibly ruinous.”5 Tellingly, Dolar’s alternative history of metaphysics goes via the treatment of music. (Incidentally, it is hard not to read Plato’s admonition, quoted by Dolar, that “a () change to a new type of music is something to beware of as a hazard of all our fortunes… f ()or the modes of music are never disturbed without unsettling of the most fundamental political and social conventions” as a critique of both PoMo popism and nostalgic rockism). Dolar’s argument is that Law-Logos has always sought to differentiate itself from a voice conceived of as feminine and chaotic, but Logos cannot extirpate the voice, and indeed depends upon it: what is the fundamental expression of the Law if not the voice of the Father?

How could your nothings be so sweet?

What to make of Green’s voice, then? Or, to pose the same question from the other side: what is the minimal difference that has always separated Scritti’s deconstructions from the real thing? There’s a tendency to locate Green’s undoings and unsettlings on the level of signifiers, as if his subversion were all to do with wordplay, and his voice were merely a site for natural expressivity. But, as Dolar establishes, the “object voice” is neither the voice stripped of all sensual qualities in order to become the neutral transmitter of signifiers, nor the voice stripped of all signification in order to become a pure source of aesthetic pleasure. With Green’s voice, we continually slide between two types of non-sense: the nonsense of “the lover’s discourse”, the nursery-rhyme-like reiterations of baby-talk phrases that are devoid of meaning, but which are nevertheless the most important utterances people perform or hear; and also the nonsense of the voice as sound, another kind of sweet nothing. That is why Green’s lyrics look very different when you read them; the voice almost prevents you hearing them except as senseless sonorous blocks, mechanically repeated refrains.

What is disturbing about Cupid and Psyche 85 by comparison with the new pop that preceded it is precisely its lack of any self-conscious meta-presence. This is where I slightly disagree with Simon, when he argues that Cupid and Psyche is “about love rather than in love”. It seems to me that what makes Cupid and Psyche so disturbingly depthless is precisely the absence of that space between the song’s form and the subject; the songs instantiate the lover’s discourse, they do not comment on it. Cupid and Psyche’s songs, creepily, aren’t about anything, any more than love itself is. Compare Cupid and Psyche with ABC’s The Lexicon of Love (an album of love songs about love songs, if ever there was one), for instance. Martin Fry’s presence is ubiquitous in The Lexicon of Love, manifesting itself in every raised eyebrow and set of inverted commas. But on Cupid and Psyche we get precious little sense of a “real”, biographical Green behind or beyond the record; as opposed to self-consciousness, we have “reflexivity without a self (not a bad name for the subject).”6 There is only the void, the voice and the signifying chain, unraveling forever in a shopping mall of mirrors, a whispering gallery of sweet nothings… But what is disturbing about Cupid and Psyche is the suggestion that this really is love, this impersonal, idiot rhyming is all love is. That is why Cupid and Psyche is far more unsettling than the supposed “reversion to a pre-linguistic condition” of the “Kristevan” psychedelic rock celebrated by Simon in the late Eighties (and mentioned in the Paul Oldfield essay I cited above as a point of comparison with Scritti); the supposed “oceanic dissolution of self” assumes not only that such a dissolution can be attained, but that there is a “real self” that can be dissolved. Like the first two Roxy albums, Cupid and Psyche’s message is far more radical: the supposed “real”, “authentic” self, with its emotional core, is a structural illusion; our most treasured “inner” feelings are trite repetitions; there is no intimate, only an extimate.

I guess it’s a sickness/that keeps me wanting…

The excess of Green’s voice resides in its sweetness, a sweetness that seems unhealthy, sickly, which puts us on our guard even as it seduces us. Green’s voice is synthetic, candied, rather than authentic, wholesome. It already sounds inhuman, so that, upon first hearing rave’s pitched-up chirruping vocals, the obvious comparison was with Scritti’s androgynous cooing. All of this is anticipated on the track that I find most captivating when I listen to Cupid and Psyche now, the machine ballad, “A Little Knowledge”, in which Green duets with what sounds like a woman, but which is in fact a Fairlight-sprite, a synthetic succubus constructed from his own voice pitched up. (This exchange with a synthetic spectre happens before the “real woman”, session singer B.J. Nelson, officially comes in…)

It’s worth remembering at this point that Green is very much the white ghost at the revel of contemporary black pop. At least since More Brilliant Than Sun, disco, techno and house’s (non)roots in white synthetics have been exposed — Moroder inducting Donna Summer into a labyrinth of synthesizers, Chic wanting to be Roxy Music, Cybotron stealing Ultravox’s accents and sound — but Cupid and Psyche’s function as a template for contemporary R&B is far less rehearsed. Specifically via its influence on Jam and Lewis’ production of Janet Jackson’s epochal Control, but more generally through its intuition — or entrepreneurial leap — that the flesh and blood of (what was then called) soul could be sutured with hip-hop’s artificiality and abstraction machine, Cupid and Psyche instituted a “new paradigm” for globalised pop. Skank Bloc Bologna has become the blobal retail arcade of capital. Cupid and Psyche is chillingly impersonal, but in a way that is much different to the staged impersonality of Kraftwerk, Numan and Visage which fascinated black American hip-hoppers, techno and house pioneers in the early Eighties. Scritti’s erasure of soul goes by way of a neurotically noteperfect, ultra-fastidious simulation of a hyper-Americanised “language of love”. It is no longer a matter of technical machines versus real emotional beings, but of “authentic emotion” as itself the refraining of signifying and sonorous machines. (It is therefore no surprise that another destroyer of soul, Miles Davis, should have covered Scritti songs and collaborated with Green.)

All of which goes some way to explaining the title of the new album, which initially seems grossly inappropriate, since the songs’ souffle lightness could not be further from carnal carbohydrate stodge or beery bloating. But what if these substances are not “basic” and “life-giving” but the non-vital excess without which life would be nothing? What if “white bread” indicates not the normal and the nutritious but the synthetic, and “black” beer indicates not the homey and the heavy but the addictive?

There is a performative flatness about the opening track and first single, “The Boom Boom Bap”; it a song about longing and addiction, which is itself arrestingly, gorgeously addictive. I can honestly say that I was hooked from the moment I heard Green sing the opening phrase, the song’s title. “The Boom Boom Bap” is so sublimely, achingly poised that the temptation is to keep hitting rewind, to remain lost in the song’s plateau, in which pop’s habitual urgencies are anti-climatically suspended.

Play it over and over again/play it over and over again

“The Boom Boom Bap”, as Green told Simon, is ostensibly about the thin line “between being in love with something and being unhealthily addicted to it”. The three addictions with which the song deals are drinking, hiphop — “the title itself is named after hip-hop’s bass-boom and syncopated breakbeats” — and love. Addiction is the pathological motor of life. “The beat of my life” is not any natural, biological rhythm but the non-organic pulse of the (death) drive. “If hooks could kill”, Green muses, knowing that of course they can; that being hooked can be lethal, but that not being hooked on anything is even more deadly and deadening.

When you do eventually pull yourself out of the honeyed embrace of “The Boom Boom Bap”, you find yourself yielding to an album of folds and fragments, slivers and sketches, in which everything comes to an end before you expect it to (amplifying your longing to hear it, again and again). Thankfully, Green’s obsession with hip-hop emerges not through the brute presence of rap (what could be more present, now, than rap?), but via a certain absence in the production which prevents the tracks ever closing into organic wholeness.

I was discussing with Owen the other week how mid-Eighties technology drew almost all pop into an arid, dated, hyper-glossed blandness: the two most conspicuous exceptions to this trend were Cupid and Psyche (which succeeds precisely because of its total identification with the time and the technics) and Kate Bush’s Hounds of Love. White Bread, Black Beer is like Green’s late-arriving Hounds of Love, an album in which pop’s history (and his own) can be re-visited without being reiterated, in which styles can be traversed without their ever being a question of inconsistent eclecticism. The very refusal to strain for contemporaneity makes the album far more now than it would have been if it engaged in an unseemly pursuit of street cool.

The references to London, to “British Homes Stores”, to the names of Green’s schoolteachers, restore some of the locality that was remorselessly stripped away by the proto-Starbucks “third place” mid-Atlantic sheen of Cupid and Psyche. This, evidently, also means a restoration of some biographical specificity; the songs are no longer lover’s labyrinths that anyone can enter, but memory lanes some of whose landmarks only Green can recognise. Amidst all of the trails of influence you can trace across the album, those Appolinians, Brian Wilson and Paul McCartney, recur most insistently. Would the album then be a redemption through melody? A recovery — from sickness? A recovery — of the self?

And when I’m with you baby

I know just who I am

And no one understands the way that you do

Darling

Hearing Green sing lines like these is a curiously haunting and unsettling experience, since Green’s voice carries with it all those Cupid and Psyche traces which ironise and undercut any gestures towards “really meaning it” or “really being” anything. In any case, listen closer to the song in which those lines occur (“Locked”), and all is not as it seems. “People want a piece of me”, Green sings, “but who they get is not what she seems”. In any case, autobiography would still be a form of writing (and the most deceptive kind), and the “you” that is the usual addressee of the love song is never the ostensible partner, the “real flesh and blood person”, but the big Other. Hence David Kelsey in Highsmith’s This Sweet Sickness — a Scritti title if ever there was one — a man who conducts his pathological love affair primarily through letters written to his fantasised Other (and which are ignored and misunderstood by their supposed flesh and blood object), is the lover in its purest state… All the parallels of love with addiction on White Bread, Black Beer suggest that Green the writer still knows that love is essentially both pathology and cure, so Scritti’s sweetness remains sick, their sickness sweet…





postmodernism as pathology, part 21

The thing is, Robbie, there’s no rehabilitation from PoMo.

The sickness that afflicts Robbie Williams is nothing less than postmodernity itself. Look at Williams: his whole body is afflicted with reflexive tics, an egoarmoury of grimaces, gurns and grins designed to disavow any action even as he performs it. He is the “as if” pop star — he dances as if he is dancing, he emotes as if he is emoting, at all times scrupulously signalling — with perpetually raised eyebrows — that he doesn’t mean it, it’s just an act. He wants to be loved for “Rudebox” but, unfortunately for him, his audience demands the mawkish sentimentality of “Angels”. How Robbie must hate that song now, with its humbling reminders of dependency (Williams’ career went into the stratosphere on the basis of “Angels”) and lost success…

Let me entertain you, let me lead you

There’s surely a Robin Carmody-type analysis to be done of the parallels between Williams and Tony Blair. Williams’ first album, the tellingly-titled Life Thru a Lens was released in 1997, the year of Blair’s first election victory. There followed for both a period of success so total that it must have confirmed their most extravagant fantasies of omnipotence (Blair unassailable at two elections; Williams winning more Brit awards than any other artist). Then, a decade after their first success, an ignominious decline into irrelevance (the post-Iraq Blair limping out of office as a lame-duck leader, Williams releasing a disastrous album and checking himself into rehab on the day before this year’s Brit awards, at which he had received a derisory single nomination). Of course, there are limits to the analogy: Blair is popular in the States, whereas Robbie…

Williams and Blair are two sides of one Joker Hysterical face: two cracked actors, one given over to the performance of sincerity, the other dedicated to the performance of irony. But both, fundamentally, actors — actors to the core, to the extent that they resemble PKD simulacra, shells and masks to which one cannot convincingly attribute any inner life. Blair and Williams seem to exist only for the gaze of the other. That is why it is impossible to imagine either enduring private doubts or misgivings, or indeed experiencing any emotion whose expression is not contrived to produce a response from the other. As is well known, Blair’s total identification with his publicly-projected messianic persona instantly transforms any putatively private emotion into a PR gesture; this is the spincerity effect (even if he really means what he is saying, the utterance becomes fake by dint of its public context). The image of Blair or Williams alone in a room, decommissioned androids contemplating their final rejection by a public which once adored them, is genuinely creepy.

It is perfectly possible to imagine Robbie exhibiting public doubts, of course — indeed, as his former reflexive potency declines into reflexive impotence, he is most likely to be seen insisting upon his inadequacy and failure. No doubt this is why Williams’ announcement of his “addiction” to anti-depressants and caffeine has been greeted with a certain scepticism (suspicion has been aroused in part because of the timing of the announcement, on the eve of the Brits). But this scepticism misses the point. Williams’ sickness is, precisely, his incapacity to do or experience anything unless it provokes the attention of the other.

Or: as Liam Gallagher more succinctly put it, in words worthy of Mr Agreeable at his compassionate best:

If you’ve got a fucking problem, why do you want the whole world to know about it? I say sort yourself out. You make a fucking crap album then want everyone to feel sorry for you. What a fucking tosser.





choose your weapons1

People are often telling me that I ought to read Frank Kogan’s work, but I’ve never got around it. (Partly that’s because, Greil Marcus apart, I’ve never really tuned into much American pop criticism at all, which in my no doubt far too hasty judgement has seemed to be bogged down in a hyper-stylised faux-naif gonzoid mode that has never really appealed to me.) The — again, perhaps unfair — impression I have is that, in Britain, the battles that Kogan keeps on fighting were won, long ago, by working-class autodidact intellectuals. No doubt the two recent pieces by Kogan that Simon has linked to are grotesquely unrepresentative of his work as a whole (I certainly hope so, since it is difficult to see why so many intelligent people would take his work seriously if they weren’t), but it’s hard not to read them as symptomatic, not only of an impasse and a malaise within what I now hesitate to call “popism”, but of a far more pervasive, deeply-entrenched cultural conservatism in which so-called popism is intrinsically implicated.

Remember, in the immediate wake of 9/11, all those po-faced Adornoite proclamations that there would be “no more triviality” in American popular culture after the Twin Towers fell? There can be few who, even when the remains of the Twin Towers were smouldering, really believed that US pop culture would enter a new thoughtful, solemn and serious phase after September 11th — and it’s surely superfluous to remember, at this point, that what ensued was a newly vicious cynicism soft-focused by a piety that only a wounded Leviathan assuming the role of aggrieved victim can muster — but would anyone, then, have believed that, only six years later, a supposedly serious critic would write a piece called “Paris Hilton () is our Vietnam…”,2 especially, when, in those years, there has, like, been another Vietnam. What we are dealing with in a phrase like “Paris is our Vietnam” is not trivia — this isn’t the collective narcissism of a leisure class ignorant of geopolitics — but a self-conscious trivialisation, an act of passive nihilistic transvaluation. Debating the merits or otherwise of a boring heiress have been elevated to the status of a political struggle; and not even by preening aesthetes in some Wildean/Warholian celebration of superficiality, but by middle-aged men in sweat pants, sitting on the spectator’s armchair at the end of history and dissolutely flicking through the channels.

The end of history is the nightmare from which I am trying to awake.

At least the “Paris is Vietnam” piece laid bare the resentment of resentment that I have previously argued is the real libidinal motor of “popism” — “we love Paris all the more because others hate her (but luckily we loved her any way, honest!)”. But this latest piece3 Simon has linked to is, if anything, even more oddly pointless and indicative. Unlike the pleasantly mediocre Paris Hilton LP, the ostensible object of the piece, Backstreet Boys’ single “Everybody (Backstreet’s Back)” is actually rather good. Practically everyone I know liked it. The problem is the idea that saying this is in some way news in 2007. No word of a lie, I had to check the date on that post, assuming, at first, that it must have been written a decade ago.

The article makes me think that, if the motivating factor with British popists is, overwhelmingly, class, with Americans it might be age. Perhaps those a little deeper into middle age than I am were still subject to the proscriptions and prescriptions of a Leavisite high culture. But it seems to me that popists now are like Mick Jagger confronted with punk in 1976: they don’t seem to realise that, if there is an establishment, it is them. Even if the “Nathan” with whom Kogan debates exists — and I’ll be honest with you, I’m finding it hard to believe that he does — his function is a fantasmatic one (in the same way that Lacan argued that, if a pathologically jealous husband is proved right about his wife’s infidelities, his jealousy remains pathological): for popists to believe that their position is in any way challenging or novel, they have to keep digging up “Nathans” who contest it. But, in 2007, Nathan’s hoary old belief that only groups who write their own songs can be valid has been refuted so many times that it is rather like someone mounting a defence of slavery today — sure, there are such people who hold such a view, but the position is so irrelevant to the current conjuncture that it is quaintly antiquated rather than a political threat. There may be a small minority of pop fans who claim to hold Nathan’s views; but, given the success of Sinatra, the Supremes, Elvis Presley and the very boybands that popists think it is so transgressive to re-evaluate, those views would in most cases be performatively contradicted by the fans’ actual tastes. (Kogan does grant that the problem is not so much fans’ tastes as their accounts of them — but the unspoken assumption is that it is alright, indeed mandatory, to contest male rock fans’ accounts of their own tastes, but that the aesthetic judgements of the figure with which the popist creepily identifies, the teenage girl, ought never to be gainsaid.) (The other irony is that, if you talk to an actual teenager today, they are far more likely to both like and have heard of Nirvana than they are the Backstreet Boys.)

The once-challenging claim that for certain listeners, the (likes of) Backstreet Boys could have been as potent as (the likes of) Nirvana has been passive-nihilistically reversed — now, the message disseminated by the wider culture — if not necessarily by the popists themselves — is that nothing was ever better than the Backstreet Boys. The old high culture disdain for pop cultural objects is retained; what is destroyed is the notion that there is anything more valuable than those objects. If pop is no more than a question of hedonic stim, then so are Shakespeare and Dostoyevsky. Reading Milton, or listening to Joy Division, have been re-branded as just another consumer choice, of no more significance than which brand of sweets you happen to like. Part of the reason that I find the term “popism” unhelpful now is that implies some connection between what I would prefer to call Deflationary Hedonic Relativism and what Morley and Penman were doing in the early Eighties. But their project was the exact inverse of this: their claim was that as much sophistication, intelligence and affect could be found in the pop song as anywhere else. Importantly, the music, and the popular culture of the time, made the argument for them. The evaluation was not some fitsall-eras a priori position, but an intervention at a particular time designed to have certain effects. Morley and Penman were still critics, who expected to influence production, not consumer guides marking commodities out of five stars, or executives spending their spare time ranking every song with the word “sugar” in it on live journal communities that are the cyberspace equivalent of public school dorms.

Whereas Morley and Penman (self-taught working-class intellectuals both) complicated the relationship between theory and popular culture with writing that — in its formal properties, its style and its erudition, as well as in its content — contested commonsense, Deflationary Hedonic Relativism merely ratifies the empiricist dogmas that underpin consumerism. More than that, Owen Hatherley has astutely observed that, in addition to reiterating the standard Anglo-American bluff dismissal of metaphysics, the Deflationary Hedonistic Relativist disclaiming of theory (“we just like what we like, we don’t have a theory”) uncannily echoes the dreary mantras of the average NME indie band: “we just do what we do, anything else is a bonus”, “the music is the only important thing”. In the UK, the rhetorical fight between “popists” and indie is as much a phoney war as the parliamentary political punch-and-judy show between Cameron’s Tories and Brown’s New Labour: a storm in a ruling-class tea-cup. In both cases, the social reality is that of ex-public schoolkids carrying on their inter-house rivalries by other means. In the case of both indie and popism, there is a strangely inverted relationship to populism and the popular. While the “popists” claim to be populist but actually support music that is increasingly marginal in terms of sales figures, the indie types claim to celebrate an alternative while their preferred music of choice (Trad skiffle) has Full Spectrum Dominance (you can’t listen to Radio 2 for fifteen minutes without hearing a Kaiser Chiefs song). In many ways, because it was attempting to analyse a genuinely popular phenomenon, Simon’s defence of Arctic Monkeys was more genuinely popist than all of the popist screeds on Paris Hilton’s barely-bought LP — but of course much of the impulse behind them was the ultra-rockist desire to be seen thumbing one’s nose at critical consensus. Witness the genuinely pathetic — it certainly provokes pathos in me — attempt to whip up controversy about the workmanlike plod of Kelly Clarkson, on a blog which, in its combination of hysterical overheating and dreary earnestness, is as boring as it is symptomatic — though, I have to confess I have never managed to get to the end of a single post, a problem I have with a great many “popist” writings, including the magnum opus of popism, Morley’s Words and Music.

Much as he occasionally flails and rails against popist commonplaces (see, for instance, his recent — I would argue unwarranted — attack on Girls Aloud), Morley is as deeply integrated into Deflationary Hedonic Relativist commonsense as Penman is excluded from it. What was the strangely affectless Words and Music if not a description of the OedIpod from inside? All those friction-free freeways, those inconsequent consumer options standing in for existential choices… Yet Morley is still a theorist of the ends of history and of music, still too obviously in love with intelligence to be fully plugged into the anti-theoretical OedIpod circuitry. Even so, Ian’s silence speaks far louder than Morley’s chatter, and, after my very few dealings with Old Media, I’m increasingly seeing Ian’s withdrawal, not as a tragic failure, but as a noble retreat.

All of UK culture tends to the condition of the clip show, in which talking heads — including, of course, Morley — are paid to say what dimwit posh producers have decided that the audience already thinks over footage of what everyone has already seen. I recently had dealings with an apparatchik of Very Old Media. What you get from representatives of VOM is always the same litany of requirements: writing must be “light”, “upbeat” and “irreverent’. This last word is perhaps the key one, since it indicates that the sustaining fantasy to which the young agents of Very Old Media are subject is exactly the same as the one in which popists indulge: that they are refusing to show “reverence” to some stuffy censorious big Other. But where, in the dreary-bright, dressed-down sarky snarky arcades of postmodern culture, is this “reverence”? What is the postmodern big Other if it is not this “irreverence” itself? (Only people who have not been in a university humanities dept for a quarter of a century — i.e. not at all your bogstandard Oxbridge grad Meeja employee/leisure-time popist — could really believe that there is some ruthlessly-policed high-culture canon. When Harold Bloom wrote The Western Canon it was as a challenge to the relativism that is hegemonically dominant in English Studies.) I’ve quickly learned that “light”, “upbeat” and “irreverent” are all codes for “thoughtless” and “mundanist”. Confronted with these values and their representatives — who, as you would expect, are much posher than me — I often encounter a cognitive dissonance, or rather a dissonance between affect and cognition. Faced with the Thick Posh People who staff so much of the media, I feel inferiority — their accents and even their names are enough to induce such feelings — but think that they must be wrong. It is this kind of dissonance that can produce serious mental illness; or — if the conditions are right — rage.

Anti-intellectualism is a ruling-class reflex, whereby ruling-class stupidity is attributed to the masses (I think we’ve discussed here before the ruse of the Thick Posh Person whereby make a show of pretending to be thick in order to conceal that they are, in fact, thick.) It’s scarcely surprising that inherited privilege tends to produce stupidity, since, if you do not need intelligence, why would you take the trouble to acquire it? Media dumbing down is the most banal kind of self-fulfilling prophecy.

As Simon Frith and Jon Savage long ago noted in their NLR essay, “The Intellectuals and the Mass Media”, which Owen Hatherley recently brought to my attention again, the plain common-man pose of the typical public school and Oxbridge-educated media commentator trades on the assumption that these commentators are far more in touch with “reality” than anyone involved in theory. The implicit opposition is between media (as transparent window-on-the-world transmitter of good, solid commonsense) and education (as out-of-touch disseminator of useless, elitist arcanery). Once, media was a contested ground, in which the impulse to educate was in tension with the injunction to entertain. Now –- and the indispensable Lawrence Miles is incisive on this, as on so many other things, in his latest compendium of insights — Old Media is almost totally given over to a vapid notion of entertainment — and so, increasingly, is education.4

In my teenage years, I certainly benefited far more from reading Morley and Penman and their progeny than from the middlebrow dreariness of much of my formal education. It’s because of them, and later Simon and Kodwo, et al., that I became interested in theory and bothered to pursue it in postgraduate study. It is essential to note that Morley and Penman were not just an “application” of high theory to low culture; the hierarchical structure was scrambled, not just inverted, and the use of theory in this context was as much a challenge to the middle-class assumptions of Continental Philosophy as it was to the anti-theoretical empiricism of mainstream British popular culture. But now that teaching is itself being pressed into becoming a service industry (delivering measurable outputs in the form of exam results) and teachers are required to be both child minders and entertainers, those working in the education system who still want to induce students into the complicated enjoyments that can be derived from going beyond the pleasure principle, from encountering something difficult, something that runs counter to one’s received assumptions, find themselves in an embattled minority. Here we are now entertain us.

The credos of ruling-class anti-intellectualism that most Old Media professionals are forced to internalise are far more effective than the Stasi ever was in generating a popular culture that is unprecedentedly monotonous. Put it this way: a situation in which Lawrence Miles languishes, at the limits of mental health, barely able to leave his house, while the likes of Rod Liddle swagger around the mediascape is not only aesthetically abhorrent, it is fundamentally unjust. Contrary to the “it’s only hedonic stim” deflationary move that both Stekelmanites and popists share, popular culture remains immensely important, even if it only serves an essential ideological function as the background noise of a capitalist realism which naturalises environmental depredation, mental health plague and sclerotic social conditions in which mobility between classes is lessening towards zero.

A class war is being waged, but only one side is fighting.

Choose your side. Choose your weapons.





variations on a theme1

Music critic Paul Morley has written a catalogue essay to accompany a recent installation by American artist Cory Arcangel, a couple thousand short films about Glenn Gould (2007). Or rather, Morley has assembled most of the text in the same way that Arcangel assembled his video montage — from fragments found on the internet. Arcangel’s installation consists of a version of Bach’s Goldberg Variations (1741) meticulously constructed from YouTube samples of individual notes played by amateurs. By making the connection between YouTube and Gould, the bricolages invite a comparison between user-generated content and the production methods of the modernist-creator figure.

Does user-generated content make possible a new form of artistry, prefigured in both Gould’s approach to the recording studio and in Wendy Carlos’ synthesizer renditions of Bach? Or are Gould and Carlos being positioned as anticipating the dissolution of the individual artist in an anonymous digital network?

Morley’s own position on these questions has been studiedly equivocal. Originally a journalist at the NME in the late 1970s, Morley has found himself gradually absorbed into the 1990s clip-show culture of chatty ephemera. His embrace of superficiality and gloss in the early Eighties played more than a small part in ushering that culture in, though what was envisaged as a revolt against post-punk austerity plays very differently in today’s pervading climate of populism. In the introductory section of Morley’s recent catalogue essay — seemingly the only section that he wrote as such — the text is positioned as the sequel to his 2003 book, Words and Music: A History Of Pop In The Shape Of A City. Morley is averse to definitive claims, but Words And Music seemed to want to establish a continuity between high modernism and pop at its most apparently disposable, a continuity exemplified by the book’s opening juxtaposition of Kylie Minogue and experimental composer Alvin Lucier. But Morley’s ultimate motive was artfully veiled by a spaghetti junction of convolutions and deferrals; it was unclear whether he sought to vindicate the avant-garde through its impact on popular culture or to ennoble pop via its incorporation of the avant-garde, or both, or neither.

His Arcangel essay retains a certain amount of this ambivalence, but, in its gnomic brevity, it is far more suggestive than the often tiresome Words And Music, which felt at times like being trapped inside an interminable series of iPod playlists. Via thumbnail portraits of the likes of Gould, Carlos, the BBC Radiophonic Workshop’s Delia Derbyshire, Genesis P-Orridge and Robert Moog, the montage follows a number of associative lines connecting music, transgendering and electronics. By paralleling Arcangel’s methodology, Morley might have wanted to imply that the electronic music of the Sixties, Seventies and Eighties paved the way for the networked world of user-generated content of which YouTube is a part. But the pop examples that figure in the text most insistently — Gary Numan, the Human League — belong not to this decade, but to a post-punk moment thirty years ago. Perhaps in spite of itself, the text ends up reading less like a justification of twenty-first-century popular culture and its modes of consumption and more like a requiem for a past moment of popular modernism, a lost circuit between pop, new technological developments and the avant-garde.

Morley’s text implicitly poses some of the questions which an essay in Philosophy Now by Alan Kirby addresses explicitly.2 Kirby talks of a new type of “text” — a text we are all now very familiar with — “whose content and dynamics are invented or directed by the participating viewer or listener (although these latter terms, with their passivity and emphasis on reception, are obsolete: whatever a telephoning Big Brother voter or a telephoning 6-0-6 football fan are doing, they are not simply viewing or listening).” Oddly, Kirby labels these texts “pseudo-modernist”, arguing that this “pseudo-modernism” has now superseded postmodernism. Kirby’s understanding of postmodernism suffers from being exclusively derived from literary studies, which has defined postmodernism narrowly, in terms of a set of reflexive strategies based around so-called “meta-fictions” such as Vladimir Nabokov’s Pale Fire (1962). But far from marking a move beyond postmodernism, the shift from creator to recipient, from producer to consumer, that Kirby describes is exactly what the most acute theorists of postmodernism — Jean Baudrillard and Fredric Jameson — had long ago got to grips with. Reading Baudrillard’s texts from the 1970s, with their extended discussions of reality TV and the “referendum mode”, is to confront analyses that now seem preternaturally prescient. What has been made obsolete is not Baudrillard and Jameson’s mordant anticipations of the monotony that would ensue in the name of viewer and consumer “involvement”, but those positions which claimed that eroding the privilege of the author and the artist carries a subversive charge.

What Kirby calls the “new weightless nowhere of silent autism” has eroded the popular modernism which Morley once belonged to just as much as it has eliminated the high cultural resources of traditional modernism. As Kirby indicates, far from leading to new forms, user-generated content has tended towards retrenchment and consolidation — for example, YouTube (for the most part) recycles old material, or else provides a space in which millions of aspirant stars ape idols whose status — established by the old systems of distribution and valuation — remains secure. Instead of being cowed by the relentless demands for viewer participation, both cultural producers and the much-derided “gatekeepers” need to find new ways of asserting the primacy of production over consumption. They need to find ways of stepping outside seamless circuits in which “everyone” is implicated but no one gets what they want. In another catalogue essay for a couple thousand short films, curator Steven Bode argues that Arcangel’s installation is “less an advert for networked participatory culture than an index of people’s increasing atomisation”. If postmodern culture presents a kind of networked solipsism, perhaps what Gould can now teach us most is the value of disappearance from the screens that eagerly seek our image. Gould, who famously retired early from concert playing, showed that sometimes it is necessary to withdraw in order to find better ways to connect.





running on empty1

In 2006, James Kirby, the man behind the V/Vm record label and the Caretaker, began a download project called The Death of Rave. The tracks have a thin, almost translucent quality, as if they are figments or phantoms of the original, exhilarating sound of rave. When I interviewed Kirby recently, he explained that the project had been initiated to commemorate a certain energy that he believes has disappeared from dance music. (Energy Flash was, of course, the title the critic Simon Reynolds gave to his compendious study of rave music and its progeny.) The question is: were rave and its offshoots jungle and garage just that — a sudden flash of energy that has since dissipated? More worryingly, is the death of rave only one symptom of an overall energy crisis in culture? Are cultural resources running out in the same way as natural resources are?

Those of us who grew up in the decades between the 1960s and the 1990s became accustomed to rapid changes in popular culture. Theorists of future shock such as Alvin Toffler and Marshall McLuhan plausibly claimed that our nervous systems were themselves sped up by these developments, which were driven by the development and proliferation of technologies. Popular artefacts were marked with a technological signature that dated them quite precisely: new technology was clearly audible and visible, so that it would be practically impossible, say, to confuse a film or a record from the early 1960s with one from even half a decade later.

The current decade, however, has been characterised by an abrupt sense of deceleration. A thought experiment makes the point. Imagine going back fifteen years in time to play records from the latest dance genres — dubstep, or funky, for example — to a fan of jungle. One can only conclude that they would have been stunned — not by how much things had changed, but by how little things have moved on. Something like jungle was scarcely imaginable in 1989, but dubstep or funky, while by no means pastiches, sound like extrapolations from the matrix of sounds established a decade and a half ago.

Needless to say, it is not that technology has ceased developing. What has happened, however, is that technology has been decalibrated from cultural form. The present moment might in fact be best characterised by a discrepancy between the onward march of technology and the stalling, stagnation and retardation of culture. We can’t hear technology any more. There has been a gradual disappearance of the sound of technological rupture — such as the irruption of Brian Eno’s analogue synth in the middle of Roxy Music’s “Virginia Plain”, or the cut-and-paste angular alienness of early rave — that pop music once taught us to expect. We still see technology, perhaps, in cinema CGI, but CGI’s role is somewhat paradoxical: its aim is precisely to make itself invisible, and it has been used to finesse an already established model of reality. High-definition television is another example of the same syndrome: we see the same old things, but brighter and glossier.

The principal way in which technology now makes itself felt in culture is of course in the areas of distribution and consumption. Downloading and Web 2.0 have famously led to new ways of accessing culture. But these have tended to be parasitic on old media. The law of Web 2.0 is that everything comes back, whether it be adverts, public information films or long-forgotten TV serials: history happens first as tragedy, then as YouTube. The pop artists who supposedly became successful because of web clamour (Sandi Thom, Arctic Monkeys) turned out to be quaintly archaic in form; in any case, they were pushed through the familiar promotional machinery of big record companies and PR firms. There is peer-to-peer distribution of culture, but little sign of peer-to-peer production.

The best blogs are one exception; they have bypassed the mainstream media, which, for the reasons described by Nick Davies in last year’s Flat Earth News, has become increasingly conservative, dominated by press releases and PR. In general, however, Web 2.0 encourages us to behave like spectators. This is not only because of the endless temptations to look back offered by burgeoning online archives, it is also because, thanks to the ubiquity of recording devices, we find ourselves becoming archivists of our own lives: we never experience live events, because we are too busy recording them.

Yet instantaneous exposure deprives cultures of the time and space in which they can grow. There is as yet no Web 2.0 equivalent of the circuit that sustained UK dance music in the 1990s: the assemblage of dubplates, pirate radio and the dance floor which acted as a laboratory for the development of new sounds. This circuit was still punctuated by particular moments (the club night, the radio broadcast), but, because anything in Web 2.0 can be replayed at any time, its temporality is more diffuse. The tendency seems to be for a kind of networked solipsism, a global system of individuals consuming an increasingly homogeneous culture alone in front of the computer screen or plugged in to iPod headphones.

All of this makes Fredric Jameson’s theories about postmodern culture’s inability to image the present more compelling than ever. As the gap between cultural breaks becomes ever longer and the breaks themselves become ever more modest and slight, it is beginning to look as if the situation might be terminal. Alex Williams, who runs the Splintering Bone Ashes blog, goes so far as to claim that “what we have experienced is merely a blip, perhaps never to be again repeated — 150 or so years of extreme resource bingeing, the equivalent of an epic amphetamine session. What we are already experiencing is little more than the undoubtedly grim ‘comedown’ of the great deceleration.” This might be too bleak. What is certainly clear, however, is that technology will not deliver new forms of culture all on its own.





you remind me of gold: dialogue with mark fisher and simon reynolds1

Kaleidoscope Magazine: The first question is linked to my experiencing UK dance music of the Nineties as a person living in a different country — via imported records and the British music press — and one interesting thing was the idea of “futurism” that seemed to permeate the scenes: in terms of how the press presented the music as an area of advancement because made with “machines”. What are, if any, are the futuristic elements and aspects in UK Nineties dance music and culture?

Simon Reynolds: The word “future” does not crop up in contemporary dance music discourse — in either the conversations surrounding the music, or in track titles and artist names — with anything like the frequency it did during the Nineties. From artists with names like Phuture, the Future Sound of London, Phuture Assassins, etc. to UK rave/early jungle which teemed with titles like “Futuroid”, “Living for the Future”, “We Are the Future”, etc., the whole culture seemed tilted forwards. Everyone was in a mad rush to reach tomorrow’s sound ahead of everyone else. That ethos continued into the early days of dubstep with the club name FWD». But looking at the last half-decade or so of UK dance music, I really struggle to think of any equivalent examples. Soul Jazz just put out a compilation of post-dubstep called Future Bass, and then you have the “future garage” sub-genre, although the irony here is that this direction involves going back to the 2step rhythm template circa 1998-2000. But generally speaking the whole idea of the future seems to have lost its libidinal charge for electronic producers and for fans alike. This seems to reflect the fact that dance music in the UK, and globally, is no longer organised along an extensional axis (projecting into the unknown, like an arrow fired into the night sky) but is intensive: it makes criss-crossing journeys within the vast terrain that was mapped out during the hyper-speed Nineties.

It seems symptomatic to me that “Gold”, the single off the debut album by Darkstar, is a cover of a Human League b-side from almost thirty years ago. It’s definitely an interesting move for Darkstar to make, in terms of their previous music and the scene they’re from, dubstep. But as an aesthetic act the creativity involved is curatorial rather than innovation in the traditional-modernist sense: it’s about finding an obscure, neglected song and re-situating it within the historical narratives of British electronic music. The whole idea of doing a cover version, which is totally familiar as an artistic move within rock, is still pretty unusual within electronic music culture. What also struck me listening to the remake next to the original (which I’d never heard before) is that both versions sound more or less as “futuristic” as each other. Well, the Darkstar reinterpretation obviously is technically more advanced in many ways; there are things done on it sonically that weren’t available to the Human League and their producer Martin Rushent. But in terms of the overall aesthetic sensation generated, neither version seems any further “into the future” than the other. Certainly, it doesn’t feel like there’s thirty years difference between the two. And it’s that precisely that feeling — that the Human League are contemporary with us — that is so mysterious and hard to explain. They ought to sound to us as ancient as early Fifties fare (Johnny Ray, say, or Louis Jordan) would have done in 1981 heard next to the Human League of “Love Action”.

Mark Fisher: The problem is that the word “futuristic” no longer has a connection with any future that anyone expects to happen. In the Seventies, “futuristic” meant synthesizers. In the Eighties, it meant sequencers and cut and paste montage. In the Nineties, it meant the abstract digital sounds opened up by the sampler and its function such as time-stretching. In each of these cases, there was a sense that, through sound, we were getting a small but powerful taste of a world that would be completely different from anything we had hitherto experienced. That’s why a film like Terminator, with its idea of the future invading the present, was so crucial for Nineties dance music. Now, insofar as “futuristic” has any meaning, it is as a vague but fixed style, a bit like a typographical font. “Futuristic” in music is something like “Gothic” in fonts. It points to an already existing set of associations. “Futuristic” means something electronic, just as it did in the Sixties and Seventies. We’ve entered the flattened out temporality that Simon describes — the Nineties ought to be as distant as the Sixties felt in 1980, but now the Sixties, the Eighties and the Nineties belong to a kind of postmoderncuratorial simultaneity.

To take up the example that Simon uses. When you compare the Darkstar cover of “Gold” to the Human League original, it’s not just that one is no more futuristic than the other. It is that neither are futuristic. The Human League track is clearly a superseded futurism, while the Darkstar track seems to come after the future. I should say at this point that the Darkstar album is my favourite album of the year — I’ve become obsessed with it. (It might be worth noting here that one thing that’s happened since 2000 in dance music is the rise of the album. The Nineties was about scenes and singles; there weren’t any great albums. But since 2000, there have been Dizzee Rascal’s debut, the Junior Boys records, the two Burial albums and the Darkstar record. The temporal malaise I’m talking about hasn’t meant there are no good records — that’s not the problem at all.) Partly why I enjoy the Darkstar album is because, like many of the most interesting records of the last six or seven years, it seems to be about the failure of the future. This feeling of mourning lost futures isn’t so explicit as it was with the Burial records, but I believe it’s there at some level with Darkstar. Where with Burial you have a feeling of dereliction and spectrality, the lost future haunting the dead present, with Darkstar it’s a question of electronic rot, digital interference.

What you could hear behind so much Nineties dance music was a competitive drive — to sonically rearticulate what “futuristic” meant. The No U Turn track “Amtrak” features a sample: “Here is a group trying to accomplish one thing, and that is to get into the future.” But I think it’s uncontroversial to say that no one was aiming to get into the future that actually arrived. If a junglist were pitched straight into now from the mid-Nineties, it’s hard to believe that they wouldn’t be disappointed and bemused. In the interview that I did with Kodwo Eshun which formed the appendix of Kodwo’s More Brilliant Than the Sun, he contrasts the textual exhaustion of postmodernism with the genetic concept of recombination. I think Kodwo captures very well the recombinatorial euphoria that many of us felt then — the sense that there were infinite possibilities, that new and previously unimaginable genres would keep emerging, keep surprising us. But, sadly, what’s surprising from that Nineties perspective is how little has changed in the last ten years. As Simon has said, the changes that you can hear now are not massive rushes of the future, but tiny incremental shifts. That deceleration has brought with it a sense of massively diminished expectations, which no amount of tepid boosterism can cover over. My friend Alex Williams has posited the idea that cultural resources have been depleted in the same way that natural resources were. Perhaps this is a reflection of today’s cultural depression in the same way that the Nineties concepts were an expression of that decade’s exhilaration.

This isn’t just about nostalgia for one decade — the Nineties was at the end of a process that began with the rapid development of the recording industry after the Second World War. Music became the centre of the culture because it was consistently capable of giving the new a palpable form; it was a kind of lab that focused and intensified the convulsions that culture was undergoing. There’s no sense of the new anywhere now. And that’s a political and a technological issue, not a problem that’s just internal to music.

SR: The Darkstar album could almost have been designed to please me: it’s the convergence of the hardcore continuum, hauntology, and post-punk and new pop! It’s growing on me, but initially I found it a bit washed-out and listless. Still, Mark’s reading of it is typically suggestive. And I do think it is significant that an outfit operating in the thick of the post-dubstep scene, the FWD» generation, has made a record steeped in echoes of Orchestral Manoeuvres (their first LP in particular was apparently listened to heavily during the album’s making), New Order, and other early-Eighties synthpop. It also means something that a record coming out of dance culture is all about isolation, regret, withdrawal, mournfulness.

The Darkstar record is an example of a self-conscious turn towards emotionality in UK dance. Most of the album features a human voice and songs, sung by a new member of the group recruited specifically for that role. And just this week I’ve read about two other figures from the same scene — James Blake and Subeena — who are releasing their first tracks to feature their own vocals. But this turn to expressivity seems to me as much rhetorical as it is actually going on in the music. After all hardcore, jungle, UK garage, grime, bassline house were all bursting with emotion in their different ways. What people mean by “emotional” is introspective and fragile in ways that we’ve rarely seen in hardcore continuum music. (Obviously we’ve seen plenty of that in IDM going back to its start: Global Communications and Casino in Japan actually made records inspired by the death of family members.) The idea that artists and commentators are groping towards, without fully articulating, is that dance music no longer provides the kind of emotional release that it once did, through collective catharsis. So there is this turn inwards, and also a fantasy of a kind of publicly displayed inwardness: the widely expressed artistic ideal of “I want my tracks to make people cry on the dancefloor”. Because if people were getting their release in the old way (collective euphoria), why would tears be needed.

MF: I think part of the reason I like the Darkstar record so much is that I don’t hear it as a dance record. In my view, it’s better heard almost as mainstream pop that has been augmented by some dance textures. “Aidy’s Girl is a Computer” apart, if you heard the record without knowing the history, you wouldn’t assume any connection with dubstep. At the same time, North isn’t straightforwardly a return to a pre-dance sound. Much has been made of the synthpop parallels but — and the cover of the Human League track brings this out — it doesn’t actually sound very much like Eighties synthpop at all. It’s more a continuation of a certain mode of electronic pop that got curtailed sometime in the mid-Eighties.

SR: In the Nineties, drugs — specifically Ecstasy — were absolutely integral to this communal release. One of the reasons hardcore rave was so hyper-emotional was because its audience’s brains were being flooded with artificially stimulated feelings, which could be elation and excitement but also dark or emotionally vulnerable (the comedown from Ecstasy is like having your heart broken). One thing that intrigues me about dance culture in the 2000s is the near-complete disappearance of drugs as a topic in the discourse. People are obviously still doing them, in large amounts, and in a mixed-up polydrug way just like in the Nineties. There have been a few public scares from the authorities and the mainstream media, like the talk about ketamine a few years ago, and more recently with mephedrone. But these failed to catalyse any kind of cultural conversation within the dance scene itself. It is as if the idea that choice of chemicals could have any cultural repercussions or effects on music’s evolution has completely disappeared. Compare that with the Nineties, where one of the main strands of dance discourse concerned the transformative powers of drugs. There was a reason why Matthew Collin called his rave history Altered State and why I called my own book Energy Flash. That was a reference to one of the greatest and most druggy anthems in techno — Beltram’s “Energy Flash” (which features a sample about “acid, ecstasy” — but also to the more general idea of a psychedelics-induced flash of revelation or the “body flash” caused by stimulant drugs.

The turn to emotionality at the moment seems like an echo of a similar moment in the late Nineties, when the downsides of drugs were becoming clear and I started to hear from clubbing friends that they’d been listening to Spiritualized or Radiohead. But where that was a flight from E-motionality (from the collective high, now considered false or to have too many negative side effects, towards more introspective, healing music), the new emotionality in the post-dubstep scene is emerging in a different context. I’m just speculating here, but I wonder if it has anything to do with a dissatisfaction with Internet culture, the sort of brittle, distracted numbness that comes from being meshed into a state of perpetual connectivity, but without any real connection of the kind that comes from either one-onone interactions or from being in a crowd. The rise of the podcast and the online DJ mix, which has been hyped as “the new rave” but is profoundly asocial, seems to fit in here.

KM: The concept of futurism also contains the idea that a cultural form can capture the zeitgeist of an era and facilitate/modulate the vision of the one to come and by implication revolt against past cultural practices; this might also in this case translate with the idea of “the sound of now” that was a vastly common mood of UK dance music in the Nineties, and the continuous re-organisation of label, clubs, promoters, DJs in new networks and sub-genres that created an inbuilt obsolescence in the micro-scenes themselves. A sort of voluntary short-term memory imbalance that is hard to understand in the following decade — the Noughties — in which one of the most original and popular artist has been Burial, which has been one visible manifestation of a fixation with the past which has previously reached similar levels in indie-rock. Not to speak of the literalist approach of a very interesting artist as Zomby in “Where Were U in 92?”

SR: I was totally caught up in the Nineties rave culture and I can testify that there was a sensation of teleology, a palpable feeling that something was unfolding through the music. It would be easy to say in hindsight that this was an illusion but I’d rather honour the truth of how it felt at the time. On a month by month basis, you witnessed the music changing and there seemed to be a logic to its mutation and intensification. From hardcore to darkcore to jungle to drum ‘n’ bass to techstep, it felt like there was a destination, even a destiny, for the music’s relentless propulsion across the 1991 to 1996 timespan. I entered the scene in late 91, when the “journey” was already well underway, so you could say that the trajectory started as far back as 1988, when acid house originally impacted the UK.

Mine is a London-centric viewpoint, but similar trajectories were unfolding in Europe, with the emergence of gabba, and trance, or the evolution of minimal techno. There was a linear, extensional development, along an axis of intensification. Each stage of the music superseded the preceding one, like the stages of a rocket being jettisoned as it escapes the Earth’s atmosphere. And you are right that there was a forgetfulness, a lack of concern with the immediate past, because our ears were trained always on the future, the emerging Next Phase.

At a certain point the London-centric hardcore/jungle narrative took a swerve, slowing down in tempo and embracing house music’s sensuality, first with speed garage in 1997 and then with the even slower and sexier 2step. But that just seemed like a canny move to avoid an approaching dead end (one that drum ‘n’ bass would bash its collective head against for… ever since really!) The rhythmic complexification that had developed through drum ‘n’ bass carried on with speed garage and 2step, just in a less punitive way.

In the Noughties, especially in the last five years, the feeling you get from dance culture and the endless micro shifts within it is quite different — whatever the opposite of teleology is, that’s what you got! It is hard to identify centres of energy that could be definitively pinpointed as a vanguard. The closest thing in recent years might well be the populist “wobble” sector within dubstep, if only because there’s a kind of escalation of wobbleness going on there. There is a full-on, hardcore, take-it-to-extremes spirit to wobblestep. Ironically, the dubstep connoisseurs and scene guardians can’t stand wobble and have veered off into disparate welter of softcore “musical” directions. Wobble is quite a masculinist sound, it reminds me of gabba. But then it is easy to forget that the Nineties was all about this kind of punishing pursuit of extremes: the beats and the bass were a test to the listener, something you endured as much as enjoyed (or had to take drugs in order to withstand). The evolution of the music was measurable in a experiential, bodily way. Beats got tougher and more convoluted, textures got more scalding to the ear, atmospheres and mood got darker and more paranoid.

Apart from grime and aspects of dubstep, Nineties post-techno music overall seems to have retreated into “musicality” (in the conventional sense of the word) and pleasantness. So instead of that militant-modernist sense of moving forward into the future, the culture’s sense of temporality seems polymorphous and recursive. And this applies on the micro as well as macro level: individual tracks seem to have less “thrust” and drive, to be more about involution and recessive details.

Touching on the question of rave nostalgia, the question “Where Were U In 92?” posed by Zomby is interesting on a bunch of levels. There is an echo, possibly unintended, of the marketing slogan for American Graffiti (“Where were you in 62?”, the year the movie is set), George Lucas’s groundbreaking vehicle for mobilising and exploiting generational nostalgia. Then there is also the unexpected biographical fact that Zomby is perfectly capable of saying where he was in 92, because he was twelve and a precocious fan of hardcore rave (which further suggests he must have just followed the trajectory of the music through jungle and speed garage to dubstep just like me and Mark, only quite a bit younger). Even as the album offers a loving pastiche of old skool hardcore, there seems to be an element of mockery of ageing ravers with their “boring stories of glory days” (to quote Springsteen). That would probably appeal to younger dubstep fans who, unlike Zomby, didn’t live through rave as participants and probably find the legacy of the hardcore continuum to be an encumbrance, a burden. Finally, it’s intriguing that Zomby did this pastiche record as a one-off stylistic exercise, in between much more cutting-edge dubstep records such as the Zomby EP on Hyperdub. It suggests that Zomby’s generation can play around with vintage styles without the kind of fanatical identification with a lost era that you generally get with musical revivalism. It’s just a period style, something to revisit.

MF: The point is that the question “Where were you in 92?” makes sense, whereas the question “Where were you in 02?” (or indeed 08) doesn’t. One of the things that has happened over the last decade or so is the disappearance of very distinctive “feels” for years or eras — not only in music but in culture in general. I’ve got more sense of what 1973 was like than what 2003 was like. This isn’t because I’ve stopped paying attention — on the contrary, I’ve probably paid more close attention to music this decade than at any other time. But there’s very little “flavour” to cultural time in the way there once was, very little to mark out one year from the next. That’s partly a consequence of the decline of the modernist trajectory that Simon describes. (One slight difference I have with Simon is that I prefer the term “trajectory” to “teleology”. For me, what was exciting about the Nineties — and popular culture between the Sixties and the Nineties — was that sense of forward movement. But it didn’t feel linear, as if everything was inevitably heading in one direction towards one goal. Instead, there was a sense of teeming, of proliferation.) If time is marked now, it’s by technical upgrades rather than new cultural forms or signatures. But the technical upgrades increasingly seem to be manifested in terms of the distribution and consumption of culture rather than in terms of production. You can’t hear or see dramatic formal innovations — but you get a higher definition picture, or a greater storage capacity on your mp3 player. Adam Harper, one of the most interesting young critics, has made a case for the new culture of micro-innovation, arguing that the kind of music culture Simon and I are talking about here — defined in terms of scenes organised around generic formulas — is an historical relic, replaced by a culture of a thousand tiny deviations, an “infinite music”, in which the temporal recursion that Simon has referred to is not a problem but a resource. Yet, for me, this sounds suspiciously like the Intelligent Dance Music that people were praising before the hardcore continuum came along. It’s easy to forget that disdain for the supposed vulgarity and repetitiveness of scene-music was a critical commonplace until Simon and Kodwo made the case for “scenius” in dance music.

But it seems to me that the phenomenon we’re talking about here — temporal flavourlessness — is a symptom of a broader postmodern malaise. Every time I go back to read Fredric Jameson’s texts from the Eighties and early Nineties, I’m astonished by their prescience. Jameson was quick to grasp the way in which modernist time was being flattened out into the pastiche-time of postmodernity. When I read some of those texts in the Nineties, I thought that they described certain tendencies in culture, but that this was far from being the only story. Now, there’s only a very weak sense of there being any alternative to the postmodern end of history. The question is, is this all temporary or terminal?

SR: I should have also noted that one of the main reasons a sense of linear progress was physically felt during the Nineties was that between 1990 and 1997, techno got faster: there was an exponential rise in beats-per-minute, that accompanied all the other ways in which the music got harder, more rhythmically dense, and so forth. So as a dancer you felt like you were hurtling.

Mark mentions the idea of technical upgrades as the metric for a sense of progression in the last decade. This reminded me of a conversation I had with the Italian DJ and journalist Gabriele Sacchi. In the space of about fifteen minutes, Sacchi went from complaining that there had been no really significant formal advances in dance music since drum ‘n’ bass (he discounted dubstep, as I recall) to then commenting with approval of how advanced sounding records were now compared with ten years ago. What he meant is that they sounded better in terms of production quality: what’s available today in terms of technology, digital software, etc., to someone making, say, a house track, enables them to make much better-sounding records (in terms of drum sounds, the textures, the placement of sounds and layers in the mix). That sounded totally plausible to me and it may well be the defining quality of electronic dance music in the 2000s. You might say that the basic structural features of the various genres were established in the Nineties but what has improved is the level of detailing, refinement and a general kind of production sheen to the music. An analogy might be a shift from architectural innovation (the Nineties) to interior décor (the 2000s). Mark also mentions Fredric Jameson. His work — the big postmodernism book from 1991 but also, especially, A Singular Modernity — helped me see that rave in general and the UK hardcore continuum in particular had been a kind of enclave of modernism within a pop culture that was gradually succumbing to postmodernism. Coming out of street beats culture, without hardly any input from art schools and only the most vague, filtered-down notion of musical progress, it nonetheless constituted a kind of self-generated flashback to the modernist adventure of the early twentieth century. The hardcore continuum especially propelled itself forward thanks to an internal temporal scheme of continual rupturing: it kept breaking with itself, jettisoning earlier superseded stages. One small aside in A Singular Modernity struck me as both true and funny, when Jameson talks about the modernists being obsessed with measurement, “how do we determine what is really new?”. That struck me as the characteristic mindset of those who came up through the Nineties as critics. But the new generation of electronic music writers (and probably musicians too) don’t seem to respond to music in this way. It’s no longer about the lust for the unprecedented, about linear evolution and the rush into the unknown. It’s about tracking these endless involutionary pathways through the terra cognita of dance music history, the tinkering with inherited forms.

KM: Another topic I find very interesting is the fact that the dance music referred to as the hardcore continuum, even if it had an international resonance through the media, has maintained a strong local connotation and a somehow insular development (in other close genres as techno or house the localisation seemed to be less prominent even if, for example, the first ground breaking LP from the band Basement Jaxx resonates with a milieu of influences not too dissimilar to some other post-rave productions). Somehow some of the music in the continuum feels like a sonic cartography of London (or other cities in the UK), responding and being connected to very specific contexts. Is the geographical aspect something you use in the reception of this genres?

SR: Music from the hardcore continuum has obviously found audiences all over the world. The early breakbeat hardcore was universal rave music for a few years in the early Nineties. Jungle established scenes in cities from Toronto to New York to São Paolo and in its later incarnation as drum ‘n’ bass became a truly international subculture. The same applies to dubstep. And even the more London-centric styles like 2step and grime had really dedicated fans in countries all over the globe and small offshoot scenes in particular cities outside the UK. That said it is incontrovertible that the engine of musical creativity for hardcore continuum genres has always been centred in London, with outposts in other urban areas of the UK that have a strong multiracial composition, particularly Bristol, the Midlands, and certain northern cities like Sheffield, Leeds, and Leicester. The next stage of the music has always hatched in London.

That is related to pirate radio, the competition between DJ and MC crews both within a particular station and between stations. And the sheer number of pirate radio stations owes a lot to the urban landscape of London, the number of tower blocks to broadcast from, and the density of the population, and the existence of a sizeable minority (in both the racial and aesthetic sense) whose musical taste is not catered for by state-run radio or by the commercial radio stations (including the commercial dance station Kiss FM). This competition — expressed through the pirates striving to increase their audience share but also through raves and clubs competing for dancers — is partly economic and partly purely about prestige, aesthetic eminence. And it has stoked the furnace of innovation.

That London-centric system focused around illegal radio stations seems to be gradually disintegrating. It is still what fuels the funky house scene, its primary audience is still “locked on” to the pirate signal. In fact I’m told that there aren’t many funky raves or clubs at all, and hardly any vinyl releases or compilations, so the only way to hear funky is through the pirate transmissions. But dubstep, like drum ‘n’ bass before it, is much more of UK national scene, and also an international scene. Martin Clark, a leading journalist on the scene and also a DJ and recording artist using the name Blackdown, told me something interesting. The Rinse FM show that he and Dusk do, which is eclectic post-dubstep in orientation, gets a high proportion of its audience responses, message and requests, through the internet, from as far afield as Finland or New Zealand (the Rinse FM signal goes out on the internet as well as broadcast through the air). But the pure funky house shows get most of their requests and calls as texts from cellphone users who live within the terrestrial broadcast range of the pirate stations. So funky is still a local scene in the traditional hardcore continuum sense, it is very much East London.

But I think that London-centric orientation is on the decline. Dubstep is fully integrated with the web, it’s all about podcasts and DJ mixes circulating on the web, about message board discussions. I think of funky as the “dwarf star” stage of the hardcore continuum: it has shrunk in sise, still emits some heat in the sense of vibe and musical creativity, but it hasn’t been able to command attention beyond the pre-converted diehards, in the way that jungle or grime once did. If you look at funky, it’s the first hardcore continuum sound not to have any UK chart hits at all. It’s not spawned any offshoot scenes in foreign countries. It hasn’t achieved critical mass in the sense of non-dance specialist journalists giving it the time of day. Jungle and grime got mainstream coverage because they simply couldn’t be ignored, they were so aggressively new and extreme. But funky, to people who don’t follow the minutiae of the hardcore continuum, just sounds like “tracky” house music with slightly odd-angled beats and a London flavour. It’s not anthemic enough to make it as pop like 2step garage did, but it doesn’t have the vanguard credentials of jungle.The interesting thing about the hardcore continuum is the way that during its prime it refuted all that Nineties internet and info-culture rhetoric about deterritorialisation. This was a music culture that derived its strength and fertility from its local nature, precisely from being territorialised. Indeed during the early days of jungle and of grime, it had a kind of fortress mentality. That seems to connect with its vanguardism, this military-modernist mindset.

Another thing is that the hardcore continuum genres were very slow to get integrated with the web. When I did early pieces on 2step garage and grime, the labels and artists had hardly any web presence. Nearly all the interviews I had to do calling mobile phone numbers or speak in person, rather than do email interviews. It was only about 2005 that you started to get grime figures with Myspaces. It was only around then that you started to get tons of DJ sets being uploaded to the web. Before that the music was really hard to get hold of if you didn’t live in London, you had to mail order expensive 12”s and CD mixtapes. Now it is totally easy to stay on top of the music no matter where you live. But some of the romance and mystique of the scene has gone as a result.

MF: It’s not only UK dance music of the Nineties that is associated with cities; the whole history of popular music is about urban scenes. It’s no accident that Motown started in Detroit, house in Chicago, hip-hop in New York… Cities are pressure cookers which can synthesise influences quickly and in a way that is both collective and idiosyncratic. Scenes in city depend on a certain organisation of space and time that cyberspace threatens. For example, the hardcore continuum depended on an ecology of interrelated infrastructural and cultural elements — pirate radio, dub plates, clubs, etc. — but it also relied on these elements being somewhat discrete. For instance, dub plates acted as probe heads, which would be tested out in clubs. But cyberspace has collapsed the differences between making a track at home, releasing it and distributing it. Now it’s possible to upload a track into cyberspace immediately, there’s less sense of occasion about a record release. So there’s a collapsing of time. But alongside this is a collapsing of the importance of spaces. Club spaces were important because of that “evental” time: you would be hearing a track for the first time… But now new tracks in DJs’ sets are immediately made available on YouTube. It goes without saying that the club experience is a collective experience — it gains much of its power from people experiencing the same thing in the same space. Cyberspace is much more individuated. Because it isn’t a “space” in the way that physical space is, you don’t get that sense of coming together. It’s more like being involved in a conversation than being in a crowd. Even with instant messaging, there’s a delay.

Clearly, there’s something potentially positive about people being able to make and release music without worrying about the costs of recording studios, about how it will be distributed and such like. But while this might remove certain obstacles for individuals making music, it’s not clear that cyberspace is good for music culture. Urban scenes compressed and concentrated things; cyberspace and digitality are in danger both of making culture too immediate (you can upload a track right now) and too deferred (nothing is ever really finished). The city-based music scene is perhaps one of the things you can hear being mourned on Burial’s records, with their many references to London. The “sonic cartography” of London you pick up from Burial’s records is in many ways a pirate-radio cartography.

KM: The international reception of some of the sounds in the continuum was the one of a music alternative to what some perceived as the pure recreational hedonism of house music, for example in Italy jungle was embraced by Centri Sociali (squats), maybe they were some of the musical genres that help dissolving resistances towards dance music within non clubbers. Maybe this was because of the persisting connections with Jamaican music, maybe because of the dystopian mood/control society references. But apart from this I’d like to know what is, in your opinion, the most significant political significance of these genres?

SR: The major political significance of the hardcore continuum is the role it’s played in the emergence of a post-racial Britain. Which has not fully arrived, obviously there is still a lot of racism in Britain, but you could talk about jungle and UK garage especially as having created a post-racial “people” within the UK — it’s most obviously a force in the major cities like London and Birmingham and Coventry, but this tribe has members scattered all across the country. It’s not just the mix of black and white, it’s all sorts. I’m always amazed at the range of ethnicities involved, there’s people whose parents are from the Indian sub-continent, or who are Cypriot or Maltese, and you also get every imaginable mix-race combination. Even talking just about “black Britain”, it’s not just people of Jamaican descent, there’s all the other islands in the Caribbean that have their own distinct musical traditions like soca and so forth, and there’s also been more recently African immigrants, whose influence is really felt in the Afro flavours you can hear in funky house.

So it’s a really rich mix, but I guess the predominant musical flavours that run through the whole span of the continuum involve the collision of British artpop traditions (post-punk, industrial, synthpop) with Jamaica (reggae, dub, dancehall) and also black America (hip-hop, house, Detroit techno). And it’s very much a two-way street: it’s not just white British youth turning on to bass pressure and speaking in Jamaican patois, it’s about second-generation Caribbean-British youth freaking out to harsh Euro techno, having their minds blown by all that early Nineties music out of Belgium. Or someone like Goldie growing up on reggae and jazz-funk but also on groups like PiL and the Stranglers.

You might say that the music of the hardcore continuum reflects the emergence of this post-racial “people” within the UK more than it has created it. But I think it has sped up the process, by being so attractive and so obviously the cutting edge in British popular culture. People have been actively drawn into joining this tribe, it’s been an identity many have wanted to embrace, because it’s been the coolest music of its era and it’s been something to be proud of: a post-racial way of affirming Britishness.

So this I think is a major political achievement for the hardcore continuum. Some commentators like the music theorist Jeremy Gilbert have asked why that never translated into politicisation per se. At various point, particularly with jungle and with grime, there has been a sense that the music has been telling us things about society and what life is like for the British underclass. The darkness and paranoia of jungle (also carried on to an extent with dubstep), and the aggression and self-assertion of grime, reflect the gritty side of urban existence. But there is also a feeling, on my part certainly, that at a certain point simply reflecting Reality isn’t enough. Jungle and grime never really managed to get beyond being “gangster rave”, which is to say the British equivalent to gangster rap. So across its historical span it has oscillated between darkness (reflecting ghetto life) and brightness (dressing up and looking expensive, partying, dancing to sexy groovy music, chasing the opposite sex — that’s the side of the continuum that produced speed garage, 2step, funky house). Apart from the post-racial aspect, the other major achievement of the hardcore continuum is the creation of an autonomous cultural space based around its own media (pirate radio) and its own economic infrastructure (independent labels and record stores). Pirate radio seems particularly significant: the fact that it is community radio, offering the music for free, and that it is amateur, with DJs and MCs actually paying to play (they have to cough up a subscription fee for their air time, to pay for equipment that is lost when the authorities seize transmitters and so forth). Pirate radio is important also because it is public: the culture is underground, but this is an audible underground, it is broadcast terrestrially, blasting out onto the airwaves of London or the other big UK cities. It’s a community asserting its existence on the FM radio spectrum. This means that people who don’t like the music or the social groups it represents will stumble on it, but also that people who don’t know about the music will encounter it — potential converts to the movement. If the pirates went completely online, it would cease to be an underground, it would become much more just a niche market of marginal music going out almost entirely to the pre-converted. The paradox of music undergrounds is that the idea is not really to be totally underground, invisible to the mainstream and the cultural establishment. You don’t want to be ignored, you want to be a nuisance! And there is also an interaction between the undergrounds and the mainstream, where ideas from below force their way up into the mainstream and enrich and enliven it. Which then forces the underground to come up with new ideas. That process worked for a really long time with the hardcore continuum: it would develop new ideas that were so obviously advanced and compelling that the major labels would sign artists and big radio stations like BBC and Kiss FM would recruit DJs to host regular shows. It seems to have broken down with funky house, though, it’s the first hardcore continuum genre to just stay in its ghetto.

MF: In my book Capitalist Realism, I quote an article that Simon wrote on jungle for the Wire magazine. Simon put his finger there on how crucial the concept of “reality”, of “keeping it real”, was for both jungle and US rap. Simon writes of an implied political position in jungle: how it was anti-capitalist but not socialist. That always struck me as very suggestive — but these politics were never developed. I would tend to agree with Jeremy Gilbert — that the encounter between jungle and politics never really happened. But this wasn’t only a failure of the music; it was also a failure of politics. During the Nineties, the British Labour Party courted the reactionary rockers of Britpop. But where was the politics that could sychronise with the science fictional textures that jungle invoked?

So yes, Simon is right, if the hardcore continuum had any impact on politics it was in playing a part in establishing a post-racial Britain. It was impossible to fit jungle into a pre-existing racial narrative — it didn’t sound like “white” or “black” music. And the extent to which the hardcore continuum has helped to consolidate this sense of the post-racial was made clear by an hilarious recent piece in Vice magazine called “Babes of the BNP”, in which female supporters of the far right British National Party were interviewed. One question was: “In terms of the BNP’s repatriation policy on immigration, if you had to choose, who would you repatriate first, Dizzee Rascal or Tinchy Stryder?”





militant tendencies feed music1

The idea that music can change the world now seems hopelessly naïve. Thirty years of neoliberalism have convinced us that there is no alternative; that nothing will ever change. Political stasis has put music in its place: music might “raise awareness” or induce us to contribute to a good cause, but it remains entertainment. Yet what of music that refuses this status? What of the old avant-garde idea that, to be politically radical, music has to be formally experimental?

The artist Michael Wilkinson’s show Lions After Slumber (exhibited last year at the Modern Institute in Glasgow) posed these questions with a quiet intensity. The show was a kind of reliquary for a bygone militancy. It was dominated by an enormous black-and-white print of the photograph of Piccadilly Circus that had hung — upside down — in Malcolm McLaren and Vivienne Westwood’s shop Seditionaries. A stretched linen included the 1871 photograph of the Paris Communards standing over the toppled Vendôme Column — but the image had been turned on its side, so that it looked as if the restored emperor was once again lording it over the Communards, who now resembled corpses.

There was no music to be heard at the show, but there were references to music scattered throughout. A screen-printed mirror showed the face of Irene Goergens, a member of the Red Army Faction — but the image came from the album sleeve to Raw Macro, by the techno artist Farben. More importantly, the title of the exhibition was a reference to Scritti Politti’s 1982 track “Lions After Slumber”. Scritti had themselves borrowed the title from Shelley’s 1819 poem “The Masque of Anarchy”, which imagined a rising “like lions after slumber/In unvanquishable number” to avenge the dead of the Peterloo Massacre.

The allusion to Scritti Politti makes it clear that the vision of politics that Wilkinson’s show simultaneously mourned and invoked was derived from post-punk — the outpouring of musical creativity in the late 1970s and early 1980s that was in many ways Britain’s version of Paris 68. In line with the Marxist and situationist theory it drew on and referenced, post-punk grasped culture as inherently political, insisting on a version of politics that went far beyond parliamentarianism.

One of the most urgent tasks for any political music was to expose the pacifying mechanisms that were already secreted in popular culture — nowhere more obviously than in the cheap dreams of love songs, which groups such as Gang of Four and the Slits deconstructed in tracks such as “Anthrax” and “Love und Romance”. In a world in which people increasingly felt as if they lived inside advertisements — where, as Gang of Four put it, at home they felt like tourists — there was nothing more ideological than culture’s claim to be entertainment. That was the word that provided the ironic title for Gang of Four’s debut LP, and was also used in one of the Jam’s most bitterly sarcastic songs, “That’s Entertainment”.

Wilkinson’s show was timely because post-punk was one of the spectres that loomed over the past decade. Its history was extensively catalogued in Simon Reynolds’ book Rip It Up and Start Again; the music was pastiched by lumpen plodders such as Franz Ferdinand and the Kaiser Chiefs, and served up again by originals such as Gang of Four, Magazine and Scritti, all of which reformed. The return of the post-punk sound had a double effect. At one level, it constituted the music’s final defeat — if conditions were such that these groups could come back, thirty years after the fact, and not even sound particularly out of date, then post-punk’s scorched-earth injunction that music should constantly reinvent itself must be as dead as its hopes for a revivified politics. Yet even the most degraded simulations of post-punk style carry with them a certain spectral residue, a demand — which these simulacra themselves betray — that music be more than consolation, convalescence or divertissement.

At the end of history, the impasses of politics are perfectly reflected by the impasses in popular music. As political struggle gave way to petty squabbles over who is to administrate capitalism, so innovation in popular music has been supplanted by retrospection; in both cases, the exorbitant ambition to change the world has devolved into a pragmatism and careerism. A certain kind of depressive “wisdom” predominates. Once, things might have seemed to happen, but we won’t get fooled again. Like the images in Wilkinson’s Lions After Slumber, the world has been turned the right way up again. The emperor is on his feet, power and privilege are restored, and any periods when they were toppled seem like ludic episodes: fragile, half-forgotten dreams that have withered in the unforgiving striplights of neoliberalism’s shopping mall.

In his study of the Sex Pistols, Lipstick Traces: A Secret History of the 20th Century — published in the politically resonant year 1989 — Greil Marcus impersonated this depressive wisdom. “By the standards of wars and revolution”, he conceded,

the world did not change; we look back from a time when, as Dwight D. Eisenhower put it, “Things are more like they are now than they ever were before.” As against the absolute demands so briefly generated by the Sex Pistols, nothing changed … () Music seeks to change life; life goes on; the music is left behind; that is what is left to talk about.

In fact, Marcus argues, the Pistols and those who followed them did change the world, not by starting a war or a revolution, but by intervening in everyday life. What had seemed natural and eternal — and which now appears to be so again — was suddenly exposed as a tissue of ideological presuppositions. This is a vision of politics as a kind of puncturing, a rupturing of the accepted structure of reality. The puncture would produce a portal — an escape route from the second-nature habits of everyday life into a new labyrinth of associations and connections, where politics would connect with art and theory in unexpected ways. When songs ceased to be entertainment, they could be anything. These punctures felt like abductions.

Abduction was what it felt like on first listening to Public Enemy. Like the post-punks, Public Enemy implicitly accepted the idea that a politics which came reassuringly dressed in established forms would be self-defeating. The medium was the message, and Public Enemy’s astonishing militant montage was remarkable for both its rabble-rousing sloganeering and its textural experimentalism. When the group’s music, produced by the Bomb Squad, looped fragments of funk and psychedelic soul into abstract noise, it was as if American history — now cut up into a science-fiction catastrophe, a permanent emergency — was made malleable and ripe for rapid-fire retelling from the perspective of a post-Panther black militancy.

Or there was the very different approach of Detroit’s Underground Resistance: in contrast to the data-density of the rap of Public Enemy’s Chuck D, they offered a largely voiceless take on techno, pursuing a strategy of stealth and invisibility, drawing listeners into a suggestive semiotic fog created by track titles (such as “Install ‘Ho-Chi Minh’ Chip”) and sleeve imagery that combined political insurgency with Afrofuturist science fiction.

What Public Enemy and Underground Resistance had in common was a rejection of the idea of music as entertainment. Instead of minstrelsy, they conceived of music in the militaristic terms explored in Steve Goodman’s recent book, Sonic Warfare: Sound, Affect and the Ecology of Fear. In this model, the use of music to subdue populations — the “psychoacoustic correction” directed by the US army against the Panamanian dictator Manuel Noriega; “sound bombs” deployed over the Gaza Strip — is by no means unusual. All music functions either to embed or to disrupt habituated behaviour patterns. Thus, a political music could not be only about communicating a textual message; it would have to be a struggle over the means of perception, fought out in the nervous system.

Underground Resistance saw their mission as fighting against “mediocre audiovisual programming”. Yet the problem is that the controllers have been all too successful in propagating this mediocrity. Where Public Enemy and Underground Resistance conceived of music as education, the dominant culture has been reclaimed by a Tin Pan Alley populism that has once again reduced music to entertainment. The internet and the iPod are part of a new economy of musical consumption in which, thus far, the possibilities of being abducted seem attenuated. In a world of niches, we are enchained by our own consumer preferences.

What is lacking in the age of Myspace is the public space that could surprise or confound our understanding of ourselves. Where, today, is the equivalent of the Top of the Pops stage, which could suddenly be invaded by the unexpected? Ironically, it is something such as The X Factor; the campaign to get Rage Against the Machine to the Christmas number-one slot was evidence of a hunger for music that was not just entertainment.

We are in a time of transition. Jacques Attali once argued that fundamental changes in the economic organisation of society were always presaged by music. Because, as a result of downloading, recorded music now seems to be heading towards decommodification, what does this suggest for the rest of the culture? And we are yet to hear the impact that the financial crash and its aftermath will have on musical production. The collapse of neoliberalism has already led to a simmering, renewed militancy on university campuses and elsewhere — how will this translate into sound? Perhaps soon we will once again hear new music that aims to turn the world upside down.





autonomy in the uk1

When the Real rushes in, everything feels like a film: not a film you’re watching, but a film you’re in. Suddenly, the screens insulating we latecapitalist spectators from the Real of antagonism and violence fell away. Since the student revolts in late 2010, helicopters, sirens and loudhailers have intermittently broken the phoney peace of post-crash London. To locate the unrest spreading across the capital, you just had to follow the Walter Murch-chunter of chopper blades… So many times during 2011, you found yourself hooked to news reports that resembled the scene-setting ambience in an apocalyptic flick: dictators falling, economies crashing, fascist serial killers murdering teenagers. The news was now more compelling than most fiction, and also more implausible: the plot was moving too quickly to be believable. But the sheen of unreality it generated was nothing more than the signature of the unscreened Real itself.

Sound was at the core of one of the year’s momentous stories, the still unravelling “hackgate” narrative of national newspaper journalists caught out cracking the mobile phone messages of public figures and the grieving relatives of crime victims for story leads. After Hackgate, the UK power elite looked like something out of David Peace’s Red Riding Quartet or The Wire television series (which itself turned on the moral issues of secretly recording phone conversations). The complicities of interest and mutual fear exposed by the phone hacking story brought to mind the party scene in the 1974 episode of Channel 4’s TV adaptation of Peace’s novels, where the illicit hedonism and skulduggery of cops, hacks, corporate plutocrats, private investigators — friends and ostensible adversaries — illustrated the true meaning of David Cameron’s notorious phrase “we’re all in this together”. In 2011, we were living the film; all that was missing was the soundtrack.

At the end of 2010, the BBC’s economics editor Paul Mason wrote a blog post called “Dubstep Rebellion”, which described a pivotal moment he witnessed in the 9 December student protests: when the “crucial jack plug” of a sound system playing “political right-on reggae”, was pulled by a “new crowd — in which the oldest person is maybe 17”, and replaced it with what he mistakenly believed to be dubstep. He was corrected by Guardian contributor and author of Kettled Youth, Dan Hancox, whose own blog posted a playlist of the tracks he heard at the protest. They turned out to be mostly grime and dancehall (Lethal B, Elephant Man, Vybz Kartel), alongside chart rap and R&B such as Rihanna and Nicki Minaj. What’s striking is the lack of explicit political content in any of this music. Yet grime, dancehall and R&B have a grip on the present in the way that older forms of self-consciously political music don’t, and here is the impasse. It’s as if we’re left with a choice between the increasingly played out feel of “politically engaged” music and the sound of the present. In the past year alone, the Guardian has run numerous articles bemoaning the lack of “protest” music, but for many of us, “protest” has always been a rather pallid model of what political music could be. Besides, it’s not protest music that has disappeared: go to the Occupy camp outside St Paul’s and you won’t find a shortage of acoustic guitars. What’s missing is a specifically twenty-first-century form of political music. While there are some grime tracks that can be understood as having a political message, for the most part the genre’s political significance lies in the affects — of rage, frustration and resentment — to which it gives voice. By contrast with US hip-hop, grime remains a form that is bound up with the failure to make it. The situation of grime is an allegory of class destiny. Just as it’s possible for some to rise from the working class but not with it, so it’s possible to rise out of grime (as artists such as Professor Green and Tinie Tempah have proven with their many crossover hits), but it’s not yet been possible for anyone to succeed as a grime artist.

Paul Mason acknowledges his mistake to correctly identify what was played at the 2010 protests in his new book, Why It’s Kicking Off Everywhere: The New Global Revolutions. Notwithstanding his inability to correctly track the changes in urban dance music, however, his original blog post was prophetic. After 9 December, the student protests lost momentum. The major moments of dissent in 2011 — which would also be the most powerful explosion of working-class rage in the UK since the riots of the early 1980s — would come from the group that Mason identified as “banlieue-style youth from places like Croydon and Peckham, or the council estates of Camden, Islington and Hackney”. As with some of the 1980s riots, the immediate cause for the UK’s first major uprising of 2011 was the death of a black person, Mark Duggan, shot by the police in Tottenham. “25 years ago police killed my grandma in her house in Tottenham and the whole ends rioted, 25 years on and they’re still keepin up fuckry”, tweeted Tottenham MC, Scorcher. His grandmother was Cynthia Jarrett, whose death prompted the Broadwater Farm riots in 1985. Dan Hancox mentioned this tweet in a piece about British urban music and the riots for the Guardian, a crucial journalistic intervention at a vertiginously scary moment when the authoritarian and racist right were using the unrest as the pretext for reheating discourse that would have been deemed unacceptable only a week before. In an extraordinary but typically incoherent rant on the BBC’s Newsnight, TV historian David Starkey astonishingly blamed the riots on “black culture” — collapsing the whole of black culture into music, and all black music into a poorly understood version of gangster rap. Like much of what happened in 2011, Starkey’s delirious diatribe is best understood as a symptom: in this case of ruling-class panic and ignorance. Starkey dismissed the idea that the riots were political on the grounds that no public buildings were attacked — but what meaning do public buildings have for youth who were born into a social landscape in which the very concept of the public has all but disappeared under sustained ideological attack? The fact that the rioters targeted chain retail outlets was blamed on their “consumerism”; as if such “consumerism” were some kind of collective moral failing rather than the inevitable consequence of immersion in late capitalism’s media culture.

As Owen Jones pointed out in his book Chavs: The Demonisation of the Working Class, work, not some lost moral sensibility, was once the source of working-class discipline. But what happens to people with no expectation of work, or of any kind of meaningful future? “When the punks cried ‘No Future’, at the turning point of 1977, it seemed like a paradox that couldn’t be taken too seriously”, Italian theorist Franco “Bifo” Berardi writes in his most recent book After The Future:

Actually, it was the announcement of something quite important: the perception of the future was changing … () Moderns are those who live time as the sphere of a progress towards perfection, or at least towards improvement, enrichment and rightness. Since the turning point of the century — which I like to place in 1977 — humankind has abandoned this illusion.2

From decrying the failure of the future, music has increasingly become part of this inertial temporality. Nothing symbolises mainstream music’s relationship to politics better than the BBC’s coverage of U2’s set at Glastonbury. The significance here was not the music — predictably moribund and lacklustre, no longer even capable of mustering the totalitarian pomp of yore — but the way in which the TV coverage ignored the protest by Art Uncut. U2 were treated like dignitaries from the Chinese government: dissenters threatening to disrupt the empty rituals of the rock emperors wouldn’t be tolerated. Where once even the most incorporated rock registered something about the tensions and temperature of the times, now you go to rock to be insulated from the present. Both U2 and their fellow headliner Beyoncé made gestures to “politics” in their sets — past struggles now reduced to an advertiser-friendly hopey-changey sentimentalism covering over a deeper, more pervasive sense that nothing of any consequence can ever change. Yet if mainstream pop has become a bubble impermeable to the new times, it’s not as if experimental culture has yet come up with forms capable of articulating the present either. The art world’s political mobilisations — via groups such as Art Against Cuts — have been more impressive than much of the actual engaged art itself, which has too often remained caught in a mode of pious inconsequence and textural poverty.

What has been lost is the transit between experimental and popular culture which characterised earlier eras. But what the student movement has been trying to prevent is nothing less than the dismantling of the last elements of the infrastructure which made this exchange possible; free higher education, after all, was one of the means by which British music culture was indirectly funded. Perhaps that is why Gang Of Four’s “He’d Send In The Army”, Mark Stewart and the Maffia’s As the Veneer of Democracy Starts To Fade or Test Department’s The Unacceptable Face of Freedom — records made more than a quarter of a century ago — still have more purchase on the traumatic and tumultuous events of the year in the UK than anything produced by a white musician in 2011. Recalling a conversation with Green Gartside at the Wire’s Off The Page festival of writing about music in February, it’s telling that today has no equivalent to Green’s post-punk anxieties about articulating new relationships between music and politics. Yet if this disconnection is bad for culture, it might be good for politics. For if music and subculture no longer act as effective mechanisms for controlled desublimation, converting disaffection into culture which can in turn be transformed into entertainment — feeding what Jean-François Lyotard memorably called the “Tungsten-Carbide stomach” of capital, which omnivorously consumes anything, and excretes it as commodities — then discontent can appear in a rawer form. This might be the reason that uber-reactionary Jeremy Clarkson has urged those at St Paul’s to stop camping and start writing protest songs.

It could be, however, that our thinking about the problem is wrong-headed. It isn’t that music is lagging behind politics; the politics itself is missing. The major political event of the year in the UK was the riots, but they were political in a negative sense. Reactionary commentators attempted to evacuate the riots of any political content by classifying them as an outburst of criminality. But even if we reject this for the absurdity it plainly is, it’s possible to regard the riots as symptomatic — a symptom, precisely, of the failure of politics. “Harming one’s own community is entirely mindless, but why would someone care for a community that doesn’t care for him?” Professor Green asked Dan Hancox. “They might think of this as an uprising, but the anger is misdirected and conveyed in such a way will not have any kind of positive effect.” Wiley also saw the riots as a sign of impotence: “They’re saying ‘We’re going to do what we want!’ — and I’m thinking ‘No you’re not, because when the police get a grip on it, you’re going to be either banged up, or dead’.” With the Draconian prison sentences imposed on many of those who played even a minor role in the riots, Wiley’s prediction has been vindicated. Ceasing to be a symptom is one definition of achieving political agency, and — in a world where professional politicians look like inert mannequins incapable of preventing multiple impending catastrophes — nothing could be more urgent than this.

It’s clear that this agency will not in the first instance be achieved through the hollowed out, decadent spaces of parliamentary politics. The political movement with which Franco Berardi is most associated, autonomism, has assumed a central importance amongst the political struggles that are coalescing in the UK and elsewhere. Consider, for example, the autonomistinfluenced “ultra-leftist propaganda machine” called Deterritorial Support Group, whose blog became a crucial hub for new political thinking in the UK. Steeped in electronic music culture, DSG are as significant for their political aesthetics as for any substantive political position they present: what they offer is a new form of political antagonism far beyond the folksiness of “protest music”, capable of operating across the cyberspatial, mediamatic and designer terrains of contemporary culture. This is politics as Underground Resistance’s Electronic Warfare. In the era of hacking collectives such as Lulzsec, Anonymous and Wikileaks, DSG recognise that cyber-insurgency can open up a new kind of political insurgency. With the Diamond Jubilee and the Olympics, not to mention Mayan prophecies of apocalypse, 2012 is shaping up to be the most symbolically charged year in the UK since 1977. Is this the year when No Future will finally come to an end?





the secret sadness of the twenty-first century: james blake’s overgrown1

A certain trajectory seems to have come to an end with James Blake’s new album, Overgrown. Blake has gone from digitally manipulating his own voice to becoming a singer; from constructing tracks to writing songs. The initial motivation for Blake’s early work no doubt came from Burial, whose combination of jittery two-step beats and R&B vocal samples pointed the way to a twenty-first-century pop. It was as if Burial had produced the dub versions; now the task was to construct the originals, and that entailed replacing the samples with an actual vocalist.

Listening back to Blake’s records in chronological sequence is like hearing a ghost gradually assume material form; or it’s like hearing the song form (re)coalescing out of digital ether. A track such as “I Only Know (What I Know Now)” from the Klavierwerke EP is gorgeously insubstantial — it’s the merest ache, Blake’s voice a series of sighs and unintelligible pitch-shifted hooks, the production mottled and waterlogged, the arrangement intricate and fragile, conspicuously inorganic in the way that it makes no attempt to smooth out the elements of the montage. The voice is a smattering of traces and tics, a spectral special effect scattered across the mix. But with Blake’s self-titled debut album, something like traditional sonic priorities were restored. The reinvention of pop that his early releases promised was now seemingly given up, as Blake’s de-fragmented voice moved to the front of the mix, and implied or partially disassembled songs became “proper” songs, complete with un-deconstructed piano and organ. Electronics and some vocal manipulation remained, but they were now assigned a decorative function. Blake’s blue-eyed soul vocals, and the way that his tracks combined organ (or organ-like sounds) with electronica, made him reminiscent of a half-speed Steve Winwood.

Many who were enthusiastic about the early EPs were disappointed or mildly dismayed by James Blake. Veiling and implying an object is the surest route to producing the impression of sublimity. Removing the veils and bringing that object to the fore risks de-sublimation, and some found Blake’s actual songs unequal to the virtual ones his early records had induced them into hallucinating. Blake’s voice was as cloyingly overpowering as it was non-specific in its feeling. The result was a quavering, tremulous vagueness, which was by no means clarified by lyrics that were similarly allusive/elusive. The album came over as if it were earnestly entreating us to feel, without really telling us what is was we were supposed to be feeling. Perhaps it’s this emotional obliqueness that contributes to what Angus Finlayson, in his review of Overgrown for FACT,2 characterises as the strangeness of the songs on James Blake. They seemed, Finlayson says, like “half-songs, skeletal place-markers for some fuller arrangement yet to come.” The journey into “proper” songs was not as complete as it first appeared. It was like Blake had tried to reconstruct the song form with only dub versions or dance mixes as his guide. The result was something scrambled, garbled, solipsistic, a bleary version of the song form that was as frustrating as it was fascinating. The delicate insubstantiality of the early EPs had given way to something that felt overfull. It was like drowning in a warm bath (perhaps with your wrists cut).

On Overgrown, the post-rave tricks and tics have been further toned down, and the album is at its weakest when it limply flirts with the dancefloor. Piano is still the lead instrument, but the chords hang over a backing that is almost studiedly anonymous — a luxuriantly warm pool of electronics where the rhythm is propelled more by the gently eddying bass rather than the beats. Like James Blake, though, Overgrown repays repeated listening. As with the first album, there is a simultaneous feeling that the tracks are both congested and unfinished, and that incompleteness — the sketchy melodies, the half-hooks, the repeated lines that play like clues to some emotional event never disclosed in the songs themselves — may be why it eventually gets under your skin. Blake has said that, by contrast with his debut, Overgrown sounds like the work of a man who has experienced love. For me, it is as emotionally enigmatic as its predecessor. The oddly indeterminate — irresolute and unresolved — character of Blake’s music gives it the quality of gospel music for those who have lost their faith so completely that they have forgotten they ever had it. What survives is only a quavering longing, without object or context, Blake coming off like an amnesiac holding on to images from a life and a narrative that he cannot recover. This “negative capability” means that Overgrown is like an inversion of the oversaturated high-gloss emotional stridency of chart and reality TV pop, which is always perfectly certain of what it is feeling.

But what is the faith that Overgrown has lost? Blake’s development has paralleled that of Darkstar, who similarly moved from the tricksy, tic-y vocal science of “Aidy’s Girl is a Computer” to the chilly melancholia of their first album, North. Their new record News From Nowhere has a brighter, dreamier feel, but, as with Overgrown, it is notable for its lack of designs on the dancefloor. In a discussion that Simon Reynolds and I had about UK dance music,3 Reynolds argued that the “emotional turn” represented by Blake and Darkstar was an implicit acknowledgement that “dance music no longer provides the kind of emotional release that it once did, through collective catharsis.” The music doesn’t have to be explicitly sad for this to be the case — there is a melancholia intrinsic to the very turn inward. As Reynolds points out, the idea that Nineties dance music was unemotional is a fallacy. This was a music saturated with affect, but the affect involved wasn’t associated with romance or introspection. The twinning of romance and introspection, love and its disappointments, runs through twentiethcentury pop. By contrast, dance music since disco offered up another kind of emotional palette, based in a different model of escape from the miseries of individual selfhood.

In the twenty-first century, there’s an increasingly sad and desperate quality to pop culture hedonism. Oddly, this is perhaps most evident in the way that R&B has given way to club music. When former R&B producers and performers embraced dance music, you might have expected an increase in euphoria, an influx of ecstasy. Yet the digitally-enhanced uplift in the records by producers such as Flo-Rida, Pitbull and will.i.am has a strangely unconvincing quality, like a poorly photoshopped image or a drug that we’ve hammered so much we’ve become immune to its effects. It’s hard not to hear these records’ demands that we enjoy ourselves as thin attempts to distract from a depression that they can only mask, never dissipate.

A secret sadness lurks behind the twenty-first-century’s forced smile. This sadness concerns hedonism itself, and it’s perhaps in hip-hop — the genre that has been most oriented to pleasure over the past twenty-odd years — where this melancholy has registered most deeply. Drake and Kanye West are both morbidly fixated on exploring the miserable hollowness at the core of super-affluent hedonism. No longer motivated by hip-hop’s drive to conspicuously consume — they long ago acquired anything they could have wanted — Drake and West instead dissolutely cycle through easily available pleasures, feeling a combination of frustration, anger, and self-disgust, aware that something is missing, but unsure exactly what it is. This hedonist’s sadness — a sadness as widespread as it is disavowed — was nowhere better captured than in the doleful way that Drake sings, “we threw a party/yeah, we threw a party,” on Take Care’s “Marvin’s Room”.

It’s no surprise to learn that Kanye West is an admirer of James Blake’s. Meanwhile, this mix4 that was doing the rounds a couple of years ago made parallels between Blake and Drake. There’s an affective as well as sonic affinity between parts of Kanye’s 808s and Heartbreak and My Beautiful Dark Twisted Fantasy and Blake’s two albums. You might say that Blake’s whole schtick is a partial re-naturalisation of the digitally manipulated melancholy Kanye auditioned on 808s: soul music after the Auto-Tune cyborg. But liberated from the penthouse-prison of West’s ego, the disaffection languishes listlessly, incapable of even recognising itself as sadness. Unsure of itself, caught up in all kinds of impasses, yet intermittently fascinating, Overgrown is one more symptom of the twenty-first century’s identity crisis.





review: david bowie’s the next day1

If you’re interested in The Next Day — and even if you aren’t — you’ve probably heard it by now. Heard it, been disappointed by it, ceased caring about it. The only really twenty-first-century thing about The Next Day is the way it exemplifies the hype velocity of current communication: artfully timed PR rumours, hints and hyperbole induce anyone within its range to hallucinate a sublime object behind the veil, only for that object to degenerate into quotidian mediocrity the very second we’ve downloaded it.

The willingness to hallucinate is certainly there. Witness the sheer heft of the coverage, and feel the desperation behind it. The prospect of Bowie’s return was guaranteed to tickle the palate of a certain age of listener, but the desires that it triggered were also for something missing from contemporary popular music. These days, Bowie stands for all the lost possibilities going by the idea of art pop — which is to say, not only pop plus art, or pop as art, but a circuit where fashion, visual art and experimental culture connected up and renewed each other in unpredictable ways. His absence was a palate cleanser — his string of forgettable 1980s and Nineties records now forgotten, he could once again be the thin white space onto which fantasies are projected. His absence almost seemed like a ploy invented by Bowie the impresario-strategist. After all, the only way to make a new Bowie record an event was for him to withdraw long enough that it could seem like it might — really, this time — be forever.

The Next Day’s first single “Where Are We Now?”, with its references to West Berlin era Potsdamer Platz and Nurnberger Strasse, sounded like an object carefully designed to pique the interest not only of the Bowie diehards but also those with a more general stake in pop history and mythology. Berlin! Tony Visconti! The track’s lugubrious melancholy prompted the fantasy that The Next Day could be Bowie’s version of Sinatra’s No One Cares — an old crooner, a man lost in time paradoxically regaining currency by giving up on the sad pursuit of a present that had escaped him for good long ago. But it was a red herring. There are all kinds of intimations of mortality in The Next Day’s words — and reviewers seeking to rescue the record have tended to take refuge in the lyric sheet — but the form is rock, and an alarmingly unprepossessing, devoid of funk (as well as electronics) rock at that. The rest of the album makes the distance between now and (Berlin) then of “Where Are We Now?” painfully evident, a pain heightened by Visconti’s failure to convert this collection of session muso workouts into anything memorable. The Next Day sounds as if it were barely produced at all: it has the flatness of a demo. The relatively warm reception The Next Day received tells its own sad tale about the state of pop in 2013.

You can’t just put Visconti and Bowie together in a studio in 2012 and expect the equivalent of Low, “Heroes” or Lodger to result. The sorcerous powers that artists seem to possess as of right are never really theirs. Bowie — who perhaps more than any artist has performed the pop star’s lack of interiority — has always known this, and he and Eno did much to puncture the Romantic conceit that creativity comes from the mysterious inner depths of a musician. Bowie’s serial passage through personae, concepts and collaborators only telegraphed what is always the case: that the artist is synthesizer and curator of forces and ideas. This is all very well when the syntheses and the synergies are working, and there’s a steady supply of new collaborators to feed off and to lionise. It’s harder in this long striplit hours in the studio when the old magic won’t come, when the revels have ended but you still have to go through the motions.

It’s cruelly appropriate that Bowie’s powers deserted him at practically the very moment that the Seventies — the decade with which he will always be synonymous — ended. I came to musical consciousness round about the time of 1980’s Scary Monsters, and took Bowie for granted. Ziggy Stardust already sounded like a hoary old rock ‘n’ roll relic, and even much of Scary Monsters sounded reactionary by comparison with what proteges like Gary Numan, the Associates and Visage were doing. Yet Bowie had helped to create the conditions of his own obsolescence. His successors were following Bowie’s template for what a pop star should be: a conceptualist and a designer, sexuality and gender indeterminate, alien and/or android, all outside and no inside, the changing face of the strange. From this point on, Bowie himself would be bereft of masks and make-up — it would be just him, the music and the Eighties suits. What followed was years of gradually lowering expectations, of spectacular misfires and the occasional lost gem, but mostly there was reliable mediocrity, the familiar declined star pattern where each new record is fanfare as a return to form, only to immediately disappear into irrelevance.

Much of this is compressed onto the cover image, which is by far the most startling thing about The Next Day. It’s startling not for the act of desecration — but for the casual character of the desecration: a white square over the “Heroes” cover — what could be more half-assed? When I first saw the cover image I thought it must be a prank — what would the real cover image be like? Here is cover designer Jonathan Barnbrook’s rationale for the design: “The ‘Heroes’ cover obscured by the white square is about the spirit of great pop or rock music which is ‘of the moment’, forgetting or obliterating the past. However, we all know that this is never quite the case, no matter how much we try, we cannot break free from the past.”

The image becomes more than a comment on Bowie — the man who once traded on his ability to escape the past is now trapped by it. It also functions as a diagnosis of a broader temporal malaise. What is this white space, this void? An optimistic reading would construe it as the openness of a present that is not yet decided. A bleaker take — one in keeping with the hackneyed quality of the music — would see the white space as standing in for the vacancy of the present, with nothing there except a necessarily failed attempt to escape and recover the past. That’s our pop predicament in 2013, a predicament which The Next Day couldn’t seriously have been expected to resolve.





the man who has everything: drake’s nothing was the same1

So here we are again: life at rainbow’s end. Everything that can be bought, available practically immediately, 24/7: women, food, cars, you name it, you click on it. Every hotel suite can be prepared to your specifications. The only things that are different are the shower controls. It’s all top quality, although naturally you can get down and dirty with the fast food options if you want to, and often (why not?) you do:

Got everything, I got everything… I cannot complain, I cannot (You sure about that, Drake?)

I don’t even know how much I really made, I forgot, it’s a lot… Fuck that, never mind what I got2

OK, then, let’s get the obvious question out of the way first. If you’ve got everything, why are you so sad?

Surely it can’t be as simple and sentimental as that hoary old chestnut: money can’t buy you love? Come on, is this really where rap was destined to end up: with the rapper as some romcom character, all the braggadocio and super-conspicuous consumption just so much bluster to conceal the boy-lack that the redeemer-woman will make good in the final reel? That old story, again? “Next time we fuck, I don’t want to fuck, I want to make love… I want to trust.” Drake can’t quite believe this routine, can’t quite make us believe it. He knows perfectly well that this sensitive stuff can play as one more pick-up-artist’s ruse… He’s spent so long deceiving and then revealing his deceptions that he’s no longer sure when he’s trying to play us or speak openly, or what the difference is. Crying real tears with one eye, while winking over the latest conquest’s shoulder to the camera with the other. He’d convinced us he was different, but that was a trick, and one that others have caught on to. There’s nothing very brave or unique about talking about your feelings now that “niggas talk more than bitches do.” Is this more honesty, or just an acknowledgement that he needs a new USP?

I got 99 problems, getting rich ain’t one.

Listening to Nothing Was the Same, I’m reminded of Judd Apatow’s Funny People. Apatow’s film is defined by a series of hesitations and avoidances. First of all, it seems as if it is going to be a film about a jaded but rich and successful comedian, George Simmons (Adam Sandler), who learns the value of life when he’s diagnosed with a serious illness; then it seems to be about a man who accepts the value of love and family. Yet each time the film seems to move towards these standard generic resolutions, Apatow pulls back. Simmons’ hedonic nihilism re-asserts himself; the threat of death can’t break the bad habits of a lifetime; the love he lost long ago was actually better off lost. He’s not happy being himself but he doesn’t want to be anyone else. Far from relieving this existential dilemma, fabulous wealth means that he has nowhere at all to hide from it.

Nothing Was the Same is characterised by the same ambivalence — a longing to be a new person who can love and trust (with a woman, naturally, charged as the agent of this transformation) together with a recognition that he will never change, that he’ll always be drinking, smoking, fucking, that he’s far from perfect, but neither is anyone else, right? He never really took off the gangsta-minstrel drag for good; instead, he keeps casting it aside, inspecting it, distancing himself from it, before wearing it again. He can’t help himself (or so he keeps telling us). But this oscillation is valuable for what it tells us about rap’s embattled masculinity in general. Drake confirms that the street-strutting bad boy “just looking for head in a comfortable bed” is the other face of the desperately alone little boy lost crying to his mommy substitute. The boasting brute is always on the run from the helpless infant inside, but, for that very reason, the emotionally broken-down male isn’t an alternative to all the ego-armour posturing, so much as it is its enabling condition. Women are to be publicly disdained, treated as currency in a homosocial bragging economy; in private they are asked to make these wounded men whole again. Is there a track that has exposed the real nature of the male-to-female love song better than Take Care’s “Marvin’s Room”? The conceit — a drunk Drake leaving a phone message to a long lost love he treated badly but now thinks he wants back — leaves us in no doubt that he was speaking to himself via a fantasised female Other.

Gangsta’s hyperbolically-staged fantasies of omnipotence were always nouveau-riche giveaways, which, like the bling, sang out that these working-class black Americans had not yet achieved the easy way in the world, the casual confidence that are the birthrights of those born to wealth and power. The (gold) chains have always clanked as loudly as Jacob Marley’s that the struggle to escape servitude has run aground, and that untold riches for a very few were the compensation for the many languishing in inertia, poverty, incarceration. Is “Started from the Bottom” — which we all laughed at: no you didn’t, Drake! — Drake’s commentary on all this? Hear it as an act of imagination, Drake putting himself in the sneakers of those who had to struggle from the depths like he never had to, rather than as some forged autobiography, and it makes more sense. But listen to the sheer weariness that weighs down the track: the heavy tristesse that starts the moment after you’ve reached the top of the tower, as the realisation sinks in that there’s no replacing the thrill of the chase. Drake was always expected to be a success, so he was deprived even of that brief moment of satisfaction before the ennui and the paranoia set in. Reaching the top was standard, the least he could expect.

Nothing Was the Same is tangled up in all the confusions of a generation of men faced with contradictory imperatives — the post-feminist awareness that treating women like shit isn’t cool, together with the Burroughsian bombardment of always-available pornography. There’s no point moralising here, either for Drake or us. Drake’s at his weakest when he half-heartedly attempts some kitschy Hallmark card affirmation of lurve; he’s at his most painfully revelatory when he admits that these impasses, these binds, are just too much for him. He can’t escape these knots because the knots are what he is. His bewilderment about what a man is supposed to be now is the very hallmark of a contemporary heterosexual masculinity that realises that the patriarchal game is up, but which is too hooked on the pleasures and privileges to relinquish them yet (just one more click on the porn, then I’ll be Mr Sensitive forever).

On Nothing Was the Same, Drake often sounds like Tony Montana in Scarface: fucking, eating, snorting, is that all there is? But the tone here couldn’t be more different from Pacino’s Eighties cocaine histrionics. A glacial fatalism runs beneath everything here, and Drake matters because he makes contact — maybe better than anyone else — with the sense of hopelessness that quietly subsists beneath all the twerking and tweeting, all the twitter and the chatter of twenty-first-century culture. Hear this in the gorgeous electro-downer haze that saturates the album and establishes its tone much more than any of the beats. Yet there’s something beyond the fatalism, too. You can hear it in Drake’s signature move — the transition from rap to singing, the slipping down from ego-assertion into a sensual purring, the relaxing into a lasciviousness that has nothing to do with the localised libido and dumb automatisms of phallic sexuality. Down here, there is a glorious release from the pressures of identity. Rave-like, pitched-up vocals are suspended on placid currents of synth. Voices stop being human, become avatars from a space where subjectivity has been left behind like a bad dream. On the opener, “Tuscan Leather”, Whitney Houston’s ghost is summoned from the hotel bathroom, mutated into some butterfly-fragile chirruping creature singing inside a specimen jar. I’m frequently reminded of nothing so much as the refracted architectures and water sprites of Balam Acab’s Wander/Wonder. When you dive into these electro-oceanic depths, Nothing Was the Same ceases to be a fascinating symptom of all the blockages of the present, and becomes a longing for something new, something strange and lovely.





break it down: dj rashad’s double cup1

Time-stretched Amen breakbeats, rave-euphoric vocals: on Double Cup, Rashad pays his dues to the hardcore continuum, but the traces of jungle and rave here only accentuate how different footwork is to Nineties British dance music.

Footwork has been greeted with the fanfare that usually accompany the arrival of an avant-garde dance music. These contradictory responses — footwork’s being written off as something that you can’t dance to at the same time as it is dismissed as a functional music, something that would only be properly appreciated by those dancing to it — is a sure sign that we are in the presence of something which scrambles the defaults of rearview hearing.

But footwork is new in a strange way. It’s not historically new: it dates back to the Nineties. And what’s uncanny, unheimlich, about footwork is that practically everything in the sonic palette is familiar. Most of the sounds on Double Cup feel like they could have come from the twentieth century, even if they have actually been produced in the twenty-first.

So, wherein resides footwork’s newness then? In a fascinating blog post,2 Tristam Adams identifies exactly what makes footwork new: its compositional innovations. To bring this out, Adams contrasts footwork to jungle. Jungle’s newness was in large part a consequence of the widespread availability of digital sampling technology, which facilitated both new sounds and new ways of treating sound (time-stretched breakbeats and vocals). Beyond this, though, I’m not sure that the way Adams constructs the comparison between jungle and footwork is quite right. Adams hears jungle as more “machinic” than footwork — but what was exciting about jungle to many of us at the time was that it gave a whole new sense of what machinism was. Jungle’s machinism was delirious; it was, in Kodwo Eshun’s immortal phrase, a rhythmic psychedelia, composed from whorls, twists, and vortexes of sound; there were none of the rigid mechanoid lines of techno. Jungle was dark, but also wet, viscous, and enveloping.

It’s here that the contrast with footwork can most be heard — and felt. To those whose ears and nervous systems were mutated by jungle in the Nineties, footwork can initially sound strangely desiccated — like the dry bones left after jungle’s digital ocean has receded. “UK bass music” is an almost wilfully bland term, but it does point to the element which gave every genre from jungle to UK garage and dubstep their consistency: a viscous, glistening bass sound. This is conspicuously absent from Rashad’s sound. Instead of functioning as a dark liquid element on (or in) which other sounds could be suspended, Rashad’s bass is a surging and reclining series of stabs and jabs that heightens and lowers tension without ever releasing it.

This leads on to another difference from jungle and the broader tendencies in Nineties digital culture. Where jungle, like Nineties CGI, used digital technology to smooth out some of the hard lines that had been characteristic of early computer sound and imagery, footwork has deliberated opted for angularity. Charlie Frame’s comparison of listening to Rashad with “gazing at an animated GIF that grows ever more absurd with each iteration”, captures very precisely footwork’s jerky repetitions. Perhaps the appeal of the animated GIF and of footwork are both tied up with the way that they reject the dominant aesthetics of digital culture now. Think of the way that the elastic architectures of Nineties animatronics gave way to the dreary photorealism of contemporary animation. Now, novelty is to be found in the refusal of communicative capitalism’s false promises of smoothness. If the Nineties were defined by the loop (the “good” infinity of the seamlessly looped breakbeat, Goldie’s “Timeless”), then the twenty-first century is perhaps best captured in the “bad” infinity of the animated GIF, with its stuttering, frustrated temporality, its eerie sense of being caught in a timetrap.

That frustrated, angular time — and the enjoyment of it — is at the heart of footwork. The genre can sound like an impenetrable thicket of rhythms if the thing you lock onto first is the most distinctive thing about footwork: the coiling spasms of super-dry snares. Lock into the floaty synth pads and the vocals, however, and footwork comes on as strangely mellow. In this respect, footwork can then be heard as an extrapolation of elements of Nineties G-funk. An earlier Hyperdub sound — the dayglo wonky of Joker — had mined G-funk for its absurdist pitch-bent synths. What footwork takes is some vocal styling (the rap that is so often subject to its stuttering repetitions), but also a certain mood. G-funk differentiated itself from standard gangsta posturing by the way it dissolved the hard ego of the rapper into clouds of Chronic. Beneath the busyness of capitalist realism — and its demands that we never stop selling ourselves — was another mode of being, where time diffused slowly as exhaled smoke. Beyond the phallic machismo, there was a different libidinal economy, defined by a superficially paradoxical combination of deep yearning and a desire to remain absolutely in the sunlight-saturated moment, liberated from the urgencies of business. This is all the more poignant because a gangster’s work is never done, his enemies don’t sleep, and chilled-out bliss could be terminated at any moment by gunfire. To the G-funk celebration of smoking, Rashad adds other affective toners: the lost-in-the-moment exhilaration of the raver, and R&B’s wistful regrets/lascivious moaning. The overall result is, in terms of mood and affect, oddly reminiscent of cool-era jazz — there is the same ambivalence, the same evocation of an harsh yet alluring urban environment, the same combination of sadness and confidence, the same articulation of longing and bliss.

Then there is the tic-talk of the voices themselves — the way they are made to stammer and circle around themselves. It’s as if there is a cross-contamination, a human-machine (psycho)pathology, the machines infecting the human voices with glitches, the humans passing on Freudian slips, parapraxes, to the machines. Rashad’s plaintive machinism reminds me of nothing so much as the hallucinatory intensity of the “I Love You” section of William Burroughs’ The Ticket That Exploded:

On my knees I hoped you’d love me too. I would run till I feel the thrill of long ago. Now my inspiration but it won’t last and we’ll be just a photograph. I’ve forgotten you then? I can’t sleep, Blue Eyes, if I don’t have you. Do I love her? I love you I love you many splendored thing. Can’t even eat. Jelly on my mind back home. ‘Twas good bye deep in the true love. We’ll never meet again, darling, in my fashion.3

Burroughs’ early cut-up and fold-in texts, with their analysis and decoding of emotional manipulation via media and their understanding of pornography as a control apparatus, now read like extraordinarily prophetic anticipations of the present moment. As with Burroughs, there is a double pathos in Rashad’s work. First of all, there is a pathos at the level of the affects in the voices themselves; and the way that the voices are orphaned from their supposed origins means that there is an overwhelming sadness even if the feeling expressed is ostensibly joyful. It’s the same kind of depersonalised sadness we might feel if we happened upon lost photographs of an unknown person’s holiday, long ago. Then there is another pathos that arises from the way that the voices are made to repeat and stutter; the sadness of recognising a speaking animal (ourselves) in the grip of automatisms, repetitions, drives. Rashad articulates the impasses of our twenty-first-century condition with a precision and a compassion that few others can match. More importantly, he suggests that — against all the odds — we might still be able to dance our way out of the time-traps and identity prisons we are locked in.





start your nonsense! on eMMplekz and dolly dolly1

There are still all kinds of possibilities for combining voice and sound in new ways. Rap was the last major form to popularise a use of the voice that was not singing, but the field is wide open, as these two new albums from eMMplekz and Dolly Dolly prove.

The first temptation with these records is to hear them as “spoken word” — with the musicality subordinated to a voice that is literary, conversational, comedic. However, what makes these two albums so unique is the way that musicality here infests and inflects the voice, the way that the sound refuses to stay (in the) background. Both albums take much of their inspiration from the very English tradition of Nonsense, which includes Edward Lear, Lewis Carroll, Monty Python, and more recently, Chris Morris. It was on account of Carroll that André Breton reputedly said that the English had no need of surrealism. Here, eMMplekz and Dolly Dolly proffer different versions of twenty-first-century English sonic surrealism.

With eMMplekz, a collaboration between Ekoplekz and Mordant Music’s Baron Mordant, the precursors that first come to mind are certain moments in post-punk — Cabaret Voltaire’s “Photophobia”, Throbbing Gristle, the Fall — yet eMMplekz don’t sound quite like any of these. From its title on in, Your Crate Has Changed, the Baron’s punconscious wordplay has a very contemporary focus.

If Drake and Kanye West expose the sadness and madness deep within the cyber-pleasuredome — the sound of depressed superstars as hypercommodities — then eMMplekz observe the malaises and pathologies of capitalist cyberspace from outside the digital matrix. Instead of the seamlessslick, depthless pixellation to which always-on digitality has habituated us, Ekoplekz’s analog electronics seethe and hiss, gathering and dispersing like a steam and mist. These synthesizer sketches function like impressionist sound paintings of what Ken Hollings has called the “digital regime”, and it’s as if, like users coming down from a psychotropic, we are finally seeing it for what it is.

“I’ve got to take this…” Baron Mordant has a schizoanalytic ear for how the digital regime reveals itself through the phrases it induces to casually utter. Doesn’t this phrase — so often repeated, so little thought about — capture all too accurately our fatalism in respect of communicative capitalism? “I’ve got to take this” — I’ve got to let it, accept it, I can’t escape, there’s nothing I can do… There’s no way out, there’s no release from the frenzied inertia of all those cyberspatial urgencies, these alerts. “Tethered to my hotspot, tethered to my hotspot…” Constant anxiety about staying connected, constant worry about holding onto the equipment that allows us to stay connected. “Can you watch my laptop?” We’re all sick of this now… we’re all sick because of this now… “Sorry for your Lossy…” What is all this digital compression costing us, and when do we ever get to count the cost? (The first thing we do in the morning is grope for our smartphones — straight from sleep into the somnambulance of capitalist cyberspace. “Unsubscribe from Soviet time” — maybe we did that too soon, and now it’s business o’clock, forever…)

Your Crate Has Changed is like an English take on Franco “Bifo” Berardi’s Precarious Rhapsody: Semiocapitalism and the Pathologies of Post-Alpha Generation. Berardi persuasively argues that the interlock between precarious work and capitalist communications technology has produced a population whose nervous systems are overloaded with stimuli. Mordant gives voice to weary old digital migrants whose middle-aged flesh is too saggy and grey to be made-over — people deprived of security, forced to keep on hustling even though they are too old for the game, bone-weary. No rest for the precarious, no chance to tune into anything except the imperatives of business. “Invoices in my head… invoices in my head…”

Invoices in my head, and too much spam and random cyber-noise to hear anything else. But I don’t think there’s been anyone since Mark E. Smith at his telepathic peak in the late Seventies/early Eighties who has managed to tune into the rogue frequencies of England’s schizo-babble as effectively as the Baron does here. Mordant finds all the clandestine signals hidden in jingles and classified ads. He channels the voices of the lonely, the desperate, all the weirdos and the saddoes; ourselves, perhaps, but the secret selves we keep stuffed behind our Facebook walls. Yet there are still avenues of escape — on a couple of tracks, an infant’s babbling offers an alternative Nonsense to capital’s infantilised huckster-speak.

A surface joviality — a different kind of humour, much less mordant — separates Dolly Dolly from eMMplekz. Yet it’s the slippages of tone and genre, from light pastiche to intimations of mortality, the sliding of persona from gone-to-seed raconteur to charity shop mystic, from short story-teller to preening bard, that make Antimacasser such an odd jewel of a record, and Dolly so singular a performer.

The opening track, “Wattle and Daub” — a collaboration with Position Normal — is more than worth the admission price alone. Over a lysergicallysmeary detuned piano (or maybe guitar), Dolly Dolly dolefully declaims a Nonsense-Shakespearean state of the nation address. “England my England… the cold mist of your fibrous trolleys stifles the sun… half-strangled uncles stuffed with crisps… your sky full of plump chintz cushions…” It’s like Tony Hancock’s melancholia has been dream-conflated with his mockery of thespian and playwright pretensions. Yet the Nonsense is disarming: “Wattle and Daub” gives us nothing less than a psychedelic-surrealist portrait of a country deprived of psychedelia and surrealism. A world without surprise, an entirely domesticated universe, banality as cosmology: “Let’s colonise the other planets, fill them with bitter and dry roasted peanuts, pigeons and oven chips.” The dead world of middle-aged Britain’s living rooms; the cheery veneer of advertising’s ever-smiling, glowing-faced families turned inside out. “I’m sick of being a man”, moans the character who narrates the closing track. Aren’t we all? But Antimacasser finds all sorts of disused or temporarily abandoned doorways into other worlds, all kinds of rabbit holes in which we can escape from being a sad human animal. Old New English Library paperbacks become occult manuals, full of esoteric philosophy. It’s still possible to transform ourselves, to transport ourselves, and Dolly Dolly shows us how.





review: sleaford mods’ divide and exit and chubbed up: the singles collection1

The East Midlands accent, lacking urban glamour, lilting lyricism or rustic romanticism, is one of the most unloved in the UK. It is heard so rarely in popular media that it isn’t recognised enough even to be disdained. I must confess that I have a dog in this fight. I grew up in the East Midlands, and when I left university I was described by a sympathetic lecturer as having a “speech and accent problem”. The accent gradually disappeared, as I learned to suppress the lazy Leicestershire consonants and articulate my speech in something closer to so-called received pronunciation — an achievement loaded with ambivalence and shame.

Sleaford Mods’ Jason Williamson makes no such accommodation to metropolitan manners, and he’s disgusted at those who speak in fake accents, whether they’re imitating someone from East London or “Lou Reeds, G.G. Allin…” The appeal to the local in politics and culture is usually smug and reactionary; a petit-bourgeois ruse to acquire more cultural and actual capital by overpricing the artisnal and the organic (Williamson is wise to this scam too, blasting at “expensive coffee shops full of local art/Fuck off”). But the politics of locality operate differently when it comes to accent. The English bourgeoisie speak in more or less the same accent wherever they come from. The insistence on retaining a regional accent is therefore a challenge to the machineries of class subordination — a refusal to accept being marked as inferior.

Williamson was born in Grantham, Lincolnshire — Sleaford is about twenty miles away — and was involved in the music scene for years, following a familiar provincial trajectory: not making it, but always being lured back at the very point he was about to give up. He was in and out of local groups, followed the dream to San Francisco and London for a while, and ended up back home when it didn’t come off. He tried to go out on his own, but he couldn’t find anything new, until, bored and frustrated in a recording studio, he started ranting over a metal track. He had found his voice, literally. He was inspired by the Wu-Tang Clan, but he didn’t so much repeat their sound as their methodology, forcing listeners to adjust to his accent, idiolect and references. This risked bathos — the East Midlands ain’t New York, and Sleaford Mods would come off as just another comic turn if it weren’t for Williamson’s incendiary intensity. (Which isn’t to deny the mordantly acidic wit that runs through his lines: “Chumbawamba weren’t political?/They were just crap”, isn’t just funny but critically astute.)

Listen to the singles collection, Chubbed Up, next to Divide and Exit, and it’s clear not much has changed in the duo’s sound. The variation is provided by Williamson’s words, the music by Andrew Fearn always fits an (unfussy) formula: pugilistic post-punk bass; functional but unprepossessing beats; occasional cheap keyboard riffs and listless wafts of guitar. It’s digitally manipulated, but conspicuously unpolished — the software is used not to micromanage the sounds but to capture them into a purgatorial loop.

The name Sleaford Mods sounds like vintage graffiti, or something you’d have sewn onto a Union Jack at an England football match three decades ago. On the face of it, they couldn’t be any less mod. Where is the style and the cool in this relentless outpouring of profanity and discontent? But mod was a complex phenomenon, as much about the failure to achieve the glamour of black America as it was about the aspiration towards possessing it. The mods might have loved Miles and Motown but when they made music it sounded like the Who and the Jam — rock born with a plastic spoon in its mouth, stuck in a monochromatic England skulking in the shadows cast by the USA’s Pop Art consumer dreams. The mods worked in office jobs, in semi-skilled occupations and in department stores, longing for a luxury far above their station. But their ambitions weren’t to climb the social ladder of bourgeois respectability — they prefigured instead a world in which style exploded far beyond the narrow calculations of business, and everyday life could become a work of art. As Dick Hebdige wrote in his essay “The Meaning of Mod”: “Every mod was existing in a ghost world of gangsterism, luxurious clubs and beautiful women, even if the reality only amounted to a draughty Parker anorak, a beaten up Vespa, and fish and chips out of a greasy bag.” With Sleaford Mods, the chips and the grease are all that’s left. Factories have closed and trade unions have been subdued. Art schools and the media have rebourgeoisified. University courses have been opened up, but the real graduate jobs are reserved for the same old suspects. The only time you are likely to hear a working-class accent on television is in a poverty porn documentary.

This is Sleaford Mods’ world, but they refuse the place assigned to them by well-meaning metropolitan liberals and by unscrupulous Tories. They won’t play the part of a dumb feckless prole or white, working-class racist (Williamson loathes St George’s flag white van men as much as their Tory overlords). They won’t knuckle down and gratefully accept zero-hours contract jobs, or be content to “rot away in the aisles of Co-Op”, as the single “Jolly Fucker” had it.

If anything, Divide and Exit feels more claustrophobic than its predecessor, Austerity Dogs, with even the tiny dreamy spaces that once opened up on tracks such as “Donkey” eliminated by Williamson’s relentless excremental flow. Excremental is the right word: piss and shit course through Williamson’s rhymes, as if all the psychic and physical effluent abjected by Cameron’s Britain can no longer be contained, and it’s bursting upwards, exploding through all the deodorised digital commercial propaganda, the thin pretences that we’re all in this together and everything’s going to be all right.

What overflows in Williamson’s pottymouth is a seething disaffection incubated on the dole or in dead end jobs and further stoked up by the shop-soiled fantasies of escape pushed by an ailing music business. An early single was called “Jobseeker”: “So Mr Williamson — what have you done to find gainful employment since your last signing on date?/Fuck all!” A fantasy exchange no doubt: here, as often in Sleaford Mods Williamson gives vent to a voice that would otherwise stay locked in his head. Discontent is everywhere in the UK now but for the most part it’s privatised: blunted by alcohol and anti-depressants, or directed into impotent comments box spite and empty social media outrage: “All you Zombies, tweet tweet tweet”.

If Williamson’s anger often seems intransitive — his fuck offs are sheer explosions of exasperation, directed at no one in particular, or at everyone — it’s underscored by a class consciousness painfully aware that there is nothing which could transform disaffection into political action. “Aren’t we all just/Pissing in the flames?” Cameron and the Tories are obviously despised — there’s a particularly memorable nightmare image of the “Prime Minister’s face hanging in the clouds/Like Gary Oldman’s Dracula” — but who can stop them? “Liveable shit/You put up with it”. This is both a taunt directed at the audience and an acknowledgement of Williamson’s own capitulation in doing what’s necessary to survive.

It isn’t always the role of political music to come up with solutions. But nothing could be more urgent than the questions that Sleaford Mods pose: who will make contact with the anger and frustration that Williamson articulates? Who can convert this bad affect into a new political project?





test dept: where leftist idealism and popular modernism collide1

There’s something very timely about the return of Test Dept. Their installation DS30 (2014), the accompanying film and the book Total State Machine (2015) — a comprehensive history and critical study of the band — have arrived just in time for the deep crisis of neoliberalism in the UK.

Test Dept were always more than a musical group. They are better understood as a popular modernist collective that had the production of sound at its centre, but which also made visuals, projections and films. Test Dept were formed in London in 1981 by Jonathan Toby Burdon, Graham Cunnington, Angus Farquhar, Paul Hines and Paul Jamrozy. They began as a second-wave industrial act, following on from a first wave led by Throbbing Gristle and Cabaret Voltaire. With their use of found metal objects and their performances in spaces of labour and logistics (disused factories, transport hubs), Test Dept offered what seemed, on the face of it, to be a very literal take on the “industrial”. Via their involvement in a number of UK struggles — including the miners’ strike (1984–85) and the anti-Poll Tax movement (1988–91) — Test Dept also became intensely invested in the politics of the industrial and the post-industrial.

Test Dept’s signature sound is intensely percussive, a convulsive dance music that took its inspiration from Soviet constructivism, but which became something like the British equivalent of the politicised US hip-hop group Public Enemy. The records are sonic mosaics, pulsing with panic, the sampled voices of Tory MPs countered by defiant statements by left-wing militants. One of Test Dept’s most powerful tracks — “Statement” from the 1986 album The Unacceptable Face of Freedom — features miner Alan Sutcliffe giving a moving account of police brutality during the strike. The track is a work of emotional engineering, a collectivist response to the manipulation of affect and desire through advertising, branding and political propaganda. Sutcliffe went on to tour with the group: one example of the way in which struggles produced not only new alliances but new social spaces, in which art-making ceased to be a matter for specialists of a certain age.

For any British, left-wing person, remembering the mid-1980s is liable to provoke a sadness that is visceral, choking, wrenching. I still can’t recall without weeping the day when the miners returned to work in 1985 after a year on strike. What I have called capitalist realism — the deeply embedded belief that there is no alternative to capitalism — was definitively established in the UK during that period, in Margaret Thatcher’s second term in government. For a significant proportion of the population, the 1982 Falklands War had transformed Thatcher from a figure of loathing into a glorious war leader. This renewed popularity, together with the formation of the Social Democratic Party by Labour Party defectors, allowed the Tories to achieve a landslide victory in the 1983 general election. It proved to be a traumatic defeat for the British left in general, and for the Labour Party in particular. Labour began its long march towards Blairism and its eventual complete capitulation to neoliberalism and corporate tyranny. Meanwhile, the crushing of the miners’ strike, and the wave of privatisations that the Tories unleashed, created the conditions for the neoliberal Britain that is only now falling apart, thirty years later.

In retrospect, it can look as if the whole of the 1980s was a series of defeats for the left. One value of Total State Machine is to remind us that it didn’t feel that way at the time. Rather, like John Akomfrah’s video installation The Unfinished Conversation (2013), the Total State Machine book invokes a forgotten 1980s, in which style culture was synchronised with the rise of an anti-authoritarian left that confidently laid claim to a new modernity, set to dispense with capital, patriarchy and racism as so many historical relics; a 1980s in which radical chic and designer socialism weren’t dirty words but real possibilities.

Total State Machine includes a section of Cynthia Rose’s 1991 book Design After Dark. Inspired by a Test Dept performance, Rose argues that young Britons would

succeed in staging a dancefloor revolution. It will not be the Komsomolstyle overthrow dreamt of by Red Wedge, the ill-fated attempt by a collective of musicians — led by Billy Bragg, Paul Weller and Jimmy Somerville — to spearhead a campaign to defeat the Tories in the 1987 General Election. Instead, it will come about through grass-roots changes — successive waves of guerrilla sounds, guerrilla design, guerrilla entertainments. The new design dynamic will be an impulse born out of celebration, rising out of leisure enacted as an event. And it will change young people’s perception about what entities like design and communication should do.2

Sadly, it didn’t work out that way. Rose was absolutely right that most of the innovative energy in British music culture would come from dance music, which was about to enjoy its most fecund period ever. But the atmosphere around rave, jungle and garage tended towards the apolitical, the libertarian or the capitalist. The alliance of the left with the new technologies, energies, infrastructures and forms of desire that Rose saw emerging was to be very short-lived.

The comparison with Red Wedge is instructive here. Part of the problem with Red Wedge was that, despite taking its name from a poster designed by El Lissitzky (Beat the Whites with the Red Wedge, 1919), its music represented a retreat from modernist experimentalism. Bragg’s blokeish neo-folk, the hamfisted jazz-funk-pop Weller made with the Style Council, the Communards’ strangely depressing party music: none of this was capable of articulating a future. It was all bogged down in the worst kind of 1980s gloss.

Test Dept were one of the last examples of what has been called post-punk, but really they are part of a longer trajectory of art pop/pop art going back to the 1950s. The conditions for this popular modernism were subject to sustained attack in the mid-Eighties, and they have never recovered. The Tories began to dismantle the infrastructure of social security, higher-education maintenance grants, squatting and art schools that had given working-class people access to the resources of so-called high culture and time to produce their own sound, fiction and art.

But the neoliberal capitalism that drove this assault on culture is now heading for disaster — in Greece, in Spain, in Scotland and, finally, in England. Far from being some static monument to a bygone era, Total State Machine is an invaluable archive, an inventory of strategies, gestures and techniques that can now be repotentiated by others ready to begin where the Test Dept of the 1980s left off. Rose’s prophecies of a new design dynamic can yet come true. Popular modernism isn’t dead: it has merely had a thirty-year hiatus.





no romance without finance1

Jennifer M. Silva’s Coming Up Short: Working-Class Adulthood in an Age of Uncertainty is a heartbreaking study of the corrosive effects of the neoliberal environment on intimacy. Silva’s book focuses on young people specifically — it is based on a hundred interviews she undertook with young working-class men and women in two American cities in Massachusetts and Virginia. Her findings are disturbing. Over and over again, Silva finds her young subjects exhibiting a “hardened” self — a form of subjectivity that prides itself on its independence from others. For Silva, this hardened subject is the consequence of this generation being abandoned, institutionally and existentially. In an environment dominated by unrelenting competition and insecurity, it is neither possible to trust others nor to project any sort of long-term future. Naturally, these two problems feed into one another, in one of the many vicious spirals which neoliberal culture has specialised in innovating. The inability to imagine a secure future makes it very difficult to engage in any sort of long-term commitment. Rather than seeing a partner as someone who might share the stresses imposed by a harshly competitive social field, many of the working-class individuals to whom Silva spoke instead saw relationships as an additional source of stress. In particular, many of the heterosexual women she interviewed regarded relationships with men as too risky a proposition. In conditions where they could not depend on much outside themselves, the independence they were forced to develop was both a culturally-validated achievement and a hard-won survival strategy which they were reluctant to relinquish.

“In a world of rapid change and tenuous loyalties”, Silva argues, “the language and institution of therapy — and the self-transformation it promises — has exploded in American culture.”2 A therapeutic narrative of heroic self-transformation is the only story that make sense in a world in which institutions can no longer be relied upon to support or nurture individuals:

In social movements like feminism, self-awareness, or naming one’s problems, was the first step to radical collective awareness. For this generation, it is the only step, completely detached from any kind of solidarity; while they struggle with similar, and structurally rooted, problems, there is no sense of “we”. The possibility of collective politicisation through naming one’s suffering is easily subsumed within these larger structures of domination because others who struggle are not seen as fellow sufferers but as objects of scorn.3

The spreading of therapeutic narratives was one way in which neoliberalism contained and privatised the molecular revolution that consciousness-raising was bringing about. Where consciousness-raising pointed to impersonal and collective structures — structures that capitalist and patriarchal ideology obscures — neoliberalism sees only individuals, choices and personal responsibility. Yet consciousness-raising practices weren’t only at odds with capitalist ideology; they also marked a decisive break with Marxist-Leninism. Gone was the revolutionary eschatology and the militaristic machismo which made revolution the preserve of an avant-garde. Instead, consciousness-raising made revolutionary activity potentially available to anyone. As soon as two or more people gather together, they can start to collectivise the stress that capitalism ordinarily privatises. Personal shame becomes dissolved as its structural causes are collectively identified.

Socialist-feminism converted Lukács’s theory of class consciousness into the practice of consciousness-raising. Since consciousness-raising has been used by all kinds of subjugated groups, it would perhaps be better to talk now of subjugated group consciousness rather than (just) class consciousness. But it is worth noting in passing that neoliberalism has sought to eradicate the very concept of class, producing a situation memorably described by Wendy Brown, in which there is “class resentment without class consciousness or class analysis”. This erasure of class has distorted everything, and allowed many struggles to be rhetorically captured by bourgeois liberalism.

Subjugated group consciousness is first of all a consciousness of the (cultural, political, existential) machineries which produce subjugation — the machineries which normalise the dominant group and create a sense of inferiority in the subjugated. But, secondly, it is also a consciousness of the potency of the subjugated group — a potency that depends upon this very raised state of consciousness. However, it is important to be clear that the aim is not to remain in a state of subjugation. As Nancy C. M. Hartsock explains, “the point is to develop an account of the world that treats our perspectives not as subjugated, insurrectionary, or disruptive knowledges, but as potentially constitutive of a different world”.4

To have one’s consciousness raised is not merely to become aware of facts of which one was previously ignorant: it is instead to have one’s whole relationship to the world shifted. The consciousness in question is not a consciousness of an already-existing state of affairs. Rather, consciousness-raising is productive. It creates is a new subject — a we that is both the agent of struggle and what is struggled for. At the same time, consciousness-raising intervenes in the “object”, the world itself, which is now no longer apprehended as some static opacity, the nature of which is already decided, but as something that can be transformed. This transformation requires knowledge; it will not come about through spontaneity, voluntarism, the experiencing of ruptural events, or by virtue of marginality alone. Hence Hartsock’s concept of standpoint epistemology, which maintains — following Lukács and Marx — that subjugated groups potentially have an access to knowledge of the whole social field that the dominant group lacks. Members of subjugated groups do not however automatically possess this knowledge as of right — it can only be accessed once group consciousness is developed. According to Hartsock, “the vision available to the oppressed group must be struggled for and represents an achievement which requires both science to see beyond the surface of the social relations in which all are forced to participate, and the education which can only grow from struggle to change those relations.”

One way of seeing Jennifer M. Silva’s book is as an account of radically deflated consciousness. Crucial to this is Silva’s restoration of the concept of class as a frame shaping the experiences of those who feature in her study. Class is what is typically missing from her interviewees’ “therapeutic” accounts of themselves. Exactly as Wendy Brown says, many of Silva’s subjects tend to exhibit (an unconscious and disavowed) class resentment without class consciousness.

Reading Silva’s descriptions of women wary of giving up their independence to men they perceive as feckless wasters, I was reminded of two R&B hits from 1999: “No Scrubs” by TLC and “Bills Bills Bills” by Destiny’s Child. Both these songs see financially independent women upbraiding (presumably unemployed) men for their shiftlessness. It is easy to attack such tracks for their seeming peddling of neoliberal ideology. Yet I think it far more productive to hear these songs in the same way that we attend to the accounts in Silva’s book. These are examples of consciousness deflated, which have important lessons to communicate to anyone seeking to dismantle capitalist realism.

It is still often assumed that politics is somehow “inside” cultural products, irrespective of their context and their use. Sometimes, agit-prop style culture can of course be politically transformative. But even the most reactionary cultural expression can contribute to a transformative project if it is sensitively attended to. It is possible to see the work of the late Stuart Hall in this light: as an attempt to bring to leftist politics the messages that culture was trying to impart to it. If this project was something of a tragic failure, it was a consequence, not of the shortcomings in Hall’s approach, but of the intransigence of the old left, its deafness to the desires and anxieties being expressed in culture. Ever since Hall fell under the spell of Miles Davis in the 1950s, he dreamed of somehow commensurating the libidinal modernity he encountered in popular music with the progressive political project of the organised left. Yet the authoritarian left was unable to tune into this ambition, allowing itself to be outflanked by a new right which soon claimed modernisation for itself, and consigned the left to the past.

To understand this failure from another angle, let’s consider for a moment the work of the late music and cultural critic Ellen Willis. In her 1979 essay, “The Family: Love It Or Leave It”5, Willis observed that the counterculture’s desire to replace the family with a system of collective child-rearing would have entailed “a social and psychic revolution of almost inconceivable magnitude”. It’s very difficult, in our deflated times, to re-create the counterculture’s confidence that such a “social and psychic revolution” could not only happen, but was already in the process of unfolding. Like many of her generation, Willis’s life was shaped by first being swept up by these hopes, then seeing them gradually wither as the forces of reaction regained control of history. There’s probably no better account of the Sixties’ counterculture’s retreat from Promethean ambition into self-destruction, resignation and pragmatism than Willis’s collection of essays Beginning To See The Light.6 As Willis makes clear in her introduction to the collection, she frequently found herself at odds with what she experienced as the authoritarianism and statism of mainstream socialism. While the music that she listened to spoke of freedom, socialism seemed to be about centralisation and state control. The counterculture’s politics were anti-capitalist, Willis argues, but this did not entail a straightforward rejection of everything produced in the capitalist field. Certainly, pleasure and individualism were important to what Willis characterises as her “quarrel with the left”, yet the desire to do away with the family could not be construed in these terms alone; it was inevitably also a matter of new and unprecedented forms of collective (but non-statist) organisation. Willis’ “polemic against standard leftist notions about advanced capitalism” rejected as at best only half-true the ideas “that the consumer economy makes us slave to commodities, that the function of the mass media is to manipulate our fantasies, so we will equate fulfilment with buying the system’s commodities”. Culture — and music culture in particular — was a terrain of struggle rather than a dominion of capital. The relationship between aesthetic forms and politics was unstable and inchoate — culture didn’t just “express” already-existing political positions, it also anticipated a politics-to-come (which was also, too often, a politics that never actually arrived).

Yet there was also an immanent transformative immediacy in the music of the counterculture. It reinforced the feelings of despair, disaffection and rage that bourgeois culture ordinarily makes us distrust. As such, music functioned as a form of consciousness-raising, in which a mass audience could not only experience its feelings being validated, it could locate the origins of those feelings in oppressive structures. Moreover, the ingestion of hallucinogens by growing numbers of the population, and the emergence of a psychedelic imaginary that touched even those who had never used acid, made for a widespread perception that social reality was provisional, plastic, subject to transformation by collective desire.

If Beginning to See the Light is a painful — and painfully honest — account of consciousness deflation, then the same story is narrated within music culture itself. Peter Shapiro has shown how early Seventies soul and funk music — the O Jays’ “Back Stabbers”, the Undisputable Truth’s “Smiling Faces Sometimes”, Sly Stone’s “You Caught Me Smiling” — “engaged in a remarkable conversation” about the newly minted Smiley yellow face image, “an imagistic minefield that played confidence games with centuries of caricatures, the beaming faces of the white establishment promising civil rights and integration and () Nixon’s Dirty Tricks gang.” With Nixon on the rise and the Panthers subdued, songs like “Backstabbers” caught a new mood of suspicion and recrimination. In his classic essay “The Myth of Staggerlee”, Greil Marcus argues that these songs — along with the rest of Sly and the Family Stone’s There’s A Riot Goin’ On and the Temptations’ “Papa Was A Rolling Stone” — were part of a bitter moment, when Sixties optimism had drained away to be replaced by paranoia and melancholy. Stone writes, “when new roles break down and there is nothing with which to replace them, old roles, ghosts, come in to fill the vacuum”. The collectivity and the multiplicity that the Family Stone had embodied — radical democracy in vibrant action: a group made up of men and women, blacks and whites — gave way to a morose and dejected individualism. “The best pop music does not reflect events so much as it absorbs them”, Marcus wrote. “If the spirit of Sly’s early music combined the promises of Martin Luther King’s speeches and the fire of a big city riot, Riot represented the end of those events and the attempt to create a new music appropriate to the new realities.”

These “new realities” would eventually become nothing less than capitalist realism itself. Capitalist realism — in which current social relations are reified to the point that any shift in them becomes unimaginable — could only be fully consolidated once the Promethean-psychedelic imaginary was all but entirely subdued. But this would take a while. The Seventies weren’t only about countercultural retreat and defeat. In When the Lights Went Out: Britain in the Seventies, Andy Beckett argues that a “liberal or left-wing melancholy about the Seventies has, in many ways, been the mirror image of the doomy right-wing view of the same period”. But, as Beckett argues, this “fails to acknowledge that for many politicised Britons, the decade was not the hangover after the Sixties; it was the point when the great Sixties party actually started”. The successful Miners’ Strike of 1972 saw an alliance between the striking miners and students that echoed similar convergences in Paris 1968, with the miners using the University of Essex’s Colchester campus as their East Anglian base. The Seventies also saw the growth in Britain of gay, anti-racist, feminist and Green movements. In many ways, it was it was the unprecedented success of the left and the counterculture in the 1970s that forced capital to respond with neoliberalism. This was initially played out in Chile, after Pinochet’s CIA-backed coup had violently overthrown Salvador Allende’s democratic socialist government, transforming the country — via a regime of repression and torture — into the first neoliberal laboratory.

The Seventies that Andy Beckett celebrates in the British context found expression in the US in the disco genre. Disco was a music that grew out of the convergence of a number of subjugated groups. It was a music made by and for gays, black people and women, and — like most postwar popular music, it was overwhelmingly produced by the working class. Chic’s Nile Rodgers — surely the most important producer and sonic conceptualist of the late Seventies and early Eighties — had been a member of the Black Panthers as a teenager. Disco provided the template for the successive waves of dance music in the Eighties and Nineties, including house, techno, rave and garage. In her 1991 book Design After Dark, Cynthia Rose prophesied a “dancefloor revolution” that would

come about through grass-roots changes — successive waves of guerrilla sounds, guerrilla design, guerrilla entertainments. The new design dynamic will be an impulse born out of celebration, rising out of leisure enacted as an event. And it will change young people’s perception about what entities like design and communication should do.7

Yet Rose understandably failed to anticipate the extent to which the new energies, infrastructures and forms of desire she identified would be appropriated by a neoliberal culture which would lay claim to freedom and pleasure, while associating the left with a grey puritan statism. Once again, the left missed an opportunity, failing to successfully align itself with the collective euphoria of dancefloor culture. Thus the “good times” on the dancefloor became fleeting escapes from a capitalism that was increasingly dominating all areas of life, culture and the psyche.

This super-domination came out in the mordant yet playful “realism” of Gwen Guthrie’s 1986 R&B hit, “Ain’t Nothing Goin’ On But The Rent”, one of the first popular musical signs of the emergence of the new hardened subject that Silva analyses so well. At a time of rising unemployment, Guthrie sang, “You’ve got to have a j.o.b. if you want be with me/no romance without finance”. The subjectivity performed in Guthrie’s song is in many ways the female counterpart to the gangster rap persona that was emerging when the single was released. Both reject intimacy and tenderness. In gangster rap there is a hyberbolic performance of invulnerability — a performance that can only appear bitterly ironic, when we consider the fact that even some of the most wealthy and successful gangster rappers (such as Tupac Shakur and Biggie Smalls) would end up being shot dead. By contrast, and despite its surface bravado, “Ain’t Nothing Goin’ On But The Rent” is a song about the need for security — “fly girl like me/needs security” — in conditions of radical uncertainty. This wasn’t some celebration of Reaganomics. On the contrary, Guthrie’s song drew out the way in which Reaganomics was corroding the conditions for intimacy — a message that was much more emotionally charged and politically resonant than most of the protest songs of the time. Similarly, the formula “no romance without finance” need not only be construed as merely some reactionary concession to capitalist realism. Rather, it can be heard as a rejection of the ideological sentimentality that separates out social reproduction from paid work. Anticipating much of twenty-first-century popular music, “Ain’t Nothing Goin’ On But the Rent” is the sound of the loneliness that happens when consciousness is deflated, and the conditions for raising it are absent. But with the new movements that are rising in the US after Ferguson, with the movements in Europe that have produced Podemos and Syrisa, there is every reason to believe that those conditions are returning. It is beginning to look as if, instead of being the end of history, capitalist realism was a thirty-year hiatus. The processes that began in the Sixties can now be resumed. Consciousness is being raised again.





PART FOUR

FOR NOW, OUR DESIRE IS NAMELESS: POLITICAL WRITINGS





don’t vote, don’t encourage them1

There was a time when elections at least seemed to mean something. I still recall, viscerally, the hollow, bitter sense of total existential defeat the day after Foot’s tragically bound-for-disaster hard left succumbed to the storm troopers of SF Kapital under Thatcher, and I, only fifteen years old, contemplated “Five More Years” of Tory rule. I didn’t hear it at the time, but the song that always brings that feeling, that moment, is Mark Stewart’s “Liberty City”: “I’ll give a wave to the management mercenaries… Don’t their clean clothes look so pretty/Try to awaken then from the comforts of slavery…”

There are still those who would like to pretend that a Tory administration would be so much worse than New Labour, so that deigning to vote for anyone else would be an “indulgence”. Choosing “the least worst” is not making this particular choice, it is also choosing a system which forces you to accept the least worst as the best you can hope for. Naturally, the defenders of the dictatorship of the elite pretend — perhaps they even deceive themselves — that the particular slew of lies, compromise and smarm they are hawking is “only temporary”; that, at some unspecified time in the future, things will improve if only we support the “progressive” wing of the status quo. But Hobson’s choice is no choice, and the delusion of progressivism is not a psychological quirk, it is the structural delusion upon which liberal democracy is based.

Johan Hari tries to make the case for reluctantly voting New Labour today, on the grounds that the Tories are the only realistic alternative and they are manifestly worse than New Labour. But just what is the threat that Howard’s Tories pose? Will they suspend habeas corpus? Can’t, Toneeeeee’s already done it. Will they shamelessly and shamefully play to the rightwing gallery on immigration? Well, yes, but that’s only what the Joker Hysterical Face is already doing. (It’s not the war that made me lose any vestigial sentimental attachment to New Labour, it was their disgusting and despicable pandering to the right on immigration.)

Let’s dispense with this idea, once and for all, that New Labour has “improved” anything. New Labour is the worst of all worlds: Thatcherist managerialism without the Thatcherite attack on vested interests. In the pre-Thatcher 1970s, it took six carworkers to do the job of one; in the post-Thatcher Noughties, it takes six consultants to do the job of none (since the mission statement wasn’t worth writing in the first place). Same decadence, different beneficiaries. New Labour and its supporters scoff at the Tories’ idea that you could cut £35 billion in public spending and yet improve public services. As someone who works in public services, it strikes me as eminently plausible (not that I believe that the Tories would do it, or do it right, if they came to power, naturally). Cutting back on red tape, bureaucrats, paperwork would have two immediately positive effects: it would get rid of the managers and administrators whose wages are a disproportionate drain on the budget, and it would improve the performance of those who actually do the jobs, simply by dint of the fact that they wouldn’t have to deal with nannying memos and those who send them all the time.

Blair isn’t just contingently a liar, he is, like the new breed of career politician he heads, a professional liar. As a lawyer turned politician, it’s no surprise that Blair treats reality as a distraction from PR. He has been complicit in producing a situation in which there is no more at stake in parliamentary democracy than “beating the other side”, as in a “debate” at the Oxford Union. His I-am-innately-good moral righteousness is as much a testament to his public school and Oxbridge education as anything else: you see, glinting in the eyes, the unwavering certainty of the truly imbecilic. Blair likes to see himself as a conviction politician, but apart from his imperialist intransigence (itself a symptom of his belief in his own innate superiority), what else IS he actually committed to? It’s telling that the only thing he was prepared to defy public opinion on was the war.

Blair’s slogan “education, education, education” is the sickest joke of all (and not only because he has presided over the dumbest front bench in recorded history, another testament to the wonder of Oxbridge). Maybe he has “pumped more money” into education, but that is useless if the extra funds are going on quangos, incompetent administrators and facile “initiatives” that were doomed to fail and pointless even if they succeeded.

The “Third Way” “solution” to Further Education is a typical Blairite catastrophe. Colleges are now funded per student, with the result that students now treat themselves as “consumers” — i.e. the canny ones quickly realise that even the most abusive or violent behaviour is unlikely to result in their being removed from the college, since it means a significant cut in the college’s revenue. Students with behavioural problems shouldn’t simply be turned away, but neither can they be allowed to continue attending college as if nothing has happened. That is a dereliction of duty towards the student, and towards the other students, whose education and learning environment is damaged while such behaviour is left unchecked. But “Third Way” funding means that the only result will be institutional cynicism. Imposing “targets” and assigning funds on the basis of meeting them — what the economist calls “reform”, i.e. ideology dressed up as realism — will only ever lead to a situation in which bureaucrats and the bureaucratically-minded prosper. The way to improve education, and all other public services, is to accept the obvious truth (though such truth is contrary to ideology): most people working in these services are not, in fact, venal, are not motivated solely by what is in the interests of “them and their famileeee”. So it would be better to hand more control back over to them; by all means intervene if it is going wrong, but don’t assume that things work better if they are run by bureaucrats (the whole of reality is a counter-example to this ludicrous thesis).

I admit that, emotionally and unthinkingly, I will find myself supporting the “left” parties when the results come in tomorrow night. Yes, I want to see Galloway give Oona King a kicking, yes I would love to see Letwin lose his seat. But only in exactly the same way that I want to see X contestant beat Y contestant in Big Brother; it really is only sentimentality to pretend that this spectacle has much consequence. This will always be the case in liberal democracy at the best of times, but especially so in a country which has an electoral system so fundamentally corrupt and unjust. Hari is right that, in the Eighties, 56% of the electorate voted for left parties, but because the vote was split between Labour and the Lib Dems, the Tories were allowed to maintain their reign of terror. But that is an argument for urgent reform of the electoral system, not for voting New Labour.

As I.T. rightly argues, the “people died for the vote” line is utterly facile. Soldiers in the Wehrmacht died for the glories of the Fatherland — does that mean I should become a Nazi? Catholics burned for their belief in transubstantiation: should I then repent and go to Mass on Sunday? Plus, I think I’m on fairly safe ground, really, with the conjecture that no one, but no one, died for the opportunity to “choose” between Blair and Howard.





october 6, 1979: capitalism and bipolar disorder1

Realism has nothing to do with the Real. On the contrary, the Real is what realism has continually to suppress.

Capitalist realism, like socialist realism, is about “putting a human face” on and naturalising a set of political determinations. The komissars of Kapital like to pose as tough-minded pragmatists who tell unpalatable truths and who alone are capable of facing up to the harsh “realities” of the world. Yet Kapitalism — no less in its its soon-to-take over Chinese State version than in its soon-to-collapse American model — is based upon a slew of fantasies so credulous that they are almost charming. In a powerful piece in the Independent today,2 Johann Hari parallels the militant complacency of the current ruling elite with the thinking of previous highly developed social groups, such as the Incas and the Mayans, which had “committed ecocide”. “What were Easter Islanders saying as they cut down the last tree on their island?,” Hari quotes geographer Jared Diamond asking in his book Collapse: How Societies Choose to Fail or Survive. It is grim to reflect that the answers — “jobs not trees!” or “technology will solve our problems; never fear, we’ll find a substitute for wood” — are precisely the rationalisations that a thanatropic drive would produce in order to do its work. In the unconscious, Freud says, no one really believes they will die, and this is no doubt also true of civilisations, which despite the melancholy monuments testifying to the demise of Maya and Easter Island, are convinced that they are the exceptions, they are the one which cannot perish.

It is easy to see what capitalist “realism” means when you consider Blair’s habitual response to appeals from the environmental lobby. Measures to rein in eco-catastrophe may well be desirable — even necessary — but they, Blair tells us with a heavy heart bursting his sleeve, are “politically impossible”. Here, then, is capitalist “realism”: the reduction to the realm of the “impossible” of any steps that will prevent the destitution of the human environment. For that is what “realism” amounts to: not a representation of the real, but a determination of what is politically possible. But what is politically possible is at odds with what is physically possible, so in a sense, it is the servomechanism-agents of Kapital, not their opponents, who “demand the impossible” now. Their fantasy of a sustainable Kapitalism carrying on, forever, without burning out the planet, is perfectly delirial.

Another insight into capitalist realism was provided last week by Marxist economist Christian Marazzi (Scuola Universitaria Professionale della Svizzera Italiana, Lugano, Switzerland) whose lecture “Finance, Attention and Affect” at Goldsmiths was an interrogation of the meaning — and psychological, social and neuronic impact of — post-Fordism.3 Christian dated the moment of the switch from Fordism to post-Fordism very precisely: 6 October 1979. It was on that date that the Federal Reserve increased interest rates by twenty points, preparing the way for the “supply-side economics” that would constitute the “economic reality” with which we are now so familiar. The rise in interest rates not only contained inflation, it made possible a new organisation of the means of production and distribution. The economy would no longer be organised by reference to production, but from the side of the point of sale. The “rigidity” of the Fordist production line gave way to a new “flexibility”, a word that will send chills of recognition down the spine of every worker today. This flexibility was defined by a deregulation of capital and labour, with the workforce being casualised (with an increasing number of workers employed on a temporary basis) and outsourced.

The new conditions both required and emerged from an increased cybernetisation of the working environment. The Fordist factory was crudely divided into blue- and white-collar work, with the different types of labour physically delimited by the structure of the building itself. Labouring in noisy environments, watched over by managers and supervisors, workers had access to language only in their breaks, in the toilet, at the end of the working day, or when they were engaged in sabotage, because communication interrupted production. But in post-Fordism, when the assembly line becomes a “flux of information”, people work by communicating. As Wiener taught, communication and control entail one another.

What Deleuze, after Burroughs and Foucault, called “the society of control” comes into its own in these conditions. Work and life become inseparable. As Christian observed, this is in part because labour is now to some degree linguistic, and it is impossible to leave language in the locker after work. Capital follows you when you dream. Time ceases to be linear, becomes chaotic, punctiform. As production and distribution are restructured, so are nervous systems. To function effectively as a component of “just in time production”, you must develop a capacity to respond to unforeseen events, you must learn to live in conditions of total instability, or “precarity”, as the ugly neologism has it. Periods of work alternate with periods of unemployment. Typically, you find yourself employed in a series of short-term jobs, unable to plan for the future.

The horrors of these new working patterns are clear, but it is imperative that the left renounces one of its most dangerous addictions, its nostalgia for Fordism. As Christian pointed out, the disintegration of stable working patterns was in part driven by the desires of workers — it was they who, quite rightly, did not wish to work in the same factory for forty years. In many ways, the left has never recovered from being wrong-footed by Kapital’s mobilisation and metabolisation of the desire for emancipation from the Fordist routine. Especially in the UK, the traditional representatives of the working class — union and labour leaders — found Fordism rather too congenial; its stability of antagonism gave them a guaranteed role. But this meant that it was easy for the advocates of post-Fordist Kapital to present themselves as the opponents of the status quo, bravely resisting an inertial organised labour “pointlessly” invested in fruitless ideological antagonism which served the ends of union leaders and politicians, but did little to advance the hopes of the class they purportedly represented. And so the stage was set for the neoliberal “end of history”, the “postideological” ideological justification for rampant supply-side economics. Antagonism is not now located externally, in the face-off between class blocs, but internally, in the psychology of the worker, who, qua worker, is interested in old-style class conflict, but, as someone with a pension fund, is also interested in maximising their investment. There is no longer an identifiable external enemy. The consequence is that, as Christian put it in a memorable image, post-Fordist workers, are like the Old Testament Jews after they left the “house of slavery”: liberated from a bondage to which they have no wish to return but also abandoned, stranded in the desert, confused about the way forward.

The psychological conflict raging within individuals — they themselves are at war — cannot but have casualties. One hidden, or at least naturalised, consequence of the rise of post-Fordism is that the “invisible plague” of psychiatric disorders that has spread, silently and stealthily, since around 1750 (i.e. the very onset of industrial capitalism), has reached a new level of acuteness in the last two decades. This is one more dimension of the Real that capitalist realism is constitutively unable to process.

It is typical of New Labour that it should have committed itself, so early in its third term, to removing people from incapacity benefit, as if most people claiming the benefit were malingerers. In contrast with this assumption, it doesn’t seem unreasonable to infer that most of the people claiming incapacity benefit — and there are well in excess of two million of them — are casualties of Kapital. A significant proportion of claimants, for instance, are people psychologically trashed as a consequence of the capitalist realist insistence that mining was no longer economically viable (though, even considered in brute economic terms, once you factor in the cost to taxpayers of such benefits, the arguments about “viability” seem rather less than convincing). Many have simply buckled under the terrifyingly unstable conditions of post-Fordism.

The current ruling ontology rules out any possibility of a social causation of mental illness. The chemico-biologisation of mental illness is of course strictly commensurate with its de-politicisation. Considering mental illness as an individual chemico-biological problem has enormous benefits for capitalism: first, it reinforces capital’s drive towards atomistic individualisation (you are sick because of your brain chemistry), and second, it provides an enormously lucrative market in which multinational “pyscho-mafias” can peddle their dodgy drugs (we can cure you with our SSRIs). It goes without saying that all mental illnesses are neurologically instantiated, but this says nothing about their causation. If it is true, for instance, that depression is constituted by low serotonin levels, what still needs to be explained is why particular individuals have low levels of serotonin.

The increase in bipolar disorder is a particularly significant development. In the discussion after Christian’s lecture, I asked him about the relationship between this form of mental illness and capitalism as a system. It is clear that capitalism, with its ceaseless boom and bust cycles, is itself, fundamentally and irreducibly, bipolar. Capitalism is characterised by a lurching between hyped-up mania (the irrational exuberance of “bubble thinking”) and depressive come-down. (The term “economic depression” is no accident). To a degree unprecedented in any other social system (and capitalism is very precisely NOT a social “structure” in the way that the despotic state or the primitive socius are), capitalism both feeds on and reproduces the moods of populations. Without delirium and confidence, capital could not function. As it happened, Christian confirmed that he had in fact been working with people who had been “psychologically smashed” by capitalism, many of whom, it turned out, had in fact developed bipolar disorder. It could hardly be denied that there is an isomorphic relationship between the social and individual disorders of capitalism.

How could madness not result when we are invited to consider America’s consuming of $600 billion a year more than it produces “realistic”? (As opposed, so we are told, to Europe’s “unrealistic” social welfare programmes.) Make no mistake, the realists are insane, which more than ever reveals the force of the slogan, “the Real is the impossible, but the impossible which happens”. Ecological catastrophe and mental illness are present in capitalism’s wrap-around simulation as warps, unassimilable discontinuities, that which cannot be but which, nevertheless, cannot be extirpated. Perhaps these negative Reals — these dark shadows which allow us to see Kapital’s striplit mall of the mind for what it actually is — have their complement in a positive Real, an event completely inconceivable in the current situation, but which will break in and re-define everything.





what if they had a protest and everyone came1

What kind of protest is it that everyone agrees with?

If you weren’t already suspicious of the dull unanamity that coalesced on Saturday Live 8 (),2 reflect on the fact that the Russian show only happened because Putin didn’t want to be the only G8 leader whose country did not have a Live 8 gig. That fact alone reveals that the relationship between the current ruling elite and their ostensible opponents in the entertainment biz goes far beyond complicity.

Live 8 rests on two “libidinal fallacies”.

The first is obvious: it ignores the systemic and abstract nature of the geopolitical situation. It really isn’t the case that “eight men in a room” can “change history” simply by an act of will. Beyond the sentimental bluster, everyone knows that, but Live 8 depends upon a fantasy that there are two types of subject who need to be enlightened: the Subject Who Does Not Know (and whose “awareness” is to be raised) and the Subject Who Knows But Who Doesn’t Care. But who are these people? Who, exactly, needs to be “made aware” of the fact that Africa is desperately poor? And does anyone, even those who buy into the cheap off-the-shelf caricature of Bush as a dumb chimp, really think that he, personally, deliberately chooses to inflict starvation on African children? More to the point, does anyone really think that, on the level of personal morality, Bush is any different from the billionaire pop stars so histrionically raising their fists against him and wagging their fingers at us? That is to say: if there is some sort of moral dividing line, would you really want to place Bush on one side and Elton John and $ Bill Gates on the other?

It is not that Live 8 is a “degraded” form of protest. On the contrary, it is in Live 8 that the logic of the protest is revealed in its purest form. The protest impulse of the Sixties posited a Malevolent Father, the harbinger of a Reality Principle that (supposedly) cruelly and arbitrarily denies the “right” to total enjoyment. This Father has unlimited access to resources, but he selfishly — and senselessly — hoards them. Yet it is not capitalism but protest itself which depends upon this figuration of the Father. It goes without saying that the psychological origins of this imagery lie in the earliest phases of infancy. The hippies’ bucolic imagery and “dirty protest” — filth as a rejection of adult grooming — both originate in the “unlimited demands” of the infant. A consequence of the infant’s belief in the Father’s omnipotence is the conviction that all suffering could be eliminated if only the Father wished it. (In terms of Live 8: if only those 8 men yield to our demands, all poverty could be eliminated forever!) The demand for total enjoyment is actually pretty indiscriminate: the protest could just easily be against war (bummer maaaan) or against being charged for going into a festival (hey, breadheadzzzzzzz, don’t be heaveeeee…)

Indidentally, one of the successes of the latest global elite — the Social Democrats — has been their avoidance of identification with the figure of the hoarding Father, even though the “reality” they impose on the young is substantially harsher than the “reality” they protested against in the Sixties. In this sense, Bush is a godsend for Blair, since Blair can pose as the “really realistic” representative of Social Democratic moderation “winning concessions” from the obscene excesses of Bush, the Junkyard King of Amerikapital’s hideous fusion of id and superego. (The reference to the Birthday Party is not idle here. Oddly, their Junkyard strikes me as an uncannily prescient psychoanalysis both of Bushite Amerika and the role that it plays in everyone else’s fantasies, “Big-Jesus-Oil-King down in Texas drives great holy tanks of Gold/screams from heaven’s Graveyard/ American heads will roll in Texas/roll like daddy’s meat…”)

This brings us to the second fallacy. What is being disavowed in the abjection of evil and ignorance onto fantasmatic Others is our own complicity in planetary networks of oppression. What needs to be kept in mind is BOTH that capitalism is a hyper-abstract impersonal structure AND that it would be nothing without our co-operation. As I will never tire of insisting, the most Gothic description of capital is also the most literal. Capital is an abstract parasite, an insatiable vampire and zombie-maker; but the living flesh it converts into dead labour is ours, and the zombies it makes are us. Determinists of both a neoliberal and anti-humanist bent (believe it or not, it is not unheard of for such positions to coincide within the same person, proving that Marx wasn’t wrong about the essentially contradictory nature of capitalist ideology) merely echo teleo-Marxism at its most eschatological when they insist that what the meat (or human) components of the capital machine are of no consequence since the total triumph of capital is historically inevitable.

The question of what capital wants from us requires answers at a number of levels: economic, psychonalytic, and perhaps most pressingly, theological. In any case, it is clear that, for the moment at least, capital cannot get along without us. It remains the case, however, that we can get along without it. The parasite needs its “mere conscious linkages”, but we do not need the parasite. In addition to anything else, to ignore the crucial functioning of the meat in the machine is poor cybernetics. The denial of human agency is an SF fantasy, albeit one that is everywhere realising itself.

But to reclaim that agency means first of all accepting our insertion at the level of desire in the remorseless meat-grinder of capital. Capital is not something imposed upon us by Bush; it is we who are hooked on the “garbage in honey’s sack”, unable to kick the habit of returning to the Big Jesus Trashcan for another hit of feel-good junk.

It also means raising the price — libidinal, personal, monetary — of agency. The repeated claim from onstage multi-millionaires that the audience were going to “change history” simply by turning up and tuning in cheapens agency in every sense. Participating in a narcissistic, self-righteous spectacle is not “doing something”. Tony Parsons, of all people, made the very good point in the Mirror today that the generation of the Thirties and Forties did not expect Crosby and Sinatra to change the world — but, as he says, many of them had either risked or given up their lives to change things.

Withdrawal from the capital matrix entails an unplugging that will seem painful to nervous systems commensurated to the Reality-Pleasure Principle. Partly it means giving up the reassuring comforter of the Bad Father Figure and facing the fact that the G8 leaders are not capable of legislating away all planetary misery, but are “old men at the crossroads”, capital’s meat puppets not its masters. There is a sense in which it simply is the case that the political elite are our servants; the miserable service they provide from us is to launder our libidos, to obligingly re-present for us our disavowed desires as if they had nothing to do with us. If anyone is in charge in Kapital it is Oedipus Rex, i.e. us. (“I yam the King!” as Cave caterwauled on “Junkyard”. Yes: the junkie as monarch, that’s capitalist sovereignty.) The political “reality” that Bush and the others will no doubt blame their failure to act upon is not just an ideological smokescreen. It is the reality constituted by the desires of that selfsame Live 8 crowd who, when push comes to shove, will not pay extra taxes, will not give up cheap flights or car use, will not make a stand against inequity and stupidity at work if it means compromising their interests and those of their famileeeee and yet who expect global crises to be magically solved by eight stooges in a room.

The great benefit of Lacanianism is to reject both the party of the Infant (“you want new masters, and you shall have your wish” as Lacan told the student protestors of the Sixties) and the party of the Father (the empircomongers who try to sell the Symbolic as the only Real). There must indeed be a demand for the Impossible, but an Impossible which does not correspond with the definition provided by either party. It is not a question of total enjoyment, but of the not-all, a sober psychosis, lessness…





defeating the hydra1

In Marvel’s Nick Fury, Agent of S.H.I.E.L.D. comics, the nefarious S.P.E.C.T.R.E.-like international crime and terror network was called H.Y.D.R.A. Its slogan was “cut off a limb and two more shall take its place”. In Saturday’s Times, Paul Wilkinson, Chairman of the Centre for the Study of Terrorism and Political Violence, described the “decentralised network” of al-Qaeda as a “true hydra”. But the lesson of the hydra myth — that to use force against certain types of enemy is not only ineffective, it is counter-productive — is one that the leaders of the War on Terror have yet to learn.

It is the absurd War on Terror itself that has fed the al-Qaeda hydra and put British citizens on the frontline. The issue here is not simply a causal one — the War on Terror has made life unsafer in the West — but a conceptual one — the very notion of a War on Terror has meant that Western populations are reclassified as active combatants in a war not only to the death, but beyond death, an infinite, excitatory cycle of violence begetting violence.

Despite what the increasingly hysterical Pro-Bombing “Left” (PBL) maintain, the causal argument is won. (A testament to this is the way in which the PBL refuse even to have the argument. As one, they have wagged their finger at anyone who has pointed out the obvious causal chain linking US and British foreign policy with Thursday’s events, tut-tutting about the unseemliness of “politicising” the atrocity “even before the bodies are buried”, as if contempt for neo-imperialist Shock and Awe somehow equated to lack of respect for the victims of the attacks in London, as if their own columns were disinterested and neutral, and as if solemn moralising rather than political analysis were what is called for.) The claim that the bombing of Iraq has been a recruiting sergeant for terrorism is uncontroversial. A Foreign Office and Home Office dossier cited in the Sunday Times today states what any intelligent observer already knows:

It seems that a particularly strong cause of disillusionment among Muslims, including young Muslims, is a perceived “double standard” in the foreign policy of western governments, in particular Britain and the US. The perception is that passive “oppression”, as demonstrated in British foreign policy, e.g. non-action on Kashmir and Chechnya, has given way to “active oppression”. The war on terror, and in Iraq and Afghanistan, are all seen by a section of British Muslims as having been acts against Islam.2

Even the Economist grants that some of al-Qaeda’s “large group of sympathisers” will have had “extra levels of motivation since the Iraq war”. (It adds: “George Bush has sometimes claimed that a silver lining to the cloud his forces are struggling through in Iraq is that at least the West’s enemies are being fought there rather than at home. The attacks in London are a reminder that that view is as wrong as it is glib.”3)

But the reclassification of the struggle with al-Qaeda as “war” is another factor that promotes, inspires and legitimates terrorism, a factor perhaps no less significant than the misadventures in Iraq and Afghanistan. For example: it used to be the case that the British government refused to accept that it was “at war” with the IRA; it was the IRA who made that claim. The unwillingness to concede that Britain was engaged in war partly had the effect of making it possible to claim both that the IRA were terrorists (i.e. BY DEFINITION not a group with whom one could be at war) and that any attack on the civilian population was an outrage visited on innocents. But if indeed we ARE at war (as the oxy/moronic War on Terror would have us believe), and if what “we” are fighting for is “our values”, and “simply getting on with our lives” is an expression of those “values” — as, since Thursday, we have endlessly been told it is — then it would follow that we are all indeed warriors co-opted into War on Terror. As Simon Jenkins put it (also in the Sunday Times), “it is Blair who gave terrorism the status of war. He can hardly complain when the enemy treats it as such”.

Johann Hari observed — surely not approvingly? — that the bombings on Thursday were received in London almost as if they were a natural disaster. Much of the media here has insisted, rather, that the bombings be treated as a SUPERNATURAL disaster, the act of a transcendent Evil that cannot and furthermore must not be explained. Both Blair and Bush find it expedient and congenial to use a theological language to describe a threat that would be better considered in more worldly terms. That language is dangerous for two reasons: first, because it contributes to the sublimation of the al-Qaeda threat, transforming a diffuse network into a supernatural force, and second, because it renders all analysis of the threat al-Qaeda actually poses all the more difficult.

According to an emerging orthodoxy in certain sections of the British media, just about any attempt to offer economic, political or sociological explanation for al-Qaeda’s emergence is tantamount to an expression of sympathy for its aims and methods. As Savonarola has pointed out, the PBL and other reactionaries attempted in the immediate aftermath of Thursday to make the very word “political” a slander as they desperately cast about trying to establish a period of non-reflection in which “politics” and thought could be suspended — a period, that is to say, in which their politics and their non-thinking could be imposed as the default response.

The most facile and stupid example of this type of argument might have been Nick Cohen’s piece in the Observer today,4 rightly excoriated by Lenin5 (I say “might” because the amount of shrill stupidity, sentimental nonsense and emotional pornography churned out by the hacks over the last few days has reached new levels of stupefaction, as the miserable reality of central London’s rapacious Hobbesian inferno, where folk will beat you to death rather than let you get into a Tube ten seconds before them, has been magically transformed by the bombs and media fairy dust into the very essence of an underdog England in which it is WWII forever: to the sound of choruses of “maybe it’s because I’m Londahner” ringing out from the ghosts of the music halls, journos have shamelessly done themselves up as pearly kings and queens, taking on the role of celebrants of a Fantasy London which is as convincing as Dick Van Dyke’s accent in Mary Poppins.) The “agalma”, the special treasure, of this London resides in the status of “heroic victim” that a disaster such as this re-confirms. A dangerous logic takes hold: we’re under attack, we must be Good.

The supernaturalisation of al-Qaeda is crucial to this strategy. If we are the Good, it can only be the senselessly Evil, the irrationally jealous, who would want to attack us. (This mode of bewildered self-aggrandising is as crucial to a certain version of American identity as spam-eating-make-doand-mend-what you-complaining-about-that-severed-leg-for dour fortitude is crucial to Blitz Englishness.) Needless to say, the positing of an ethnic subject — We, the Good — whose innate virtue is reconfirmed by its being attacked is constitutive of both the al-Qaeda and the post-911 US mindset. A military asymmetry is doubled by a fantasmatic symmetry. Each is the other’s Satan.

To talk of al-Qaeda in theological (rather than in political, social or economic) terms is to adopt their mode of discourse in an inverted form. It is to return to a pre-Feuerbachian, pre-sociological perspective in which all the lessons of the nineteenth- and twentieth-century studies of the social psychology of religion — undertaken by figures as diverse as Durkheim, Marx, Weber, Nietzsche and Freud — are forgotten. If a particular strain of religion is to be understood as, in Cohen’s words, “an autonomous psychopathic force” rather than as a social, economic and psychological phenonenon with complex causes, then all hope of reasoned analysis is a priori ruled out. Unreason is abjected onto the enemy (even as it is evinced in one’s own not even minimally coherent ravings), thus legitimating the idea that “the only option” is military force.

The floating of the pseudo-concept of “Islamofascism” has been central here. There are any number of reasons to consider the idea that there is such a thing as Islamofascism a nonsense. Here are two. First of all, fascism has always been associated with nationalism, but, like global capital, Islamism has no respect for nationality; the first loyalty of the Islamist is to the global Umma. Secondly, fascism is about the State — Islamism has no model of the State, as could be seen in Afghanistan under the Taliban.

The only sense one can make of “fascism” as used by the PBL is that it names anything that is really, really bad (that well-defined category) or it involves the curtailment of liberties. The brand of Islamism al-Qaeda favours would certainly curtail liberties, but not necessarily the same ones that fascism would curtail, or for the same reasons.

Rather than engaging in nebulous negative sublimation — “Behold, Satan” — it would better behove the opponents of Islamist Terrorism to consider more carefully what is specific about it. As John Stevens noted over the weekend, the typical al-Qaeda terrorist is unlikely to have been parachuted in from an Afghan village. They are much more likely to have lived in the West, either as residents or as nationals. Their affiliation with al-Qaeda will, we can speculate, almost certainly serve the function of resolving a tension in themselves. Al-Qaeda recruit from schools and colleges because they are astute enough to recognise that male adolescence is a time of boiling confusion that craves easy certainties. It cannot be that difficult for a fervent Jihadi to convince impressionable young men adrift in the miserable haze of Babylonic capitalism that it is not al-Qaeda but their enemies who are really Evil.

After all, it is not hard to construct a convincing story that the success of the West has been achieved at the expense of Muslims. The Sunday Times reports that in Britain “Muslims are three times more likely to be unemployed than the population as a whole; 52% of them are economically inactive (the highest of any faith group) and 16% have never worked or are long-term unemployed. This is blamed on a lack of education: 43% of Muslims have no qualifications.” But it is not just the poor themselves who flock to al-Qaeda; it is also those burning with a sense of injustice on behalf of the poor.

In this context, it is worth remembering Giuliani’s jaw-dropping proclamation (to which Savonarola has been assiduous in drawing our attention): “People who live in freedom always prevail over people who live in oppression.” So speak the Masters, the Winners… Who speaks for the oppressed then? The rise of Islamism must be correlated with the demise of the left. If it has become the default repository for Muslim rage against injustice then that is partly due to the US, which, as is well-known, funded Islamist Jihadis in a bid to defeat Communism. Since only something like Communism could absorb and re-direct the energies that are fuelling alQaeda, I look forward to the day when the US will fund Islamic Communism, and the circle will be complete.





the face of terrorism without a face1

So Tony Blair is the leader who has brought suicide bombing to Britain.

Any remaining doubt about the link between 7/7 and the Iraq bombing and occupation was dissipated today when a friend of one of the suspects, Mohammed Sadique Kahn, spoke to — of all things — the Evening Standard. “The friend … () said Khan, Tanweer and Hussain grew up together and ‘often talked about their anger at their Muslim brothers and sisters being unfairly treated in Iraq by the US.’”

No surprises there. And no surprises, at least not for k-punk readers, that the bombers were British. That, at least, somewhat undermined the racist agendas of European and US “Experts” who blamed the atrocity on Britain’s supposedly insufficiently authoritarian immigration and asylum policies, barely concealing their disgust at multi-ethnic “Londonistan”, a stance that echoes Mark Steyn’s Islamophobic revulsion at “Eurabia”. The BNP in Barking found that their predictable attempts to extract political capital from the bombings — a leaflet with a photograph of the trashed number 30 bus over a caption saying, “Maybe now it’s time to listen to the BNP” — also fell foul of the revelation that the bombers came from Leeds, not the Middle East. Naturally, that news brings with it the possibilities for other kinds of exploitation by racists. It is a grotesque understatement to say that the next few months will not be easy for Muslims in Britain. Emollient words about “true Islam” will be as ineffective as they are misleading. There is no true Islam. Islam, like all other religions, is a riot of contradictions, a tissue of interpretations. The words of the Prophet give as much comfort to zealots as to pacifists.

David Davis said last week that modern terrorism is “terrorism without a face”. Suddenly, however, the terrorists have a face — even though it is not the one that many expected, or wanted. The photographs of the perpetrators and the photographs of the victims — who could tell them apart? There is no tell-tale “demonic stain” on the faces of the killers. They aren’t the austere, obsessive “foreigners” that the popular imagination had conjured. They wore trainers and tracksuits, they were religious, sure, but no one thought they were fanatics. They weren’t even socially dysfunctional geeks. By all accounts, they were popular, played cricket. Nor was there any obvious lack or deprivation in their lives.

The obvious questions seem to be “how”, “why”? Yet the same questions do not seem the obvious ones to ask when we see photographs of similar young men who happen to be in in the US or British forces, men who have participated in the killing of very many more civilians.

The Blairite objection to terrorism cannot be its means, since he, too, considers the killing of a certain number of civilians an acceptable sacrifice for the greater Good. (One of the problems this kind of utilitarian calculus has always faced is that there is no obvious point at which to stop counting the consequences. But, as we’ve already established, surely Thursday must count amongst the consequences of the Iraq misadventure.) It is the ends, then, in which the difference must reside, not the means. Blair is supernaturally confident that he is on the side of the angels, that he is pursuing the Good, whereas his enemies are Evil. The problem is that they think exactly the same way.

He tells us that we are in a war. But to many Muslims — not “mad mullahs”, but, amongst others, young men from “ordinary” backgrounds — it is as obvious as it is to Blair what the right, the only side, to be on is. It is the side of the poor and the oppressed, not the side of the hyperprivileged and the massively well-armed. The rage, the righteous sense of injustice that led those four to give their lives and take the lives of others — and please, do not describe what they did as “cowardly”; “brutal” by all means, but not “cowardly”, and certainly nowhere near as cowardly as the Powell doctrine of bombing from a great height — that anger needs to be channeled by other forces, forces which don’t counter oppression with repression, which don’t transform rage into outrage.

UPDATE: Breakfast TV, BBC1. A group of young Muslims from Leeds — not “fanatics” by any means — tell the reporter (who has to concede that they are articulate and measured) that Iraq is the major factor in switching young men onto extremism in Britain. They make it clear that they are appalled by the events of last Thursday, condemn them without reservation, but nevertheless are angered by the patent double standards of the British media. The fifty people who died last week — whose deaths they in no way trivialised — seem to count much more than the thousands who die in Iraq. (It makes me wonder what would happen if the media indulged in what Simon Jenkins called “grief pornography” for Iraqis: if there were back stories and photographs for all of them, would the public mood change?) In the studio, Irshad Manji, author of The Trouble with Islam Today, tries to demur, falling back on the standard line that 9/11 preceded Iraq. True enough, but there had never been suicide bombing in Britain until last week. Manji makes some good points: in a piece the other day (I think in the Standard?), she broke ranks with the sentimental consensus about “true Islam”, arguing that there needs to be an Islamic Reformation, with the acceptance within the religion that certain passages of the Koran can be wrong. But the call for Islamic auto-critique must go alongside a recognition that the “Crusader” policies of the US and the UK feed an aggrieved militancy that will make that kind of Reformation much less likely.





conspicuous force and verminisation1

The paradoxical War on Terror is based on a kind of willed stupidity; the willed stupidity of wishful thinking. Only the logic of dreamwork can suture “War” with “Terror” in this way, since terrorists were, by classical definition, those without “legitimate authority” to wage war. However, it is horribly evident for some while that a new, frighteningly facile, definition of Terrorism has come into play. What makes Terrorists terrorists is not their supposed lack of legitimate authority but their Inherent Evil. We are ontologically Good; Good by our very nature, no matter what we do. We belong to an “alliance of moderation” against the Axis of Evil. So when “we” “accidentally” level an apartment block full of children with our moderate bombs, we do not cease to be moderate. The difference between They, the Evil, and We, the Good is, of course, intent; the Terrorists deliberately target civilians. This is their only aim, because they are Evil. Although we kill vastly more civilians, we do not intend to it, so we remain Good.

For the libidinal roots of this wishful thinking, we have to look beyond the foibles of individuals to the political unconscious of the hyper-militarised state. It is geared to deal with threats if they come from other armed states, so it pretends — deceives itself, and then attempts to deceive us — that this is in accord with the actual geopolitical situation. Condi’s crocodile tears notwithstanding, the US, needless to say, is in no position to condemn Israel’s air strikes, since the Israeli bombings follow the War on Terror script to the letter. The conflict with Hezbollah turns into a destruction of Lebanese people and infrastructure, just as the struggle with al-Qaeda became a war on Afghanistan and Iraq. For the hyper-miltarised state, asymmetry can only be thought of as an advantage: we have more and better weaponry than them, therefore we must win.

The stupidity here is evident, and multi-levelled. First of all, it involves a literal occlusion and suppression of intelligence. Terrorism is a problem to be met with brute force rather with intelligence. Successfully defeating Terrorist groups is a long-term business, dirty, but above all, stealthy, invisible. But the War on Terror is inherently and inescapably spectacular; it arises from the demands of the post 9/11 military-industrial-entertainment complex: it is not enough for the state to do something, it has to be seen doing something. The template here is Gulf War 1, which as both Baudrillard and Virilio knew, could not be understood outside logics of mediatisation. Gulf War 1 was conceived of a kind of re-shooting of Vietnam, with better technology, and on a videogame desert terrain in which carpet bombing would be industrially effective. This is the kind of asymmetry that the military-industrial-entertainment complex likes: no casualties (on our side).

The bringing to bear of what, following Veblen, we might call conspicuous force presupposes a second stupidity: the verminisation of the enemy. Before Gulf War 1 had even happened, Virilo saw the logic of verminisation rehearsed in James Cameron’s Aliens, wherein the “machinic actors do battle in a Manichean combat in which the enemy is no longer an adversary, a fellow creature one must respect in spite of everything; rather, it is an unnameable being that it is more appropriate to exterminate than to examine or analyse.” In Aliens, Virilio ominously notes, attacks on the “family form () the basis of … () neocolonial intervention”. The teeming, Lovecraftian abominations which can breed much faster than we can are to be dealt with by machines whose “awesome appearance is part of their () military effectiveness”. Shock and awe.

Aliens was the moment in which a new mode of the military-industrialentertainment-complex became visible. Virilio argued that Aliens’ privileging of military hardware “could only lead in the end to the extinction of the talking film, its complete replacement by film trailers for hardened militarists”. In fact, the talking film has been replaced by the shoot-em-up videogame whose picnoleptic delirium is flat with the prosecution of the Sega-Sony-CNN war. “Realists” who attacked Baudrillard and Virilio for their insistence upon the fact that war is now constitutively mediatised missed the point that hyperrealisation is precisely what permits the production of very real deaths on a mass scale.

Verminisation not only transforms the enemy into a subhuman swarm that cannot be reasoned with, only destroyed; it also makes “us” into victims of its repulsive, invasive agency. As Virilo perspicaciously observed, Aliens itself operated “a bit like a Terrorist attack. Women and children are slaughtered in order to create an irreversible situation, an irremediable hatred. The presence of the little victim has no theatrical value other than to dispose us to accept the madness of the massacres…”

While “we” have “families” who are being senselessly killed, vermin have neither memory nor motive; they act unreflexively, autonomically. Their extermination is a practical problem; it is simply a matter of finding their nests and using the right kind of weapon. Applying this thinking to Hezbollah or any other group is appalling racism, naturally, but also astonishingly poor strategy, implying no understanding of Terrorism whatsoever. Destroy all the infrastructure, kill all the operatives: but you will have only created more images of atrocity; indestructible and infinitely replayable repositories of affect, which, by demanding response and producing (a usually entirely justified) recrimination, act as the best intensifiers and amplifiers of Terror.





my card: my life: comments on the amex red campaign1

The current American Express Red advertising campaign2 cries out for the kind of intricate semiotic dissection Roland Barthes pioneered in Mythologies. The ad — which shows happy, smiling supermodel Gisele embracing happy, smiling African Maasai warrior, Keseme — is a succinct emblem of the current ruling ideology.

The image, with its evocation of ideas of culture and nature, consumerism and debt, independence and dependence — fairly drips with polysemic resonances. There is enough here to keep semiologists busy for years.

But the central opposition — “My Card” versus “My Life” — says more than it intends. The First World is metonymically represented by a plastic card, and it is left to the Third World to symbolise all the “natural” vitality that unliving capital has eliminated from Western culture. The Western woman equals (artificial, cosmetic) culture; the African man equals living nature. Indeed, when we click on the “My Life” button we see the stereotypicallydescribed “proud and fiercely independent … () Maasai tribes of East Kenya” suborned into the role of embodying “the dignity, courage and breathtaking beauty of Africa”, their culture quickly flattened back into nature.

Slavoj Žižek has argued that what he calls “liberal communism” — as exemplified by the charitable gifts made by super-succesful capitalists such as Bill Gates and George Soros — is now the dominant form of capitalist ideology. “According to liberal communist ethics”, Žižek argues,

the ruthless pursuit of profit is counteracted by charity: charity is part of the game, a humanitarian mask hiding the underlying economic exploitation. Developed countries are constantly “helping” undeveloped ones (with aid, credits, etc.), and so avoiding the key issue: their complicity in and responsibility for the miserable situation of the Third World.3

This is the real meaning of the embrace between Giselle and Keseme — under global capitalism, the relationship between First and Third Worlds can never be a symmetrical synergy in which both partners win. It will always be a system of structural inequality in which one side is always destined to lose.

But Product Red marks a move on from Žižek’s liberal communism. Liberal communism is really just old-style philanthropy, in which exploitation is atoned for by subsequent acts of charity. With Red, by contrast, the act of consumption is presented to us as already and immediately benevolent. At the Product Red launch in January, Bono,4 Red’s most high-profile advocate, made a point of differentiating the new approach from philanthropy. “Philanthropy is like hippy music, holding hands”, Bono claimed. “Red is more like punk rock, hip-hop, this should feel like hard commerce.” (It is unclear what inspired Bono’s invocation of punk rock — perhaps he was thinking of The Great Rock ‘n’ Roll Swindle — but his reference to hip-hop might be the most savage indictment of the genre yet.)

We confront here the curious mixture of brutal cynicism and dewy-eyed piety that is so characteristic of late-capitalist culture. The billboard version of the American Express ad tells us that “This card is designed to eliminate Aids in Africa”. Even when we dismiss this as obvious nonsense — the most credulous consumer cannot but be aware that the card was designed to increase the profits of American Express — the ideological blackmail still holds: how can anything which assists in the struggle against Aids in Africa possibly be wrong?

We’ve already touched upon one reason: campaigns such as this occlude and mystify the systemic character of the relationship between Western capital and the Third World. The picturesque image of a “traditional” Maasai warrior beguiles us into forgetting the way in which Western institutions profit from Third World debt. It also photoshops out capital’s attempt, in Žižek’s words, to “export the (necessary) dark side of production — disciplined, hierarchical labour, ecological pollution — to ‘non-smart’ Third World locations”.

Another, related, reason is that Product Red promises to eliminates politics as such. If the invisible hand of the credit card user can ameliorate the problem of Aids in Africa, there is no need for a political response at all — what John Hayes of American Express calls “conscientious commerce” will be sufficient. In this way, Product Red goes beyond using a Masaai tribesman to advertise American Express, and uses him to sell neoliberal ideology itself.





the great bullingdon club swindle1

We’re all in this together.

Capitalist realism everywhere… On television yesterday morning, the relentless message coming from pundits and vox pops — even from most of those who reject the particular form that the cuts have taken — was that “something had to be done”. The Great Bullingdon Club Swindle is larceny and deception on such a grand scale that one almost has to admire its breathtaking audacity. The Bullingdon Club has pushed Doublethink to new limits with its mantric repetition of the ludicrous claim that it was New Labour policy, rather than the bank bailouts, that was responsible for the massive deficit. The strategy seems to be to employ the illocutionary power of repetition — if they keep saying it, then it will have been true. The Bullingdon boys are working a mass hypnosis trick, forcing through shock doctrine measures while the population are still in a kind of postcrash trance. But where, previously, neoliberals had used the crises in other political systems (state socialism, social democracy) as an opportunity to helicopter in their “reforms”, on this occasion they are using a crisis brought about by neoliberal policy itself to try to electro-shock the neoliberal programme back into life. I heard one buffoon on television saying that “we’ve been in denial for the last ten years”. If there’s denial, it’s happened in the last two years, and on the part of the neoliberals and their friends in the business elite, who — after demanding at gunpoint unprecedented sums of public money — are now brazenly continuing to peddle the story that they are the friend of the taxpayer and that it is welfare claimants, not them, who are the scroungers who have brought the country to the “brink of bankruptcy”. In what must surely be the most astonishing bait and switch in British parliamentary history, the victims of neoliberal policy — public services and the poor — are now being asked (or rather forced) to pay for the manifest and total failure of that policy. As John Gray argues in the LRB2, it’s no surprise that Orange Bookers like the “wolf-eyed replicant” Nick Clegg — as China Mieville3 memorably described him — are happy to impose on the country the same neoliberal programme that they have imposed on their own party. Even so, has there even been a party that has so comprehensively and so quickly squandered the good will of those who voted for them as have the Lib Dems? Cuddly Vince Cable’s grinning excuse for the backtracking on student fees was a masterclass in capitalist realism, as he practically said, “Well, that’s what happens when you get into power — you give up your principles.” (Cable is increasingly looking like a villain from a John Grisham flick, the avuncular eminence grize whose charm lures you into the firm, before being revealed to be a sinister embezzling fraudster.)

For months now, we’ve been sold the story that public services are “bloated”. There’s no doubt that New Labour mismanaged public services and wasted money — on managers, on market Stalinist control procedures imported in from business, and on GPs’ ludicrously overinflated salaries. But the narrative of an overfunded public sector produces cognitive dissonance for those of us who have actually been delivering frontline public services in the last ten years, where we’ve been expected to do more work for less money and with fewer resources. If those were the good times, you can only feel a shudder of dread anticipating what it will be like when things are bad. Incidentally, if you’ve wondered why there have been so few posts here in the last month or so, it’s because I’ve been trying to piece together a living as a visiting (i.e. casualised) lecturer, working in institutions that are strained to breaking point by neoliberal “reforms”. Cuts will mean more casualisation, in those institutions that will be able to survive at all.

But the most breathtaking aspect of the Bullingdon swindle is the “we’re all in this together” slogan, rightly described by Seumas Milne4 as “preposterous”. What we’re seeing now is the Terminator of Capital with its neoliberal-managerialist mask wrecked, and the Big Society (Victoriana 2.0) ruse not convincing anyone. The doughy, fat-of-the-land face of privilege now shows itself openly, exuding the emollient manner of noblesse oblige, but without any sense of obligation. What survives is pure ideological reflex, the decorticated Terminator blindly blasting at its usual targets: public services, welfare, the arts. It’s folk economic faux-wisdom (“if a household overspends, we know that we have to give up things we’d rather keep”) that is providing the smokescreen for this ideological assault. Myths and deliberately cultivated misapprehensions abound: judging from all the rhetoric, you’d think that education and the arts were drains on the economy, rather than the highly successful “businesses” that they in fact function as.

Nevertheless, it’s crucial that we recognise that this is a time of opportunity for the left. Laurie Penny5 is right that the Labour Party does not have the answers at the moment. Yet the Labour Party’s current lack of an agenda can be seen as a good thing, for two reasons. Firstly, at least this means that Labour has lost the managerialist neoliberal agenda that defined it for the last fifteen years. The de-New Labourisation process will take a while, but it will be expedited much quicker with Ed Miliband as leader than it ever would have been with David at the helm. (Notice how David — whom the media were presenting as a great lost leader, a kind of world-historic statesman, on the grounds, presumably, that Hilary Clinton took a fancy to him — is already a forgotten man. In the media’s soap narrative, David’s leaving frontbench politics was an open wound which the Labour Party would take years to recover — that doesn’t quite seem to be the case.) Secondly, the fact that the post-Blair and Brown Labour Party is now a cored-out shell means that it is a space, which it is at least plausible that could be filled by new ideas and strategies. For the first time in fifteen years, the future of the Labour Party is not fixed. It’s worth remembering at this point that the failures of the Labour Party, its succumbing to capitalist realism, is not just the consequences of the internal logic of the party. It was extra-Parliamentary forces that gave rise to the Labour Party in the first place; it was the defeat of those forces that drove the Labour Party into its craven placating of business in the New Labour era. If Labour is to be anything more than a zombie party once again, it will be new forms of extra-parliamentary organisation that revivify it.

For that reason, this is definitely not the time to recline into the leftist version of capitalist realism, the defeatist counterpart to the Bullingdon club’s bullishness. Now is the time to organise and agitate. The cuts can provide a galvanising focus for an anti-capitalist campaign that can succeed. Protests in these conditions won’t have the hubristic impotence of anticapitalist “feelgood feelbad” carnivals and kettles. This is shaping up to be a bitter struggle, but there are specific, determinate and winnable goals that can be achieved here: it isn’t a question of taking a peashooter to the juggernaut of capital.

The UK, the first capitalist country, is the world capital of apathy, diffidence and reflexive impotence. But it is also a country that periodically explodes into rage. Beneath todays’s ideological trance, beneath the capitalist realist hopelessness, an anger simmers here that it is our task to focus and coordinate. Public displays of rage can play an enormously significant role in shifting the symbolic terrain that is currently governed by capitalist realism. I know there are some who see parallels between now and the initial phases of the first Thatcher government. But Thatcher had a number of factors on her side which the Bullingdon boys don’t.

Firstly, Thatcherism was part of a wider global restructuring of capitalism — the objective tide of history was on its side. But global capital has not yet found a solution to the problems that led to the banking crisis.

Secondly, this shift from Fordism to post-Fordism allowed Thatcher to offer inducements that can’t be repeated: cheap shares from formerly nationalised companies, the sales of council houses. The nationalised companies have long since been sold off, and their private counterparts have in most cases failed to deliver the promised increases in consumer satisfaction — although they have certainly delivered massive profits to those who do hold shares in them. Now all we can look forward to are spiralling energy bills and higher train fares. There are no council houses to sell — indeed, the coalition is planning to effectively end what is left of social housing in this country for good, by forcing up council tenants’ rates, and limiting tenancies to five years.

Thirdly, there was of course the Falklands — but, since the forces are already stretched threadbare, where are the resources for such a neocolonialist intervention now, and would jingoism function in the same way in 2010 that it did in 1982?

Fourthly, there was Thatcher herself — a divisive but charismatic politician, who could plausibly present herself as struggling against vested interests, not only on the left, but also in the British establishment. The current Tory government has none of these advantages, and the neoliberal right in general has lost control of the future, much as it refuses to acknowledge this. In the Standard, Anne McElvoy recently described Ed Miliband as “an unreconstructed social democrat”. From what position does McElvoy think she is speaking here? Like much of the mainstream media, which is contriving to carry on as if 2008 didn’t happen, McElvoy is desperately clinging to the myth of a political “centre ground” that no longer has any legitimacy. After the bank bailouts, the neoliberal settlement is just as dead as social democracy.

The “we’re all in this together” slogan may turn out to be a phrase that comes to haunt the Tories in the way that “Labour isn’t working” dogged Labour for a generation. Classlessness might have seemed plausible for a moment when fronted by John Major, who didn’t go to university, or by Tony Blair, the poster boy for (leftist) post-political administration. But that moment has long passed, and cuts of this kind being forced through by a cabinet of aristocrats and millionaires make brutally apparent a class antagonism that the New Labour government obfuscated. Whenever the ruling class tells us that “we’re all on the same side”, it is a sure sign that we can hurt them. Similarly, the current media phobia about unions is an indication of the power that they have at this time. History is starting again, which means that nothing is fixed and there are no guarantees. Right-wing victory is only inevitable if we think that it is.





the privatisation of stress1

Ivor Southwood tells the story of how, at a time when he was living in a condition of underemployment — relying on short-term contracts given to him at the last minute by employment agencies — he one morning made the mistake of going to the supermarket.2 When he returned home he found that an agency had left him a message offering him work for the day. But when he called the agency he was told that the vacancy was already filled — and upbraided for his slackness. As he comments, “ten minutes is a luxury the day-labourer cannot afford”. Such labourers are expected to be waiting outside the metaphorical factory gates with their boots on, every morning without fail. In such conditions

daily life becomes precarious. Planning ahead becomes difficult, routines are impossible to establish. Work, of whatever sort, might begin or end anywhere at a moment’s notice, and the burden is always on the worker to create the next opportunity and to surf between roles. The individual must exist in a state of constant readiness. Predictable income, savings, the fixed category of “occupation”: all belong to another historical world.3

It is hardly surprising that people who live in such conditions — where their hours and pay can always be increased or decreased, and their terms of employment are extremely tenuous — should experience anxiety, depression and hopelessness. And it may at first seem remarkable that so many workers have been persuaded to accept such deteriorating conditions as “natural”, and to look inward — into their brain chemistry or into their personal history — for the sources of any stress they may be feeling. But in the ideological field that Southwood describes from the inside, this privatisation of stress has become just one more taken-for-granted dimension of a seemingly depoliticised world. “Capitalist realism” is the term I have used to describe this ideological field; and the privatisation of stress has played a crucial role in its emergence.

Capitalist realism refers to the widespread belief that there is no alternative to capitalism — though “belief” is perhaps a misleading term, given that its logic is externalised in the institutional practices of workplaces and the media, as well as residing in the heads of individuals. In his discussions of ideology, Althusser cites Pascal’s doctrine: “Kneel down, move your lips in prayer, and you will believe”: psychological beliefs follow from “going through the motions” of complying with official languages and behaviours. This means that, however much individuals or groups may have disdained or ironised the language of competition, entrepreneurialism and consumerism that has been installed in UK institutions since the 1980s, our widespread ritualistic compliance with this terminology has served to naturalise the dominance of capital and help to neutralise any opposition to it.

We can quickly grasp the form that capitalist realism now takes by reflecting on the shift in the meaning of the famous Thatcher doctrine that “there is no alternative”. When Thatcher initially made this notorious claim, the emphasis was on preference: neoliberal capitalism was the best possible system; the alternatives were undesirable. Now, the claim carries an ontological weight — capitalism is not just the best possible system, it is the only possible system; alternatives are hazy, spectral, barely conceivable. Since 1989, capitalism’s success in routing its opponents has led to it coming close to achieving the ultimate goal of ideology — invisibility. In the global North at least, capitalism proposes itself as the only possible reality, and therefore it seldom “appears” as such at all. Atilio Boron argues that capitalism has been shifted to a “discreet position behind the political scene, rendered invisible as the structural foundation of contemporary society”, and cites Bertolt Brecht’s observation that “capitalism is a gentleman who doesn’t like to be called by his name”.4

The Depressing Realism of New Labour

We would expect the Thatcherite (and post-Thatcherite) right to propagate the idea that there is no alternative to the neoliberal programme. But the victory of capitalist realism was only secured in the UK when the Labour Party capitulated to this view, and accepted, as the price of power, that “business interests, narrowly conceived, would be henceforth be allowed to organise the shape and direction of the entire culture”.5 But perhaps it would be more accurate to record that, rather than simply capitulating to Thatcherite capitalist realism, it was the Labour Party itself that first introduced capitalist realism to the UK political mainstream, when James Callaghan gave his notorious 1976 speech to the Labour conference in Blackpool:

For too long, perhaps ever since the war, we have () postponed facing up to fundamental choices and fundamental changes in our economy … () We’ve been living on borrowed time … () The cosy world we were told would go on forever, where full employment could be guaranteed by a stroke of the chancellor’s pen — that cosy world is gone…

However it is unlikely that Callaghan foresaw the extent to which the Labour Party would come to engage in the politics of “corporate appeasement”, or the extent to which the cosy world for which he was performing the last rites would be replaced by the generalised insecurity described by Ivor Southwood.

The Labour Party’s acquiescence in capitalist realism cannot of course be construed as a simple error: it was a consequence of the disintegration of the left’s old power base in the face of the post-Fordist restructuring of capitalism. The features of this — globalisation; the displacement of manufacturing by computerisation; the casualisation of labour; the intensification of consumer culture — are now so familiar that they, too, have receded into a takenfor-granted background. This is what constitutes the background for the ostensibly post-political and uncontestable “reality” that capitalist realism relies upon. The warnings made by Stuart Hall and the others writing in Marxism Today at the end of the 1980s turned out to be absolutely correct: the left would face obsolescence if it remained complacently attached to the assumptions of the disappearing Fordist world and failed to hegemonise the new world of post-Fordism.6 But the New Labour project, far from being an attempt to achieve this new hegemony, was based precisely on conceding the impossibility of a leftist hegemonisation of post-Fordism: all that could be hoped for was a mitigated version of the neoliberal settlement.

In Italy, autonomists such as Berardi and Negri also recognised the need to face up to the destruction of the world within which the left had been formed, and to adapt to the conditions of post-Fordism, though in rather a different manner. Writing in the 1980s, in a series of letters that were recently published in English, Negri characterises the painful transition from revolutionary hopes to defeat by a triumphalist neoliberalism:

We have to live and suffer the defeat of truth, of our truth. We have to destroy its representation, its continuity, its memory. All subterfuges for avoiding the recognition that reality has changed, and with it truth, have to be rejected. The very blood in our veins had been replaced.7

We are currently living with the effects of the left’s failure to rise to the challenge that Negri identified. And it doesn’t seem a stretch to conjecture that many elements of the left have succumbed to a collective form of clinical depression, with symptoms of withdrawal, impaired motivation and the inability to act.

One difference between sadness and depression is that, while sadness apprehends itself as a contingent and temporary state of affairs, depression presents itself as necessary and interminable: the glacial surfaces of the depressive’s world extend to every conceivable horizon. In the depths of the condition, the depressive does not experience his or her melancholia as pathological or indeed abnormal: the conviction of depression that agency is useless, that beneath the appearance of virtue lies only venality, strikes sufferers as a truth which they have reached but others are too deluded to grasp. There is clearly a relationship between the seeming “realism” of the depressive, with its radically lowered expectations, and capitalist realism.

This depression was not experienced collectively: on the contrary, it precisely took the form of the decomposition of collectivity in new modes of atomisation. Denied the stable forms of employment that they had been trained to expect, deprived of the solidarity formerly provided by trade unions, workers found themselves forced into competition with one another on an ideological terrain in which such competition was naturalised. Some workers never recovered from the traumatic shock of seeing the Fordistsocial-democratic world suddenly removed: a fact it’s worth remembering at a time when the Conservative-Liberal Democrat coalition government is hounding claimants off incapacity benefit. Such a move is the culmination of the process of privatising stress that began in the UK in the 1980s.

The Stresses of Post-Fordism

If the shift from Fordism to post-Fordism had its psychic casualties, then post-Fordism has innovated whole new modes of stress. Instead of the elimination of bureaucratic red tape promised by neoliberal ideologues, the combination of new technology and managerialism has massively increased the administrative stress placed on workers, who are now required to be their own auditors (which by no means frees them of the attentions of external auditors of many kinds). Work, no matter how casual, now routinely entails the performance of meta-work: the completion of log books, the detailing of aims and objectives, the engagement in so-called “continuing professional development”. Writing of academic labour, the blogger Savonarola describes how systems of permanent and ubiquitous measurement engender a constant state of anxiety:

One of the more pervasive phenomena in the current cod-neoliberal academic dispensation is CV inflation: as available jobs dwindle down to Kafkian levels of postponement and implausibility, the miserable Träger of academic capital are obliged not just to overfulfil the plan, but to record … () every single one of their productive acts. The only sins are sins of omission … () In this sense, the passage from … () periodic and measured measurement … () to permanent and ubiquitous measurement cannot but result in a kind of Stakhanovism of immaterial labour, which like its Stalinist forebear exceeds all rationales of instrumentality, and cannot but generate a permanent undercurrent of debilitating anxiety (since there is no standard, no amount of work will ever make you safe).8

It would be naïve to imagine that this “permanent undercurrent of debilitating anxiety” is an accidental side-effect of the imposition of these self-surveillance mechanisms, which manifestly fail to achieve their official objectives. None other than Philip Blond has argued that “the market solution generates a huge and costly bureaucracy of accountants, examiners, inspectors, assessors and auditors, all concerned with assuring quality and asserting control that hinder innovation and experiment and lock in high cost”.9 This acknowledgement is welcome, but it is important to reject the idea that the apparent “failures” of managerialism are “honest mistakes” of a system which sincerely aims for greater efficiency. Managerialist initiatives served very well their real if covert aims, which were to further weaken the power of labour and undermine worker autonomy as part of a project to restore wealth and power to the hyper-privileged.

Relentless monitoring is closely linked to precarity. And, as Tobias van Veen argues, precarious work places “an ironic yet devastating” demand on the labourer. On the one hand, work never ends: the worker is always expected to be available, with no claims to a private life. On the other hand, the precariat are completely expendable, even when they have sacrificed all autonomy to keep their jobs.10 The tendency today is for practically all forms of work to become precarious. As Franco Berardi puts it, “Capital no longer recruits people, but buys packets of time, separated from their interchangeable and occasional bearers”.11 Such “packets of time” are not conceived of as having a connection to a person with rights or demands: they are simply either available or unavailable.

Berardi also notes the effects of digital telecommunications; these produce what he characterises as a diffuse sense of panic, as individuals are subjected to an unmanageable data-blitz:

The acceleration of information exchange … () is producing an effect of a pathological type on the individual human mind and even more on the collective mind. Individuals are not in a position to consciously process the immense and always growing mass of information that enters their computers, their cell phones, their television screens, their electronic diaries and their heads. However, it seems indispensable to follow, recognise, evaluate, process all this information if you want to be efficient, competitive, victorious.12

One of the effects of modern communications technology is that there is no outside where one can recuperate. Cyberspace makes the concept of a “workplace” archaic. Now that one can be expected to respond to an email at practically any time of the day, work cannot be confined to a particular place, or to delimited hours. There’s no escape — and not only because work expands without limits. Such processes have also hacked into libido, so that the “tethering” imposed by digital telecommunications is by no means always experienced as something that is straightforwardly unpleasant. As Sherry Turkle argues, for example, though many parents are increasingly stressed as they try to keep up with email and messages while continuing to give their children the attention they need, they are also magnetically attracted to their communications technology:

They cannot take a vacation without bringing the office with them; their office is on their cellphone. They complain that their employers rely on them to be continually online but then admit that their devotion to their communications devices exceeds all professional expectations.13

Practices ostensibly undertaken for work, even if they are performed on holiday or late at night, are not experienced simply as unreasonable demands. From a psychoanalytic point of view, it is easy to see why such demands — demands that cannot possibly be met — can be libidinised, since this kind of demand is precisely the form that the psychoanalytic drive assumes. Jodi Dean has convincingly argued that digital communicative compulsion constitutes a capturing by (Freudian/Lacanian) drive: individuals are locked into repeating loops, aware that their activity is pointless, but nevertheless unable to desist.14 The ceaseless circulation of digital communication lies beyond the pleasure principle: the insatiable urge to check messages, email or Facebook is a compulsion, akin to scratching an itch which gets worse the more one scratches. Like all compulsions, this behaviour feeds on dissatisfaction. If there are no messages, you feel disappointed and check again very quickly. But if there are messages you also feel disappointed: no amount of messages is ever enough. Sherry Turkle has talked to people who are unable to resist the urge to send and receive texts on their mobile telephone, even when they are driving a car. At the risk of a laboured pun, this is a perfect example of the death drive, which is defined not by the desire to die, but by being in the grip of a compulsion so powerful that it makes one indifferent to death. What’s remarkable here is the banal content of the drive. This isn’t the tragedy of something like The Red Shoes, in which the ballerina is killed by the sublime rapture of dance: these are people who are prepared to risk death so that they can open a 140 character message which they know perfectly well is likely to be inane.

Public Renewal or Private Cure?

The privatisation of stress is a perfect capture system, elegant in its brutal efficiency. Capital makes the worker ill, and then multinational pharmaceutical companies sell them drugs to make them better. The social and political causation of distress is neatly sidestepped at the same time as discontent is individualised and interiorised. Dan Hind has argued that the focus on serotonin deficiency as a supposed “cause” of depression obfuscates some of the social roots of unhappiness, such as competitive individualism and income inequality. Though there is a large body of work that shows the links between individual happiness and political participation and extensive social ties (as well as broadly equal incomes), a public response to private distress is rarely considered as a first option.15 It is clearly easier to prescribe a drug than a wholesale change in the way society is organised. Meanwhile, as Hind argues, “there is a multitude of entrepreneurs offering happiness now, in just a few simple steps”. These are marketed by people “who are comfortable operating within the culture’s account of what it is to be happy and fulfilled”, and who both corroborate and are corroborated by “the vast ingenuity of commercial persuasion”.

Psychiatry’s pharmacological regime has been central to the privatisation of stress, but it is important that we don’t overlook the perhaps even more insidious role that the ostensibly more holistic practices of psychotherapy have also played in depoliticising distress. The radical therapist David Smail argues that Margaret Thatcher’s view that there’s no such thing as society, only individuals and their families, finds “an unacknowledged echo in almost all approaches to therapy”.16 Therapies such as Cognitive Behavioural Therapy combine a focus on early life (a kind of psychoanalysis-lite) with the self-help doctrine that individuals can become masters of their own destiny. Smail gives the immensely suggestive name magical voluntarism to the view that “with the expert help of your therapist or counsellor, you can change the world you are in the last analysis responsible for, so that it no longer cause you distress”.17

The propagation of magical voluntarism has been crucial to the success of neoliberalism; we might go so far as to say as it constitutes something like the spontaneous ideology of our times. Thus, for example, ideas from self-help therapy have become very influential in popular television shows.18 The Oprah Winfrey Show is probably the best-known example, but in the UK programmes such as Mary, Queen of Shops and The Fairy Jobmother explicitly promote magical voluntarism’s psychic entrepreneurialism: these programmes assure us that the fetters on our productive potentials lie within us. If we don’t succeed, it is simply because we have not put the work in to reconstruct ourselves.

The privatisation of stress has been part of a project that has aimed at an almost total destruction of the concept of the public — the very thing upon which psychic well-being fundamentally depends. What we urgently need is a new politics of mental health organised around the problem of public space. In its break from the old Stalinist left, the various new lefts wanted a debureaucratised public space and worker autonomy: what they got was managerialism and shopping. The current political situation in the UK — with business and its allies gearing up for a destruction of the relics of social democracy — constitutes a kind of infernal inversion of the autonomist dream of workers liberated from the state, bosses and bureaucracy. In a staggeringly perverse twist, workers find themselves working harder, in deteriorating conditions and for what is in effect worse pay, in order to fund a state bailout of the business elite, while the agents of that elite plot the further destruction of the public services on which workers depend.

At the same time as a discredited neoliberalism plots this intensification of its project, a kind of right-wing autonomism has emerged in Phillip Blond’s Red Toryism and Maurice Glasman’s Blue Labourism. Here the critique of social-democratic and neoliberal bureaucracy goes alongside the call for a restitution of tradition. Neoliberalism’s success depended on its capturing of the desires of workers who wanted to escape the strictures of Fordism (though the miserable individualist consumerism in which we are all now immersed is not the alternative they sought). Blond’s laughable “Big Society” and Glasman’s disturbingly insular “white working-class” “communities” do not represent persuasive or credible responses to this problem. Capital has annihilated the traditions that Blond and Glasman hanker after, and there is no bringing them back.

But this should not be a cause for lament; far from it. What we need to revive is not social formations that failed (and failed for reasons that progressives should be pleased about), but a political project that never really happened: the achievement of a democratic public sphere. Even in Blond’s work, the lineaments of a hegemonic shift can be discerned — in his startling repudiation of the core concepts of neoliberalism and his attack on managerialism; and in the concession that, contra Thatcher, it turns out that there is such a thing as society after all. Such moves give some indication of the extent to which — after the bank bailouts — neoliberalism has radically lost credibility.

The recent upsurge in militancy in the UK, particularly amongst the young, suggests that the privatisation of stress is breaking down: in place of a medicated individual depression, we are now seeing explosions of public anger. Here, and in the largely untapped but massively widespread discontent with the managerialist regulation of work, lie some of the materials out of which a new leftist modernism can be built. Only this leftist modernism is capable of constructing a public sphere which can cure the numerous pathologies with which communicative capitalism afflicts us.





kettle logic1

No left turn into Parliamentary Square, flashed a sign as we marched through Whitehall last Wednesday. But all the other signs are suggesting quite the opposite: there’s a tentative but very definite shift to the left in the mainstream, nowhere better exemplified than by NUS President Aaron Porter’s2 admission that he had been “spineless” in failing to support student militancy. This leftward lean by the NUS — which has long been a bastion of capitalist realist moderation — is a significant symptomatic moment. See also Polly Toynbee’s slight shift away from centrist condescension, as evidenced in the difference in tone and stance between these two recent pieces.3

Lenin4 and IT have written reports on the kettle, so I won’t detain you for long by repeating what you’ve already heard. Suffice it to note that the mood walking down Whitehall from Trafalgar Square in the Winter sun was almost jubilant: far from the negative solidarity you might have expected, cabbies and bus drivers honked their horns or waved in support of the young protesters. Even after the kettle was imposed, the mood remained remarkably good humoured in the main. You already know about the thin pretext for the kettle, the suspiciously abandoned police van, which was only attacked once the kettle was already in place. As others have observed, there can be no doubt that the real purpose of the kettle is to punish people for protesting, and to deter them from doing so in the future. Lenin is quite right: it’s imperative that this doesn’t happen — the ruling class are counting on the street militancy fizzling out as suddenly as it flared up. We have an opportunity here, not only to bring down the government — which is eminently achievable (keep reminding yourself: this government is very weak indeed), but of winning a decisive hegemonic struggle whose effects can last for years. The analogy that keeps suggesting itself to me is 1978 — but it is the coalition, not the left, which is in the position of the Callaghan government. This is an administration at the end of something, not the beginning, bereft of ideas and energy, crossing its fingers and hoping that, by some miracle, the old world can be brought back to life before anyone has really noticed that it has collapsed.

At the moment, so many mainstream commentators and politicians resemble nothing so much as the denizens of the post-apocalyptic world of Richard Lester’s The Bed Sitting Room: tragicomically persisting with the same customs and habits as if the catastrophe hasn’t happened. Until the weekend, Aaron Porter was walking the ideological junkyard, apparently under the delusion that a career as a New Labour politician was still on the cards. But his change of position suggests that even opportunists have seen which way the wind is blowing. It looks as if the situation might be starting to dawn on Clegg, who increasingly has the cheated and desperate look of a man who has sold his soul to the devil at the very moment the devil went out of business.

Victory will require a range of strategies, and new kinds of intervention are being improvised all the time — see for instance the University For Strategic Optimism.5 Victory will also require others to follow where the students have led — if public service workers join the militancy, then we can look forward to a Winter of Discontent every bit as bitter as the one in 1978.

In addition to the physical kettling of the protests, we’re also seeing a media strategy of containment. Hold your nose and take a look at Jan Moir6 if you want to see a prize example of this kettle logic. The preferred strategy of the old guard seems to be one of phobic panic disguised as insouciant disdain: witness the way Moir shuttles between sexist and ageist belittling (“St Trinian’s Riots”, “fem-factions”, “boys and girls”, “throwing tantrums”) and moral horror (the deploring of “violence and damage”). The protest, in other words, was both a trivial jape and breach of civil order so serious that it merited “detaining () thousands of the students for hours in a ‘kettling’ movement”. I wonder, incidentally, how long the “civic-minded” Moir and her fellow Mail journos would “fight the urge” to “trash cop cars” if they were kettled; I fancy their patience would break long before that of the protesters did. (Imagine the mood hacks would be in after eight hours without alcohol.) Then of course we get the wheeling out of the capitalist realist canards… “the cold reality of the economic times. There is no money left to fund further education for all. Which in any case is an extraordinary privilege, not a right.”

In reply to which I can do no better than quote Digital Ben’s excellent post:

The economic argument (and the alibi given by the Liberal Democrats to explain their about-face on the fees issue) is that we, as a nation, don’t have the money for things anymore. We certainly can’t afford to pay tuition fees, and give grants rather than loans. We managed both of those things for several decades up to 1997, without the economy collapsing around our ears and people pushing wheelbarrows of money through the streets and/or queueing for bread and salt, but never mind.7

Moir demands, with a perfectly straight face, that students “ask themselves why they should expect hard-pressed taxpayers to fork out for their further education, when a great number of those taxpayers are less well off than the students’ own families.” Let’s leave aside the little matter of the fact that this didn’t seem to trouble Moir and her fellow right-wingers when they were receiving free higher education; let’s also leave aside the fact that the current government is full of millionaires who received the same “privilege”. How, you have to wonder, can Moir expect that those same “hard-pressed taxpayers” take cuts in order to fund the bankers, who are more well off than almost everyone else?

Digital Ben also makes a crucial point about the way that the current capitalist realist discourse depends upon a ridiculously outdated figuration of The Student:

There’s still a dimwitted lack of understanding of the nature of these actions — too many television and newspaper reporters seem to be operating under the assumption that those of the protesters who are currently students are only attempting to get their own fees waived. A moment’s consideration would of course reveal that these people will all be working and paying back their loans by the time the Browne proposals are in full effect. The inability to comprehend the idea that people can have motivations other than self-interest reveals far more about the Burleyesque sections of the media than it does about the marchers. The archetype of the spoiled, selfish student living it up on taxpayer money, never particularly fair, is now positively antiquated. Viz — often a reliable social barometer — dropped its “Student Grant” character years ago, but it’s being dug up and spat back at us in 2010. Desperate stuff. To dismiss the students (as every organ in the land seemed to do) as wanting “something for nothing” or “everything handed to them on a plate” is to completely, wilfully misunderstand the situation. The immediate demand of the protesters was for a proposed fee increase to be scrapped. In other words, for the maintenance of a situation in which students work jobs in term-time, live in cheaply built (but tastefully coloured!) PFI rabbit hutches, study hard, and three years later, accept a debt measured in the tens of thousands that will hang over them for most of their adult lives. Compassion for these students might be dulled by the thought that they will eventually be earning high salaries — the risible Gove defended the Browne Report with the uncannily bad argument — “why should a postman subsidise someone who will go on to become a millionaire?” — but in times like these, how many students (even those in vocational subjects) do we really believe will be prospering after they graduate? It should be obvious that what these students want is something for something — the prospect of some kind of reward for all of the hard work and financial risk they’ve undertaken.8

IT has also pointed out the way in which the stereotype of the lazy student is completely out of touch with the reality of so much student experience today. No doubt the students in Moir’s and Toynbee’s families — who, I think we can assume, will be at elite institutions — have an experience of university life which differs little from that which Moir and Toynbee enjoyed. (“Rich parents for all”, as one of the more acerbic placards had it last week.) But many students now routinely have to work long hours during term-time, meaning that they barely have the energy to read anything. By comparison with former generations, these students are paying more for a worse quality educational experience, not to mention the fact that their degrees will in many cases fail to yield them any significant long-term financial advantage. I take Alex Callinicos’ point about the dangers of “generational” politics, but there is surely an unavoidable generational dimension to the current situation. Witness Paxman’s patronising treatment of young protesters on Newsnight last week. Transformed from attack dog rentasneer into the kindly, avuncular advocate of capitalist realism, Paxman “explained” to the teenagers that, yes, it’s unfair that he received an education completely gratis and that they will have to pay thirty grand, but sadly, that’s just how things are — there’s no money left. Generational affiliation here is a matter of political decision. I effectively belong to Paxman’s generation in that I too received higher education completely free of charge. But the issue in question is whether one finds it conscionable to stand by while the young are systematically denuded of the “privileges” that we took for granted. It’s true that higher education has been massively expanded over the past thirty years, but that isn’t the fault of the young. They are the victims of an illthought and poorly planned out experiment in the expansion of the sector which successive governments have pursued on the grounds that the UK would need more graduates in order to be internationally “competitive”. It’s not even as if the young have the alternatives to higher education that once existed. So here they are: the ConDemned, and it’s down to us whether we stand with them or watch them get further sold out and abandoned.

Then there’s the attempt to rubbish the motivation of the protesters: they were just along for a “laff”, Pied-Piper lured along by our old friends, a hard core of anarchists. Even if we were to accept this, Moir and Gove need to explain why it is that these “anarchists” — who, presumably, didn’t start scheming only a few weeks ago — have suddenly been able to motivate the young so effectively. Despite the best efforts of the media and the politicians to maintain business as usual, something has changed. But this change is precarious. We have to do everything we can to keep it going — supporting protests and occupations wherever we can, introducing and exacerbating antagonisms in the workplace, thinking and discussing new strategies, continuing to build a “new politics” that has nothing to do with the dead neoliberal consensus that the coalition is seeking to resuscitate.





winter of discontent 2.0: notes on a month of militancy1

9.45pm. Day X, 24 November. I’m at Charing Cross, grabbing my first food of the day. Actually, it’s not particularly abnormal for me to be eating for the first time this late in the evening; but usually it’s because of overwork, not a consequence of my being “contained” by the police for eight hours. Two protestors arrive, coming down from the day’s anger, frustration and exhilaration. I catch their eye and one of them asks me if I will be joining them next week. I say, yes, tell them that I’ve been kettled in Whitehall, only just got out. They say they were kettled twice. One of them has a V for Vendetta mask pulled up off his face. The police held him for a while but had to release him because of lack of evidence. (Later, one of my students at UEL will tell me a similar story — arrested by the cops on the grounds that he was wearing a red tracksuit top, the same as someone who supposedly set fire to a litter bin, held for a while, his clothes and mobile phone seized, bailed until April — obviously one of many intimidation tactics the police were trying on that day.) They show no surprise, no self-pity or hyperbolic self-dramatisation, just a resolute sense of what needs to be done, and a delight in doing it. I enjoyed it, looking forward to next week…

I ask one of them what he does. He says his friend is already going to college; he will be going next year. But it’s not just about that… It wasn’t just about him; it wasn’t just about tuition fees, or EMA…

It’s not just about that… We are no longer that post-ideological generation

Contrast this () with some of the responses from the “liberal” commentariat — those who belong the real “post-ideological generation”, if ever there was one. For Deborah Orr, it’s business as usual. Resistance to capitalist realism remains futile:

It is sometimes suggested that there is little protest against the cuts, except from students and schoolchildren, because adults are too craven and apathetic to stand up and be counted. The truth is that they are too wise to waste their energy on something so silly. Protesting against the cuts is like protesting against water’s stubborn habit of flowing downwards.2

Compare also with David Aaronvitch on Newsnight: the avuncular grey vampire body posture, that performance of simultaneous weariness and infinite ease in the world, the jaded fatalism passed off as mature wisdom. Yes, of course, I would have gone on the marches when I was a student, but of course I know better now… It’s little different to an argument made by Richard Littlejohn: the protestors will be the next generation of politicians… As if that’s what they want, as if, even if that ended up being true, it would diminish what’s happening now…

3.15pm. 1 December. In one of the dream-like transitions that are becoming increasingly common in the new atmosphere, I am sitting in the UEL occupation, when in walks Richard Seymour to give a talk on the recent history of the Tory party. The students at UEL have been holding Room 101 for a week, since Day X2. Things have changed rapidly in the space of those seven days; they are changing all the time. There are now banners draped all over the central concourse of UEL’s Ballardian Docklands campus. Elsewhere, occupations are sprouting everywhere, like unexpected wildflowers.

The only thing I can compare the current situation with is emerging from a state of deep depression. There’s the rush that you get simply from not being depressed anymore — the occasional lurching anxieties, a sense of how precarious it all seems (don’t drag me back into nothing) — and yet not only is it maintaining itself, it’s proliferating, intensifying, feeding on itself — it’s impossible, but it’s happening — the reality programme resetting itself — David Cameron’s response is both patronising and misjudged. The students should understand what they are protesting against before they protest. Yet it’s clearly Cameron who doesn’t have a handle on the current situation (who does?). As Richard argued in his talk at the UEL occupation, these flabby toffs don’t have the experience, the strategic intelligence or the ideological consistency to win a bitter fight. Cameron was a Tory leader constructed in, and geared up for, the pre-2008 “consensus of indifference” (Baudrillard) — he didn’t expect a struggle, certainly not with those who intend to win. What Cameron doesn’t grasp, doesn’t want to grasp, is the way that the fees are only the immediate cause of the new militancy. What has been provoked is a generalised discontent with nothing less than capitalist realism itself.

5.30pm, 2 December. Neoliberalism isn’t working. I’ve been stuck on Dartford station for ninety minutes. No trains moving in either direction. No one knows where the trains are, or if they will be able to travel any further even if they arrive. One train tried to head further south, but it only got a hundred yards out of the station before having to stop. Official communication is minimal, but only has the status of rumour any way. The railway workers, bereft of reliable information, tell you one thing, then find it immediately contradicted by developments. Are the buses running? Who can say…?

I strike up conversation with someone who happens to be heading to my destination. The usual complaints and bemusement. Why does everything in the UK have to be so crappy? He’s a casual worker, worried that his Christmas will be ruined if this weather keeps up. If he doesn’t go to work, he doesn’t get paid, and he already had to have a week off for flu.

Frail hopes of a train receding, we consider options — we’re less than ten miles from where we want to be, but we could end up having to stay in a hotel. Then he gets a phone call; a friend will pick him up, and he can give me a lift. As we stand shivering and drinking coffee from the station cafe bar, the news comes over the radio. Russia to get the 2018 World Cup. It feels as if the Winter is closing in around.

Cameron. Neoliberalism isn’t working. No joy for Cameron and the other members of the ruling class Holy Trinity — the Prince and David Beckham, the poster boy for New Labour-era celebrity soccer. The grimly smirking Putin arrives last minute to claim the prize. All the boom gloss is falling away, and England feels shoddier and shabbier than it ever did in the Seventies.

Saturday, 4 December. I’m following the news of the UK Uncut protests on Twitter. In the cold of the kettle on Day X1, it occurred to me that the best place to be kettle would be in a shopping mall, where the containment tactics would massively inconvenience capital. But the movement is well ahead of me… Flash mobs invade a number of Topshop stores across the country. IT is right about the crucial significance of this kind of intervention, which “indicates, among other things, an absolute fatigue with the corporate face of city centres”. And also a fatigue with the mandarin-celebrity status of figures like Green. Discontent with celebrity-wealth culture has long been like an indelible shadow that no amount of digital manipulation could quite eradicate, but, until recently, the persistent sense that something is missing amidst all this conspicuous consumption and listless hedonism has had no outlet or agent.

Day X3, 9 December. There’s long been a discrepancy between culture and the post-crash situation. It’s now evident that the New Fifties are over — the scenery still survives, but you can push your fingers through it. Paul Mason3 talks of a “dubstep rebellion”, and, although it would be churlish to complain about Mason’s report, given that he was one of the very few mainstream media commentators to properly engage with the movement. Dan Hancox is surely right: it wasn’t dubstep that was being played last Thursday but “R&B, bashment, road rap, american hip-hop and — albeit only once or twice — grime”.4 What’s striking here is the lack of any political content, or even — “Pow” excepted — much anger in the music that was played. What we can hear exemplified, in fact, is the disengagement from politics that Jeremy Gilbert has persuasively argued was typical of the Nineties hardcore continuum:

given the social and political radicalism characterising most of their immediate antecedents (acid house, with its origins in the black gay clubs of Chicago; hip-hop, only recently having left its “golden age” of political consciousness; reggae, with its history of anti-capitalism and anti-racism), as well as the traditional radicalism of their core constituency — the multiracial poor of urban London — the music scenes of the “nuum” were notable for their detachment from any kind of politics, their embrace of competitive entrepreneurial values, and their defence of masculinist and heterosexist norms which other dance cultures were busily and visibly deconstructing at just that moment.5

What we’ve grown accustomed to is a split between leftist political commitments and the most vibrant, experimental dance musics. No doubt this is an aspect of capitalist realism, and it’s no accident that I referred to Simon’s 1996 piece on hardstep6 in Capitalist Realism. In fact, it might well have been the case that the central concept of the book was triggered by Simon’s commentary on “keeping it real” there:

In hip-hop, “real” has two meanings. First, it means authentic, uncompromised music that refuses to sell out to the music industry and soften its message for crossover. “Real” also signifies that the music reflects a “reality” constituted by late capitalist economic instability, institutionalised racism, and increased surveillance and harassment of youth by the police. “Real” means the death of the social: it means corporations who respond to increased profits not by raising pay or improving benefits but by what the Americans call downsising (the layingoff the permanent workforce in order to create a floating employment pool of part-time and freelance workers without benefits or job security).

“Real” is a neo-Medieval scenario; you could compare downsising to enclosure, where the aristocracy threw the peasants off the land and reduced them to a vagabond underclass. Like gangsta rap, Jungle reflects a Medieval paranoiascape of robber barons, pirate corporations, conspiracies and covert operations. Hence the popularity as a source of samples and song titles of martial arts films and gangsta movies like The Godfather, Reservoir Dogs, Goodfellas, Pulp Fiction, whose universe revolves around concepts of righteous violence and blood-honour that predate the liberal, social-democratic era. … ()

The pervasive sense of slipping into a new Dark Age, of an insidious breakdown of the social contract, generates anxieties that are repressed but resurface in unlikely ways and places. Resistance doesn’t necessarily take the “logical” form of collective activism (unions, left-wing politics); it can be so distorted and imaginatively impoverished by the conditions of capitalism itself, that it express itself as, say, the proto-fascist, anti-corporate nostalgia of America’s right-wing militias, or as a sort of hyper-individualistic survivalism.

In hip-hop and, increasingly, Jungle, the response is a “realism” that accepts a socially-constructed reality as natural. To “get real” is to confront a state-of-nature where dog eats dog, where you’re either a winner or a loser, and where most will be losers. There’s a cold rage seething in Jungle, but it’s expressed within the terms of an anti-capitalist yet nonsocialist politics, and expressed defensively: as a determination that the underground will not be co-opted by the mainstream.7

At Day X1 I heard the predictable “Killing in the Name” and the even more predictable “Sound of the Police”, alongside the Beatles, Madness, and — depressingly — the Libertines — and, most jarringly, “Another Brick In The Wall” (hearing “we don’t need no education” as we shuffled out of the kettle made for a suitably incongruous experience).

But a video that Jeremy shot on Thursday suggests a possible convergence between post-nuum musics and politics. It is my belief that the UK music culture of the next decade will emerge from the stew of sound and affect in the kettles these past few weeks. Paul Mason dismissed the idea that the demo was exclusively populated by “Lacan-reading hipsters from Spitalfields” — but of course (we) Lacan-reading hipsters were also there, alongside the “bainlieue-style youth from Croydon, Peckam, the council estates of Islington”. In other words, this brought together working-class culture and bohemia in something like the same way that art schools — so crucial to UK pop-art culture since the Fifties — used to. But — with very good reasons from its own point of view — neoliberal policy has been hostile to this proletarianbohemian cultural circuit. While Further Education and the new universities have precisely tried to make theory such as Lacan available to the working class — while also trying to engage with everything vibrant coming out of working-class culture — the policy has been to re-cement rigid class and cultural distinctions: philosophy for the bourgeoisie; “vocational” courses for the masses.

Siobhan captures very well the frustrations we encountered on Day X3. Trying to be part of a crowd without being kettled proves all but impossible. The cops’ ontology of the crowd is at least interesting: to enter the crowd is to be responsible for anything that any member of the crowd does. You wouldn’t have been hurt if you weren’t there. (One is struck by the way that this is the complete opposite of the “corporate irresponsibility” that applies to the cops themselves.) Dominic notes the “underlying identification of disorder with uncleanliness, an identification which is transferred onto the disorderly themselves, supports the cop’s self-image as a preserver of public moral health, keeping the clean and decent citizen separate from the filthy and abject underside of society.”8 It’s Foucault 101:

The plague is met by order; its function is to sort out every possible confusion: that of the disease, which is transmitted when bodies are mixed together; that of the evil, which is increased when fear and death overcome prohibitions. It lays down for each individual his place, his body, his disease and his death, his well-being, by means of an omnipresent and omniscient power that subdivides itself in a regular, uninterrupted way even to the ultimate determination of the individual, of what characterises him, of what belongs to him, of what happens to him. Against the plague, which is a mixture, discipline brings into play its power, which is one of analysis. A whole literary fiction of the festival grew up around the plague: suspended laws, lifted prohibitions, the frenzy of passing time, bodies mingling together without respect, individuals unmasked, abandoning their statutory identity and the figure under which they had been recognised, allowing a quite different truth to appear. But there was also a political dream of the plague, which was exactly its reverse: not the collective festival, “but strict divisions; not laws transgressed, but the penetration of regulation into even the smallest details of everyday life through the mediation of the complete hierarchy that assured the capillary functioning of power; not masks that were put on and taken off, but the assignment to each individual of his “true” name, his “true” place, his “true” body, his “true” disease. The plague as a form, at once real and imaginary, of disorder had as its medical and political correlative discipline. Behind the disciplinary mechanisms can be read the haunting memory of “contagions”, of the plague, of rebellions, crimes, vagabondage, desertions, people who appear and disappear, live and die in disorder.9

I was at Hillsborough, and I’ve seen what can happen when the police treat people as an undifferentiated mass, too subhuman to be disciplined. At these protests, the police have been the agents of negative solidarity: Why should we pay for those students? It’s bad for all of us, why can’t they accept it like the rest of us do? By now, it’s clear how prophetic Alex’s post on “post-Fordist plasticity and negative solidarity” has become, since the movement — the alternative to negative solidarity — has assumed exactly the (plastic) form that Alex called for:

Unpicking negative solidarity, which is clearly an internalisation of the conditions of flexibility and atomised “homo economicus” individualism necessary for the embedding of Neoliberal post-Fordism, requires the constructing of a new form of solidarity, a form of solidarity adequately configured to effectively oppose the chief machines of Neoliberal praxis: finance. This new form of solidarity must be capable of fluidity and rapid response, able to exploit weaknesses within systems and structures opportunistically and with a global purview, one which crucially can mirror the rapidity and fluidity of international finance. This is solidarity as plasticity, rather than the static brick-like form of Fordist labour solidarity, capable of flowing and shifting, yes, but also of fixing into position and assuming a hardened form where necessary. This form of solidarity must be inclusive of the new protest and occupation movements which have emerged in recent years, which although they have been largely ineffectual to date, have certainly led to new and interesting configurations of interest groups. What has been lacking however are the necessary cybernetic coordination systems to effectively enable these disparate and fragmentary groups to achieve the status of a counter-hegemonic power, a “class” power in the broadest sense of the term, one which is capable of counter-balancing effectively the rapacious if discredited centres of neoliberalism. Indeed it is this which must be formulated as the political conclusion of theories of post-Fordisation, rather than any kind of fantastical and strictly imaginary political subject such as the multitude. Only when there is an effective counterbalancing power can new theoretical socio-economic post-capitalist forms be properly disseminated, and successfully gain purchase.10

Post-Fordist plasticity is also in play in the other major political story of the day (Mail headline on Thursday: Now It’s Cyber War): Assange and WikiLeaks. Now is not the time to go into this in any depth, but surely what we can see here — and something which those who say that the leaks only tell us what we already know have not grasped — is a new level of symbolic crisis. The authoritarian big Other has always relied upon maintaining a clear difference between off-the-record utterances and official proclamations, but it is precisely this distinction which WikiLeaks (and its successors) threaten to abolish.

On the train home, I read Clegg denouncing “student dreamers” on the front page of the Standard. “I would feel ashamed if I didn’t deal with the way that the world is, not simply dream of the way the world I would like it to be”: capitalist realism in a nutshell. (An unfortunate echo of Bobby Kennedy’s famous slogan: “Some men see things as they are and say why. I dream things that never were and say why not.” See how, under pressure from capitalist realism, the rhetoric of mainstream liberalism has inverted.)

From Foucault 101 to Barthes 101. The coverage of the demo on the BBC News channel is a masterclass in the technique that Barthes called anchorage. What we actually see are mounted police horse charges and some property damage; what we hear about — as bravely narrated by a helmeted reporter from behind the police lines — is the “violence” of the student protestors. (It’s of course not accidental that Paul Mason’s report came from inside the kettle.) One of the most notable features of the media coverage since Day X has been the persistent equivalence it has made between violence and property damage. Having narrowly avoided two kettles, I hardly see any violence or property damage. The violence I do see is perpetrated by the police, as a line of baton-swinging cops impose a kettle on protestors standing on Whitehall. I only learn about Alfie Meadows later, and the disjunction between the reality of the demo and its media representation becomes even more maddening, to the point where I can hardly bear to watch the news coverage any more. While a young student has a brain operation, the media are fixated on a cosmetic “attack” on the heir to the throne’s car. The effects of all this are ambiguous,11 but it’s now clear that the UK hasn’t been as visibly divided as this since the Miners’ Strike.

In the afternoon of Day X1, streaming from Trafalgar Square up towards Whitehall, we didn’t know where we were going or who, if anyone, was leading us. A month later, the situation feels the same. We’ve broken out of the end of history onto terra incognito. What’s certain is that the old world is disintegrating, and soon it will not be possible to even pretend that we can return to it.





football/capitalist realism/utopia1

Football and Neoliberal Anti-Utopianism

“English football”, the writer Robin Carmody argued on his LiveJournal page, is a metaphor for precisely what the neoliberals have done to England itself.” But it’s more than a metaphor. Football has been at the forefront of the total re-engineering of English culture, society and economy wrought by neoliberalism over the last thirty years. Neoliberalism presented itself as supremely realistic — as the only possible realism. It told us that utopia is impossible because there is no such thing as society, only individuals pursuing their own interests. What better image of this anti-utopianism is there than the Premiership, with its imperious, untouchable elite of clubs, its synergy with multinational media conglomerates, its conspicuously consuming players, its super-predatory club owners buying success like they are buying another yacht? Competition, exploitation, the strong lording it over the weak, paparazzi snaps of the fabulously wealthy masters of the universe players exiting nightclubs, flashing their very new money: football as anti-egalitarian Nietzschean combat. Forget utopia: dream, instead — if you’re young — of eventually becoming like this, of owning these Cheshire mansions, of getting a cyborg-slick WAG; or if you’re too old to ever lace up those ultrabranded boots, get used to being inferior, to never making it — dream instead of media-transfiguration via reality TV, or of a lottery win…

Yet the Premiership is often treated as if it were a cause rather than an effect. In the lack of a coherent, general critique of capitalism, complaints about the inflation of players’ wages make no sense. After all, it is not public money being redistributed. Players’ spiralling wages are a consequence of the very market dynamics that, until last year’s bank crisis, were held to be sacrosanct. You can detect a sour anti-working class resentment — shared by self-hating elements of the working class itself — in the attack on football’s “undeserving” rich. But all of this — the player’s high wages, the exorbitant ticket prices — is an effect of football’s total subsumption into post-Fordist capital. But what if it wasn’t like this? What if there had been another way?

Football’s Lost Utopias (in Nottingham)

There’s a poignant moment in Duncan Hamilton’s biography of Brian Clough — also recounted in David Peace’s The Damned United — when Clough and Peter Taylor (who “wanted the ship-builders to earn as much as the ship-owners”) go to see Harold Wilson speak and come away glowing with the white heat of Old Labour optimism, fired up by the prospect of a new era for the proletariat. “You could hear the passion for change in what he said”, Clough told Hamilton. “We went back to Taylor’s house burning with it ourselves.” It’s like a scene from Our Friends In The North: Our Friends In The Midlands, perhaps. The future that Clough and Taylor anticipated would of course never arrive. There’s a parallel, perhaps, with another achingly painful scene in Hamilton’s book: Peter Taylor speaking after Forest’s second victory in the European Cup, proclaiming that this was only the beginning… What in fact lay ahead was underachievement and overpriced players, decline and mediocrity, the final dissolution of the volatile partnership between Clough and Taylor, a rift opening up between the two men that would remain bitter until Taylor’s death. Who of us can identify when the moment of our greatest triumph has already passed? And how bearable would life be if we could?

If the brave new world wouldn’t arrive for the working class, it did arrive for Clough personally. Instead of being at the vanguard of a newly assertive working class, Clough’s period of greatest success coincided with the ebb tide of postwar proletarian collectivism. Clough was sometimes sneered at as a “champagne socialist” because he saw no contradiction between being a leftist and achieving success. Like many born poor, Clough was never able to fully believe that he had finally vanquished poverty from his life — hence, all those TV appearances, ghosted columns and the bung-rumours. In his review of The Damned United for the Guardian, Chris Petit argued that Clough “embodied many of the forthcoming dilemmas of Thatcher’s Britain, his career a constant argument between self-proclamation and partnership, between probity and the demon drink, between financial irregularity and the belief that football was about more than acquisition.”2 The Premiership terminated this, finally destroyed what was left of Clough’s crumbling world — a world in which working-class managers could outwit and overcome puffed-up patrician patriarchs, a world in which unfancied provincial clubs could outdo the established colossuses — and his final decline was all-too punctual. With Clough an ailing Lear at the helm, Forest were relegated in 1993, at the end of the Premier League’s first season.

The End of an Era

May 2009. Flamboyant Barcelona outplay Manchester United in the European Champions League final. United have come to represent the harsh capitalist reality principle of modern football. Only the already-successful and the wealthy can win. Fans dream now not of their club being revivified by some Brian Clough-like managerial genius, but of it being saved by the largesse of a bored plutocrat. Barcelona famously have no shirt sponsor, and display the logo of UNICEF on their jerseys. United’s shirt sponsor is AIG, the insurance company at the heart of the financial crisis (according to the Economist, AIG’s “tentacles reach into every part of the economy.”) The neoliberal anti-utopia disintegrated with the bank bailouts, even though it survives in an undead form as a set of defaults which continue to dominate social reality.

A non-profit making association owned and controlled by its members, Barcelona’s slogan is “more than a club”. Do Barca, with their foundations and educational activities, give a hint as to how football might operate in a utopia? Proletarian artistry the beauty of teamwork, competition, yes, but not the dog-eat-dog combat of capitalist realism. There could surely be no utopia that didn’t include something like this…





the game has changed1

In my column for this publication a few months ago, I called for a new negativity, in the spirit of Herbert Marcuse’s claim that the proper function of art was to be a “Great Refusal”. What better answer could I get than the massive “NO” painted on the grass of Parliament Square in London during one of the recent series of protests against government cuts in the UK? Only four weeks ago, this kind of negativity still seemed to be only a distant possibility in a place like the UK. When, at a conference on public art and civility organised by SKOR in Amsterdam at the end of October, I suggested that there would soon be expressions of massive public anger in the UK, some of the UK-based delegates were sceptical, accusing me of “revolutionary nostalgia”. I was confident that they were being unduly dismissive — but I still didn’t anticipate the scale of the recent protests.

Like Ireland, the UK has been at the forefront of what I have called “capitalist realism” — the view that, since capitalism is the only game in town, all we can do is find a way of accommodating ourselves to it. Part of leftist capitalist realism has been the disavowal of people’s own pessimism and disillusion and its projection onto others. Nothing will happen; people will remain apathetic. That kind of diagnosis has been blown apart by the astonishing student movement that has changed the political landscape in the UK so dramatically since November. Apathy is dead, said a placard at one of the London protests. The game has changed, the protestors have chanted, and so it has. What we’ve seen is an efflorescence of oppositional activity: not only massive protests — which have led to increasingly naked displays of antagonism — but occupations and flashmobs invading chainstores. Comparisons with 68 have inevitably been made, but this movement is in many ways much more remarkable than what happened forty years ago. 68 came at the end of the “cultural revolution” of the Sixties — a series of challenges to the monolithic Marxist meta-narrative (its claim that everything could be reduced to class conflict). 68 presupposed both a credible leftist political project (from which it could deviate) and a social democratic context (which provided the conditions for its exorbitant demands). But both of these have definitively disappeared. They are a distant memory even for the parents of many of the teenagers who took part in the recent UK protests. The current movement has had to build itself up almost from nothing, in a situation where the revolutionary left has no infrastructure and the moderate left has long since acquiesced to capitalist realism; and, perhaps most astonishingly, it has been constructed by those who had previously been the most obvious victims of capitalist realism — the young. And it should also not be forgotten — even though it often is — that 68 failed. The new breed of protestors expect to win. They do not have the ingrained defeatism — and romanticism of failure — that has been the vice of so much of the so-called radical left since the Sixties. Another difference between 68 and now is the class composition of the protestors. Where the university students of the Sixties were a small elite, many of the students involved in the current wave of demonstrations are working class. 68 was about a short-lived alliance between workers and students, but many of today’s students are already workers, forced to do part-time — and often fulltime — jobs in order to support their studies. Similarly, the Fordist model of the worker (as someone who does forty hours a week in a factory for forty years of their life) has long since been replaced by precarious work, which assumes “flexibility” and short-term contracts. Finally, new technology has played a crucial role in the current movement. The rapid-response nature of the protests has only been made possible by social networking sites such as Facebook and Twitter.

In the UK, the government has targeted education, the arts, public services and benefits, imposing cuts that are breathtakingly punitive. The justification for cuts in all these areas has been the capitalist realist rationale that “there is no more money”, but opponents have rightly identified this as a thin pretext used by the rump of neoliberalism in order to pursue its uncompleted ideological project of totally eliminating public space. But this has created the conditions for an alliance between all those groups, which are “naturally” hostile to neoliberalism. In terms of art and education, what we are potentially seeing here is the reconsolidation of a relationship between bohemia — those elements of the bourgeoisie, which disdain business values — and the working class. That relationship — which allowed the arty working class to escape drudgery, and for the bohemian middle class to make contact with the mutational energies of proletarian culture — was the engine of British and Irish popular culture during the Sixties, Seventies and Eighties. Could today’s antagonism revive this? I see no reason not to be optimistic.





creative capitalism1

“We have to live this dead reality, this mad transition, in the same way that we lived prison, as a strange and ferocious way of reaffirming life. You could not escape the atrocious experience of prison, the contact with death and its violence. … () We were constrained to suffer dark romantic hallucinations. There was no longer any alternative. Certainly for us, there has never been any alternative to the world, but always an alternative in the world. A la Rauschenberg: a world that is assumed, shattered, reinvented in the form of its monstrosity. But even the possibility of such a heroism was denied to us. … () We have to live and suffer the defeat of truth, of our truth. We have to destroy its representation, its continuity, its memory, its trace. All subterfuges for avoiding the recognition that reality has changed, and with it truth, have to be rejected. … () The very blood in our veins had been replaced.”

— Antonio Negri, Art and Multitude2

Negri’s Art and Multitude consists of nine letters, most of which were written to his friends at the end of the 1980s while he was in exile in France. Negri here describes the destitution that the left endured after the defeats of the 1970s: the destruction of all its hopes, the way in which it had been outflanked by a neoliberalism which successfully installed business thinking into all areas of everyday life. What emerges here, in other words, is an account of the immediate after-effects of the installation of what I have called capitalist realism: the view that, since there is no alternative to capitalism, the only possible attitude consists in adjusting to its demands. Negri poses the left’s predicament very acutely.

To go back to the seeming certainties of older forms of militancy would be to consign oneself to irrelevance, obsolescence, to become an historical relic; but to accept the new situation, to adapt to it, would be to concede total defeat. The only possibility, Negri suggests, is to endure the time in the desert as a kind of religious trial: a moment of terrible and terrifying renewal, a transformation of the revolutionary subject happening at the very moment when revolution seems impossible and the forces of reaction control everything. The new situation — capital’s mutation into a postFordist form in which labour becomes “immaterial”, “flexible” and subject to the pressures of globalisation — offers new potentials, which must be embraced.

Reading these at times extraordinary communications, I find myself, as ever, persuaded by Negri’s negative analysis, his vision of culture and consciousness totally subsumed by capital. What I am much less convinced by is his positive alternative to this banal yet dark dominion. Like his inspirations, Deleuze and Guattari, Negri is a vitalist who opposes capital’s necrotic force to the living potenza of the creativity of the multitude.

Art, Negri maintains, is intrinsically rebellious and subversive. Even though Negri himself recognises the dangers of taking too much consolation in art, he ends up retaining faith in it. “When I myself suffered the political defeat of the seventies and in the depths of despair, asked art to help me to endure it and to help me find individual ways of resistance and redemption”, Negri writes, “I was overestimating the capacity of art.” Yet Negri is soon arguing that art is a “perennial demonstration of the irreducibility of freedom, of subversive action, of love for radical transformation”.

From Negri’s point of view, there is no contradiction between these two claims. What he is arguing is that an individual can never find his way out of despondency through art alone; rather, it is only by new forms of solidarity — which necessarily must involve art — that escape is possible. While the point about collectivity has never been more pressing, Negri’s hymning of art seems strangely nostalgic. For the era of capitalist realism has also seen all kinds of synergies between art and business, nowhere better summed up than in the concept of the “creative industries”.

It is of course possible to argue that the art that has dominated in capitalist realism, its artistic and commercial value massively inflated, is a fake art, a betrayal and dilution of art’s inherent militancy. But why not go all the way with Negri’s logic of negativity, and argue that there is no readymade, already-existing utopian energy; that there is nothing which, by its very nature, resists incorporation into capital? So it is not then a matter of creativity versus capitalism — or rather of capitalism as the capturing of the creativity of the multitude. Instead, the enemy now could better be called creative capitalism, and overcoming it will not involve inventing new modes of positivism, but new kinds of negativity.





reality management1

Johann Hari’s defenders — and practically every defence of Hari served to further underscore what a complacent self-serving Oxbridge club so much of the UK broadsheet commentariat is — might have pathetically seized upon the News of the World hacking story in order to underplay their boy’s misdemeanours, but the reality is that the Hari and the News of the World situations are part of a single crisis that also includes the Ed Miliband “these strikes are wrong” video2 and ongoing cyberwar (Wikileaks, Lulzsec, 4Chan). Perhaps the reason that the Assange/Žižek dialogue was so disappointing is that Žižek’s basic point about the crisis of symbolic efficiency is now so clear that it doesn’t require much elaboration. It is one thing our knowing about the corrupt practices that the power elite routinely engage in; it is another for that knowledge to be officially validated. The space that power needs to manage reality is disappearing.

With the “Milibot” video, the offscreen manipulations of PR came off less like a dark art and more like surrealist comedy — Miliband for all the world resembling an ROM entity from eXistenZ, only capable of giving one pre-prepared response no matter what the question. The exposure of Hari’s manipulations is significant, meanwhile, because (as Petra Davis argued on her Twitter feed) it showed how his construction of “commonsense reality” depended on techniques proper to fiction. Reading Hari’s pieces back, it’s quite astonishing how crass these techniques were — a “she drew on the omnipresent cigarette” here, and “he asked for more wine” there, inserted between screeds of pirated text. It’s like Hari’s “interviewing” career is one long postmodern prank, and, really, this episode ought to be liberal empiricism’s equivalent of the Sokal scandal. It was fitting that the Deterritorial Support Group’s exposure of Hari3 started with Hari’s hatchet job on Negri, a masterclass in liberal propaganda and knee-jerk loathing of theory — privately educated Hari reassuring his readers that he couldn’t understand Empire, therefore they shouldn’t worry about reading it. The old we don’t read it, so you don’t have to… routine. The Negri “interview” crudely alternates between personal attacks on Negri and appeals to self-evidence (of course communism is evil, why won’t this bad tempered old man admit it?). Yet Hari’s conclusion — “this is where revolutionary Marxism comes to die. It has been reduced to an obscure parlour game for ageing bourgeois nostalgics” — now itself reads like a relic of a bygone world. The “certainties” and self-evidences of the near-past are unravelling quicker than we can keep up.

As for the News of the World story, it is clear that it is not just about the News of the World or phone hacking. A whole ruling class, a whole mode of governance, stands accused. All the signs are that neoliberalism’s standard tactics of containment — offering an individual as scapegoat-trophy in order to deflect from a structural tendency — are now starting to fail. News International are trying to re-sacrifice a scapegoat they’ve already served up (Coulson) but the process is out of their control and now has its own momentum (which is sure to drag other newspapers into its wake before very long). What was made to look like a series of disconnected incidents now appears as what it always was: a worldwide web of corruption whose byzantine murkiness resembles something out of The Wire or a David Peace novel. A dark network comprising private investigators, the criminal underworld, tabloid newspapers, multinational media conglomerates, the police, politicians, the banks, and the bodies supposed to regulate them (who are at best impotent, at worst part of the problem) cannot now be kept hidden from public scrutiny. This is less a conspiracy than a network of complicities: fear on all sides, nobody trusting anybody else, the whole thing depending on who’s got the goods on whom… Cops watching hacks watching cops; threatened politicians looking for favours…

What characterises capitalist realism is fatalism at the level of politics (where nothing much can ever change, except to move further in the direction of neoliberalisation) and magical voluntarism at the level of the individual: you can achieve anything, if you only you do more training courses, listen to Mary Portas or Kirsty Allsopp, try harder. Magical voluntarism, naturally, also drives the tabloid culture of individual blame (resign, resign!) in which the tabloids themselves are now caught up, although, as Zone Styx noted, News International clearly expects far more from public service managers like Sharon Shoemith than it does from its own executives.) Individualise, individualise, insists capitalist ideology. Note the way in which the media sought to reduce the Lulsec story to Ryan Cleary, or the way in which the clueless Peter Preston4 finds the idea of a collective entity such as DSG unfathomable.

A manageable level of cynicism about the media actually serves the capitalist realist media system well. Since the media stands in for the public sphere, if journalists and politicians are perceived to be “all liars”, as they widely are, then there is no hope to be had in public life at all. Hack exculpations appeal to a market Hobbesianism: they are giving people what they want but what they won’t admit to liking. When, pickled in the jouissance of self-loathing and their other stimulants of choice, the hacks style themselves as “princes of darkness”, they see themselves as reflecting the public’s own disavowed cynicism back to it. Nobody likes working in the sewers, but don’t you all love the pretty little globules of sensation that we dredge up for you? Similarly, Glenn Mulcaire whines that the NOTW put him under pressure for results, this isn’t only an excuse — what we’re seeing here is in part the consequence of the intense competitive pressures at work in print media as its market share declines. Negative solidarity again: a race to depths so infernally pressurised that only alcohol-breathing subhuman crustaceans can survive there. (You only have to look at ex-NOTW hack Paul McMullan to see that.) As one by one those who played their part are dragged into the light, the old bullying sneers become familiar plaints: that’s reality, we couldn’t help it, that’s how things are now… But we must hear their excuses as indictments of a system: behold what a wretched state overwork and pitiless competition can reduce human beings to.

All of which means that a few sackings here and there will clearly not suffice. What is needed, as Dan Hind argues, is total media reform:

The current structure of power and decision-making in the media cannot now be allowed to remain unchanged. The employees of large media organisations have monopoly control of decisions about what is investigated and what prominence is given to the results of investigations. They have been unable or unwilling to use this monopoly power in the public interest. Accordingly it is time to assert our democratic right to communicate freely amongst ourselves. Each of us must take some some fraction of the commissioning power, the power to initiate and publish inquiries. If we do not our public life will remain a mess of officially sanctioned fairy tales, crocodilian excuses, and grotesque abuses of the innocent, in which market forces and elite prerogatives set the limits of our understanding and hence of our capacity for self-government.5

In the House of Commons emergency debate today, many MPs had the relieved and faintly bemused air of the henchmen and victims of a bully who can’t quite believe that the tyranny might be nearing its end. As Assange said on Saturday — and as Dan Hind also argues in The Return of the Public — the function of corporate media has been to isolate people, to make them distrust their discontent with a world controlled by business interests. What has combated this is the production of new collectivities of dissent, both online and in the streets. What we’re seeing in this extraordinary moment of transition is a reality management system imploding from within at the same time as it is being undermined from outside. And, this is only the beginning — you haven’t seen anything yet.





uk tabloid1

It took all of Cameron’s replicant smarm to get through this morning’s astonishing press conference.2 Events have moved so swiftly this week that it’s easy to overlook how momentous some of his admissions were. Many are rightly sceptical about whether Cameron will act on what he said today. Sometimes, however, words are acts, and the ultimate significance of what Cameron said today is that it constituted an official acknowledgement — from the very mouth of the beast — that there is indeed a corrupt system involving the press, the police and other politicians, and that he is implicated in it. We’re all in it together, he ruefully observed, another iteration of the fateful phrase that will define his wretched premiership. This might count as capitalist realism’s equivalent of Krushchev’s acknowledgement of corruption in the USSR. There are also those who are sceptical as to whether all of this will lead anywhere very different. If, as I argued in my last post, the scenes we’re now living through resemble the denouement of The Wire or one of David Peace’s novels, then we must confront the political ambivalence of those fictions again. For what they show, after all, is the System as a Schopenhauerian monstrosity, impersonal and implacable, remorselessly reproducing itself, no matter how many local victories are achieved, no matter how many individuals die or are exposed. Is this an analysis of capitalist realism, or a contribution to it? It’s possible now to see both Peace and The Wire as symptomatic of a political impasse; Peace’s novels show the defeat of collective politics, and The Wire anatomises the consequences of that defeat.

What we’re seeing now may not herald the collapse of the system, but I’m confident that this week will be looked back upon as a moment when power in the UK was forced to reconfigure. We’re too ready to see the Murdochs as Machiavellian, one step ahead of events. But no empire lasts forever; even the canniest operator loses their touch eventually, and Murdoch, let’s remember, is the man who bought Myspace. Closing down the News of the World may have been a smart move, but it is one that the Murdochs made on the back foot; it was a reactive bid to regain initiative, or at least to gain some traction on a situation that remains out of their control.

This is all a consequence of an excess of power. If the old autonomist argument is correct and capital’s innovations were forced by workers’ acts of refusal — and what could illustrate this thesis more effectively than Murdoch’s struggle with the unions in the 1980s — then it’s now clear how sloppy and shoddy capital’s operatives became in the lack of any effective opposition. This is decadence — not merely in the moral sense, but also in the sense of decay and deterioration. During the early twentyfirst-century high pomp of neoliberalism, hacks, cops and politicians were so confident that they would never be exposed that they behaved in an ever more brazenly depraved manner, and appeared to take little care in covering their traces. What’s also emerging into clearer view now is the tabloid media’s crucial role in the biopolitical control which was central to the constitution of neoliberal hegemony. Too much is made of Murdoch the kingmaker; his hold over politicians, like that exercised by Paul Dacre, depended far less on what he could do for them, and far more on what he could do to them, if they crossed him or his organisation. It’s suggested, for instance, that the reason that the previous police “investigations” into News International were so inadequate is that NI held compromising information on the investigating officers, and that MPs feared calling Rebekah Brooks to account because they were warned that they would be subject to tabloid humiliation. Dacre and Murdoch are the princes of piety and cynicism.3 The neoliberal tabloid is an almost too crude diagram of a Burroughsian biocontrol apparatus: stimulating hedonic excess on the one hand while condemning it on the other. Surveillance need only be virtual. There’s always something potentially shaming that can be dragged out of the closet, for whose fantasy life is not humiliating when exposed to the glare of the big Other? No matter who the victim of these exposes might be, they serve right-wing purposes, because they reinforce a Hobbesian account of “human nature”: everyone is out for themselves; everyone has a price; everyone is sexually incontinent, given the opportunity. It’s no accident that Ellroy called his great work of political demythologisation American Tabloid.

But it was the pairing of piety and cynicism which ultimately did for the News of the World. The revelations that practically every cause or individual about which the NOTW waxed so sentimentally and sanctimoniously — Our Boys, murdered children, the 7/7 victims — was being phone hacked means that the distance between public piety and private cynicism could no longer be maintained.

Read Adam Curtis’ potted history of Murdoch4 and it’s instructive to see how the justification for tabloid sensationalism has changed. The denials that the News of the World would be salacious which Murdoch made when he took over the paper in the social democratic era give way to neoliberalism’s claim to be only giving people what they want. This was the line that witless reactionary oaf Jon Gaunt pursued on Question Time last night. There’s nothing quite so sad as an unpopular populist, and Gaunt’s goading of Hugh Grant — “if you didn’t want to be on the front of the papers, you should have kept it in your trousers”, “who are you to tell people what they can or can’t watch” — embarrassingly misjudged the audience’s mood. Tabloid sensationalism is a drug, but there was a sense last night that the QT audience was no longer willing to conceal from itself the cost of procuring that cheap hit. There was little appetite for Gaunt’s now quaint-seeming rhetoric of “choice” and his bashing of paternalism. The old neoliberal lines Gaunt was haplessly hawking had all the appeal of yesterday’s fast food. What we’re left with is a whole set of questions about culture that are now posed again with renewed force: neoliberalism has failed, the patrician culture it defeated cannot be revived, nor should it be — so where next?





the future is still ours: autonomy and postcapitalism1

Adam Curtis’ recent documentary series All Watched Over by Machines of Loving Grace argued that discourses of self-organisation, which had formerly been associated with the counterculture, were now absorbed into dominant ideology. Hierarchy was bad; networks were good. Organisation itself — held to be synonymous with “top-down control” — was both oppressive and inefficient. There is clearly something in Curtis’ arguments. Practically all mainstream political discourse is suspicious of, and sceptical towards, the state, planning and the possibilities of organised political change. This feeds into the ideological framework that I have called capitalist realism: if systemic change can never happen, all we can do is make the best of capitalism.

There’s no doubt that the right has been able to profit from identifying the left with an allegedly superseded “top-down” version of politics. Neoliberalism imposed a model of historical time which places bureaucratic centralisation in the past, by contrast with a “modernisation” that is held to be synonymous with “flexibility” and “individual choice”. More recently, the much derided idea of the Big Society is, in effect, a right-wing version of autonomism. The work of Phillip Blond, one of the architects of the “Big Society” concept, is saturated with the rhetoric of self-organisation. In the report “The Ownership State”, which he wrote for the ResPublica thinktank,2 Blond writes of “open systems” which “recognise that uncertainty and change render traditional command-and-control ineffective”. While Blond’s ideas have been seen by many as obfuscatory justifications for the neoliberal privatisation agenda, Blond himself positions them as critical of neoliberalism. Blond notes a paradox that I also discuss in Capitalist Realism: rather than eliminating bureaucracy, as it promised to, neoliberalism has led to its proliferation. Since public services can never function as “proper” markets, the imposition of the “market solution” in healthcare and education “generates a huge and costly bureaucracy of accountants, examiners, inspectors, assessors and auditors, all concerned with assuring quality and asserting control that hinder innovation and experiment and lock in high cost.” Such systems, Blond writes, are

organic rather than mechanistic, and require a completely different management mindset to run them. Strategy and feedback from action are more significant than detailed planning (‘Fire — ready — aim!’ as Tom Peters wrote); hierarchies give way to networks; the periphery is as important as the centre; self-interest and competition are balanced by trust and cooperation; initiative and inventiveness are required rather than compliance; smartening up rather than dumbing down.

Since the right is now prepared to talk in these terms, it is clear that networks and open systems are not enough in themselves to save us. Rather, as Gilles Deleuze argued in his crucial essay “Postscript on the Societies of Control”,3 networks are simply the mode in which power operates in the “control” societies that have superseded the old “disciplinary” structures.

Does all this then mean that ideas of autonomy and self-organisation would inevitably be co-opted by the right, and that there is no further political potential in them for the left? Definitely not — far from indicating any deficiency in autonomist ideas, the co-option of these ideas by the right shows that they have continuing potency. Seeing what is wrong with Blond and his ilk’s appropriation of autonomism will also tell us something about what the difference between right and left might be in the future.

Curtis is right that the principal way in which autonomist ideas have been neutralised is by using them against the very idea of political organisation. Yet autonomist theories continue to be crucial because they give us some resources for constructing a model of what leftist political organisation could look like in the post-Fordist conditions of mandatory flexibility, globalisation and just-in-time production. We can no longer be in any doubt that the conditions which gave rise to the “old left” have collapsed in the global North, but we must have the courage not to be nostalgic for this lost Fordist world of boring factory work and a labour movement dominated by male industrial workers. As Antonio Negri so powerfully put it in one of the letters collected in the recently published Art And Multitude, “We have to live and suffer the defeat of truth, of our truth. We have to destroy its representation, its continuity, its memory, its trace. All subterfuges for avoiding the recognition that reality has changed, and with it truth, have to be rejected. … () The very blood in our veins had been replaced.”4 Even though the shift into so-called “cognitive” labour has been overstated — just because work involves talking doesn’t make it “cognitive”; the labour of a call centre worker mechanically repeating the same rote phrases all day is no more “cognitive” than that of someone on a production line — Antonio Negri is right that the liberation from repetitive industrial labour remains a victory. Yet, as Christian Marazzi has argued, workers have been like the Old Testament Jews: led out of the bondage of the Fordist factory, they are now marooned in the desert. As Franco Berardi has shown, precarious work brings with it new kinds of misery: the always-on pressure made possible by mobile telecommunications technology means that there is no longer any end to the working day. An always-on population lives in a state of insomniac depression, unable to ever switch off.

But what has to differentiate the left from the right is a commitment to the idea that liberation lies in the future, not the past. We have to believe that the currently collapsing neoliberal reality system is not the only possible modernity; that, on the contrary, it is a cybergothic form of barbarism, which uses the latest technology to reinforce the power of the oldest elites. It is possible for technology and work to be arranged in completely different ways to how they are configured now. This belief in the future is our advantage over the right. Phillip Blond’s networked institutions may have a cybernetic sheen, but he argues that they must be situated in a social setting which is re-dedicated to “traditional values” coming from religion and the family. By strong contrast, we must celebrate the disintegration of these “values”, as the necessary precondition for new kinds of solidarity. This solidarity won’t emerge automatically. It will need the invention of new kinds of institutions, as well as the transformation of older bodies, such as trade unions. “One of the most important questions”, Deleuze wrote in the “Control” essay,

will concern the ineptitude of the unions: tied to the whole of their history of struggle against the disciplines or within the spaces of enclosure, will they be able to adapt themselves or will they give way to new forms of resistance against the societies of control? Can we already grasp the rough outlines of the coming forms, capable of threatening the joys of marketing?

Perhaps the lineaments of that future can be seen in Latin America, where left wing governments facilitate worker-run collectives. The issue is not any more of abandoning the state, government or planning, but making them part of new systems of feedback that will draw upon — and constitute — collective intelligence. A movement that can replace global capitalism does not need centralisation, but it will require co-ordination. What form will this co-ordination take? How can different autonomous struggles work together? These are the crucial questions we must ask as we begin to build the post-capitalist world.





aesthetic poverty1

“A salient feature of these riots,” designer Adrian Shaughnessy wrote of the recent disorder in England, “has been the fact that the main target of the attacks has been the shops of the major retail brands of British commercial life.”2 Writing on Design Observer’s website, Shaughnessy further noted that most of the outlets which were targeted — sports stores, mobile phone shops — “spend huge amounts of money on branding, on store layout, on window displays, and slick advertising.” The comments on Shaughnessy’s blogpost were telling: many fellow designers saw the post as, at best, spurious, and, at worst, offensive. Shouldn’t the rioters take responsibility for their own behaviour? What role could design possibly play in inciting such “criminal” actions?

The reactionary commentary on the riots has tried to downplay the idea that the rioters were deprived. The rioters had expensive smart phones and wore top-end sportswear — so how could they be poor? While this has been exaggerated — the places where the riots took hold overwhelmingly tended to be areas of poverty and unemployment — it’s true that, so far as we can tell, most of the rioters weren’t homeless or starving. But there are other kinds of destitution than these. As well as “physical” poverty, there is also an aesthetic poverty, evident to anyone who takes a second look at the dismal vistas of England’s hyper-corporatised high streets. While the rich have the material and cultural resources to “unplug” from the dreary banality of these cloned spaces, the poor are far more embedded in them. This embedding in tightly defined media, social and physical environments is in fact a major symptom of aesthetic poverty.

One feature of the moral panic over the riots was the claim that the rioters “destroyed their own communities”. But this presupposes both that the rioters belonged to a “community” and that chain stores could constitute any sort of “community” in any case. (It is true that the rioters did not only target corporate outlets, and I don’t for a moment want to underplay the horrific destruction caused to small businesses and to people’s homes, but it remains the case that most of the destruction and looting was aimed at corporate chains.) Isn’t the point, rather, that the rioters were outside, not a “community”, since, increasingly, no such thing exists under late capitalism, but from the quiet desperation and miserable resignation that characterises many people’s working lives today? The fact that some of the rioters had jobs was supposed to prove that these were not insurrections of the underclass. But many of the jobs that the British media kept citing — one of the rioters, it was trumpeted, was a classroom assistant, another, interestingly, was none other than a graphic designer — were not in themselves indications that the rioters had serious prospects. Such jobs, which are often part-time and short term, are typical of the “precarity” in which increasing numbers of young people — graduates as well as those with few or no qualifications — now find themselves languishing. Those pushing the idea that being a “graphic designer” automatically means that you are inured from poverty or hopelessness only demonstrate how out of touch they are.

The point about mobile phones is also worth pursuing. In what the theorist Jodi Dean has called “communicative capitalism”, a smart phone can no longer be conceived of as a mere “luxury item”. Communicative capitalism is not about the production of material objects, but the ceaseless circulation of messages. The “content” in this culture comes from users themselves; hence paying for an interface into the communicative matrix is more like paying for one’s own tools at work than it is like buying a luxury good. The very distinction between work and non-work, between entertainment and labour, erodes. There are no office hours, no clocking off. In addition to ensuring that we are always connected to the communicative matrix, smartphones are tethering devices which allow employers to call short-term workers into work at a moment’s notice. But the notorious use of social networking sites and BlackBerry messenger to propagate the riots shows that the potential of these machines and these websites is not exhausted by communicative capitalism. It has been said that the riots in London spread once groups who usually engage in territorial turf wars called a truce in order to band together against the authorities. While the riots in England could hardly be said to be a coherent political statement, in this collective use of social media there was perhaps the beginnings of something like class consciousness. And in the destruction of the depressing facades of corporate retail, is it too fanciful to see a rejection of the aesthetic poverty that corporate capitalism imposes on so many of us?





the only certainties are death and capital1

“This isn’t just art that exists in the market, or is ‘about’ the market. This is art that is the market — a series of gestures that are made wholly or primarily to capture and embody financial value, and only secondarily have any other function or virtue.” So wrote Hari Kunzru of Damien Hirst’s work in the Guardian.2 I’m not interested in rehearsing here discussions of Hirst’s merit as an artist; what interests me instead is his symptomatic status as a figure who embodies capital’s penetration into all areas of culture. As Kunzru points out, Hirst’s own relationship to capital is more than close. He is a “house artist to the 1%”, and the way that value is generated out of his work — a mixture of hype and the exploitation of the poorly remunerated “assistants” who actually produce many of the pieces — is a model of how exchange value is created in late capitalism. Hirst’s notorious auction, “Beautiful Inside My Head Forever”, took place at the very moment that Lehman Brothers was collapsing. But while the banks failed, Hirst remains a powerful brand. In fact, some of Hirst’s pieces were among the works that were auctioned when Lehman Brothers’ art collection was sold off in order to recoup something for the bank’s creditors. The way that the prices of Hirst’s pieces became not just part of the story of the works, but practically their sole interest, reminds me of nothing so much as Michael Jackson after Thriller. Yet, while Jackson was tragically maddened and destroyed by the colossal scale of his success, Hirst gives every impression of being perfectly at home at the heart of a vast capital-generating factory.

The current Hirst retrospective at the Tate should now look like a reliquary of bygone world, but it merely highlights that art and culture have yet to come to terms with the traumatic events of 2008. Our imaginations are still dominated (or stultified) by work which emerged from the cocaine-buzzy mixture of hedonism, cynicism and piety which governed art and politics in the 1990s and 2000s. Hirst is the Warhol of capitalist realism, but he has none of Warhol’s blank charisma. In place of Warhol’s android awkwardness, Hirst offers a blokish bonhomie. Warhol’s studied banality has become the genuinely ultrabanal. Or, rather, the Hirst phenomenon typifies the way in which, in late-capitalist art and entertainment culture, the ultrabanal and the super-spectacular have become (con)fused. Watching Hirst halfheartedly reiterate half-baked clichés — death as the antithesis of life; art as religion — while he was being interviewed in the television coverage that surrounded his current retrospective at the Tate, I was struck by the guilelessness of his thinking. But, then again, what is there to say about this work that it doesn’t already say itself? For all its fixation on death, this is work that, in its bleak immanence, repudiates negativity, and leaves no space for commentary.

It is this obdurate refusal to be more than what it is that makes Hirst’s work flat with what I have called capitalist realism. Capitalist realism refers to a set of political beliefs and positions, but also a set of aesthetic impasses. “Realism” here does not connote a realist style so much as the inability to see, think or imagine beyond capitalist categories. It’s no accident that “reality” entertainment came to the fore in the unprecedented period of neoliberal domination before the bank crises of 2008. Hirst’s work belongs to a corresponding development that we might call reality art. The dead animals in the formaldehyde really are dead animals. The skull really is a skull. This inertial tautology may be the real “point” of Hirst’s work, and also the reason it emptily but emphatically resonated in a neoliberal era characterised by political fatalism and the corrosion of social imagination. Things are as they are; they cannot be re-imagined, transfigured, or changed. Is there any art object which better captures this than the diamond-encrusted skull of Hirst’s “For The Love Of God”, the object which, more than any other, may come to stand for the decadence and vanity of the pre-2008 neoliberal world? “For The Love Of God” makes explicit the guiding logic of much of Hirst’s work: the only certainties are death and capital. But it can tell us nothing about this. It is a mute symptom which exemplifies a condition it can neither describe nor transcend.





why mental health is a political issue1

“Welfare suicides don’t exist. Suicide is a mental health issue.” That line, by the former Labour official Luke Bozier, pretty much sums up the standard right-wing response to the website Calum’s List.2 According to its founders, the aim of Calum’s List is “to list the number of deaths where welfare reform has alleged to have had some culpability, and to make the best effort possible to work towards reducing this death toll.” Bozier’s Twitter comments were a gloss on blogposts by the Spectator’s Isabel Hardman3 and the Telegraph’s Brendan O’Neill.4

There’s more than a whiff of Freud’s “kettle logic” (I didn’t borrow your kettle; when I borrowed the kettle it was already broken; when I returned the kettle it wasn’t damaged) about the cluster of incompatible arguments that these three presented against Calum’s List. Their principal claims were as follows. The suicides have not been caused by the changes, and therefore to mention them is an act of opportunistic exploitation; if suicides have been caused by the reforms, this is no reason to abandon them; the problem is not the reforms themselves but how they are managed (i.e. those forced back to work should be given adequate support); suicide is not a rational act, which means that it can have no political significance.

I don’t wish to argue here about whether or not specific cases of suicide were caused by the new legislation. But I do want to contest the bizarre idea that, in principle, suicides could not be adduced as evidence against the changes in the welfare system. If people dying as a consequence of the implementation of measures cannot count as evidence that the legislation has detrimental effects, what would?

O’Neill displays a strangely judgmental attitude towards suicide, arguing suicide “is not a rational response to economic hardship; it is not a rational response to having your benefits cut”. This is a spectacular case of missing the point: for many of those suffering from mental illnesses, the capacity to act rationally is impaired, which is one reason that they need to be protected. As for the idea that those returning to work should receive proper support, the lack of such support is the issue. Atos, the agency responsible for testing whether claimants are fit to work, has seen a large number of appeals against its judgments upheld. And who can have faith the government will properly support those returning to work when it entrusts the transition to a discredited agency such as A4e?

But there’s a more general problem here. Some of the right-wing commentators condemning Calum’s List have deplored the “politicisation” of mental illness, but the problem is exactly the opposite. Mental illness has been depoliticised, so that we blithely accept a situation in which depression is now the malady most treated by the NHS. The neoliberal policies implemented first by the Thatcher governments in the 1980s and continued by New Labour and the current coalition have resulted in a privatisation of stress. Under neoliberal governance, workers have seen their wages stagnate and their working conditions and job security become more precarious. As the Guardian reports today, suicides amongst middleaged men are on the increase, and Jane Powell, chief executive of Calm, the Campaign Against Living Miserably, links some of this increase with unemployment and precarious work.5 Given the increased reasons for anxiety, it’s not surprising that a large proportion of the population diagnose themselves as chronically miserable. But the medicalisation of depression is part of the problem.

The NHS, like the education system and other public services, has been forced to try to deal with the social and psychic damage caused by the deliberate destruction of solidarity and security. Where once workers would have turned to trade unions when they were put under increasing stress, now they are encouraged to go to their GP or, if they are lucky enough to be able to be get one on the NHS, a therapist.

It would be facile to argue that every single case of depression can be attributed to economic or political causes; but it is equally facile to maintain — as the dominant approaches to depression do — that the roots of all depression must always lie either in individual brain chemistry or in early childhood experiences. Most psychiatrists assume that mental illnesses such as depression are caused by chemical imbalances in the brain, which can be treated by drugs. But most psychotherapy doesn’t address the social causation of mental illness either.

The radical therapist David Smail argues that Margaret Thatcher’s view that there’s no such thing as society, only individuals and their families, finds “an unacknowledged echo in almost all approaches to therapy”. Therapies such as cognitive behavioural therapy combine a focus on early life with the self-help doctrine that individuals can become masters of their own destiny. The idea is “with the expert help of your therapist or counsellor, you can change the world you are in the last analysis responsible for, so that it no longer cause you distress” — Smail calls this view “magical voluntarism”.

Depression is the shadow side of entrepreneurial culture, what happens when magical voluntarism confronts limited opportunities. As psychologist Oliver James put it in his book The Selfish Capitalist, “in the entrepreneurial fantasy society”, we are taught “that only the affluent are winners and that access to the top is open to anyone willing to work hard enough, regardless of their familial, ethnic or social background — if you do not succeed, there is only one person to blame.” It’s high time that the blame was placed elsewhere. We need to reverse the privatisation of stress and recognise that mental health is a political issue.





the london hunger games1

Welcome to the Hunger Games. The function of the Hunger Games is to suppress antagonism, via spectacle and terror. In the same way, London 2012 — preceded and accompanied by the authoritarian lockdown and militarisation of the city — are being held up as the antidote to all discontent. The feelgood Olympics, we are being assured, will do everything from making good the damage done by last year’s riots to seeing off the “threat” of Scottish independence. Any disquiet about London 2012 is being repositioned as “griping” or “cynicism”. Such “whinging”, it is claimed, assumed its proper place of marginality as the vast majority enjoy the Games, and LOCOG is vindicated.

The Olympics semiosphere is one from which all negativity must be banished. Witness this masterpiece of circularity, in a blog defending Coca Cola and McDonalds’ sponsorship of the Games:

Considering they have both recently signed long extensions of their contracts and the Olympics are just days away it was rather irresponsible of Jaques Rogge to be in any way negative about such committed Olympic sponsors. Especially because it has also brought negativity to the IOC and the Olympic Games at a crucial period.

Negativity is bad because it brings negativity! The BBC is even periodically running a little film about the importance of positive thinking (even though positive thinking can result in worse outcomes2).

Sadly, Charlie Brooker3 has joined those who think that negativity about the Games was overplayed. But once the Olympic floodlights are turned off, most will switch back from an attitude of mild interest to indifference towards even the most dramatic Olympic sports, never mind those many Olympic sports which plainly have limited spectator appeal. This isn’t the point though: disquiet about London 2012 was never necessarily based in any hostility towards the sports. Enjoyment of the sport and loathing for LOCOG and the IOC are perfectly compatible.

Cynicism is just about the only rational response to the doublethink of the McDonalds and Coca Cola sponsorship (one of the most prominent things you see as you pass the Olympic site on the train line up from Liverpool Street is the McDonalds logo). As Paolo Virno argues, cynicism is now an attitude that is simply a requirement for late-capitalist subjectivity, a way of navigating a world governed by rules that are groundless and arbitrary. But as Virno also argues, “It is no accident … () that the most brazen cynicism is accompanied by unrestrained sentimentalism.” Once the Games started, cynicism could be replaced by a managed sentimentality. The BBC has given itself over to propagating an hysterical PR delirium, as Mike Marqusee described after seeing the boxing at ExCel:

Breathless BBC commentators reiterate the same round of superlatives — “unbelievable”, “incredible”, “amazing”, “brilliant”, “unbelievable” — telling us again and again how unique, how special, how extraordinary these Olympics are. It feels like they’re the ones on performance-enhancing drugs, not the usually sober, poised and realistic competitors.4

Sadly, at the ExCel, after the refreshment of the boxing came the utterly formulaic torpor of a video package in which celebrities waxed banal on the “atmosphere” that makes the Olympics special and the “unforgettable” moment we’re privileged to be part of.

Affective exploitation is crucial to late capitalism. The BBC’s own Caesar Flickerman (the interviewer who extracts maximum sentimental affect from the Hunger Games contestants before they face their deaths in the arena) is the creepily tactile trackside interviewer Phil Jones. Jones’ “interviews” with exhausted athletes, are surely as ritualised as any Chinese state broadcast. Emote. Emote again. Emote differently. Praise the crowd.

It is via emotion that advertising can make the spurious connection between brands and the sport, but, as Marqusee points out, PR boosterism cannot tolerate the very thing which makes sport so fascinating — its unpredictability, the fact that high drama is not guaranteed.

The point of capital’s sponsorship of cultural and sporting events is not only the banal one of accruing brand awareness. Its more important function is to make it seem that capital’s involvement is a precondition for culture as such. The presence of capitalist sigils on advertising for events forces a quasi-behaviouristic association, registered at the level of the nervous system more than of cognition, between capital and cultural. It is a pervasive reinforcement of capitalist realism.

There is a strange duality of the Olympics — such that, surrounding the Games, there can be a semioblitz of commercial exploitation, but, in the spaces where the athletes compete, there is a coy chasteness about advertising, so that even the O2 has to be renamed North Greenwich Arena for the duration of London 2012. Of course, the reason for this is so only those who pay the IOC for the privilege can commercially exploit the Games. Nevertheless, these zones from which capitalist semiotic pollution has been minimised make a pleasant contrast with the ubiquitous tawdry hucksterism elsewhere, inviting us to imagine the Games without capital.

But we don’t have to. It’s clear that what people are already enjoying in the Games is everything for which capital is not responsible: the efforts of the athletes, the experience of a shared publicness. Insofar as the torch relay was a success, this, too, was not due to the parade itself — a dreary countrywide corporate carnival, consisting of Samsung, CocaCola and Lloyds TSB floats — but because it allowed people to experience their own sociality. Note also, for instance, that the improved British performance, which has the BBC in such a jingoistic froth, was likely due to (the privatised-public) National Lottery funding rather than corporate sponsorship.

Nothing could be a clearer example of Negri’s claim that capital is essentially parasitic than the Games. Capital’s contribution to London 2012 has been systematically overpriced and shoddy: whether it be the branding, with its infantile colouring and lettering (we’ve grown used to the logo, but, really, has there been a more embarrassingly inept logo in the history of the world for an event of this magnitude?), the soon to be demolished Olympic stadium, magnificent only in its mediocrity, and the grand folly of the ArcelorMittal Orbit. The ArcelorMittal Orbit is perhaps the best symbol of capital’s parasitic relation to the London 2012 Games. The echo of Vladimir Tatlin’s Monument to the Third International tells you an awful lot about the impasses, inertia and sterililty of capitalist realist culture. As Douglas Murphy points out, comparing the Orbit to Vladimir Tatlin’s Monument to the Third International, “w ()hereas Tatlin’s twists were a yearning evocation of the teleological thrust of dialectical materialism, the Orbit’s creators, in their design statement, merely explain that it ‘should make an iconic statement about Tower-ness’”.5

As Juliet Jacques has argued, the “deconstructed tower” is — unwittingly — the perfect monument for capitalist realist Britain:

With its funding and name coming mostly from billionaire Lakshmi Mittal’s integrated steel company, who provided up to £19.2m towards its costs, with the rest given by the London Development Agency, the Orbit is less a radical structure than an utterly conservative one. In saying that it would pay for itself throgh the renting of private dining spaces at its summit, Boris Johnson may have said more about its legacy than he planned when he described it as a “corporate money-making venture”. In that, Kapoor and Balmond’s Orbit captures the spirit of its time and place as much as Eiffel or Tatlin’s designs — but perhaps not quite as they intended.6





time-wars: towards an alternative for the neo-capitalist era1

Time rather than money is the currency in the recent science fiction film In Time. At the age of twenty-five, the citizens in the future world the film depicts are given only a year more to live. To survive any longer, they must earn extra time. The decadent rich have centuries of empty time available to fritter away, while the poor are always only days or hours away from death. In Time is, in effect, the first science fiction film about precarity — a condition that describes an existential predicament as much as it refers to a particular way of organising work.

At the most simple level, precarity is one consequence of the “post-Fordist” restructuring of work that began in the late 1970s: the turn away from fixed, permanent jobs to ways of working that are increasingly casualised. Yet even those within relatively stable forms of employment are not immune from precarity. Many workers now have to periodically revalidate their status via systems of “continuous professional development”; almost all work, no matter how menial, involves self-surveillance systems in which the worker is required to assess their own performance. Pay is increasingly correlated to output, albeit an output that is no longer easily measurable in material terms.

For most workers, there is no such thing as the long-term. As sociologist Richard Sennett put it in his book The Corrosion of Character: The Personal Consequences of Work in the New Capitalism, the post-Fordist worker “lives in a world marked … () by short-term flexibility and flux … () Corporations break up or join together, jobs appear and disappear, as events lacking connection.”2 Throughout history, humans have learned to come to terms with the traumatic upheavals caused by war or natural disasters, but “w () hat’s peculiar about uncertainty today”, Sennett points out, “is that it exists without any looming historical disaster; instead it is woven into the everyday practices of a vigorous capitalism”.3

It isn’t only work that has become more tenuous. The neoliberal attacks on public services, welfare programmes and trade unions mean that we are increasingly living in a world deprived of security or solidarity. The consequence of the normalisation of uncertainty is a permanent state of low-level panic. Fear, which attaches to particular objects, is replaced by a more generalised anxiety, a constant twitching, an inability to settle. The uncertainty of work is intensified by digital communication technology. As soon as there is email, there are no longer working hours nor a workplace. What characterises the present moment more than our anxious checking — of our messages, which may bring opportunities or demands (often both at the same time), or, more abstractly, of our status, which, like the stock market is constantly under review, never finally resolved?

We are very far from the “society of leisure” that was confidently predicted in the 1970s. Contrary to the hopes raised at that time, technology has not liberated us from work. As Federico Campagna writes in his article “Radical Atheism”, published on the Through Europe website,

In the current age of machines … () humans finally have the possibility of devolving most productive processes to technological apparatus, while retaining all outcomes for themselves. In other words, the (first) world currently hosts all the necessary pre-conditions for the realisation of the old autonomist slogan “zero work/full income/all production/to automation”. Despite all this, twenty-first-century Western societies are still torn by the dusty, capitalist dichotomy which opposes a tragically overworked section of population against an equally tragically unemployed one.4

Campagna’s call for a “radial atheism” is based on the recognition that the precariousness that cannot be eliminated is that of life and the body. If there is no afterlife, then our time is finite. Curiously, however, we subjects of late capitalism act as if there is infinite time to waste on work. Work looms over us as never before. “In an eccentric and an extreme society like ours”, argue Carl Cederström and Peter Fleming in their book Dead Man Working, “working has assumed a universal presence — a worker’s society in the worst sense of the term — where even the unemployed and children become obsessed with it.” Work now colonises weekends, late evenings, even our dreams. “Under Fordism, weekends and leisure time were still relatively untouched”, Cederström and Fleming point out, “Today, however, capital seeks to exploit our sociality in all spheres of work. When we all become “human capital” we not only have a job, or perform a job. We are the job.”5

Given all of this, it is clear that most political struggles at the moment amount to a war over time. The generalised debt crisis that hangs over all areas of capitalist life and culture — from banks to housing and student funding — is ultimately about time. Averting the alleged catastrophe (of the end of capitalism) will heighten the apocalyptic temporality of everyday life, as the anticipation of catastrophe gives way to a sense that we are already living through the catastrophe and it, like work, will never end. The increase of debt justifies the extending of working hours and working life, with retirement age being pushed ever further back. We are in a state of harassed busyness from which — we are now promised — there will never be any relief.

The state of reactive panic in which most of us find ourselves is not an accidental side-effect of post-Fordist labour. It is highly functional for capital that our time is not only quantitatively short but qualitatively fragmented, bitty. We are required to live in the condition that Linda Stone has called “continuous partial attention”, where our attention is habitually distributed across multiple communication platforms.

As Franco “Bifo” Berardi has argued, we now live in the tension between the infinity of cyberspace and the vulnerable finitude of the body and the nervous system. “The acceleration of information exchange has produced and is producing an effect of a pathological type on the individual human mind and even more on the collective mind,” Berardi writes in Precarious Rhapsody,

Individuals are not in a position to process the immense and always growing mass of information that enters their computers, their cell phones, their television screens, their electronic diaries and their heads. However, it seems indispensable to follow, recognise, evaluate, process all this information if you want to be efficient, competitive, victorious. … () The necessary time for paying attention to the fluxes of information is lacking.6

The consequence is a strange kind of existential state, in which exhaustion bleeds into insomniac overstimulation (no matter how tired we are, there is still time for one more click) and enjoyment and anxiety co-exist (the urge to check emails, for instance, is both something we must do for work and a libidinal compulsion, a psychoanalytic drive that is never satisfied no matter how many messages we receive). The fact that the smartphone makes cyberspace available practically anywhere at anytime means that boredom (or at least the old style, “Fordist” boredom) has effectively been eliminated from social life. Yet boredom, like death, posed existential challenges that are far more easily deferred in the always-on cyberspatial environment. Ultimately, communicative capitalism does not vanquish boredom so much as it “sublates” it, seeming to destroy it only to preserve it in a new synthesis. The characteristic affective tonality for the insomniac drift of cyberspace, in which there is always one more click to make, one more update to check, combines fascination with boredom. We are bored even as we are fascinated, and the limitless distraction allows us to evade confronting death — even as death is closing in on us.

No doubt this chronic shortage of time goes some way to accounting for the stalled and inertial quality of culture in recent years. The neoliberal gambit was that the destruction of social security would have a dynamic effect on culture and the economy, liberating an entrepreneurial spirit that was inhibited by the red tape of bureaucratic social democratic institutions. The reality, however, is that innovation requires certain forms of stability. The disintegration of social democracy has had a dampening, rather than a dynamic, effect on culture in highly neoliberalised countries such as the UK. Fredric Jameson’s claims that late-capitalist culture would be given over to pastiche and retrospection have turned out to be extraordinarily prophetic.

We’ve grown so accustomed to repetition and recycling that we no longer notice them. Yet it’s no surprise that this is the case. New cultural production requires a use of time that communicative capitalism is profoundly hostile towards. Most social energy is sucked into the vortex of late-capitalist labour and its vast simulation of productivity. Innovation depends upon an absorbed (rather than distracted) drift; but it is increasingly difficult to muster the attentional resources necessary for such immersion. Cyberspatial urgencies — the smartphone’s flashing red light, the siren call of its alert — function like trance-inhibitors or alarm clocks that keep waking us out of collective dreaming. In these conditions, intellectual work can only be undertaken on a short-term basis. Only prisoners have time to read, and if you want to engage in a twenty-year-long research project funded by the state, you will have to kill someone.

To understand the time-crisis, we only have to compare the current situation with the height of punk and post-punk in the UK and the US. It’s no accident that the efflorescence of punk and post-punk culture happened at a time when cheap and squatted property was available in London and New York. Now, simply to afford to pay rent in either city entails giving up most of your time and energy to work. The delirious rise in property prices over the last twenty years is probably the single most important cause of cultural conservatism in the UK and the US. In the UK, much of the infrastructure which indirectly supported cultural production has been systematically dismantled by successive neoliberal governments. Most of the innovations in British popular music which happened between the Sixties and the Nineties would have been unthinkable without the indirect funding provided by social housing, unemployment benefit and student grants.

These developments precisely opened up a kind of time that is now increasingly difficult to access: a time temporarily freed from the pressure to pay rent or the mortgage; an experimental time, in which the outcomes of activities could neither be predicted nor guaranteed; a time which might turn out to be wasted, but which might equally yield new concepts, perceptions, ways of being. It is this kind of time, not the harassed time of the business entrepreneur, which gives rise to the new. This kind of time, where the collective mind can unfurl, also allows the social imagination to flourish. The neoliberal era — the time when, we were repeatedly told, there was no alternative — has been characterised by a massive deterioration of social imagination, an incapacity to even conceive of different ways to work, produce and consume. It’s now clear that, from the start (and with good reason) neoliberalism declared war on this alternative mode of time. It remains tireless in its propagation of resentment against those few fugitives who can still escape the treadmill of debt and endless work, promising to ensure that soon, they too will be condemned to performing interminable, meaningless labour — as if the solution to the current stagnation lay in more work, rather than an escape from the cult of work. If there is to be any kind of future, it will depend on our winning back the uses of time that neoliberalism has sought to close off and make us forget.





not failing better, but fighting to win1

Capitalist realism, to sum it up briefly, can be seen as both a belief and an attitude. It is a belief that capitalism is the only viable political/economic system, and a simple restatement of the old Thatcherite maxim, “There is no alternative”.

People like Paul Mason have been saying that since 2011 there has been an upsurge in global militancy, including a number of uprisings, and this represents the end of capitalist realism. But that is clearly not the case. It is true that the major crisis of capitalism from 2008 led to a situation where capital has never been weaker ideologically in my lifetime, and as a result there is widespread disaffection, but the question is why nevertheless capitalist realism still exists.

In my view it is because it was never really necessarily about the idea that capitalism was a particularly good system: it was more about persuading people that it is the only viable system and the building of an alternative is impossible. That discontent is practically universal does not change the fact that there appears to be no workable alternative to capitalism. It does not change the belief that capitalism still holds all cards and that there is nothing we can do about it — that capitalism is almost like a force of nature, which cannot be resisted. There is nothing that has happened since 2008 that has done anything to change that, and that is why capitalist realism still persists.

So capitalist realism is a belief, but it is also an attitude related to that belief — an attitude of resignation, defeatism and depression. Really then, capitalist realism, whilst it is disseminated by the neoliberal right, and very successfully so, is a pathology of the left, or elements of the so-called left, that they succumb to. It was an attitude promoted by New Labour — what was New Labour if not instantiating the values of capitalist realism? In other words, we resign ourselves to the fact that there is no getting around capital: capital will ultimately run things, and all we can do is perhaps bolt on a couple of tethers as gestures toward social justice. But essentially ideology is over, politics is over: we are in the era of so-called post-ideology, the era of post-politics, where capital has won. This so-called “post-political” presentation by New Labour was one of the ways in which capitalist realism imposed itself in the British context.

There is a problem, however, in seeing capitalist realism just as a belief and an attitude, in that both are based on individual psychology. The discussion needed is one that interrogates where those beliefs and attitudes come from, for what we are actually dealing with is the social decomposition that gives rise to them. For that, we really need a narrative about the decline of solidarity and the decline of security — the neoliberal project achieved its aim of undermining them. Capitalist realism then is also a reflection of the recomposition of various forces in society. It is not just that people are persuaded of certain beliefs, but rather that the beliefs people have reflect the way that forces in society are composed in contemporary capitalism.

“Modernisation”

The decline of the unions is probably the biggest factor in the rise of capitalist realism for ordinary people. Now we find ourselves in a situation where everybody disdains bankers and finance capitalism, and the level of control that these people still hold over all of our lives. Everyone is aghast at the plunder, avoidance of tax and so forth, yet at the same time there is this sentiment that we can do nothing about it. And why has that sentiment grown so powerful? It is because there really is no agent to mediate the feelings people have and organise those people. The effect is that discontent can be widespread, but without such an agent it will remain at the level of individual disaffection.

That easily converts into depression as well, which is one of the stories I try and tell in my book, Capitalist Realism. I deal with the association between post-politics, post-ideology, the rise of neoliberalism and the conjoined rise of depression, particularly among young people. I call this process the “privatisation of stress”.

I do not want to hang everything on trade union decline — unions are just an example of what has been removed from the psychic and political infrastructure of people’s lives over the last thirty or forty years. However, in the past, if your pay and conditions got worse, you might go to the unions and organise, whereas now we are encouraged, if, for example, stress at work increases, to see it as our own problem and deal with it as an individual.

We must deal with it through self-medication, through antidepressants, which are increasingly widely prescribed, or, if we are lucky, through therapy. But these concerns — experienced now as individual psychic pathologies — do not really have their roots in brain chemistry: they reside in the wider social field. But, because there is no longer an agent, a mediator, for a class acting collectively, there is no way of tackling that wider social field.

Another way of getting to this story is via the restructuring of capital in the late Seventies and early Eighties, the arrival of post-Fordism. That meant the increasing use of precarious conditions at work, just-in-time production, the dread word “flexibility”: we must bend to capital, no matter what capital wants; we are required to bend to it and we will bend to it. On the one hand, there was that kind of stick, but there was also at least the appearance of carrots in the Eighties: neoliberalism did not just hammer workers; it encouraged people no longer to identify as workers. Its success was in being able to seduce people out of that identification, and out of class consciousness.

The genius at the centre of Thatcherism could be found in the selling-off of council houses, because alongside the straightforward inducement of owning your own home was the narrative about time and history, whereby Thatcher and people like her were out to make your life more free. They were opposed to those stuck-in-the-mud, centralising bureaucrats, who want to control your life for you. That involved a very successful harnessing of the desires that had grown up, particularly since the Sixties.

Part of the problem here was the absence of a left response to post-Fordism — instead there was an attachment to the comfort of old antagonisms, you could say. We had internalised the story that there was a strong workers’ movement which depended on unity. What were the conditions for that? Well, we had Fordist labour, the concentration of workers in confined spaces, the domination of the industrial workforce by male workers, etc. The breakdown of those conditions threatened the breakdown of the workers’ movement. There was the emergence of a plurality of other struggles, leading to the undermining of the common purpose that the workers’ movement once possessed. But that kind of nostalgia for Fordism was actually dangerous — the failure was not that Fordism ended, but that we had no alternative vision of modernity to compete with the neoliberal account.

In fact, neoliberalism owns the word “modernisation” now. If you hear the word in news broadcasts, it is synonymous with neoliberalisation. Whenever there is a dispute — in, say, Royal Mail — the phrasing used is something like, “Royal Mail is trying to modernise, but its plans are opposed by workers”. But when they say “modernise”, they really mean “privatise” and “neoliberalise”. We saw this with Blairism: those who wanted to “modernise” really wanted to neoliberalise the Labour Party. Of course, if you are opposed to modernisation, you must be out of touch with reality and you immediately find yourself on the back foot.

The left almost seemed to believe it, and the only way to “modernise” was to make some sort of accommodation with capital. But the opposite mistake was to think that things could stay as they were before — and that was really a very dangerous line to go down. The challenge was to come up with a post-Fordist leftism — a project which was begun in the Eighties. But this soon got derailed, as any attempt to do this was seen as just folding to Blairism, even though that was not the case.

Education

There is more than just one particular zone where capitalist realism applies and most of the anecdotes and key concepts that went into the book came from my experiences teaching sixteen to nineteen-year-olds. So let us turn now to the key question of capitalist realism in education.

One of its central features in this area is “business ontology”, as I have called it, which is simply the idea that the only things that actually count, the only criteria that matter, are related to business. Within education we have seen a creeping spread of practices, language and rhetoric from business. And this has spread into teaching, into the kind of self-policing and self-surveillance teachers are now required to perform.

One of the things I try to point out in Capitalist Realism is the strange anomaly here: one of the things we were sold about neoliberalism was that it liberated us from bureaucracy, that it was only old Stalinists and crusty social democrats who obsess with bureaucracy. Neoliberalism was supposed to cut away the red tape. So why is it that teachers are required to perform more bureaucratic tasks than they ever were in the heyday of social democracy?

Simply because neoliberalism has got nothing to do with the freeing of markets, and everything to do with class power. That is reflected in the introduction of certain methods and strategies, ways of assessing teachers and schools, justified because they allegedly increase efficiency. Well, anyone who has engaged in this kind of, to coin another phrase, market Stalinism knows that nowadays what matters is what appears on the forms, irrespective of whether it actually corresponds to reality.

It was New Labour which accelerated this development in education by introducing targets — isn’t it interesting that New Labour presented itself as the extreme antithesis of Stalinism, but it ended up reconstituting at a formal level Stalinism’s really bad aspects (not that there were many good ones!). The language of planned targets has come back, like the return of the repressed.

Given that this clearly does not increase efficiency, we need to see it as a disciplinary mechanism, an ideological, ritualising system. If you are a teacher sitting at home filling in lots of forms full of quasi-business rhetoric, you are not going to teach a better lesson the next day. In fact, if you just watched TV and relaxed, you would probably be better equipped in that regard. But the authorities are not idiots: they know this; they know they are not really increasing your performance.

So what is the function of these practices? Well, one is obviously discipline and control: control via anxiety, control via the destabilisation of professional confidence. These things are framed as “continuous professional development”, and that sounds good, doesn’t it? You always want to learn more, don’t you? And now you always have access to training. But what it really means is that your status is never really validated — you are constantly subject to review. And it is a review of a bizarre and Kafkaesque type, because all the assessment criteria are characterised by a strategic vagueness, whereby it might appear possible to fulfil them, but in reality that fulfilment can be constantly deferred. The result is that teachers are in a constant state of anxiety — and anxiety is highly functional from the perspective of those who want to control us.

On a second level it is merely ideological ritual, of exactly the kind that Althusser described. For him a good part of ideology is made up of ritual: you just repeat the phrases and, as Althusser says, via Pascal, “Kneel and you will believe”. That is a highly ambiguous phrase. Does it mean, “Kneel and you will believe afterwards”? Or that in the act of kneeling you already believe? I think both, but it reinforces the idea that belief is really the crucial thing about capitalism. And one of the sources of that belief is the contamination of public life and former public services by this kind of incantation and language of business. Many people regard what they are required to do at work as quite ridiculous and ask why they have to do it. Capitalist realism is confronted, as the response comes back: “Well, you know, it’s just how it is now. We don’t really believe this stuff, of course, but we just have to go along with it.”

That is all ideology really needs. You do not have to believe it in your heart of hearts: all you are required to do is act as if you believe it. In education this has been crucial as part of the way in which we view its purpose. Today education is to be determined by the needs of business. Of course, such a tendency has always been present, but there is almost no contesting it anymore.

Debt

There are many different dimensions to capitalist realism in education, but the other key one is debt, plainly. What is interesting is that after the phoney peace, I suppose you could call it, following 2008, where nothing really significant happened in terms of public displays of anger, the first real manifestation of discontent was the student movement of 2010.

Just before it started, I said to a friend of mine that there was going to be some expression of anger over the cuts in higher education, and he responded to the effect that that could not happen: it was just “revolutionary nostalgia” on my part. I do not tell that story to claim some special prophetic vision, but to illustrate the fact that his view had seemed to be the realistic one — there really had been no sign of such anger erupting.

But it did erupt at the end of 2010. Why was that? What was really being argued over with regard to fees? Clearly the rhetoric about paying down the debt is ludicrous, in as far as anyone can make out anything in this necromantic economics surrounding university fees. It seems that it is costing the government more to impose this new system anyway, so it has actually increased the deficit. What were they actually trying to achieve with this massive hike in fees? To me it is obvious that this is another version of the production of a certain kind of anxiety — the student population had to be constituted as debtors.

There was a good piece by Mark Bolton in the New Left Project arguing that debt is now the key social category in capitalism: capital does not need to work in the same way as before, but it does need us to be in debt — a main source of our subjectivity.2 What is debt? It is also a capture of time, of our future. So the confrontation with university students in the UK is a dramatic example of the kind of switch-around we have seen — a struggle over the use of time.

What was university like when I went? First, I did not pay a penny in fees and, secondly, I received a maintenance grant, upon which it was possible to actually live if you were quite frugal. In other words, there was this funded time outside the frenetic activity of work. I say that because now work has changed into simply a means of paying off debt.

The article in the New Left Project was arguing against a ludicrous rightwing Tory book, Britannia Unchained, which claims that Britain had been chained up, but those chains have now been cut.3 So how are we freed as a result? We can work harder and longer — even harder than those Chinese, because we need to do a far better job of exploiting ourselves than we have up to now. But the reality of work is that it does not pay enough and that is why we are in debt.

This government has attempted to moralise debt. It is analogous to the ludicrous assertion it keeps making (the government operates in a kind of neuro-linguistic way, believing that if you repeat something often enough then it will become true) that the crisis was caused by New Labour overspending — just like an individual who has maxed out their credit cards. Of course, it was not a moral failing at all when people relied so much on their credit cards: it was unavoidable. More importantly, the entire economy now needs people to be in debt — they are doing their duty to capital! That duty to capital in the past is used as a new reason in the present to exploit them further, to cut their public services and standards of living. It would be funny if it were not so grotesque. But this ridiculous personalisation of debt, as if it were a moral failing, is the meat and drink of capitalist realism.

Connected to this is the reduction in the amount of time that could be spent for purposes other than the kind of frenetic anxiety related to the world of work. That Tory book is really part of this attempt to impose such anxiety — we are not working hard enough, after all. What we have seen with the coalition government is the systematic shutting down of space where time could be used differently. This has a massive impact on culture, because it was within those spaces that any alternative culture could be produced. Many of the key developments in popular culture since the 1960s were facilitated by the space provided by the welfare state, social housing, etc. They amounted to a kind of indirect funding for cultural production. With those spaces closed down, much of the culture of late-capitalist Britain is moribund, miserable, repetitious and homogenous.

Another one of the paradoxes of capitalist realism is the hyper-regulation of learning in the classroom, so that any deviation from the official programme is closed down. When you step outside the narrow parameters of the examination drill, students themselves will complain today. They will ask, “Is this going to be in the exam?” A narrow teleological focus is what is inculcated, along with a super-instrumentalisation of education.

Of course, one of the things senior management is trying to do with the introduction of fees is to create a split between students and lecturers. As the students are paying more in fees, it is expected that they will demand more from the lecturers. Management is fairly cynically trying to get students to behave as “aggrieved consumers” who should demand more for their money, but the problem is that none of that extra money is going to the lecturers. I know of a communication from a senior manager at a higher education institution saying that, in the wake of the hike in fees, “We’d better prepare ourselves for students demanding more”. Which means that lecturers will have to work more for the same money.

In It Together?

How is it possible to impose all this? Well, only because of the general ideological atmosphere of capitalist realism. Whilst I do not agree with Paul Mason, capitalist realism has certainly changed its form compared to before 2008. Then it had a bullish quality that declared: “Either you get on board with us or you’re a sad loser who will die drinking meths in a gutter — if you’re lucky.” Since 2008, it has had a more desperate quality, which is what lies behind the ostensibly inclusive rhetoric of “We’re all in it together”. In other words, if we do not all pull together, we will all go down — rather different from the previous implication that anyone who does not come on board will just be crushed beneath the juggernaut of capital.

So the tone of capitalist realism has changed, but harsh measures have been imposed very quickly because of the absence of an alternative. In fact it is even worse than that, because the previous form of the system to which we are told there is no alternative is now impossible. There is no returning to pre-2008 capital. Capital has no idea of any solution to the crises which led up to 2008. There is no guarantee that the current crisis can be ended, because capital’s means of keeping wages low and demand up was debt itself. If you make debt harder to come by, then what is going to take its place? There is no answer to that, and plainly capital’s apologists are just flailing about.

Their only answer has been the strategy of austerity, which in large part has been based on a historical forgetting of why the welfare state was introduced. It was introduced not out of the kindness and largesse of the capitalists, but as “revolution insurance”, so that widespread discontent did not spill over into revolution. They have forgotten that, and as a consequence they think they can keep pulling away those social safety nets without any problem. Last year’s riots give us a glimpse of some of the possible repercussions.

What then can we do? Well, it is first necessary to defeat the anarchists — I am only half-joking about that. It is essential that we ask why it is that neo-anarchist ideas are so dominant amongst young people, and especially undergraduates. The blunt answer is that, although anarchist tactics are the most ineffective in attempting to defeat capital, capital has destroyed all the tactics that were effective, leaving this rump to propagate itself within the movement. There is an uncomfortable synergy between the rhetoric of the “big society” and a lot of the neo-anarchist ideas and concepts. For example, one of the things which is particularly pernicious about some of the dominant ideas within anarchism at the moment is their disengagement from the mainstream.

There is the idea, for instance, that the mainstream media is an inherently corrupt monolith. The point is that it is completely corrupt, but it is not a monolith. It is a terrain that is effectively controlled at present by neoliberals, who took the fight over the mainstream media very seriously, and consequently won that struggle.

One of the things which I am pushing for is media consciousness-raising with some younger people — for example, Channel 4 used to have hourlong programmes featuring a debate between three philosophers. Now Big Brother takes up that slot. The slot once occupied by European Arts cinema is now taken by Location, Location, Location. If you want to look at the changes in British society, politically and culturally over the last thirty years then there is no better example than Channel 4.

Why is that? Because Channel 4 emerged as a result of all sorts of struggles within the media for control of things like film, and people took that very seriously. Alongside the labour struggles of the Eighties there were also cultural struggles. Both were defeated, but at the time it was by no means obvious that they would be. If you remember, the Eighties were the time when there were moral panics about “loony left” councils, and there was also a moral panic over Channel 4 with its politically correct lefties, who were supposedly taking over broadcasting.

That is part of what I mean by an alternative modernity — an alternative to the neoliberal “modernity”, which is actually just a return to the nineteenth century in many ways. But the idea that the mainstream culture is inherently coopted, and all we can do is withdraw from it, is deeply flawed.

The same is true about parliamentary politics. You should not pin all of your hopes on parliamentary politics, because that would be sad and ludicrous, but, at the same time, if it was pointless then you have to ask why the business class expends so many resources in subjugating parliament to its own interests.

Again, the neo-anarchist idea that the state is finished, that we do not need to participate in it at all, is deeply pernicious. It is not that parliamentary politics will achieve much on its own — the object lesson of what happens if you believe that to be the case was New Labour. Power without hegemony — that is effectively what New Labour was. But that is pointless. You cannot hope to achieve anything through an electoral machine alone. But it is hard to see how struggles can succeed without being part of an ensemble. We have to win back the idea that it is about winning the hegemonic struggle in society on different fronts at the same time.

Because the anti-capitalist movements that have arisen since the Nineties have ultimately done nothing, they have caused capital no concern at all — it has been so easy to route around them. Part of the reason for that is the fact that they have taken place out on the street, ignoring the politics of the workplace and of the everyday. And that feels remote to ordinary working people, because at least with the unions, for all their flaws, there was a direct connection between everyday lives and politics. That connection is now missing, and anti-capitalist movements have not provided it.

Coordination

It seems to me that the crucial question now is coordination, and so many debates around centralisation versus decentralisation, top-down versus horizontal, obfuscate the real issues, which are about what is the most effective form of co-ordination against capital. Coordination does not need centralisation: in order for things to have common purpose they do not have to be centralised. We need to resist the false oppositions which come out of the way neo-anarchist ideas are narrativised.

Obviously all the anti-capitalist movements, right up to Occupy, have managed to mobilise disaffection, but they have not been able to coordinate it in a way that causes capital any long-term problems at all. What could coordinate discontent? And what could convert ambient disaffection into sustainable antagonism? It is a lack of the sustainability of these antagonisms which is part of the problem with them. Another problem with them, which my comrade, Jeremy Gilbert, has raised, is their lack of institutional memory. If you do not have something like a party structure then you do not have institutional memory, and you just end up repeating the same mistakes over and over.

There is far too much toleration of failure on our side. If I ever have to hear that Samuel Becket quote, “Try again, fail again, fail better”, I will go mad. Why do we even think in these terms? There is no honour in failure, although there is no shame in it if you have tried to succeed. Instead of that stupid slogan we should aim to learn from our mistakes in order to succeed next time. The odds might be stacked in such a way that we do keep losing, but the point is to increase our collective intelligence. That requires, if not a party structure of the old type, then at least some kind of system of coordination and some system of memory. Capital has this, and we need it too to be able to fight back.





the happiness of margaret thatcher1

So they win again. If anything is to be taken from the miserable time we endured last week, it must be to learn some lessons about how the enemy operates. It couldn’t have worked much better from their point of view. A series of punitive attacks on the poorest and most vulnerable in society ended up being simultaneously cloaked and justified by the brazen hijacking of an appalling, aberrant act of violence. This is one part of the “legacy of Thatcher” that we will be invited to reflect upon in the coming days. The bitter edge to all those leftist celebrations of Thatcher’s death is all too evident. She retired from the field of class war twenty years ago, her work a spectacular success. Looking at Britain now — a country much more Thatcherite than when she left office — she could have died a happy woman.

The Tories have long been struggling with the problem of how to escape Thatcher’s shadow while continuing her project. Last week, we saw their quest to square a circle — how to lose their “nasty party” image while actually intensifying the attack on the remnants of social democracy — bearing some fruit. Helmed by the reinvented IDS, now cast as a caring but tough-minded friend of the poor, the simple strategy has involved the displacement of the concept of unemployment by that of welfare dependency. The idea of welfare dependency is inherently obfuscatory, part of the inverted world of magical thinking the Tories have been all too successful at pushing in opposition. In Thatcher’s day, unemployment was the price to pay for reconstruction; now, insofar as the Tories now mention unemployment at all, it is posited only as an effect of welfare dependency. Just as the state “crowds out” private sector entrepreneurialism, so — we are solemnly informed — the benefit system obstructs the capacity of people to act in their own interests. The Tories now can sound like inverted Marxists who aren’t attacking individuals, but the system which produces their behaviour. In the immortal words of Grant Shapps: “It is not that these people were trying to play the system, so much as these people were forced into a system that played them.” By shifting the focus onto the benefits system, the Tories can pose as the good patrician parent, offering the tough love solution to the bureaucratic indulgences of left paternalism.

Meanwhile, Labour shuffles uncomfortably in the shadows, looking at its feet, before offering up its depressing policy review on the future of welfare.2 This confirms what few could have doubted: that Labour has learned next to nothing from the failures of Blairism, and that its only strategy is to hide out, do nothing to frighten the horses, and wait for government to be handed back to them as a consequence of discontent with the Tories. Without Blair’s charismatic thespianry and false hopes, without even the Shakespearean drama of Brown’s blighted leadership, an atmosphere of deathly, affectless decadence has settled over the Labour Party. Populist but not very popular, Labour has become a dead mechanism animated by a blind drive: win elections. It is an election-winning machine which can barely win elections, and which has long ago forgotten why you would want to win an election in the first place. By contrast, the Tories have a feverish sense of purpose. They serve ruling-class interests even when not in power by dragging the “centre” ground to the right. Once in government, they impose their policy agenda at high speed, without majority or mandate, retrospectively justifying it, if they bother to justify it at all, with the kind of “debate” we saw last week.

No doubt Labour’s silence last week — allowing it to seem as if Owen Jones was the only voice speaking up on mainstream media against the benefit cuts — is motivated by its awareness that attacks on benefits are popular amongst elements of the working class.3 But rather than challenging this failure of class consciousness and the myths which contribute to it, rather than beginning the difficult work of unpicking this negative solidarity,4 Labour of course acquiesces in it.

The fact that the right is “using value-laden and pejorative language when discussing benefits and welfare”5 is not some moral or intellectual error on its part — it is a crude but remorselessly effective form of neuro-linguistic programming, designed to create a series of enduring associations which become embedded in the political unconscious. (Some of the miserable effects of this anti-benefits discourse are outlined in painful detail in this moving blog post.6) Here, as with the infamous attempts to shift the blame for the deficit from capitalist crisis onto the Labour Party, the technique is incantatory repetition. The Tories know that if phrases and memes are repeated enough times, facts can be suspended. The reality technicians running the right understand that, as Freud said, there is no negation in the unconscious. No matter how much Owen Jones refuted the “arguments” of the right on radio and TV last week, they made hegemonic ground simply by the fact that they had managed to create a chain of equivalence connecting a child murderer with welfare. Whether the right actually choreographed their positions doesn’t much matter, they still functioned as a coordinated campaign (the right is much better at class solidarity than us, performing it instinctively). The Mail fulfilled its usual role as outlier, floating an “outrageous” position which it inevitably tempts other media outlets into propagating, thus allowing Cameron and Osborne to “respond” in an apparently more measured — but actually only minimally distanced — way. The right won ground by the sheer fact that the “debate” was happening, and anything we do could only ever be a question of clawing back territory. The right is on the front foot, and we, as ever, are playing catch-up.

It’s worth reflecting a little on the techniques deployed by the Mail — the most-read online newspaper in the world, remember — not least because they involve a certain complicity on our part. “Outrage” is the Mail’s stock in trade, and the bind we’re in is that we seem compelled to provide more than our fair share of it. Outrage is not merely impotent, it is actively counterproductive, feeding the very enemy we claim to want to defeat. That’s because, firstly, outrage is part of the very currency of what Jodi Dean calls communicative capitalism, which depends not on content but on the sheer circulation of messages. Even when the Mail was vilified for its headline, such vilification only becomes the libidinal juice of the Mail’s communicative capitalism (there will be more messages, more posts, more tweets; we will read even if we don’t “want” to; we will read because we’re not supposed to). Secondly, since there is an infinite supply of things to be outraged about, the tendency towards outrage indefinitely locks us up in a series of reactive battles, fought on the enemy’s territory and on its terms. (How many of us on the left, faced with our social media timelines when we wake up in the morning, don’t feel a certain weariness, as we ask ourselves, what are we supposed to be outraged about today?). Thirdly, outrage reflects a fundamental political misunderstanding, both of our opponents and of the war that they are waging. Such outrage, as Wendy Brown puts it in her crucial essay “Moralism as Anti-Politics”, “implicitly figures the state (and other mainstream institutions) as if it did not have specific political and economic investments, as if it were not the codification of various dominant social powers, but was, rather, a momentarily misguided parent who forgot her promise to treat all her children the same way.”7 We use the rhetoric of class war, but too often we behave as if we are engaging in liberal debate with ungentlemanly opponents, whose social power will evaporate once the “errors” in their arguments are pointed out.

In an important blog post last year,8 Adam Kotsko discussed this liberal leftist compulsion — rife in social media — to point to superficial contradictions in conservative ideology. “‘They believe in small government… until it comes time to control women’s bodies!’ Zing!” The problem is that these kind of sarcastic dismissals confuse argumentative or philosophical incoherence with strategic incoherence. The stated rationales for right-wing positions may not make much add up philosophically, but seen

in terms of strategy, they all make perfect sense. Taken together, they serve to blame the victims, assert that the powerful are powerful for moral reasons, and then claim that the role of government is to endorse and reinforce the morally-discovered power structure rather than futilely try to disrupt it. The arguments might clash on a superficial level, but their effects are perfectly coherent and rational once the goal is granted.

As Kotsko observes, the “stated rationales” are libidinal lures which

function as a kind of weapon against liberals, who jump at the chance to engage and disprove — and will happily waste infinite amounts of time doing so. It’s like a drug for a certain type of ‘reasonable liberal’: they’re showing their broad-mindedness by engaging in dialogue with their ideological enemies, and they’re showing their intellectual superiority!

The implication of all this is not that we should withdraw from the debates the right imposes. Once these debates have been set up, we need to firefight, and Owen Jones did a great job last week. But if the right have engaged our resources in permanent firefight mode, that is already a significant victory for it. Just as we can’t simply withdraw from debates, we can’t just ignore the Mail either. The idea that the Mail will vanish if we simply don’t click on links to its stories is as fallacious as the idea that we can destroy capitalism by being ethical consumers. Ignoring the Mail will only mean that we don’t come to terms with the way it shapes what is taken for social reality. We must engage, just not on its terms. Instead of the “hot” response of outrage (with its immediate nugget of satisfaction, achieved at the cost of a long-term political impotence), we need a cooler stance of appraising the enemy’s weapons and strategies, and thinking about how to counter, overcome and ultimately outwit them. Is a left-wing version of the Mail possible? If not, how could we construct a discursive hub that is as successful for the left as the Mail is for the right? This needs to be part of a broader strategy of devoting our energy and resources to goals and projects that will deliver change in the long-term, breaking us out of the short-termism that has become endemic in the age of Twitter. What we need to overturn is something that has been the case since before Thatcher’s rise to power — the tendency for reactionary political forces to be pro-active, and for progressives to be reactive.





suffering with a smile1

“I usually get up at 5 or 5.15am. Historically, I would start sending emails when I got up. But not everyone is on my time schedule, so I have tried to wait until 7am. Before I email, I work out, read, and use our products. … () I am not a big sleeper and never have been. Life is too exciting to sleep.”

“I quickly scan my emails while my son is taking over my bed and having his milk. Urgent ones I reply to there and then. I flag others to follow up on my commute into work. … () I receive an average of 500 emails a day, so I email throughout the day.”

— “What Time Do CEOs Wake Up?”2

These two accounts — both taken from a Guardian article entitled “What Time Do CEOs Wake Up?” — might have been designed to illustrate the theses of post-autonomist theorists such as Antonio Negri, Paolo Virno and Franco “Bifo” Berardi. Labour is essentially communicative. The boundaries between work and life are permeable. The incessant demands of semiocapitalism stretch the limits of physical organisms. Email means that there is no such thing as a workplace or a working day. You start working the minute you wake up.

These descriptions of a CEO’s day also prove Deleuze and Guattari’s claim in Anti-Oedipus that, in capitalism,

there are no longer even any masters, but only slaves commanding other slaves … () The bourgeois sets the example … (): more utterly enslaved than the lowest of slaves, he is the first servant of the ravenous machine, the beast of the reproduction of capital … () “I too am a slave” — these are the new words spoken by the master.3

At the top of the tower, there is no liberation from work. There is just more work — the only difference is that you might now enjoy it (life is too exciting for sleep). For these CEOs, work is closer to an addiction than something they are forced to do. In a provisional formulation, we might want to posit a new way of construing class antagonism. There are now two classes: those addicted to work, and those forced to work. But this isn’t quite accurate. Whether we are working for our employers (who pay us) or for Mark Zuckerberg (who doesn’t), most of us find ourselves compulsively gripped by the imperatives of communicative capitalism (to check email, to update our statuses). This mode of work makes Sisyphus’s interminable labours seem quaint; at least, Sisyphus was condemned to perform the same task over and over again. Semio-capitalism is more like confronting the mythical hydra: cut off one head and three more grow in its place, the more emails we answer, the more we receive in return.

The good old days of exploitation, where the boss was interested in the worker only to the extent that they produced a commodity which could be sold at a profit, are long gone. Work then meant the annihilation of subjectivity, your reduction to an impersonal machine-part; it was the price that you paid for time away from work. Now, there is no time away from work, and work is not opposed to subjectivity. All time is entrepreneurial time because we are the commodities, so that any time not spent selling ourselves is wasted time. Hence, like the characters in the film Limitless, we’re always seeking ways to increase the time available to us — via intoxicants, cutting back on sleep, working while we commute… The unemployed do not escape this condition — the simulation tasks that they are now induced to perform in order to qualify for benefit are more than preparations for the futility of paid work, they are already work (for what is so much “real” work if not an act of simulation? You don’t just have to work, you have to be seen working, even when there’s no “work” to do…)

Being exploited is no longer enough. The nature of labour now is such that almost anyone, no matter how menial their position, is required to be seen (over)investing in their work. What we are forced into is not merely work, in the old sense of undertaking an activity we don’t want to perform; no, now we are forced to act as if we want to work. Even if we want to work in a burger franchise, we have to prove that, like reality TV contestants, we really want it. The notorious shift towards affective labour in the Global North means that it is no longer possible to just turn up at work and be miserable. Your misery has to be concealed — who wants to listen to a depressed call centre worker, to be served by a sad waiter, or be taught by an unhappy lecturer?

Yet that’s not quite right. The subjugatory libidinal forces that draw enjoyment from the current cult of work don’t want us to entirely conceal our misery. For what enjoyment is there to be had from exploiting a worker who actually delights in their work? In his sequel to Blade Runner, The Edge of Human, K.W. Jeter provides an insight into the libidinal economics of work and suffering. One of the novel’s characters answers the question of why, in Blade Runner’s future world, the Tyrell Corporation bothered developing replicants (androids constructed so that only experts can distinguish them from humans):

Why should the off-world colonists want troublesome, humanlike slaves rather than nice, efficient machines? It’s simple. Machines don’t suffer. They aren’t capable of it. A machine doesn’t know when it’s being raped. There’s no power relationship between you and a machine. … () For the replicant to suffer, to give its owners that whole master-slave energy, it has to have emotions. … () The replicant’s emotions aren’t a design flaw. The Tyrell Corporation put them there. Because that’s what our customers wanted.

The reason that it’s so easy to whip up loathing for “benefit scroungers” is that — in the reactionary fantasy — they have escaped the suffering to which those in work have to submit. This fantasy tells its own story: the hatred for benefits claimants is really about how much people hate their own work. Others should suffer as we do: the slogan of a negative solidarity that cannot imagine any escape from the immiseration of work.

To understand work now, consider the pornographic practice of bukkake. Here, men ejaculate in women’s faces, and the women are required to act as if they enjoy it, to lasciviously lick the semen from their lips as if it is the most delicious honey. What’s being elicited from the women is an act of simulation. The humiliation is not adequate unless they are seen to be performing an enjoyment they don’t actually feel. Paradoxically, however, the subjugation is only complete if there are some traces of resistance. A happy smile, ritualised submission; this is nothing unless signs of misery can also be detected in the eyes.





how to kill a zombie: strategising the end of neoliberalism1

Why has the left made so little progress five years after a major crisis of capitalism discredited neoliberalism? Since 2008, neoliberalism might have been deprived of the feverish forward momentum it once possessed, but it is nowhere near collapsing. Neoliberalism now shambles on as zombie — but as the afficionados of zombie films are well aware, it is sometimes harder to kill a zombie than a living person.

At the conference in York, Milton Friedman’s notorious remark was quoted a number of times:

Only a crisis — actual or perceived — produces real change. When that crisis occurs, the actions that are taken depend on the ideas that are lying around. That, I believe, is our basic function: to develop alternatives to existing policies, to keep them alive and available until the politically impossible becomes the politically inevitable.

The problem is that although the 2008 crisis was caused by neoliberal policies, those selfsame policies remain practically the only ones “lying around”. As a consequence, neoliberalism is still politically inevitable.

It is by no means clear that the public has ever embraced neoliberal doctrines with much enthusiasm — but what people have been persuaded of is the idea that there is no alternative to neoliberalism. The (typically reluctant) acceptance of this state of affairs is the hallmark of capitalist realism. Neoliberalism may not have succeeded in making itself more attractive than other systems, but it has sold itself as the only “realistic” mode of governance. The sense of “realism” here is a hard won political achievement, and neoliberalism has succeeded in imposing a model of reality modeled on practices and assumptions coming out of the business world.

Neoliberalism consolidated the discrediting of state socialism, establishing a vision of history in which it laid claim to the future and consigned the left to obsolescence. It captured the discontent with centralised bureacratic leftism, successfully absorbing and metabolising the desires for freedom and autonomy that had emerged in the wake of the Sixties. But — and this is a crucial point — this isn’t to say that those desires inevitably and necessarily led to the rise of neoliberalism. Rather, we can see the success of neoliberalism as a symptom of the leftist failure to adequately respond to these new desires. As Stuart Hall and others involved in the New Times project of the 1980s prophetically insisted, this failure would prove catastrophic for the left.

Capitalist realism can be described as the belief that there is no alternative to capitalism. However, it is more usually manifest not in grand claims about political economy, but in more banal behaviours and expectations, such as our weary acceptance that pay and conditions will stagnate or deteriorate.

Capitalist realism has been sold us to by managers (many of whom see themselves as left-wing) who tell us that things are different now. The age of the organised working class is over; union power is receding; business now rules, and we must fall into line. The self-surveillance work that workers are now routinely required to perform — all those self-assessments, performance reviews, log books — is, we have been persuaded, a small price to pay for keeping our jobs.

Take the Research Excellence Framework (REF) — a system for assessing the research output of academics in the UK. This massive system of bureaucratic monitoring is widely reviled by those subject to it, but any opposition to it has so far been token. This double situation — in which something is loathed but at the same time complied with — is typical of capitalist realism, and is particularly poignant in the case of academia, one of the supposed strongholds of the left.

Capitalist realism is an expression of class decomposition, and a consequence of the disintegration of class consciousness. Fundamentally, neoliberalism must be seen as a project which aimed to achieve this end. It was not primarily — at least not in practice — dedicated to freeing up the market from state control. Rather, it was about subordinating the state to the power of capital. As David Harvey has tirelessly argued, neoliberalism was a project which aimed to reassert class power.

As the traditional sources of working-class power were defeated or subdued, neoliberal doctrines functioned as weapons in a class war increasingly fought by one side only. Concepts like the “market” and “competition” have functioned not as the real ends of neoliberal policy, but as its guiding myths and ideological alibi. Capital has no interest in either the health of markets, or in competition. As Manuel DeLanda, following Fernand Braudel, has argued, capitalism, with its tendency towards monopoly and oligopoly, can more accurately be defined as anti-market rather than as a system which promotes thriving markets.

David Blacker mordantly observes in his forthcoming book, The Falling Rate of Learning and the Neoliberal Endgame, that the virtues of “competition” are “conveniently to be reserved only for the masses. Competition and risk is for small businesses and other little people like private and public sector employees.” The invocation of competition has functioned as an ideological weapon — its real aim is the destruction of solidarity, and, as such, it has been remarkably successful.

Competition in education (both amongst institutions and amongst individuals) is not something that spontaneously emerges once state regulation is removed — on the contrary, it is something actively produced by new kinds of state control. The REF and the school inspections regime overseen in the UK by OFSTED are both classic examples of this syndrome.

Since there is no automatic way to “marketise” education and other public services and there is no straightforward way of quantifying the “productivity” of workers such as teachers, the imposition of business discipline has meant the installation of colossal bureaucratic machineries. So an ideology which promised to liberate us from state socialist bureaucracy has instead imposed a bureaucracy all of its own.

This only looks like a paradox if we take neoliberalism at its word — but neoliberalism is not classic liberalism. It is not about laissez faire. As Jeremy Gilbert, developing Foucault’s prescient analyses of neoliberalism, has argued, the neoliberal project was always about vigilantly policing a certain model of individualism; workers have to be continually surveilled for fear they might lapse into collectivity.

If we refuse to accept neoliberalism’s rationales — that control systems brought in from business were intended to improve workers’ efficiency — then it becomes clear that the anxiety produced by the REF and other managerialist mechanisms is not some accidental side-effect of these systems — it is their real aim.

And if neoliberalism will not collapse of its own accord, what can be done to hasten its demise?

Reject Strategies That Don’t Work

In a dialogue between Franco “Bifo” Berardi and me published in Frieze,2, Berardi talked of “our present theoretical impotence in the face of the dehumanising process provoked by finance capitalism.” “I can’t deny reality”, Berardi continued,

which seems to me to be this: the last wave of the movement — say 2010 to 2011 — was an attempt to revitalise a massive subjectivity. This attempt failed: we have been unable to stop the financial aggression. The movement has now disappeared, only emerging in the form of fragmentary explosions of despair.

Bifo, one of the activists involved with the so-called autonomist movement in Italy in the 1970s, here identifies the rhythm that has defined anti-capitalist struggle since 2008: exhilarating outbursts of militancy recede as quickly as they erupt, without producing any sustained change.

I hear Bifo’s remarks as a requiem for the “horizontalist” strategies that have dominated anti-capitalism since the Nineties. The problem with these strategies is not their (noble) aims — the abolition of hierarchy, the rejection of authoritarianism — but their efficacy. Hierarchy cannot be abolished by fiat, and a movement which fetishises organisational form over effectiveness concedes ground to the enemy. The dismantling of the many existing forms of stratification will be a long, arduous and attritional process; it isn’t simply a matter of eschewing (official) leaders and adopting “horizontal” forms of organisation.

Neo-anarchist horizontalism has tended to favour strategies of direct action and withdrawal — people need to take action now and for themselves, not wait for compromised elected representatives to act in their stead; at the same time, they should withdraw from institutions that are not contingently, but necessarily corrupt.

The emphasis on direct action, though, conceals a despair about the possibility of indirect action. Yet it is via indirect action that the control of ideological narratives is achieved. Ideology isn’t about what you or I spontaneously believe, but about what we believe that the Other believes — and this belief is still determined to a large extent by the content of mainstream media.

Neo-anarchist doctrine maintains that we should abandon mainstream media and parliament — but our abandoning it has only allowed the neoliberals to extend their power and influence. The neoliberal right might preach the end of the state, but only while ensuring that it controls governments.

Only the horizontalist left believes the rhetoric about the obsolescence of the state. The danger of the neo-anarchist critique is that it essentialises the state, parliamentary democracy and “mainstream media” — but none of these things is forever fixed. They are mutable terrains to be struggled over, and the shape they now assume is itself the effect of previous struggles. It seems, as times, as if the horizontalists want to occupy everything except parliament and the mainstream media. But why not occupy the state and the media too? Neo-anarchism isn’t so much of a challenge to capitalist realism as it is one of its effects. Anarchist fatalism — according to which it is easier to imagine the end of capitalism than a left-wing Labour Party — is the complement of the capitalist realist insistence that there is no alternative to capitalism.

None of this is to say that occupying mainstream media or politics will be enough in themselves. If New Labour taught us anything, it was that holding office is by no means the same thing as winning hegemony. Yet without a parliamentary strategy of some kind, movements will keep foundering and collapsing. The task is to make the links between the extra-parliamentary energies of the movements and the pragmatism of those within existing institutions.

Retrain Ourselves to Adopt a War Mentality

If you want to consider the most telling drawback of horizontalism, though, think about how it looks from the perspective of the enemy. Capital must be delighted by the popularity of horizontalist discourses in the anti-capitalist movement. Would you rather face a carefully co-ordinated enemy, or one that takes decisions via nine-hour “assemblies”?

Which isn’t to say that we should fall back into the consoling fantasy that any kind of return to old-school Leninism is either possible or desirable. The fact that we have been left with a choice between Leninism and anarchism is a measure of current leftist impotence.

It’s crucial to leave behind this sterile binary. The struggle against authoritarianism needn’t entail neo-anarchism, just as effective organisation doesn’t necessarily require a Leninist party. What is required, however, is taking seriously the fact that we are up against an enemy that has no doubt at all that it is in a class war, and which devotes many of its enormous resources training its people to fight it. There’s a reason that MBA students read The Art of War, and if we are to make progress we have to rediscover the desire to win and the confidence that we can.

We must learn to overcome certain habits of anti-Stalinist thinking. The danger is not anymore, nor has it been for some time, excessive dogmatic fervor on our side. Instead, the post-68 left has tended to overvalue the negative capability of remaining in doubt, scepticism and uncertainties — this may be an aesthetic virtue, but it is a political vice. The self-doubt that has been endemic on the left since the Sixties is little in evidence on the right — one reason that the right has been so successful in imposing its programme. Many on the left now quail at the thought of formulating a programme, still less “imposing” one. But we have to give up on the belief that people will spontaneously turn to the left, or that neoliberalism will collapse without our actively dismantling it.

Rethink Solidarity

The old solidarity that neoliberalism decomposed has gone, never to return. But this does not mean that we are consigned to atomised individualism. Our challenge now is to reinvent solidarity. Alex Williams has come up with the suggestive formulation “post-Fordist plasticity” to describe what this new solidarity might look like. As Catherine Malabou has shown, plasticity is not the same as elasticity. Elasticity is equivalent to the flexibility which neoliberalism demands of us, in which we assume a form imposed from outside. But plasticity is something else: it implies both adaptability and resilience, a capacity for modification which also retains a “memory” of previous encounters.

Rethinking solidarity in these terms may help us to give up some tired assumptions. This kind of solidarity doesn’t necessarily entail overarching unity or centralised control. But moving beyond unity needn’t lead us into the flatness of horizontalism, either. Instead of the rigidity of unity — the aspiration for which, ironically, has contributed to the left’s notorious sectarianism — what we need is the coordination of diverse groups, resources and desires. The right have been better postmodernists than us, building successful coalitions out of heterogeneous interest groups without the need for an overall unity. We must learn from them, to start to build a similar patchwork on our side. This is more a logistical problem than a philosophical one.

In addition to the plasticity of organisational form, we need also to pay attention to the plasticity of desire. Freud said that the libidinal drives are “extraordinarily plastic”. If desire is not a fixed biological essence, then there is no natural desire for capitalism. Desire is always composed. Advertisers, branders and PR consultants have always known this, and the struggle against neoliberalism will require that we construct an alternative model of desire that can compete with the one pushed by capital’s libidinal technicians.

What’s certain is that we are now in an ideological wasteland in which neoliberalism is dominant only by default. The terrain is up for grabs, and Friedman’s remark should be our inspiration: it is now our task to develop alternatives to existing policies, to keep them alive and available until the politically impossible becomes the politically inevitable.





getting away with murder1

The Mark Duggan verdict was both shocking and predictable. Shocking, because it is a verdict that so clearly ignores not only evidence but blatant inconsistencies in evidence. Predictable, because we are now accustomed to seeing the Met getting away with murder.

As Stafford Scott’s piece in the Guardian2 today makes clear, the police case explanation for what happened was an obvious fabrication that lacked even minimal coherence. It’s a classic example of kettle logic, in which the police’s obvious cover-up actually undermined the rationale for shooting Duggan. Either Mark Duggan was holding a gun when he died — as officer V53 claimed at the inquest — or he threw the gun away. If the former, how could the gun end up seven metres away from him (and without any trace of his fingerprints or DNA on it)? If the latter, then how could Mark Duggan have been thought to have pose sufficient threat that he had to be shot dead? At best, the operation was a monumental blunder — compounded by a cover-up which was at least as inept. So how do we explain the jury’s perverse decision?

Partly, we have to look to the legal framework itself. As Christian Werthschulte observed in a Facebook comment last night, when we read the official verdict, we see that “the jury is somehow made to ask themselves if they had felt threatened if they’d been in the shoes of the police officer in order to conclude if the killing was lawful or not. Inevitably this will lead to a ‘Oh, I would’ve been scared, too!’ reaction.” This is both absurd and terrifying, given the amount of sub-machine guns that Met officers carry around London. If the question posed to juries in such cases is going to be “might you, an ordinary member of the public, have been scared”, then it’s hard to see what would ever constitute an unlawful killing.

Then we have to look at the broader reality management operation that swings into place in these contingencies. If the plebgate story revealed anything, it was the brazen and slapdash nature of Met fabrications, which they can get away with because they can usually count on the supine support of Tories and the right-wing press. In the Duggan case, we saw the Met’s standard tactic of leading with a totally false story3 which is later repudiated4 but only after the tone has been set. Then there is the demonisation of the victim, which Stafford Scott describes:

immediately after the shooting the police and the Independent Police Complaints Commission began to brief the media with inaccurate and misleading information that ensured that Duggan was demonised, even before his body had turned cold. The headlines declared him a gangster who was on a mission to avenge the killing of his cousin, Kelvin Easton. However, during the inquest no evidence was offered in support of this claim. It was further alleged that he was a large-scale drugs dealer, but yet again not a shred of evidence was provided to substantiate these allegations. But that did not matter, the mud had been slung and it clearly stuck as it was designed to. Even now most people still do not realise that he was only ever convicted for two relatively minor offences — one count of cannabis possession, and one count of receiving stolen goods.

The description of Mark Duggan as a “gangster” then reliably triggers a whole set of racist associations, which we can quickly grasp when we compare the way in which white criminals such as the Krays (“they only killed their own and they loved their muvvas”), or Ronnie Biggs (involved in a violent crime, but treated as a cuddly rogue) are mythologised. We might also pause to note that Raoul Moat was able to kill people over the course of a number of days before “shooting himself”.

All of this then prepares the way, not only for the jury to see Mark Duggan in the worse possible light, but for those hearing of the verdict to agree with the jury’s exculpation of the police marksman. I saw any number of comments last night to the effect of “well, he had a gun, what was he going to do with it?” Again, this is terrifying: apparently, it was OK to kill Mark Duggan because of what he might have done. The era of pre-crime is truly upon us.

Then, of course, there is the massive overload of ambient propaganda in favour of the police. The police don’t themselves have to generate this; it is freely provided by the right-wing media, but also by a popular culture which overwhelmingly depicts the police as either heroic or “ordinary but flawed people, doing a tough job”.

All of this must have produced some sort of cognitive dissonance in the jury. All the evidence pointed to Duggan not being armed when he was shot — as the jury itself conceded. Furthermore, the blatant cover-up with the gun should have fatally undermined the Met’s story. But no (so the “reasoning” must have gone) — the police cannot be guilty, a priori, therefore they are not.

Now the verdict has to be protected, and the next stage of reality management comes into effect. What we’re now seeing at the moment is the trooping out of right-wing politicians and commentators calling on Mark Duggan’s family to “respect the law”. As with the families of the Hillsborough victims, the family will now be smeared as crazed with grief, hysterical, their desire to set right a terrible injustice will be pathologised and attributed to an inability to move on. If the reality management system is allowed to do its work unobstructed, we can expect the truth to dribble out in twenty or thirty years’ time, as it did with Hillsborough, or, more recently, with the Miners’ Strike. By then, the man who pulled the trigger and those who aided and abetted in the cover-up will be either pensioned off or dead. Either way, they will be beyond the reach of any justice.

I write this not as some ACAB-anarchist, but as someone well aware of the mundane realities of much police work, which increasingly involves attempting to manage the disintegration of civil society brought about by neoliberalism. Yet surely it is by now clear that the Met is a systematically corrupt force. It is equally clear that the IPCC is a joke, and that courts cannot be relied upon to deliver the right verdicts.

Systemic problems require systemic solutions. While Mark Duggan’s family must be supported in their quest for justice, this should not allowed to be seen as an isolated incident. Somehow, the whole system — the Met, the media, the judiciary — which produced this perverse verdict needs to be brought to account, and ultimately replaced.

The significance of Hackgate was that it started to bring these systemic complicities — this “dark network comprising private investigators, the criminal underworld, tabloid newspapers, multinational media conglomerates, the police, politicians, the banks, and the bodies supposed to regulate them (who are at best impotent, at worst part of the problem)” — into the open. The reality management system was strained then, but whether it will suffer any serious damage will be partly determined by the results of the ongoing trial of two of Murdoch’s reality managers. It’s might be that, as with Vito and Michael Corleone, there are too many layers of subordinates between Coulson and Brooks and those who committed the actual crimes for a jury to find them guilty this time. But the cracks in the old reality management system are real. It’s an open question as to how long they can keep being smoothed over.





no one is bored, everything is boring1

One of the most intriguing and provocative pieces on politics and culture this year was We Are All Very Anxious by the Institute of Precarious Consciousness (the essay gained a great deal of attention when it was republished on Plan C’s website).2 It argues that the key problematic affect capitalism now faces is anxiety. In an earlier, Fordist era, it was boredom that was the “dominant reactive affect”. Repetitive labour on production lines engendered boredom, which was both the central form of subjugation under Fordism and the source of a new oppositional politics.

It could be argued that the failure of the traditional left is tied up with its inability adequately to engage with this politics of boredom, which wasn’t articulated via trade unions or political parties, but via the cultural politics of the Situationists and the punks. It was the neoliberals, not the organised left, who were best able to absorb and instrumentalise this critique of boredom. Neoliberals quickly moved to associate Fordist factories and the stability and security of social democracy with tedium, predictability and top-down bureaucracy. In place of this, the neoliberals offered excitement and unpredictability — but the downside of these newly fluid conditions is perpetual anxiety. Anxiety is the emotional state that correlates with the (economic, social, existential) precariousness which neoliberal governance has normalised.

The Institute of Precarious Consciousness were right to observe that too much anti-capitalist politics is locked into strategies and perspectives that were formed in an era when the struggle was against boredom. They are also correct both that capitalism has effectively solved the problem of boredom, and that it is crucial that the left finds ways of politicising anxiety. Neoliberal culture — which came to dominance as the anti-psychiatry movement was waning — has individualised depression and anxiety. Or rather, many cases of depression and anxiety are the effects of neoliberalism’s successful tendency to privatise stress, to convert political antagonisms into medical conditions.

At the same time, I believe that the argument about boredom has to be somewhat nuanced. It is certainly true that one could feel almost nostalgic for Boredom 1.0. The dreary void of Sundays, the night hours after television stopped broadcasting, even the endless dragging minutes waiting in queues or for public transport: for anyone who has a smartphone, this empty time has now been effectively eliminated. In the intensive, 24/7 environment of capitalist cyberspace, the brain is no longer allowed any time to idle; instead, it is inundated with a seamless flow of low-level stimulus.

Yet boredom was ambivalent; it wasn’t simply a negative feeling that one simply wanted rid of. For punk, the vacancy of boredom was a challenge, an injunction and an opportunity: if we are bored, then it is for us to produce something that will fill up the space. Yet, it is through this demand for participation that capitalism has neutralised boredom. Now, rather than imposing a pacifying spectacle on us, capitalist corporations go out of their way to invite us to interact, to generate our own content, to join the debate. There is now neither an excuse nor an opportunity to be bored.

But if the contemporary form of capitalism has extirpated boredom, it has not vanquished the boring. On the contrary — you could argue that the boring is ubiquitous. For the most part, we’ve given up any expectation of being surprised by culture — and that goes for “experimental” culture as much as popular culture. Whether it is music that sounds like it could have come out twenty, thirty, forty years ago, Hollywood blockbusters that recycle and reboot concepts, characters and tropes that were exhausted long ago, or the tired gestures of so much contemporary art, the boring is everywhere. It is just that no one is bored — because there is no longer any subject capable of being bored. For boredom is a state of absorption — a state of high absorption, in fact, which is why it is such an oppressive feeling. Boredom consumes our being; we feel we will never escape it. But it is just this capacity for absorption that is now under attack, as a result of the constant dispersal of attention, which is integral to capitalist cyberspace. If boredom is a form of empty absorption, then more positive forms of absorption effectively counter it. But it is these forms of absorption which capitalism cannot deliver. Instead of absorbing us, it distracts from the boring.

Perhaps the feeling most characteristic of our current moment is a mixture of boredom and compulsion. Even though we recognise that they are boring, we nevertheless feel compelled to do yet another Facebook quiz, to read yet another Buzzfeed list, to click on some celebrity gossip about someone we don’t even remotely care about. We endlessly move among the boring, but our nervous systems are so overstimulated that we never have the luxury of feeling bored. No one is bored, everything is boring.





a time for shadows1

Jean Baudrillard’s 1987 text The Ecstasy of Communication reads like an astonishing science-fictional prophecy of our current moment. Writing nearly thirty years ago, Baudrillard invoked an era of “absolute proximity, total instaneity”, of informational schizophrenia. “The schizo”, Baudrillard writes, “is bereft of every scene, open to everything in spite of himself … () It is the end of interiority and intimacy, the overexposure and transparency of the world which traverses him without obstacle. He is now only a pure screen, a switching centre for all the networks of influence”.2 Baudrillard’s heightened rhetoric captures what is now a banal experience — indeed, it might be the very signature of contemporary banality. With the ubiquity of smartphones, the feeling of being overwhelmed by cyberspatial injunctions is now commonplace. It is this strangely prescient anticipation of twentyfirst-century banality that makes reading Baudrillard’s text such an uncanny experience. (It as if Baudrillard was already writing about Twitter. What in the experience of 1980s French telecommunications could give Baudrillard this feeling of transparency, overload, instaneity — this sense of the overwhelming of privacy and the limits of the individual subject, to which social media has now habituated us?)

Baudrillard wrote of a new era of “tactility”. According to Baudrillard, even in the 1980s, the spectacle was already superseded. The spectacle subjugated us to image; the tactile system, however, solicits our participation, enjoins us to join in. Again, this is a strikingly prescient observation of trends that are now dominant — corporations are no longer satisfied with bombarding us with hard sell propaganda, they want us to interact with them, like their Facebook page, comment using hashtags.

Smartphones with touchscreen technology seem to secure the age of tactility. Yet, with smartphones, shouldn’t we rather talk of a touching without tactility? For the smartphone is certainly operated by touch, but it is a touch devoid of any sensuality. When the fingers encounter the glassy surface of the iPhone, everything they touch on the screen feels the same. The fingers are effectively acting as extensions of the eye and the brain — an eye and a brain that have now been radically re-habituated by cyberspace. The fingers become relays in a digital compulsion system, a set of digital triggers. Yet they are inefficient digital triggers, monkey digits that are too fat and lacking in suppleness to properly operate the touchscreen interface. If, as an episode of The Simpsons observed in a sight gag, the iPhone is strikingly reminiscent of the monoliths from 2001: A Space Odyssey, then too often when we are using them, we feel as primitive and as baffled as the apes in Kubrick’s film when faced with the enigmatic opacity of the monolith’s black surface.

Of course, smartphones aren’t really phones at all. The term now favoured by airlines, “handheld electronic devices”, better captures what these machines are. (Increasingly, we are now permitted to use these devices the very moment that the aircraft lands — waiting until we get to the terminal is now deemed too long a wait.) The telephone function of the electronic handheld device is rapidly becoming archaic. As Sherry Turkle maintained in her recent book Alone Together, we have moved beyond the era of talking into a new age of text.3Conversations present anxieties, which are circumvented by SMS and direct messages.

For all that it evades older kinds of anxieties, Baudrillard’s circuit of constant contact generates a whole set of new ones. The pressure of the instantaneous — of what, in their new manifesto, “On the Creative Question — Nine Theses”, Geert Lovink, Sebastian Olma and Ned Rossiter call “frantic entrepreneurship and instant valorisation”4 — inevitably weighs heavy on cultural producers. In an enigmatic but suggestive formulation, Lovink, Olma and Rossiter argue that the urgencies of the immediate need to be replaced by principles of “shadow and time”. “Shadow,” they write,

is an unintended consequence, an event vacuum, which remains invisible for passers by. It does not register on the development maps of the managerial class. Time is needed in order for the substantially different to grow. Maturation, which is creative growth, requires time.

It is imperative that we carve out some spaces beyond the hyper-bright instant. This instant is insomniac, amnesiac; it locks us into a reactive time, which is always full (of outrage and pseudo-novelty). There is no continuous time in which shadows can grow, only a time that is simultaneously seamless (without gaps: there is always “new” content streaming in) and discontinuous (each new compulsion makes us forget what preceded it). The result is a mechanical and unacknowledged repetition. Is it still possible for us to cultivate shadows?





limbo is over1

Tony Blair’s brief appearance in this election campaign, offering tepid support for a tepid Ed Miliband, ought to have been irrelevant. In many ways it was: who needs yesterday’s man, the hawker of an outmoded “modernisation”? Except, like so much of today’s culture, Blairism is obsolete but it has not yet been surpassed.

In Blair’s Castle Grey Skull, it is always 1997. Blair is like some inverted Miss Havisham, frozen not at the moment of his defeat and failure, but just before his moment of greatest success. Be cautious, don’t do anything to jeapordise the project. Blairism was this particular form of false promise, this deferral — if we are careful now, tomorrow we can do more… But tomorrow never arrives, the aim is always to be in government, the price is always the lack of any real power to change the inherited parameters of the possible. This is the formula: government without power, an increasingly unpopular populism.

The illusion of Blairism is that it was an overcoming of the defeats of the 1980s rather than their final consequence. It was a post-traumatic normalisation of catastrophe, not any sort of new dawn. Its legacy is organisational as much as ideological: a Labour Party that napalmed its grassroots (contempt for, and fear of the working class being a signature element of Blair’s rendition of populism) and which now beams down policy and PR from some rarefied Thick Of It Oxford PPE helicarrier circling miles above earth. The project remains getting into government, but without Blair’s showman-messiah charisma to cover over the vacuum beneath this aspiration. Miliband’s awkwardness stems as much from this lack of any vision as from any personal quirks. There is nothing animating the transparently choreographed moves: tack to the right on immigration, a little to the left on taxation, etc. The ambition — to be the slightly lesser evil — is painfully clear to all, and can inspire no one.

All of this is exactly what we expected… But the entry of the SNP, Plaid Cymru and the Greens into the TV debates changed the atmosphere. Suddenly, the picture the reality managers have fed us for the last few years — the three “big” parties each offering a slightly different version of capitalist realism, with Farage and UKIP offering capitalist realism with even more ultra-nationalism — was interrupted, and it was possible to imagine that Britain was “headed, in its nuanced way, leftward”.2 In their different ways, Sturgeon, Wood and Bennett have widened the bandwidth of a media-political scene previously monopolised by the Oxbridge boys’ club. In terms of policy, there isn’t much on offer beyond a reset to social democracy (Plan B as opposed to Austerity’s Plan A3), but capitalist realism is so deeply embedded that it was hard not to feel a frisson when, for instance, Wood defended trade unions and the welfare state. Cameron’s refusal to appear in the BBC debate — and his banning of Clegg from doing so — was meant as a display of magisterial confidence, the only credible Prime Minister rising above the irrelevant squabbling of lowly pretenders — but it ended up further reinforcing the sense of ennui that has attended his performances this campaign. Cameron’s appeal has always depended on his ruling-class ease-in-the-world, but, in his case especially, insouciance always risks shading into an appearance of diffidence and hauteur. As for the Lib Dems — as Craig McVegas observed4 — their absence was barely even acknowledged in the last debate.

Which brings us to the photograph analysed so well by Jonathan Jones in the Guardian.5 But, in addition to everything that Jones picks out, one of the most striking elements in the photograph is the empty centre. A clustering to the left, sulking Farage to the right, Cameron and Clegg — the current “centre” ground — absent. Here is one picture of a post-neoliberal UK: a soft left regaining its confidence on the one hand, a glowering far right on the other, nothing where the capitalist realist “middle” used to be. (Whether Farage will be the figure around which this right will coalesce is now open to serious doubt — with it looking as if he is unlikely to win South Thanet, it might be that his moment as the people’s stockbloker is already over. The ominous question is: if Farage falls, which right-wing demagogue will emerge to take his place?)

The SNP-Labour coalition is far more than we could have hoped a few weeks ago, but it is far from enough. How have we settled for so little? asked an incendiary Russell Brand at the screening of his and Michael Winterbottom’s The Emperor’s New Clothes in Hackney this week. For those hipster priests who wish to keep activism a marginal pursuit, Brand’s fame and wealth automatically exclude him from being taken seriously. Yet fame, charisma and money are resources, and the left badly needs to be associated with glamour instead of moralising asceticism. Watching the film in a cinema alongside so many of those who feature in it — campaigners from the New Era estate, striking careworkers, fire-fighters — was moving, humbling, electrifying. The Free Association6 have been doing some interesting work on why comedy has replaced music as a political force. Now, much more than any contemporary musician, it is Brand who embodies the psychedelic-Promethean principle that any given reality is provisional, plastic, subject to transformation by collective action. I love crowds… Brand functions as a figure of identification who intensifies and links together already existing struggles, and incites us to breach the invisible thresholds that lock us into atomised impotence. We can do what we want… Having passed through what on Tuesday he memorably called the “fame paddock” of contemporary celebrity, Brand is now in a practically unique position. Instead of remaining in the condition of hedonic melancholia typical of those with unlimited access to late capitalism’s pleasure gardens, he’s come out the other side, laughing his trickster laugh, with more resources and an invaluable insiderknowledge of how the media machine constructs what counts as reality. His gleeful performance of de-subordination reminds us of the countercultural lesson: if you gain money and success, there’s only one thing to do with the hand that feeds you, and that’s bite it.

In many ways, The Emperor’s New Clothes tells us what we already know, but this is the point. How can we accept what we know, when what we know is so monstrous, so obscene, so insane? In the Q and A, Brand was asked why people care more about the X Factor than political struggles. But he argued that, rather than decrying the X Factor, its techniques — in particular those which incite emotion — need to be repurposed. “Capitalism has given us the organisms and the machines we can use to produce the revolution”. #accelerate! So the film is an exercise in affective engineering which patiently yet relentlessly dismantles capitalist realist commonsense. One of its most powerful techniques is the use of simple but devastating contrasts: cleaners at RBS earning hundreds of times less than the bosses (same physical space, different worlds); rioters jailed for stealing small items next to bankers who caused social catastrophe not only going unpunished but receiving bonuses. Mark Kermode’s accusation that the film is “simplistic” misses the point. When faced with a media machine that pushes an outrageously simplistic story of its own — it was Labour wot done it — while recounting neoliberal catechisms like Medieval Catholic priests reciting the Mass in Latin, we need an equally simple counter-narrative.

It’s hard not to have some sympathy with Brand’s disdain for voting, which is part of a widespread disillusion with the massively circumscribed conditions of electoral politics under capitalist realism, in which the best that can be hoped for is the least worst. But the problem is that popular disengagement from parliamentary politics suits the right more than us. The right doesn’t need the enthusiasm that Thatcher could call upon from certain portions of the population; it doesn’t need legitimacy. Popular disengagement, ambient despair, the sense that nothing is at stake in elections, is in the interests of capital, now that all the defaults have been set to neoliberal options. Of course, there was no golden age of parliamentary democracy any more than there was a golden age of the Labour Party; there was no point at which progressive achievements were entirely free of compromise and corruption. But the progressive function of parliamentary politics has been to put some limits on tyranny. Capitalist realism has meant the tacit but definite acceptance that corporate tyranny cannot be curbed, resulting in the democratic deficit that Aditya Chakrabortty described so vividly the other day:

democratic leaders have parted ways with their voters — literally. Membership of the main parties has dropped sharply over the past three decades, so that there are now more vegans in Britain than members of the Conservative party. What’s replaced mass democracy is big donors and a professional political elite. It no longer pays for politicians to think hard about fair growth or build more houses, because to do so would antagonise the big corporates or the big media, or deter those middle-class and retired voters who actually do turn out to the polling stations.7

The phobic panic that the prospect of a Labour-SNP coalition is provoking indicates that capital fears any reversal, no matter how modest, of this situation. It has grown used to having everything its own way — but this has led to a certain decadence, an exhaustion of thinking and of strategy. It is surely this exhaustion, as much as any desperation, which accounts for the ludicrous, beyond-satire poking about in Ed Miliband’s anodyne love life, or the scarcely believable attempts to discredit Nicola Sturgeon.8

Sturgeon poses a threat, not merely because of her lawyerly poise in debate, not merely because she has articulated an anti-austerity position, nor even because she makes Scottish independence more likely, but more because she has a mobilised base of support behind her. In Scotland, as in Greece and Spain, new models of political organisation, new “logics of proliferation”9 are emerging and being experimented with. Rather than compulsively repeating the same strategies, rather than dogmatically insisting on the inherent futility of elections, these developments are part of a process of collective learning about how popular movements can be (re)connected with parliamentary politics. The potential power of such strategies is clear. The electoral impasse is not down to some semiotic failure (if only we had the right PR initiative to engage the kids!), but reflects the actual composition of forces in society. Capitalist realism is class war fought by one side only, an organised corporate elite which is very clear about what its own class interests are and what must be done to keep things aligned with those interests. Only a mobilised population can give political parties the power to challenge corporate tyranny. As Keir Milburn says in an important piece10, and, as the situation in Greece is showing, you can’t vote out neoliberalism. But as Keir also argues, “e ()ven at their point of failure Plan B electoral politics can be useful if they can clarify the anti-democratic effects of neoliberalism that work against all forms of collective action.”

In the UK, this could be the most important election since 1979. Even the most sentimental pipe-dreamer couldn’t imagine the Labour Party will be returning to Plan B socialism in the immediate future, still less offering something more modern and radical. Yet it’s perfectly plausible that a Labour-SNP coalition could now achieve what Jeremy Gilbert and I argue that New Labour could have been expected to attempt: “make some efforts to change the strategic situation in the long-term: to rebuild the unions, to re-energise local government, to facilitate the growth of an alternative media sector”.11 For even this to happen, it will be necessary for those in the party who really want to break with capitalist realism — and, believe it or not, there are such people — to seize the initiative. What is the alternative for Labour? Even the lacklustre and affectless brand of politics that the party have served up under Miliband so far won’t be sustainable for much longer. Entropy might be the best fate a Labour Party which can’t grasp the new mood can hope for; the more likely scenario is a PASOK-like disintegration. In any case, there’s no way back to the pre-2008 world, no way back to capitalist realism with a joker-hysterical face. The party needs really to register that Blairites — and the residual Blairite atmosphere in a demoralised and disconnected Labour party — are as out of date now as Blair argued “Old Labour” was in 1997. Now, more than ever, there are no guarantees. The road to renewal has never seemed harder, or longer. Yet, as Margarita Tsomou said in an important intervention at the Monopol aug Morgen event in Vienna last week, limbo is now over. Are we plunging deeper into nihiliberal dystopia — the ultra-rich retreating into compounds, a vast “surplus population” abandoned to fight amongst itself, and subdued by a militarised Hunger Games-style police force? Or is a new popular leftism about to begin the escape from capitalist realism?





communist realism1

Normal capitalist realist service was resumed on Thursday, on the BBC Question Time Leaders Special. With the SNP, Plaid Cymru and the Greens absent, horizons contracted, expectations lowered, we were once again asphyxiating in the Oxbridge-Westminster bubble. This was most obviously signalled by a discursive exclusion: “austerity” was never mentioned, so we were back on the arid terrain of a debate the terms of which were set by England’s austerians in 2010. The question, once more, was: who would cut the deficit quickest?

Miliband further deflated the mood — I think deliberately — by explicitly ruling out a “deal” or a “coalition” with the SNP. Given the right-wing press’s scaremongering, Miliband’s denying that a deal will happen might have been necessary in order to make the conditions for such a deal possible. Any equivocation would surely have been seized upon by the right-wing media, and relentlessly used to stoke up the fears of voters less likely to vote for Labour because of the prospect of a coalition. The audience members imploring Cameron and Miliband to be honest about possible deals were as ingenuous as those who hailed the programme as a triumph of participatory democracy. Neither leader could “be honest” about how the vote is likely to go on Thursday because that very speculation could change what actually happens. Such is the state of our current “democracy”: everything is distorted by media projections, by politicians’ (second) guesses as to how voters may behave in response to those projections, a whole phantom science of feedback.

Baudrillard: “Polls manipulate the undecidable. Do they affect votes? True or false? Do they yield exact photographs of reality, or of mere tendencies, or a refraction of this reality in a hyperspace of simulation whose curvature we do not know? True or false? Undecidable.”2

For most of this campaign, Cameron has given every impression that he’d far rather be tucking into a country supper than demeaning himself hustling on the hustings. Defending the status quo is not as energising as tearing it down, and comfortable Cameron never had the class resentment-jouissance that drove grocer’s daughter Thatcher to battle trade unionists and oldschool Tory grandees alike. For him, it’s a career,3 not a mission. Cameron has never seemed like a man burning with conviction; he comes across more like the captain of some public school cricket team who whose main motivation for winning is to remind uppity comprehensive kids who’s boss. On Thursday, Cameron finally went into bat for his class like he meant it.

He needs to. This election is pivotal. Either the Tories can “finish the job” of looting and pillaging everything working-class struggle built, or they themselves could be on the brink of destruction. The Conservative Party haven’t won an overall majority since 1992. It’s difficult enough keeping this party of opportunists, quislings and crazies together at the best of times; if they fail to win again, will even Boris be able to prevent meltdown? And with the Tories in disarray, the right could finally be forced off the centre ground that they won and radically re-defined under Thatcher.

Pumped Up, Calmed Down

In front of the BBC cameras, Cameron’s performance wasn’t quite as slick as his upper lip, but he discovered a poise that he has seldom mustered in the past few weeks. The problem with Cameron getting pumped up last week is not only that it looked pathetically forced (his claim that he was “pumped up because I am” was a transparent deception as well as a tautology. He was “pumped up” because Tory backers demanded that he at least gave the appearance of caring). The more serious issue is that such displays of simulated passion undermine Cameron’s key appeal, which has to do with projecting casual authority: what David Smail, writing before Cameron came onto the scene, called “t ()he confident slouch of the hands-in-pocket, old Etonian cabinet minister.” Cameron’s accent, his posture, his smirk, convey a consistent message: relax, I’m in control, defer to me. When he strays from this “ease and familiarity”, he risks looking angry and/or uncomfortable, and apparent affability gives way an affronted sense of class superiority, as in the “calm down, dear” incident.

Presenting the Tories as the nasty party has been counterproductive, the fake letter of support from small businesses devolved into yet another Thick of It farce, but Thursday’s flooding of the audience with Tory supporters posing as undecided voters worked. Cameron was back on home territory: the bizarre inverted world of English capitalist realism in which referring to a global banking crisis was desperate reaching for excuses, and austerity was the only possible course of action for any prudent government. (The best thing about New Labour was Alastair Campbell — a skilled operator and a technician, an expert on how to win ground on a hostile media terrain. It’s hard to imagine that, if he were still running things, that Labour would have been ambushed like they were on Thursday.)

A Picture of Discontented New Wealth

Under the questioning of businesswoman Catherine Shuttleworth, Ed started to look like a supply teacher who had earnestly planned an interesting and informative lesson, only to find out that the kids just wanted to humiliate him, whatever he said. The Tory narrative of Labour profligacy was once again established as a self-evident truth that only a fool and/or a brazen liar would contest. This narrative was all the more convincing when it was re-cycled/re-cited by a “concerned businesswoman”, “struggling to survive in a tough climate”. The subsequent exposure of Shuttleworth as a probable Tory plant will not erase the impact of her TV encounter with Miliband, if only because complaining about the audience not only implicitly concedes defeat, it makes Labour look like sore losers.

For the moment, let’s believe Shuttleworth’s story that she isn’t a Tory. (Although note that even the DM whitewashing is carefully worded: Shuttleworth only denies that she’s ever been a member of the Tory party, not that she’s a lifelong Tory voter, which is of course impossible to prove or disprove.) The question then would be why she should be so ready to blame hard times not on the government which has been in power in the last five years, but on the government which was in power when she actually built and grew her business? Miliband’s pitch — Labour is all about supporting small business owners — is part of a strategy that could be fruitful in the long run, since it could break the alliance between small business and corporate capital which has been so central to the installation of capitalist realism. But Shuttleworth’s response to these overtures shows that breaking that alliance will be a long and hard struggle. She immediately started bleating on behalf of Tesco — as if Tesco didn’t enjoy its greatest success under New Labour, and as if its downfall wasn’t a direct consequence of the very corporate tyranny that Miliband was moving to attack?

Reflexive Cringe

While Miliband was correct not to capitulate to nonsense about Labour overspending, it was clear that Labour has left it far too late to challenge the dominant narrative. On the face of it, Labour’s acquiescence in the austerity myth has been inexplicable. Paul Krugman writes of

the limpness of Labour’s response to the austerity push. Britain’s opposition has been amazingly willing to accept claims that budget deficits are the biggest economic issue facing the nation, and has made hardly any effort to challenge the extremely dubious proposition that fiscal policy under Blair and Brown was deeply irresponsible — or even the nonsensical proposition that this supposed fiscal irresponsibility caused the crisis of 2008-2009. Why this weakness? In part it may reflect the fact that the crisis occurred on Labour’s watch; American liberals should count themselves fortunate that Lehman Brothers didn’t fall a year later, with Democrats holding the White House. More broadly, the whole European centre-left seems stuck in a kind of reflexive cringe, unable to stand up for its own ideas.4

You say “reflexive cringe”, I say “reflexive impotence”… Labour’s slowness to respond to the crisis was not merely some failure of judgement or strategy; it was a consequence of how deeply capitalist realism had saturated the party. There was no question of Labour using the crisis to impose its own programme, because, by 2008, it didn’t have much of programme beyond capitalist realism. Everything had been set up for a corporate appeasement, and there were neither the organisational nor the intellectual infrastructure to come up with anything new. Capitalist realism wasn’t something that Labour was waiting out and planning to overcome, one day; it was embedded as an effectively permanent baseline set of conditions — conditions which receded from visibility even as they imposed strict limits on what could be said and thought.

I’m In a Trance, I Don’t Ask Questions

Following Wendy Brown, I argued that capitalist realism can be understood as a kind of dreamwork. In this dreamwork, briefly interrupted in 2008, the banking crisis is some repressed trauma which is known about but never confronted, a Real that the dreamer stays asleep to keep avoiding. Capital is the dreamer here, and, insofar as capitalist realism is sustained, we remain figments in its dream. Yet capital is also our dream, which, Matrix-like, has constructed the virtual reality in which we think we live from our energy, our desires and our fantasies.

You would think that mention of the banking crisis would produce some cognitive dissonance when set against the narrative of Labour profligacy. If there was a global financial crisis, how could Labour also be responsible for the deficit? No doubt, part of the success of the “Labour did it” story is due to the hold of folk politics. A narrative about incompetent politicians maxing out the credit cards is easily digested; it’s far more difficult to assimilate the opaque and abstract mechanics of finance capital. But one of the most valuable insights in Philip Mirowski’s Never Let A Serious Crisis Go To Waste: How Neoliberalism Survived the Financial Meltdown comes from his account of cognitive dissonance itself. Referring to the work of Leon Festinger, the social psychologist who worked extensively on cognitive dissonance, Mirowski reminds us that cognitive dissonance is not a threat to false beliefs. On the contrary, cognitive dissonance is a mechanism by which false beliefs can be maintained when confronted with evidence that directly disproves them. In fact, as Mirowski writes, Festinger’s crucial claim was “that confrontation with contrary evidence may actually augment and sharpen the conviction and enthusiasm of a believer”. Mirowski quotes Festinger:

Suppose an individual believes something with his whole heart… suppose that he is presented with evidence, unequivocal and undeniable evidence, that his belief is wrong; what will happen? The individual will frequently emerge, not only unshaken, but even more convinced of the truth of his beliefs than ever before. Indeed, he may even show a new fervour about convincing and converting people to his view.5

This points to a relationship between desire and belief that has been posited at least since Hume and Spinoza’s critiques of religion: we believe in part because we want to believe. But we also want to believe because the belief has become core to our subjectivity.

If You Get Too Burnt You Can’t Come Back Home

The great mystery of neoliberalism is to what extent its advocates “really” believed it. Was it ever anything more than a ruse to restore ruling-class power and wealth? Of course, the answer to this partly depends on which advocates we are talking about. It’s possible that certain key proselytisers for neoliberalism never believed it, and only opportunistically fixed upon it as a way of destroying the “red bases” of working-class power. With others, it’s more likely that a belief was aided by the desire to believe. This desire was motivated by economic interest, of course, but also by certain libidinal satisfactions: the pleasures of seeing the working class defeated, of seeing the poor and vulnerable stripped of social security. For a certain English petit-bourgeois sensibility, Thatcherism was the equivalent of a riot: a jubilee of destruction, a temporary autonomous zone for a reactionary desire that feeds off suffering and misery.

And as I was standing by the edge

I could see the faces of those led pissing theirselves laughing (and the flames grew)

Their mad eyes buldged their flushed faces said

The weak get crushed as the strong grow stronger6

The funeral pyre will be re-lit if the Tories win on Thursday (Bring some paper and bring some wood/Bring what’s left of all your love for the fire), and after five more years, there won’t be much left… The NHS will have been gutted, sold off by stealth; education will continue to be asset stripped, ripe for yet more corporate plundering… the most vulnerable will be pushed further into destitution, women and children first…

This is why Cameron’s android smoothness, like Boris’s bluster, is so crucial for the Tories. It is a cloaking device, obfuscating the project, keeping the gibbering libido hidden behind a humanoid face and a calming, plummy voice. Imagine if Gove (who’s been pushed back into the attic for trying just too hard to be one of the posh boys — so vulgar, so nouveau) — imagine if Gove, with his defrocked pantomime-dame pout, his lickspittle lips smacking with the class hatred that only a class traitor can feel, imagine if he were leader…

By contrast, Cameron’s strength is that it is hard to work up much class hatred for him. People that wealthy and privileged are like rare beasts: something you hear about but rarely encounter. In fact, I’ve seen more pandas in the flesh than old Etonians. You also get the sense that Cameron has no particular animus towards the poor — it’s rather that the experience of poverty is so remote for him that he simply cannot understand it, except as some theoretical possibility. The poor are pixellated background characters in the blearily cheerful steampunk simulation that Dave projects: everything’s fine so long as you don’t look too closely.

Dismantling Capitalist Realism

But let’s return to Mirowski’s summary of Festinger’s research:

Philosophy of science revels in the ways in which it may be rational to discount contrary evidence, but the social psychology of cognitive dissonance reveals just how elastic the concept of rationality can be in social life. Festinger and his colleagues illustrated these lessons in his first book (1956) by reporting in a neutral manner the vicissitudes of a group of Midwesterners they called “The Seekers,” who developed a belief that they would be rescued by flying saucers on a specific date in 1954, prior to a great flood coming to engulf Lake City (a pseudonym). Festinger documents in great detail the hour-by-hour reactions of the Seekers as the date of their rescue came and passed with no spaceships arriving and no flood welling up to swallow Lake City. At first, the Seekers withdrew from representatives of the press seeking to upbraid them for their failed prophecies, but rapidly reversed their stance, welcoming any and all opportunities to expound and elaborate upon their (revised and expanded) faith. A minority of their group did fall away, but Festinger notes they tended to be lukewarm peripheral members of the group. Predominantly, the Seekers never renounced their challenged doctrines. The ringleaders tended to redouble their proselytising, so long as they were able to maintain interaction with a coterie of fellow covenanters.7

Mirowski makes an analogy with proponents of neoliberal economic doctrine, who — far from abandoning this doctrine after its discrediting in the crisis — held to it even more doggedly. This is what Miliband faced on Thursday. Blank stares of mesmerised true believers seven years after the saucers didn’t arrive. Shuttleworth’s interjection like some Manchurian Candidate trigger, provoking automaton-applause…

This shows how difficult the task of dismantling capitalist realism will be. A whole process of deprogramming, involving new narratives, new libidinal attractors, as well as new ways of sharing knowledge, will have to be undergone. While this is certainly a formidable challenge, it is something that is already underway and which we can intensify quite quickly.

Of particular importance, it seems to me, is a popular demystification of economics and “the economy”. The austerity myth has only seemed credible because of a widespread economic illiteracy — an illiteracy I very much share. Economics functions now much as theology functioned in the Medieval world — as an intricate and elaborate system of concepts, objects and reasoning that is closed to non-initiates. We need something like a Reformation in/and against capitalist economics — the equivalent of the Bible being translated into English. I think this could be done, not by a series of large-scale conferences, televisions, or films — although of course these wouldn’t hurt — but virally. Small groups of people, including at least one individual who is an expert in economics, could get together and talk through some key concepts and principles, major economic events, etc. This could take place in private homes, in universities and colleges, in social clubs… In addition to everything else, this would also serve the function of reviving sociality, of re-building a class consciousness that has been dissipated by the individualising tendencies of neoliberalism and communicative capitalism.

Communist Realism

Back to Thursday, here’s “entrepreneur” Chris. “A ban on zero hours contract would prevent me from running my small business…” Well, would it now? We’ve heard many versions of this plaint over the last few months, from businesses big and small. What this amounts to is saying that, these businesses cannot function without super-exploiting workers, and they cannot function without indirect government subsidies (with benefits supplementing low wages). Hold on a minute: didn’t the capitalist realists make their “hard decisions” to close down nationalised industries on the grounds that they weren’t viable and they were draining too much public money?

We need a new, communist, realism, which says that businesses are only viable if they can pay workers a living wage. This communist realism would reverse the capitalist realist demonisation of those on benefits, and target the real parasites: “entrepreneurs” whose enterprises depend on hyperprecarious labour; landlords living it large off housing benefit; bankers getting bonuses effectively or actually out of public money, etc.

But the concept of communist realism also suggests a particular kind of orientation. This isn’t an eventalism, which will wager all its hopes on a sudden and final transformation. It isn’t a utopianism, which concedes anything “realistic” to the enemy. It is about soberly and pragmatically assessing the resources that are available to us here and now, and thinking about how we can best use and increase those resources. It is about moving — perhaps slowly, but certainly purposively — from where we are now to somewhere very different.





pain now1

A grief without a pang, void, dark, and drear

“Pain now, more pain later” was the headline on the front page of the Guardian on the day my son was born nearly five years ago.2 That year, my wife and I earned fifteen thousand pounds between us. I was working as an hourly paid lecturer in adult education and in a university, as well as doing some freelance writing and copyediting. We were able to survive without living in penury because of the £300 a month in tax credits we received.

This was the way Brownism and Blairism worked: allowing low wages and precarity to proliferate with one hand, mitigating their effects with benefits on the other. By then, like most of the population, I loathed New Labour. Labour had become so capitalist realist that surely it couldn’t be much worse if the Tories got in? I shared the widespread view that elections don’t change much: all that’s on offer are minimally different versions of the same thing (neoliberalism).

It soon became very clear that this was not the case. Cameron and Osborne unleashed capitalist realism 2.0, the most audacious confidence trick in recent political history: make the poor and vulnerable pay for the banking crisis. Use the crisis as a pretext to destroy even more of the welfare state. Sigh their fake sighs, and tell us what “difficult choices” they had to make…

Today, if my wife and I earned what we did in 2010, we would receive only £50 in tax credits a month.

Of course, for me, working like this was something of a bohemian lifestyle choice. If I’d wanted to, I could probably have got better paid work — after all, only a fool would expect to enjoy working for a living. But what of all those stuck in low-paid precarious work forever? The disabled? The longterm sick and the chronically mentally ill, forced back to work?

A stifled, drowsy, unimpassioned grief.

I wasn’t very interested in this election a few weeks ago. To be honest, even though I had been commissioned to write a piece about the TV coverage of the election, I couldn’t muster up the enthusiasm to watch the first debate (I’ll watch it later) until Laura Oldfield Ford, excited by Nicola Sturgeon’s performance, texted me and asked what I thought. I switched on ITV+1, and the process of re-awakening that has occurred in the last few weeks began.

For reasons I will explore more fully in subsequent posts, I have spent the last year in a state of de-activation. I was thrown back into the privatised connectivity of the OedIpod, with its constant stream of low-level anxiety and compulsive micro-enjoyments. I couldn’t write, except in a mechanical way; what I produced seemed stillborn, stilted. My main mood-altering drug of choice, music, didn’t work. I binged on boxsets. I enjoyed time with my wife and son, but there was a fugitive quality to this enjoyment: my fingers always itched to reach for my smartphone. There was always something I should already have done that I hadn’t — the urgencies piling up, like a flashing red light constantly blinking in my peripheral vision, never letting me settle. Most of these urgencies were small things, they didn’t matter too much, but perhaps there would be some long-forgotten urgency that was going to calamitously re-emerge, too late for me to do anything about it? I’ll just check…

Liveable Shit

Which finds no natural outlet, no relief.

The coldly terrifying thing about this state of dejection was that it was not a completely paralysing depression — more a kind of exhausting drudgery. It felt liveable; indeed, it felt like I could — perhaps would — live the rest of my life in it. Perhaps I have expected too much from life. Now I would have to adjust to misery, like everyone else does. Others were much, much worse off than me. It wasn’t like I was to chip ice off the windscreen in the morning. I had been precarious for years — now I was in well-paid secure employment. Why couldn’t I just be happy? OK, so I had to do marketing promotions, complete “quality” paperwork, amend module proposal forms six times — but it was hardly coal mining, was it?

You see, you see: I had become once again the compliant subject of capitalist realism:

…isolated, cut off, surrounded by hostile space, you are suddenly without connections, without stability, with nothing to hold you upright or in place; a dizzying, sickening unreality takes possession of you; you are threatened by a complete loss of identity, a sense of utter fraudulence; you have no right to be here, now, inhabiting this body, dressed in this way; you are a nothing, and “nothing” is quite literally what you feel you are about to become.3

Engines of Dejection

Bifo is right. It wants us to be dejected: not so catatonically depressed that we can’t work, but not so confident and secure that we will refuse to do bullshit jobs. (What is this it that wants us to miserable? Why, the real management of the Overlook Hotel of course. Our misery is like nectar to it…) Capital needs people desperate, scrambling on the edge (watch Tory MPs laugh at starving families!), it needs people scrimping and saving and crossing off lists, it needs people to be grateful for any work, no matter how poorly paid, no matter how insecure, struggle after struggle, year after year…

In the last five years, after the initial euphoria of dissent in 2010 and 2011, an acrid fog of despair has slowly but ineluctably sunk over what Cameron, chillingly, calls “our country”… choking the social energy out of institutions (no time to talk, sorry!)… reducing workers to automata issuing commands to one another… diminishing, at every level, our capacity to care… no time, no time… no money… Don’t know, I’ve got to go mate… looking over our shoulders, fearing the worst… maybe it will be me next… better stay in line… accept the extra workload, I’m afraid that’s how things are now…

Pain now, more pain later…

Misery Is Over (If We Want It)

The last week or so, I have, each day, played with my son for a few hours, been out on long walks, enjoying extended time with my wife, and managed to write thousands of words. Why can’t life always be like this? Why indeed? It’s only been possible because I have decided to suspend all my bureaucratic obligations until after the election. (Back to “proper” work tomorrow: so expect another post in a year or so.) I have managed to do this, not by some heroic act of magical voluntarist will, but because of a lift in mood that is not just personal. Scotland, Syriza, Podemos… It’s taken a long while for the significance of these developments to filter through to me… but talking to comrades… attending to what Plan C are up to… feeling the electricity that Russell Brand has generated… All of this has gradually returned to consciousness during this election campaign. I don’t think I’m the only one. But have we awoken too late to stop the Tories? Has their smog of dejection de-activated enough people — people who were hardly likely to have been reactivated by Labour’s campaign?

Shy Effects

The two most obvious parallels for this election would seem to be 1974 — a weak Labour government, propped up by smaller parties, or, ominously, 1992, with Labour crushingly defeated by John Major’s Tories after they were expected to win. Shaun Lawson makes a strong and convincing case for why today might turn out to be a re-run of 1992. Much of this is to do with the unreliability of polls. Because of the so-called “shy Tory” phenomenon — voters not admitting to pollsters that they would vote Conservative — the polls were spectacularly wrong in 1992. Major didn’t only win, the Tories ended up with the largest amount of votes ever cast for a political party in Britain. Lawson argues that, despite polling being adjusted to factor in the shy Tory effect, current polling may still be inaccurate (because, for instance, it tends to be internet-based, which biases things towards a younger demographic).

I’m not sure how convinced I am by the parallels with 92, however, for two reasons:

1. Hyperstitional effects

As Baudrillard argued, we can’t treat opinion polls as neutral positivist descriptions since they might well affect the very thing they are claiming to predict. It seems likely that this might have happened in 92.

The atmosphere leading up to the 92 election was very different to that preceding the current contest. There was the disastrous Sheffield Rally. Kinnock’s triumphalist shout of “We’re alright!”, still excruciatingly embarrassing to remember nearly twenty five years on, not only destroyed the “statesmanlike persona” he had confected, it gave the impression of a manic and jubilatory over-confidence. The premature celebration came off as unseemly, desperate — as if Kinnock himself, never mind the electorate, couldn’t quite believe that he would be Prime Minister. It also gave Murdoch’s press something to really stoke the fears of reluctant Tories with, especially when the polls were suggesting that Labour would win: look, they think they’ve won! If you’re thinking of staying at home, don’t — every vote is needed!

It isn’t really like that this time. Polls are predicting a hung parliament, not a Labour victory — there isn’t the same resource of fear to feed off. Victory for Labour is uncertain, not an imminent possibility that needs to be desperately averted. Furthermore, while the Tories have certainly tried to scaremonger, a Labour government now is not the terrifying prospect that it could be made to seem in 92. After Blairism, Labour is no longer the Other to neoliberal commonsense that it could be presented as then.

As I said in the last post, Miliband has kept his campaign emotionally subdued — no extravagant promises (“I want to underpromise and overdeliver”); no messianic fervour (this by contrast with Blair as much as Kinnock). It’s true, Miliband doesn’t seem to have Prime Minesterial gravitas, but, then again, neither did John Major, surely the least likely Prime Minister ever.

2. We’re in New Times

In 1992, we were still in the high pomp of capitalist realism. The crash had not yet happened. There was still something on offer to those who wanted to vote in their own interests and let everyone else go hang.

The Tories have nothing very much to bribe most of their supporters with this time. Without the false balm of the “Big Society”, they only have a negative message — it will be worse under Labour — and a muted promise: pain now, a little less pain later. Is this enough to motivate the wavering?

Neoliberalism is finished as a project, even if it lurches on, thrashing around like a decorticated terminator. We’re finally groping our way, blinking, out of capitalist realism. The psychic blockade that prevented us from thinking and acting is lifting. This has only registered in this campaign in some minor way with the SNP, Plaid Cymru and the Greens (the multiparty nature of British politics now is of course another way in which we are in new times by comparison with 74 and 92). If Labour manages to form a government, we will be celebrating a Tory defeat far more than we will be hailing a Labour victory.

But nothing is certain at the moment. I don’t think there will be much certainty tomorrow either. My feeling is that things will be very volatile over the next few weeks. One thing is for sure: we need to be prepared to mobilise if the Tories attempt a coup. And they surely will…





abandon hope (summer is coming)1

So it was to be a re-run of 1992, after all. It seems that even elections are subject to retromania, now. Except, this time, it is 1992 without jungle. It’s Ed Sheeran and Rudimental rather than Rufige Kru. Always ignore the polls, wrote Jeremy Gilbert late on election night:

You get a better sense of what’s going on in the electorate by sniffing the wind, sensing the affective shifts, the molecular currents, the alterations in the structures of feeling. Listen to the music, watch the TV, go to the the pubs and ride the tube. Cultural Studies trumps psephology every time.2

Contemporary English popular culture, with its superannuated PoMo laddishness, its smirking blokishness (anyone fancy a pint with Nigel?), its poverty porn, its craven cult of big business, has become like some gigantic Poundbury Village simulation, in which nothing new happens, forever… while ubiquitous “Keep Calm” messages, ostensibly quirky-ironic, actually function as They Live commands, containing the panic and the desperation…

England is a country in which every last space where conviviality might flourish has been colonised by a commercial imperative… supermarket check-out operatives replaced by crap robots… unexpected item in bagging area… every surface plastered with corporate graffiti and haranguing hashtags… no trick missed to screw every last penny out of people… exorbitant parking charges in NHS hospitals (exact amount only, no change given), all the profits going to private providers…

Everything seen through a downer haze… “Mostly you self-medicate”… comfort eating and bitter drinking… What’s your poison?

The suburbs are hallucinating, England is hallucinating. Monster Ripper and Smirnoff, Brandy Boost, oversized glasses of chardonnay at Weterspoons monday club, valium scored for a few quid in the pub, the stink of weed drifting from portakabins, red eyes and yellow bibs.. The pharmaceuticals industry is one of UK Plc’s biggest success stories (along with arms dealing and loans companies) as prescriptions for anti-depressants are kept on repeat.3

Time for one more, Nigel?

Time, gentlemen, please…

There is no time… Time is on your side (yes it is)…

In any case, Shaun Lawson is to be congratulated — if that is the word — for what turned out to be an astonishingly accurate prediction of how the election would go.4 My attempts to refute the parallels with 92 in my last post were as much wishful thinking as anything else. I suppose at some level I knew after the BBC Leaders Debate how things would go — which is why I found watching it so dejecting. (Another rhyme with the past: Ed’s stumble at the end of his interrogation by the petit-bourgeoisie was a minor echo of Kinnock’s tumbling into the sea in 1983.)

Don’t Fear…

It seems that the very thing which gave us hope — the possibility of vacillating Labour being pulled to the left by an alliance with the SNP — might have been what motivated Tory voters to come out in such numbers in England. (Another echo of 92: fear as a hyperstitional force.) The truth is what many of us have long suspected: Labour lost this election five years ago, by failing to challenge the Tories’ narrative. Yet this failure wasn’t about the wrong leader, PR strategy or even policies; it is ultimately rooted in Labour’s disconnection from any wider movement, and this is in turn rooted in the wider emergence of capitalist realism. Blairism may have won Labour three elections, but the unfolding of its logic could well lead to the destruction, in the not so far distant future, of the party. As Paul Mason acidly summarises, “Labour no longer knows what it is for, nor how to win power”.5 With Blairism, Labour knew how to win power, but in acquiring this knowledge, it forgot what it was for.

That existential quandary is bitterly ironic given that there is a large proportion of the population in England — I still believe it is the majority — which feels it has no party which represents it. I maintain that the shift to UKIP is ultimately much more to do with this sense of disenfranchisement and despair than with any intrinsic tendency towards racism or even nationalism in its supporters. Everyone has chauvinistic potentials of one kind or another which can be activated by particular sets of forces. Ultranationalism is a symptom of the failure of class politics; or, class politics emerges through the ultra-nationalist lens in a distorted and displaced way.

As Paul Mason also points out, a return to Blairism will certainly not win back those Labour supporters who turned to UKIP. In England, as in Scotland, it was Blairism’s taking for granted and abandonment of its working-class base that produced the sense of betrayal which led to so many former Labour supporters losing patience with the party on Thursday. In Scotland, the response to betrayal took a progressive form; in England, it assumed a reactionary mode. Partly, this is because there was no progressive outlet available in England. Working-class English voters alienated from Labour’s Oxbridge elite were left a choice between a UKIP that deliberately talked up its appeal to working families, and an array of small left-wing parties to whose message they were not exposed and which had no chance of being elected. UKIP were also practically forced on them to by a political media so decadent, so boring, that it counts Nigel Farage as a charismatic flash of colour. Hence what Tim Burrows calls “the curiously mediated entity of Farage, a man whose direct manner, coloured tweed and pints of ale seem made for meme-politics. UKIP are more popular on Facebook than Labour and the Liberal Democrats put together.”6

Don’t Despair…

It would be easy to fall into despair about England after Thursday; it would be easy to conclude that the country is full of selfish, mean-spirited and stupid individuals. Yet we have to remember that most people’s engagement with politics is quite minimal; thinking in political terms, framing everyday life in terms of political categories, is now a minority pursuit. This is not a moral or intellectual failing on the part of the electorate: it is a consequence of a neoliberalism which has largely succeeded in its aim of disabling the mechanisms of mass democracy. Overworked and told they need to work harder, busy, but still feeling that they can’t get everything done, many are too drained to care. (Too knackered to think, just give me time to come round…) How many Tory voters are committed Conservatives, really? Mostly, they are jaded and detached, maybe voting out of fear as much as self-interest (and self-interest is often experienced as fear).

Capitalist realism is not about people positively identifying with neoliberalism; it is about the naturalisation and therefore the depoliticisation of the neoliberal worldview. The Tories’ pitch is in tune with this ambient neoliberalisation, with its apparently commonsensical emphasis on choice, opportunity and the dignity of labour, and its emotional appeal to negative solidarity. To break out of this, you need a repoliticisation, and this requires a popular mobilisation, just as we saw with the SNP.

The Tory success depended upon a popular de-activation (the days of Thatcher’s rallies are long gone). There was no enthusiasm for either of the two leading parties. The only party that could call on massive popular enthusiasm in the UK was the SNP. That popular enthusiasm — an enthusiasm that capitalist realism is set up to prevent emerging — is the rushing in of something that, for a long time, there hasn’t seemed to be any glimmer of in England: the future.

Don’t Be Depressed…

“What hope for a country where people will camp out for three days to glimpse the Royal Couple? England is like some stricken beast too stupid to know it is dead. Ingloriously foundering in its own waste products, the backlash and bad karma of empire.”

— William Burroughs, The Place of Dead Roads7

So we shouldn’t take the Tories’ victory as a sign that we are totally out of sync with the majority of the population in England. As Jeremy remarked to me on Thursday, it is not as if the equivalent of Syriza or Podemos had lost. (Although that was part of what was so devastating — our expectations were low, but reality contrived to go even lower.) Given the serious weakness of Labour’s offer, given the ferocity of the attack on Labour from the right-wing media machine in the UK, given the failure of supposedly neutral popular media such as the BBC to offer the public an adequate account of the banking crisis and its aftermath, it is actually surprising that the Tories’ victory was not even more comprehensive. Those who voted Tory aren’t necessarily indifferent to the suffering of the poor, or to the plight of the vulnerable — most merely accept (why wouldn’t they) the capitalist realist story about there being “no money left” and the need for “difficult choices”. No doubt, their acceptance of this is somewhat self-serving; no doubt, it depends on keeping those who suffer out of sight or in their peripheral vision.

But it is also a fundamentally depressing and depressive outlook. There is a connection between capitalist realism and depressive realism. The idea that life is essentially drudgery (and that therefore no one should get a free ride) is a depressive conception of fairness (if I have to be miserable, so should everyone else), which has a particular traction in a burnt-out post-Protestant culture like England’s… (England is the oldest capitalist country, don’t forget…)

All Cameron offered was more of this depression: a vision of a man chipping ice off his windscreen and going to a job he hates, forever. Yet Labour not only failed to offer a narrative about how the economy had gone wrong, it also failed to offer any positive vision of what society would look like if it had its way. I’m convinced that even the most minimal sense of this might have been enough to have inspired people to reject the Tories. Yet the fact that Labour couldn’t offer it was not some mistake (a few more focus groups and meetings with advertising people, and they’d have been there!). It was one more symptom of the way in which the party has been completely colonised by capitalist realism.

The Tories quickly abandoned the “Big Society” after the 2010 campaign, but the concept did actually point to what neoliberal culture has corroded: the space between “individuals and their families” and the state. In addition to its clunky and uncommunicative name — it was a kind of anti-meme — the problem with the “Big Society” was that, in the Tories’ hands, it was a transparent ruse to dismantle the welfare state. To resocialise a culture that has been individualised to the extent that England has demands massive resources — it requires time and energy, the very things that capital (especially the contemporary neoliberal, English version of capital) strips us of most thoroughly.

Real wealth is the collective capacity to produce, care and enjoy. This is Red Plenty. We, and they, have had it wrong for a while: it is not that we are anti-capitalist, it is that capitalism, with all its visored cops, its teargas, all the theological niceties of its economics, is set up to block Red Plenty. The attack on capital has to be fundamentally based on the simple insight that, far from being about “wealth creation”, capital necessarily and always blocks our access to this common wealth. Everything for everyone. All of us first.

Labour has allowed election after election to be fought not on the Red terrain of resocialisation, but on the Blue territory of identitarian community, with its border guards (we’ll have as many as you!) and barbed wire fences (they will be as high as yours!). The genius of the progressive forces which have seized the SNP, meanwhile, was to have moved from the Blue of identitarian community — and the nationalism of colonised peoples is of course very different to the nationalism of the colonisers — to the Red of internationalist cosmopolitan conviviality.

Red belonging offers something different to traditional forms of belonging (faith, flag, family — so many corrupted forms of the commons, as Hardt and Negri have it). Jodi Dean has movingly described how the Communist Party in the US

gave some Americans the feeling that the world was of one piece, their work meaningful as the work of a class, their struggles significant as part of a global struggle to liberate collective work from those claiming it for their own private profit. For desperately poor and barely literate immigrants, communism is a source of knowledge and power — the knowledge of how the world works and the power to change it.8

The sense of belonging here could not be reduced to the chauvinistic pleasures that come from being an insider in any group whatsoever; it was a special sense of involvement that promised to transfigure all aspects of everyday life in a way that, previously, only religion had promised to, so that even the dreariest task could be imbued with high significance. “Even those engaged in the boring, repetitive work of distributing leaflets or trying to recruit new members as the official line changed, or chafing against the smugness of higher ups, experience their life in the party as intensely meaningful.”

As opposed to the essentially spatial imaginary of Blue belonging — which posits a bounded area, with those inside hostile and suspicious towards those who are excluded — Red belonging is temporal and dynamic. It is about belonging to a movement: a movement that abolishes the present state of things, a movement that offers unconditional care without community (it doesn’t matter where you come from or who you are, we will care for you anyway).

But Don’t Hope Either…

“There’s no need to fear or hope, but only to look for new weapons,” Deleuze writes in “Postscript on the Societies of Control”.9 He was no doubt thinking of Spinoza’s account of hope and fear in the Ethics. “There is no hope unmingled with fear, and no fear unmingled with hope”, Spinoza claimed. He defines hope and fear as follows:

Hope is a joy not constant, arising from the idea of something future or past about the issue of which we sometimes doubt.

Fear is a sorrow not constant, arising from the idea of something future or past about the issue of which we sometimes doubt.10

Hope and fear are essentially interchangeable; they are passive affects, which arise from our incapacity to actually act. Like all superstitions, hope is something we call upon when we have nothing else. This is why Obama’s “politics of hope” ended up so deflating — not only because, inevitably, the Obama administration quickly became mired in capitalist realism, but also because the condition of hope is passivity. The Obama administration didn’t want to activate the population (except at election time).

We don’t need hope; what we need is confidence and the capacity to act. “Confidence”, Spinoza argues, “is a joy arising from the idea of a past or future object from which cause for doubting is removed”. Yet it is very difficult, even at the best of times, for subordinated groups to have confidence, because for them/us there are few if any “future objects from which cause for doubting is removed.”11

“Class disadvantage is a form of injury inflicted on the person at birth,” David Smail explains, “The confident slouch of the hands-in-pocket, old Etonian cabinet minister speaks not so much as a current possession of power (on some measures the union boss might possess as much) as of a confidence which was sucked in with his mother’s milk.”12 (Even if the milk he fed on was unlikely to have come from his mother). The welfare state was supposed to be a structure which removed some of this doubt, while the imposition of precarity is a political project designed to remove the confidence that the working class had attained after years of struggle. (See Jennifer M. Silva’s heartbreaking Coming Up Short: Working-Class Adulthood in an Age of Uncertainty — a book to which I shall certainly return in future posts — for an account of the devastating impact of precarity on the emotional lives of young working-class men and women in the US.)

Whereas hope and fear are superstitious (although they may have some hyperstitional effects), confidence is essentially hyperstitional: it immediately increases the capacity to act, the capacity to act increases confidence, and so on — a self-fulfilling prophecy, a virtuous spiral.

So how are we to rebuild our confidence? While the conditions are difficult — and in England, they are about to get much more difficult — we can still act, and act imminently and immanently. How?

Socialisation Beyond Social Media

The answer of course is that many groups are already doing what is necessary. But these processes will become more powerful when they are logistically coordinated (which is not to say “unified” — unity is a strategic weakness, not a strength) and bound together by stronger common narratives and fictions. Jason Read’s essay “The Order and Connection of Ideology Is the Same as the Order and Connection of Exploitation: Or, Towards a Bestiary of the Capitalist Imagination”13 explains why narrativisation is so important. In his account of two neo-Spinozist thinkers, Frédéric Lordon and Yves Citton, Read reminds us that

our desire, our loves and hates, are already shaped by narratives, by scripts inherited through television and books. We enter into a world already scripted, and, as Spinoza argues in his definition of the first kind of knowledge, our life is defined as much by signs and images as things experienced.

This means

that the scenarios that we imagine, the stories and narratives that we consume, inform our understanding of reality, not in the sense that we confuse fiction with reality, but that the basic relations that underlie our fictions shape our understanding of reality. It is not that we confuse fiction with reality, believing everything that we see, but that the fundamental elements of every narrative, events, actions, and transformations, become the very way that we make sense of reality. Fiction exists in a permanent relation of metalepsis with reality, as figures and relations from one constantly inform the other.

This is why the intensification and proliferation of the capitalist technologies of reality management and libidinal engineering in the 1980s was not merely some happy coincidence for neoliberalism; neoliberalism’s success was inconceivable without these technologies. It is also the reason that direct action, while of course crucial, will never be sufficient: we also need to act indirectly, by generating new narratives, figures and conceptual frames.

By first of all imposing a particular set of narratives, figures and frames which it then naturalised, capitalist realism hobbled what Jason Read identifies as the “particular power of humanity (and the linchpin of our emancipation)”: “our faculty to reorder differently the images, the thoughts, the affects, the desires and the beliefs that are associated in our mind, the phrases that come out of our mouths, and the movements that emanate from our bodies.” Cultural Studies was also based on this account of the capacity for reordering (which it derived partly from Spinoza, via Althusser). The reordering of images thoughts, affects, desires, beliefs and languages plainly cannot be achieved by “politics” alone — it is a matter for culture, in the widest sense.

Seen from this point of view, the locking of popular culture into repetition that I describe in Ghosts Of My Life14 — and which Simon Reynolds also describes in Retromania15 — is therefore a very serious problem. Popular culture’s incapacity to produce innovation is a persistent ambient signal that nothing can ever change. Sometimes, it can seem fiendishly difficult to account for what has happened to popular culture, but the explanation for its sterility and stasis is ultimately quite simple. Innovation in popular culture has overwhelmingly come from the working class. Neoliberalism has been a systematic and sustained attack on working-class life — the results are now all around us.

Furthermore, the incursion of capitalist cyberspace into every area of life and the psyche has intensified the processes of de-socialisation. This is not to say that there are no progressive potentials in the web, but these have almost certainly been overrated, while the impact of cyberspace in de-socialising culture and subjectivity has been massively underestimated. Here I merely rehearse Bifo’s account of semio-capitalism and Jodi Dean’s critique of communicative capitalism, but it is important to operationalise this critique.

Blogs and social media have allowed us to talk to ourselves (but not to reach out beyond the left bubbles); they have also generated pathological behaviours and forms of subjectivity which not only generate misery and anger — they waste time and energy, our most crucial resources. Email and handhelds, meanwhile, have produced new forms of isolation and loneliness: the fact that we can receive communications from work anywhere and anytime means we are exposed to work’s order-words when we are alone, without the possibility of support from fellow workers.

In sum, the obsession with the web, its monopolisation of any idea of the new, has served capitalist realism rather than undermined it. Which does not mean, naturally, that we should abandon the web, only that we should find out how to develop a more instrumental relationship with it. Put simply, we should use it — as a means of dissemination, communication and distribution — but not live inside it. The problem is that this goes against the tendencies of handhelds. We all recognise the by now clichéd image of a train carriage full of people pecking at their tiny screens, but have we really registered how miserable this really is, and how much it suits capital for these pockets of socialisation to be closed down?

Knowing Someone in this Life Feels as Desperate as Me

Some folk in Plan C have been talking about consciousness-raising, and for many reasons, I believe that it is a crucially important to revive and proliferate this practice (or range of practices) now. Consciousness-raising is partly about the discovery and production of subjugated knowledges, but it is also about the immediate production of socialisation, of forms of subjectivity antithetical to the always/on-always lonely mode of contemporary capitalist individuality.

Consciousness-raising opens up the possibility of living, not merely theorising about, a collective perspective. It can give us the resources to behave, think and act differently at work (if it makes any sense to talk about being “at” work anymore), where capitalist realism has become second nature. The roots of any successful struggle will come from people sharing their feelings, especially their feelings of misery and desperation, and together attributing the sources of these feelings to impersonal structures, albeit impersonal structures mediated by particular figures to which we must attach populist loathing.

In the harsh conditions of cyberspatialised capitalism — conditions that, as Jennifer M. Silva demonstrates, have produced a “hardening” of the self, especially in the young — consciousness-raising can produce a new compassion, for others and for ourselves. Neurotic-Oedipalising capitalism responsibilises, harshly blaming us, while — in its therapeutic mode — telling us that we have the power as individuals to change anything and everything: if we’re unhappy, it’s up to us to fix it. Consciousness-raising, meanwhile, is about positive depersonalisation: it’s not your fault, it’s capitalism. No individuals can change anything, not even themselves; but collective activation is already, immanently, overcoming individualised immiseration.

So I present below a number of strategies, practices and orientations, starting from the most immediate (something groups can do right now) and moving towards the more remotes. The list is of course not exhaustive; and I can’t claim credit for coming up with any of the strategies myself. The point is to share them, add to them, elaborate them.

The chief obstruction to all of these steps is what, in a trenchant and clear-eyed analysis, Ewa Jasiewicz calls “time poverty”:16

Our time is under attack. Work will be intensified, worse paid, and more casualised — if we don’t have it, we’ll be working to have it; mandatory and supervised job searches and workfare will see people forced to spend their time locked into coerced, computerised distraction. A real, diverse, working class self-representative movement needs to include people facing and living these experiences, but how will that happen when we’re too tied up working?

Access to time and our own labour is key and will determine participation and the ability to organise. If we can’t have our own time to organise, we can’t organise, we can’t meet each other, we cannot find each other. Work and the benefits regime — which is work under different conditions and profit margins — are key sites of struggle. Solidarity will need to step up if we are to win workplace disputes and strikes, refusals of workfare and support for people getting sanctioned, so that people have more control over their time and labour.

All our commons are under attack. The condition of time poverty and its roots — intensification of labour, welfare repression, criminalisation and incarceration — have to be recognised as major obstacles to movement, diversity and power. These obstacles need to be tackled if we want to overcome the ideology of wage labour as a determinant of human value on a popular level.

The problem is that, in order to struggle against time poverty, the main resource we require is time — a nasty vicious circle that capital, with its malevolent genius, now has… This problem is absolutely immanent — writing this and the other posts I have completed this week has meant that I have fallen enormously behind on my work, which is storing up stress for the next week or so.

The first thing we must do in response to all this is to put into practice what I outlined above: try not to blame ourselves. #Itsnotyourfault We must try to do everything we can to politicise time poverty rather than accept blame as individuals for failing to complete our work on time. The reason we feel overwhelmed is that we are overwhelmed — it isn’t an individual failing of ours; it isn’t because we haven’t “managed our time” properly. However, we can use the scarce resources we already have more effectively if we work together to codify practices of collective re-habituation (setting new rules for our engagement with social media and capitalist cyberspace in general for example).

Anyway, here goes:

1. Talk to fellow workers about how we feel. This will re-introduce care and affection into spaces where we are supposed to be competitive and isolated. It will also start to break down the difference between (paid) work and social reproduction on which capitalism depends.

2. Talk to opponents Most people who vote Tory and UKIP are not monsters, much as we might like to think they are. It’s important that we understand why they voted as they did. Also, they may not have been exposed to an alternative view. Remember that people are more likely to be persuaded if defensive character armour is not triggered.

3. Create knowledge exchange labs. This follows from what I argued a few days ago. Lack of knowledge about economics seems to me an especially pressing problem to address, but we could also do with more of us knowing about law, I suspect.

4. Create social spaces. Create times and spaces specifically dedicated to attending to one another: not (yet more) conferences, but sessions where people can share their feelings and ideas. I would suggest restricting use of handhelds in these spaces: not everything has to be live tweeted or archived! Those with access to educational or art spaces could open these up for this purpose.

5. Use social media pro-actively, not reactively. Use social media to publicise, to spread memes, and to constitute a counter-media. Social media can provide emotional support during miserable events like Thursday. But we should try to use social media as resource rather than living inside it at all times. Facebook can be useful for discussions and trying out new ideas, but attempting to debate on Twitter is absurd and makes us feel more stressed. (He says, thinking of the time when, sitting on a National Express coach, perched over his handheld, he tried to intervene in an intricate discussion about Spinoza’s philosophy — all conducted in 140 characters.)

6. Generate new figures of loathing in our propaganda. Again, this follows up from what I argued in the “Communist Realism” post.17 Capitalist realism was established by constituting the figure of the lazy, feckless scrounger as a populist scapegoat. We must float a new figure of the parasite: landlords milking the state through housing benefit, “entrepreneurs” exploring cheap labour, etc.

7. Engage in forms of activism aimed at logistical disruption. Capital has to be seriously inconvenienced and to fear before it yields any territory or resources. It can just wait out most protests, but it will take notice when its logistical operations are threatened. We must be prepared for them cutting up very rough once we start doing this — using anti-terrorist legislation to justify practically any form of repression. They won’t play fair, but it’s not a game of cricket — they know it’s class war, and we should never forget it either.

8. Develop Hub struggles Some struggles will be more strategically and symbolically significant than others — for instance, the Miners’ Strike was a hub struggle for capitalist realism. We might not be able to identify in advance what these struggles are, but we must be ready to swarm in and intensify them when they do occur.

Summer is Coming

The Lannisters won on Thursday, but their gold has already run out, and summer is coming. What we saw in the debates dominated by Nicola Sturgeon was not a mirage — it is a rising tide, an international movement, a movement of history, which has not yet reached an England sandbagged in misery and mediocrity. Comrades, I hope (ha!) for the sake of your mental health and your blood pressures that you didn’t see the right-wing tabloids over the weekend (tw for class hatred): middle England crowing over its “humiliation” of “Red” Ed. Well if they think Ed was Red, wait until they see the coming Red Swarm. Outer England has been sedated, but it is waking from its long slumber, carrying new weapons…





for now, our desire is nameless1

“‘In our day’, Nikita Khrushchev told a crowd in the Lenin Stadium of Moscow on 28 September 1959, ‘the dreams mankind cherished for ages, dreams expressed in fairy tales which seemed sheer fantasy, are being translated into reality by man’s own hands’.”

— Francis Spufford, Red Plenty2

This quotation from Francis Spufford’s extraordinary Red Plenty reminds us that when communism was defeated, it wasn’t just a particular ideology that disappeared. The demise of communism was also the disappearance of modernism’s Promethean dream of a total transformation of human society. Michael Hardt has argued that “the positive content of communism, which corresponds to the abolition of private property, is the autonomous production of humanity — a new seeing, a new hearing, a new thinking, a new loving.”3

The arrival of what I have called capitalist realism — the widespread acceptance that there is no alternative to capitalism — therefore meant the end of these new productive, perceptual, cognitive and libidinal possibilities. It meant that we would be reduced to the same old seeing, hearing, thinking, loving… forever. Fredric Jameson long ago argued that postmodernism was the cultural logic of late capitalism, and the features that Jameson claimed were characteristic of the postmodern — pastiche, the collapse of historicity — are now ubiquitous. The only future that capital can reliably deliver is technological — we count historical time not in cultural shifts, but in technological upgrades, watching the same old things on higher definition screens.

The Reality of Class Continues

The attitude of realism that dominant capitalism requires is essentially depressive. The management of this collective depression goes through a series of thresholds. First of all, we come to expect very little: nothing will ever happen again. Then we think that maybe the things that once happened weren’t actually so great. Finally, we accept that nothing has ever happened, nor could ever happen. The more that depression is normalised, the harder it is to even identify it. Radically lowered expectations become habituated. Time flattens out.

This generalised depression is one reason that so little has happened since the major capitalist crisis of 2008. Yet this depression is itself both a symptom and a cause of something else: the decomposition of class solidarity. We would have to go deep into the nineteenth century to find a moment when class consciousness was as weak as it is now. Not only capital, but also elements of the post-68 left, have maintained that class is an outmoded category, unfit to deal with the multiplicities and complications of twentyfirst-century life. Yet these complications are in some respects a mirage, concealing the persistence of a class structure in which the majority of the population is marked as inferior. The reality of class continues, but without class consciousness. Beverley Skeggs and Helen Wood’s work on the class basis of reality TV and Owen Jones’s analysis of the “demonisation of the working class” show that class is displayed even as it is disavowed in contemporary culture.

Since the 1960s, the left has split into an authoritarian-nostalgic Leninism, committed to a party form and a class politics whose historical moment seems to have passed, and a supposedly “new” Left which rejects institutions and the centrality of the class struggle and puts all its faith in the capacity of the people to mobilise autonomously and to produce outside capitalist social relations. We desperately need to undo this binary. There is no way back to the old Leninist party, any more than there is a way back to Fordist capitalism. Yet naïve autonomism has shown that it has no purchase on the current moment either. Anti-capitalism and its retinue of strategies — occupations, protests — have not caused capital a moment’s serious alarm. 68 preached that structures don’t walk on the street — but if anti-capitalism has taught us anything, it is that, by itself, street activism has little effect on structures.

There Is No Desire for Capitalism

We don’t have to choose between class politics and anti-authoritarianism any more than we need to choose between Gramsci, Deleuze or Guattari, between a hegemonic approach and a politics of desire. In fact, if we are to succeed, we must absolutely refuse this false choice. Class politics must be renewed and resumed, not simply revived as if nothing has happened. In a Gramscian mode, we need to take institutions seriously again. Mainstream media are still where our sense of reality is produced; and despite all the claims about the waning of the state, parliament still has power over life and death via its control of the military, health services and social security. Yet these institutions cannot be renewed from within — it is necessary to articulate the institution and the forces outside them.

At the same time, desire is not some vitalistic energy which will spontaneously emerge once bodies are freed from institutions. Rather, desire is always the result of processes of libidinal engineering — and at the moment, our desire is manipulated by capital’s army of PR, branding and advertising specialists. The left needs to produce its own machineries of desire. It’s true that, at first sight, we seem to be at something of a disadvantage here, when we consider the vast resources that capital has at its disposal aimed at capturing our desire. Yet there is no desire for capitalism as such, just as culture is composed from libidinal materials that have no essential relation to capital — which is why capital has to distract, depress, and addict us in order to keep us captivated and subordinated.

But if we are no longer to define ourselves negatively, by our opposition to capital, what will be the name of our positive project? I don’t believe that the old signifier “communism” can be revived for this purpose. It is now irretrievably tainted by terrible associations, forever tied to the nightmares of the twentieth century. At the moment, our desire is nameless — but it is real. Our desire is for the future — for an escape from the impasses of the flatlands of capital’s endless repetitions — and it comes from the future — from the very future in which new perceptions, desires, cognitions are once again possible. As yet, we can grasp this future only in glimmers. But it is for us to construct this future, even as — at another level — it is already constructing us: a new kind of collective agent, a new possibility of speaking in the first person plural. At some point in this process, the name for our new desire will appear and we will recognise it.





anti-therapy1

The idea that talking about our feelings could be a political act seems counterintuitive. Aren’t people talking about their emotions more than ever before? And hasn’t this new emotionalism coincided with the emergence of what I have called capitalist realism — the deeply embedded view that capitalism is the only “realistic” economic system?

New Labour and the Birth of Emo-Politics

In order to begin to answer this, let’s turn to one of the central hubs of capitalist realism, the UK. Tony Blair’s New Labour naturalised what Thatcher had to fight for: the idea that there was no alternative to neoliberal capitalism. In retrospect, it is now clear that the first few months of Tony Blair’s first term as prime minister also inaugurated a new moment in British political life — the birth of what we might call emo-politics. Blair brought a new emotional tone to British government. He positioned himself as part of a Britain that was more at ease with expressing its feeling than his parents’ generation and their predecessors — with their stereotypical “stiff upper lips” — had been. Crucial to this was Blair and his advisers’ manipulation of the extraordinary grief jamboree that ensued in the immediate wake of the death of Diana, Princess of Wales, which happened only a few months after New Labour came to power.

The death famously wrongfooted the monarchy, with its older models of duty and emotional restraint, but Blair’s delivery of his famous speech about the “People’s Princess” — scripted by New Labour’s spin doctor, Alastair Campbell — not only established his authority as a prime minister, it initiated a new phase of neoliberal governance in Britain.

Thanks to Campbell and compliant members of the British media, a strong narrative soon emerged, in which Blair’s apparent emotional openness was contrasted with the Queen’s “coldness”. The monarch’s remoteness was now equated with “unhealthy” forms of emotional repression. Just as Blair sold himself as a moderniser who was taking the Labour Party away from the “class politics of the past”, so New Labour would also make a break with the traditional account of emotions. The government would now take the lead in ensuring that the population had the “correct”, “healthy” response to emotional distress. The normative tone would have been worrying enough, but New Labour’s emotional politics went far beyond mere mood-setting or the offering of recommendations.

Instead, the new conception of emotional health was passive-aggressively enforced — in the authoritarian style of neoliberalism which New Labour made their own — by a battery of measures which intervened to an unprecedented degree in the population’s emotional lives. Health, education and social control were all part of this project. Teachers were suborned into the role of emo-cops, ensuring that schoolchildren complied with the new emotional normativity. Parents judged to be failing were now required to attend “parenting classes”.

Meanwhile, the question of how genuine Blair’s feelings of grief were takes us to the heart of the Blair enigma: did he really believe in the doctrines he hawked, or was he a strange combination of charismatic showmanmanipulator and depthless puppet of capital? What did Blair see when he looked in the mirror then, and what does he see now? Are we dealing with self-deception, messianic delusion, or a new kind of postmodern psychopathy? The enigma remains as unsolvable now as it was twenty years ago. What is certain is that Blair led the way in normalising the emotional self-exploitation that was necessary for the final phase of neoliberalism in Britain.

The early Blair perfected the art of “spincerity” — the public performance of an emotion that you may or may not actually feel. As Britain’s economy became ever more reliant on the service and sales jobs, increasing numbers of workers were forced to develop the techniques of emotional simulation which Blair publicly pioneered.

In their book The Dangerous Rise of Therapeutic Education, Kathryn Ecclestone and Dennis Hayes argue that New Labour turned to popular therapy to fill the gap left by class politics. These “therapeutic orthodoxies”, they argue,

include claims that past life experiences have long-term negative emotional effects for everyone, and particularly pernicious effects for an increasing minority. The overall message is that, behind our apparently confident facades, we are all, to a greater or lesser extent, fragile and vulnerable and, as a consequence, we need particular forms of emotional support.2

Ecclestone and Hayes are right that these therapeutic tenets have been widely promulgated, and often accepted without much criticism. As Eva Illouz has been especially perspicacious in identifying, therapeutic orthodoxies have been disseminated, not only by therapists themselves, but by a popular culture which has enthusiastically adopted therapeutic motifs and conceptual frames. Ecclestone and Hayes are also right that therapy filled the gap that appeared when New Labour explicitly repudiated the concept of class struggle. However, Ecclestone and Hayes’s solution to the “therapeutic turn” is simply to play off one form of reactionary politics against another. Their call for a return to an education based on “reason, science and progress” is superficially laudable. Ultimately, however, theirs is conservative position, which offers us only a (false) choice between different kinds of authoritarianism. In place of New Labour’s soft — but highly invasive — authoritarianism, Ecclestone and Hayes posit an unappetizing return to traditional forms of authoritarianism. They are also in danger of endorsing the very emotional remoteness that superficially justifies the therapeutic turn. The problem with what I would like to call here the therapeutic imaginary is not that it posits subjects as vulnerable, haunted by events in their past lives, and lacking in confidence. Most subjects in capitalism — including those in the ruling class — fit that description. The problem with the therapeutic imaginary — and this is a problem that goes back to Freud and the origins of psychoanalysis — is its claim that these issues can be solved by the individual subject working on him- or herself, with only the therapist to assist them.

In addition, Ecclestone and Hayes’ refusal of the role of emotion in education — or rather their placing of emotion in opposition to “reason, science and progress” — presents a diminished account of the Enlightenment project to which they claim allegiance. This is the Enlightenment as understood by someone like Richard Dawkins — an Enlightenment rightly criticised for its patriarchal bias by the “postmodern” theorists that it is no surprise at all to see Ecclestone and Hayes disdaining. The “Enlightenment” here ends up simply reinforcing the largely unexamined class, gender and race assumptions of the ruling class.

This account of Enlightenment can be contrasted with the one that emerges in the work of Jonathan Israel. In Israel’s narrative, Enlightenment corrodes the bases of all traditional forms of authority. This does not lead to some “postmodern” free-for-all any more than it mandates some dogmatic adherence to the current institutions of science. Rather, forms of “authority” which claim their legitimacy from tradition stand exposed as illegitimate, which is to say authoritarian. It then becomes possible to contrast such authoritarianism with a democratic and transparent model of authority.

The defining principle of Radical Enlightenment is the conviction that there is nothing that — in theory if not in fact — cannot be understood. This was the belief animating Spinoza’s philosophy, which, Israel argues, provided the foundations upon which Radical Enlightenment would grow.

Here we can return to the emotions. As is well known, far from ignoring emotions, or assuming they could be bypassed in some way, Spinoza’s philosophy makes the management of emotions central to its project. It aims not to subdue emotions, but to engineer joy — a task that can only be achieved when reason is not simply opposed to feelings, but brought to bear on them. According to Spinoza’s logic, ignoring emotions only mystifies them, putting them beyond the purview of rational enquiry. All of which makes Spinoza an eminently modern philosopher, but also a thinker whose work is an indispensable resource for any progressive project. This is especially so now, in an era in which more and more areas of life and the psyche dominated by agencies which engage in libidinal and emotional engineering — most of which is undertaken, knowingly or unknowingly, in the interests of capital.

New Labour’s authoritarian emo-politics was ostensibly part of its “progressive” supplement to capitalist realism. Blairism maintained that the only way to implement any measures that would produce “social justice” was to capitulate to the dominance of capitalism. It was “unrealistic” to hope for anything more; such expectations were a relic of an earlier moment — the conditions for which have now disappeared - when the organised working class could assert itself against capital. New Labour accepted and naturalized this new composition of social forces, arguing that its capitulation would allow it the bargaining room to bring in measures — such as the minimum wage - which a Thatcherite neoliberal party would always block. It turned out, however, that New Labour’s emo-politics were actually fundamental to the securing of neoliberalism in the UK. To understand why that is, we have to reflect more closely on what neoliberalism is. We must also further reflect on the role that the therapeutic imaginary has played in embedding neoliberalism. To do that, we will now shift our attention away from the UK, and onto the US.

Antinomies of the Therapeutic Imaginary

Jennifer M. Silva’s Coming Up Short: Working-Class Adulthood in an Age of Uncertainty heartbreakingly registers the corrosive effects of the neoliberal environment on intimacy.

Silva’s book focuses on young people specifically — it is based on a hundred interviews she undertook with young working-class men and women in two American cities (Lowell, Massachusetts and Richmond, Virginia). On the face of it, Silva’s starting point is similar to Ecclestone’s and Hayes’. “In a world of rapid change and tenuous loyalties,” Silva argues, “the language and institution of therapy — and the self-transformation it promises — has exploded in American culture.”3 Ecclestone and Hayes saw New Labour’s adoption of therapeutic tropes as the consequence of some mixture of opportunism, authoritarianism and bungled good intentions. For Silva, meanwhile, the spread of therapeutic culture in the US is both a means by which neoliberal individualism has been embedded and a consequence of that embedding. According to Ecclestone and Hayes, therapy produces a “softening” of subjectivity and culture, manifested in a weakening of authority and a strengthening of an ever more intrusive state. For Silva, by contrast, the dissemination of therapeutic concepts has resulting in a hardening of the individual subject. “W ()orking class men and women born in the wake of neoliberalism … () learn to see their struggles to survive on their own as morally right, making a virtue of not asking for help; if they could do it, then everyone else should too.”4

This brings out the difference between New Labour’s rendition of neoliberalism and neoliberalism in the American context. The New Labour model of the (implicitly working-class) subject functioned as a double-bind. The double bind, as Deleuze and Guattari explain in Anti-Oedipus, “is the term used by Gregory Bateson to describe the simultaneous transmission of two kinds of messages, one of which contradicts the other, as for example the father who says to his son: go ahead, criticize me, but strongly hints that all effective criticism — at least a certain type of criticism — will be very unwelcome.”5 The contradictory instructions serve to destabilise the subject, keeping them in a state of permanent neurotic anxiety.

On the one hand, the working-class subject was interpellated by New Labour as a being capable of radical, indeed practically infinite, selftransformation. (One of the most significant effects of this ideology — which was at one and the same time its presupposition — was the divesting of the subject of its class position. Class “identity” was perceived as both an atavism and a constraint, holding the subject back from the infinite promises of self-reinvention.) On the other hand, as soon as something went “wrong” — when the behavior of working-class individuals inevitably went outside the parameters policed by the myriad of surveillance and control agencies which the New Labour administration invented — they were seen as fundamentally lacking in self-determination and the capacity for self-care, and were subject to intensive disciplining (e.g. the parenting classes mentioned above).

In practice, the American situation that Silva describes operates with the same double bind. It is just that the emphasis is different. New Labour, still haunted by a socialist and social democratic history that it could never fully abjure, presented its management and disciplining of the working class in passive-aggressive terms, as “care”. In the US, where this social democratic history is lacking, the hyper(neo)-liberal interpellation of the subject as capable of self-determination and self-reinvention is supplemented — especially in the case of black working-class individuals — by the aggressive use of incarceration. Therapeutic narratives of self-transformation feed into what Alex Williams has called “negative solidarity”. This is the tendency for neoliberal subjects to “race to the bottom”. If others are perceived to be in receipt of resources or benefits that they “haven’t earned”, they should not only be denied those resources, they should be publicly shamed for claiming them. Everyone should “stand on their own two feet”.

One of the many values of Silva’s book is the thorough account it gives of the emotional and cultural roots of negative solidarity. Silva argues that the hardened model of subjectivity that she sees exhibited by most of the people she interviewed for her study is the result of years of institutional and existential abandonment. A therapeutic narrative of heroic selftransformation is the only story that makes sense in a world in which institutions can no longer be relied upon to support or nurture individuals. In an environment dominated by unrelenting competition and insecurity, it is neither possible to trust others, nor to project any sort of long-term future. Naturally, these two problems feed into one another, in one of the many vicious spirals which neoliberal culture has specialised in innovating. The inability to imagine a secure future makes it very difficult to engage in any sort of long-term commitment. Rather than seeing a partner as someone who might share the stresses imposed by a harshly competitive social field, many of the working-class individuals to whom Silva spoke instead saw relationships as an additional source of stress. In particular, many of the heterosexual women regarded relationships with men as too risky a proposition. In conditions where they could not depend on much outside themselves, the self-reliance they were forced to develop was both a culturally validated achievement and a hard-won survival strategy which they were reluctant to give up.

In any case, what we confront here is a first antinomy of the therapeutic imaginary: the idea that the proliferation of therapeutic orthodoxies simultaneously produces “softened” subjects — subjects who identify as lacking, if not actually damaged — and subjects that are “hardened” — subjects who pride themselves on a claimed invulnerability. We can approach the second antinomy via the notion of subjects that are excessively invested in their own vulnerability. The severe problems inherent in such an investment from a left-wing point of view were analysed twenty years ago by Wendy Brown in her important essay “Wounded Attachments”.6 Brown understood very well the libidinal, discursive and administrative complex that would produce New Labour: “As liberal discourse converts political identity into essentialized private interest,” she wrote, “disciplinary power converts interest into normativized social identity manageable by regulatory regimes.” However, the main point of Brown’s essay was to diagnose the psycho-libidinal origins of an identarian political formation which has become even more deeply embedded since she wrote the essay in the 1990s. Drawing on Nietzsche’s account of resentment in On The Genealogy of Morals, Brown wrote of a political subjectivity which “becomes deeply invested in its own impotence, even while it seeks to assuage the pain of its powerlessness through its vengeful moralizing, through its wide distribution of suffering, through its reproach of power as such.” As Brown observed, “politicized identity thus becomes attached to its own exclusion both because it is premised on this exclusion for its very existence as identity.” Brown’s careful diagnoses of this political psychopathology turned out to be prophetic as well as astute. Twenty years on, and the mixture of moralizing aggression and investment in impotence has proliferated in a political atmosphere now substantially shaped by the online environment. In her article, “Sexual Paranoia Strikes Academe”, published in The Chronicle of Higher Education, Laura Kipnis describes a situation on American campuses in which female students are encouraged to see themselves as helpless victims of predatory lecturers. “Everywhere on campuses today,” Kipnis wrote,

you find scholars whose work elaborates sophisticated models of power and agency. It would be hard to overstate the influence, across disciplines, of Michel Foucault, whose signature idea was that power has no permanent address or valence. Yet our workplaces themselves are promulgating the crudest version of top-down power imaginable, recasting the professoriate as Snidely Whiplashes twirling our mustaches and students as helpless damsels tied to railroad tracks. Students lack volition and independent desires of their own; professors are would-be coercers with dastardly plans to corrupt the innocent.7

Kipnis’s article predictably became embroiled in the very processes it sought to analyse, as she became the target of aggressive moralising attack from groups self-identifying as representatives of the vulnerable.

Here, then, is the first part of our second antinomy of the therapeutic imaginary: there is an excessive tendency amongst many subjects today to identify as victims of abuse. It is important to note at this point that I am not conflating Kipnis’s argument with that of Ecclestone and Hayes. Whereas their position ultimately amounts to a call for the restoration of older models of authority, Kipnis is more of a left-libertarian who deplores the moralising authoritarianism that has spread so pervasively through American student politics. At no point does Kipnis underplay the suffering caused by actual abuse, or imply that the “survivors” of such abuse should button up and get on with it.

If both Kipnis and Brown’s essays highlight real and pervasive psychopathologies on the left, their analyses need to be weighed against an acknowledgement that sexual abuse by those in politics and media is actually far more widespread than had been previously supposed. The obvious example here would be the disturbing and curious case of Jimmy Savile in the UK (which is echoed by the accusations that have recently circled around Bill Cosby in the US). Savile was a DJ turned light entertainer, best known in the 1970s for his work on the children’s wish-fulfilment television show Jim’ll Fix It. After his death, rumours that had dogged him for many years were confirmed — Savile had sexually abused thousands of victims, including many children.

Savile was no ordinary entertainer or media figure. Like some character out of a David Lynch film, Savile had links with both the criminal underworld and the most powerful members of the ruling class. A massive police investigation into those who had worked with Savile (Operation Yewtree) discovered that he was not alone — many of his associates were also paedophiles. Yet the remit of Operation Yewtree was confined to the entertainment world — Savile was also a friend of politicians and policemen. In the wake of the Savile allegations emerging, a new scandal is brewing in the UK. This time it centres on politics, with Thatcher’s right-hand man Leon Brittan and former Conservative prime minister Edward Heath among those accused of paedophilia.

This brings us to the second half of the second antinomy of the therapeutic imaginary: there is far more abuse than had previously been thought possible. The sense of the possible here has little to do with what actually happened; rather, it is what is deemed credible by the virtual figure that Lacanian theory calls the big Other. The big Other is something like the virtual observer assumed to be the audience for official discourse, and it is the big Other which secures the consistency of any reality system. There is always some discrepancy between what groups and individuals know and what the big Other believes. This is because, as Lacan notes, a defining feature of the big Other is its inability to see everything. However, a severe crisis will occur if the discrepancy between what groups and individuals know and what the big Other “believes” becomes too marked. In such conditions, the official reality system is in danger of collapse. There is every reason to suspect that, in the UK and elsewhere in Europe, this is what we are currently encountering. Under pressure from the banking crisis of 2008, and the emergence of new political parties such as Syriza and Podemos, the reality- and libidinalengineering systems that have maintained capitalist realism for the last thirty years are beginning to look dysfunctional. In England in particular — the oldest capitalist country, and the culture with the most effective and historically durable dampening mechanisms in the world available to it — capitalist realism has operated by dramatically narrowing the affective and representational bandwidth of culture. A culture dominated by reality TV, self-improvement propaganda and corporate appeasement — all of which push therapeutic orthodoxies — has produced diminished expectations and representational conservatism. Yet the representational frameworks which have served English capitalist realism so well since the 1980s clearly cannot accommodate the trauma of the establishment paedophile scandals, any more than they can accommodate popular mobilisations against neoliberalism. You would indeed need the formal inventiveness of a David Lynch or a David Peace to do justice to the extremity of what the English ruling class has got up to. It turns out that the supposed fantasmatic and melodramatic excesses of Lynch and Peace’s work — its tendency to see conspiracies and abuse everywhere — is much closer to actuality than the moderation of respectable middlebrow literary and televisual “realism”.

So here is the second antinomy in full: there is an excessive tendency amongst many subjects today to identify as victims of abuse; however, there is far more abuse than had previously been imagined. How can both these claims be true — and if they are, what does it tell us about the therapeutic imaginary?

Capital Is More Real Than You Are: There Is No Such Thing as the Autonomous Individual

To break out of this impasse, we need to abandon the belief in the autonomous individual that has been at the heart, not only of neoliberalism, but of the whole liberal tradition. In a successful attempt to break with social democratic and socialist collectivism, neoliberalism invested massive ideological effort into reflating this conception of the individual, with its supporting dramaturgy of choice and responsibility.

If we want to reject this conception of the individual, then we might turn once again to Spinoza, whose whole work was based on the premise that such an individual could not exist. But, in the context of therapy, we might also turn to the radical therapist David Smail, who rejected all of the standard tropes of individualist therapy. “W ()hat we take to be causal processes of thought, decision and will are frequently little more than a kind of commentary that accompanies our action,” Smail argued in his book Power, Interest and Psychology: Elements of a Social Materialist Understanding of Distress.8 The interiority presupposed by much therapy is little more than an ideological special effect. Like Spinoza, Smail understands that the socalled “inside” is really a folding of the outside. Most of what is supposedly “inside” us has been acquired from the wider social field. “Many of the characteristics that we tend to regard as entirely ‘psychological’ are acquired from outside. The most significant case in point is probably ‘self-confidence’, the crumbling of which is so often at the root of the kind of personal distress which can be ‘diagnosed’ by the experts as ‘neurotic’.”9 This means that, contrary to the founding principles of something like cognitive behavioural therapy, the means for self-transformation are not available to individuals.

What people who suffer psychological distress tend to become aware of is that no matter how much they want to change, no matter how hard they try, no matter what mental gymnastics they put themselves through, their experiences of life stay much the same. This is because there is no such thing as an autonomous individual. What powers we have are acquired from and distributed within our social context, some of them (the most powerful) at unreachable distances from us. The very meaning of our actions is not something that we can autonomously determine, but is made intelligible (or otherwise) by orders of culture (proximal as well as distal) over which we have virtually no control.10

This is why any individual therapy — even that practiced by a sympathetic and politically progressive therapist — can only ever have limited effects. In order to really come to terms with the damage that has been done to them by and in the wider social field, individuals need to engage in collective practices that will reverse neoliberalism’s privatisation of stress. Here we can return to an important observation by Jennifer M. Silva:

In social movements like feminism, self-awareness, or naming one’s problems, was the first step to radical collective awareness. For this generation, it is the only step, completely detached from any kind of solidarity; while they struggle with similar, and structurally rooted, problems, there is no sense of ‘we’. The possibility of collective politicization through naming one’s suffering is easily subsumed within these larger structures of domination because others who struggle are not seen as fellow sufferers but as objects of scorn.11

The spreading of therapeutic narratives was one way in which neoliberalism contained and privatised the molecular revolution that consciousnessraising brought about. The struggle to dismantle neoliberalism will therefore necessarily involve the rediscovery and reinvention of these formerly popular practices. So now we are in a position to answer the question I posed at the start of this essay: When can talking about our feelings become a political act? When it is part of a practice of consciousness-raising that makes visible the impersonal and intersubjective structures that ideology normally obscures from us.





democracy is joy1

“The meaning of OXI we should fight for is the belief in politics itself. OXI is the belief that we can throw off the demands of a supposedly ‘impartial’ economy that serves only the few, that we can reject the fallacy that ‘economic necessity’ demands something we consider socially unacceptable, and instead begin to make decisions about our own collective social life. It is precisely this that makes the Greek OXI vote inspiring, the potential for a return of politics, and the headaches and uncertainties and dangers of attempting to walk an unknown path.”

— Bert Russell, Plan C2

“Nothing lasts forever, of that I’m sure”

It’s somewhat ironic that theories of the “Event” have come to the fore in the most fashionable areas of academic political philosophy at just the moment in history when it has become clear that events in and of themselves don’t change anything. From the G20 protests, to the millions marching against the Iraq war, to the Arab Spring, to the short-lived student campaign against fees in the UK — the narrative of evental politics since the late 1990s has been reliably repetitious. Euphoric outbursts of dissent are followed by depressive collapse. Eventalism is the manic flipside of the general depressive tendency in boring academic Marxism — in which an ostensible Leninism/ Maoism (everything will change after the revolution!) obfuscates a de facto Adornianism (nothing could ever happen, everything is bad, so we might as well keep on taking the state’s pay cheques). The whole rehabilitation of the status of philosophy itself in the past couple of decades — the reversal of the democratising move to theory, and the colonisation of what is now called theory by third-rate obscurantist “philosophy” and curator-speak babble — is a sideshow, of course, but a symptomatic one. The sour comedy of academic philosophical Leninism and Maoism can now be seen as one of the last acts in a postmodern shadowplay — a pantomime in which we are condemned to the role of interactive audience, tweeting our responses onto the screen behind the main players, who carry on regardless.

The emergence of Podemos and Syriza, the post-referendum SNP and the Kurdish women’s movement are part of another rhythm of political transformation. The unseemly way in which swivel-chair Marxist philosophers and “anarchists” have slavered over any perceived mis-step by Syriza tells us all we need to know about these “revolutionaries”. They don’t want any sort of positive change to spoil the purity of the “revolutionary” theory. The revolutionary event will redeem everything… when it comes… but the time is not right, not yet, never yet.

Whether capital crushes Syriza or not, it has already made major contributions to what will be a long struggle to overturn neoliberal hegemony. A line from Keir’s “On Social Strikes and Directional Demands” has kept coming back to me in all of the noise and chaos around the Greek situation: “Even at their point of failure Plan B electoral politics can be useful if they can clarify the anti-democratic effects of neoliberalism that work against all forms of collective action.”3

If political change doesn’t happen through events alone, there are nevertheless moments which function as thresholds, opening up a new terrain of struggle, and allowing different collective emotions to propagate. While — for the sake of our fragile collective mental health — we shouldn’t get too carried away by the Oxi vote last week, we shouldn’t underestimate its significance either. Besides, as Bert Russell argues, the meaning of Oxi is not already guaranteed — it has to be established politically. The current struggle in Europe — currently focused on Greece, but sure to spread much wider in the near future — is an opportunity for us to reclaim democracy after its capture by neoliberalism in the 1970s and 1980s. The founding moment of neoliberalism was the decidedly anti-democratic overthrow of the democratic socialist Allende government in Chile. This was a double defeat: not only was a democratically elected, non-authoritarian, technologicallyorientated administration overthrown, an extreme neoliberal government was installed in its place. In Chile, the forced forgetting of the possibility of democratic socialism required mass torture, imprisonment and repression.

Since then, the capitalist counter-revolution called neoliberalism has had a long run of it. But we should start to accept that, even if we can hardly believe it ourselves, neoliberal capitalism is now in its final, decadent phase… (Remember the End of History? Only a year ago, it seemed like it would last forever…)

Restoration capital reeks of defeat and exhaustion, like the Eastern bloc at the end of the 1980s. The Soviet system, just like neoliberal capitalism now, was a gigantic Empire of Simulation in which by then, no one — not even the big Other — believed. Except, under state socialism, there was at least social housing, energy supplied by the state, etc. Under late neoliberalism, even in the “wealthiest” countries, such as ours, we don’t even have that: only a cybergothic Dickensian re-run… Temples of finance looming above food banks… nineteenth-century England minus the Victorian capitalists’ philanthropy and Promethean projects (imagine trying to install a sewer and an underground rail system in neoliberal London now: the whole of the West End feels like a vast construction site and film set, an anxiety dream terrain in which new obstacles appear by the minute)… Everything (mis)controlled by malfunctioning outsourced IT systems, impenetrable and unintelligible, like relics left behind by some long-since-absconded Gnostic demiurge…

“The emotional contagion of the no vote is incalculable”

The reality and emotional management systems that have served neoliberalism so well are now not only failing, but conspicuously failing… Of course, the buffers, the spoilers and the blockers haven’t given up yet… Not here, not in England, the country which designed the oldest and most effective damping system the world has ever known… They haven’t given up, they haven’t even realised that they will have soon have to adjust the reality programme they have been peddling for so long that it has become a drab second nature… Soon, they will have to pull the oldest trick in the English bourgeoisie’s book (they perfected it in 1688)… First of all you say it is impossible, then, when it happens, you say it was inevitable… “You see, you have to preserve the impression that nothing happens, especially when it does, is that clear? We don’t have revolutions here…”

So the old capitalist realist script is not about to be abandoned, but those still spouting it are increasingly coming off like donkey-jacketed Old Lefties after the Thatcher victory in 83, bewildered and traumatised, still relying on habits which were once functional, but now amount to a kind of madness. (A boring madness, of course, it being them.)

Listen to the BBC, Pravda for Market Stalinism. Roberto Mozzachiodi reprises an interview from Radio 4 in the wake of the Oxi vote:

Reveller: I’ve got no money, but if I had money I wouldn’t base my decision on money, money flows, money evaporates. I have democracy in my heart, and I’m full up.

BBC: Yes, but will democracy put a dinner on the table? You’re a young man. Let me tell you as an older man, that money matters when you’re responsible for a wife and a child.

Meanwhile, Huw Lemmey listens to Today, as John Humphrys is momentarily shellshocked out of his smirking knowingness:

John Humphrys did an excellent impression of a Telegraph comments section contributor secretly kidnapped in his sleep, paradropped into Greece, and waking up in Syntagma Square confused, lonely and crying out for his wife.

Yet the dreary old message, the mantra that the British bourgeoisie recites in its sleep — nothing has ever happened, nothing can ever happen, we need more time — is getting harder to push now that it’s evident that the ruling reality structure is coming apart practically everywhere we look.

Capitalist realism cannot survive when alternatives are efflorescing… These alternatives are not only “political” in the narrow sense — they are also emotional. Kodwo Eshun, via email: “the emotional contagion of the No vote is incalculable, i.e. a different logic of calculation and futurity”. The Winter Years are ending, and summer is coming… A hyperstitional spiral: the more we believe it, the more we can make it happen, the more we make it happen, the more we believe it…

Pyschopathologies of Corporate Capitalism

In its pomp, neoliberalism used hope as well as fear, as part of a doublebind strategy which battered organised labour while seducing individual workers with the promises of consumer durables, satellite TV, job security… all these riches provided you comply with capital… provided, that is to say, you give up the possibility of Red Plenty…

Since 2010, it’s become clear that the (flatpack) cupboard is bare: there are no more bribes, only threats. What’s more, there has been no new thinking, no new strategic orientation from the managers of capital. Gorged on decades of easy pickings, capital’s meat puppets have let their master down this time. Their unspoken conviction is: if it is broke, it’s too much like hard work to fix it. They have defaulted to the managerialist equivalent of retromania: more cuts, more accumulation by dispossession, more asset stripping of public services.

This programme has to be understood in libidinal as well as politicaleconomic terms (because there is no economy without politics, no economy without libido). It is a psychopathology of the corporate elite. Even if the ultimate libido driving capital is miser-masochism (I will let myself become the means by which capital grows and proliferates), it’s clear that capital — which can machine whatever desiring complexes it needs — has from the start called upon an ancient Gothic impulse towards humiliating and subjugating others. Neoliberalism is in trouble now because, decoupled from any positive inducement, these drives — whether exhibited by the Troika in the deadly “loan-shark theatre” it is playing out with Greek people’s lives, or IDS “visibly excited by the prospect of hurting the poor”4 — are now appearing in a more and more exposed form.

Neoliberal austerity is at once a form of Sadism — in the technical, psychoanalytic sense, rather than the everyday, moralising sense — and corporate anorexia. What Sadism and anorexia have in common is the belief in the indestructibility of the fantasmatic body: no matter how much I cut, how much I punish, the body will survive… In the Sadist’s case, the fantasmatic body is the body of the endlessly humiliated Other; in the anorexic’s case, the fantasmatic body is, in a sense, their “own”. Yet the infinite elasticity of the fantastic body eventually comes up against the limits of the physical body. (Anorexia is the only mental illness that can directly kill you, but anorexics don’t want to die — they are engaged in an indefinite process of becoming-thinner which death actually interrupts.) It’s important to see how the capitalist fantasy necessarily oscillates between a punishing-without-end of an abjected fantasmatic body — where workers can be endlessly punished (restructured) and/or eliminated (cut) — and a belated recognition that the fantasmatic body depends on an actual, physically precarious body, with vulnerabilities and real limits. You could say that capital as such cannot recognise the collective worker-body as belonging to it; only communism can perform this integration.

The ultimate fantasy here — the ultimate fantasy of capital “itself” — is of cutting workers away altogether. Capital’s libidinal metaphysics is a kind of cosmic libertarianism: capital identifies itself as a force of unbounded energy, whose capacity for infinite accumulation is obstructed only by political contingencies. Soon, always soon, capital dreams, I will be free of the need for politics… and free of the need for humans too… (“…liquidate labor, liquidate stocks, liquidate farmers, liquidate real estate…”). Capital’s realised utopia would be a burned-out planet full of fully-automated factories turning out shit that no one wants to buy, with no one left to buy it anyway, because the conditions for the continued existence of these factories is the destruction of an environment humans can live in.

A great deal of modern economic discourse takes it as axiomatic that economic forces are the only ones that matter. This idea has bled into politics too, at least in the Western world: economic forces have been awarded the status of inexorable truths…The scenario we’re given — the one being made to feel inevitable — is of a hyper-capitalist dystopia. There’s capital, doing better than ever; the robots, doing all the work; and the great mass of humanity, doing not much, but having fun playing with its gadgets. (Though if there’s no work, there are going to be questions about who can afford to buy the gadgets.) 5

The absence of abundance is already accepted. The metaphors of the nature poets, mapping human hearts through once commonly understood imagery, are irrelevant and impenetrable. “The sun of Winter/The moon of Summer, and all the singing birds/Except the missel-thrush that loves juniper/Are quite shut out.” I’m sorry. The missel-what? Can the juniper be monetised? Is this missel-thing for sale? Our children already have no stable baseline from which to calibrate the loss of all that lives. It’s game over.

Bearing this in mind, I finally find myself reluctantly agreeing with the business community. There is no time for delay. Let’s build the runway. Let’s choke the Earth. Let’s get this damn thing over with, for what can be avoided, whose end is purposed by the mighty gods of business? Hasten our demise, let our children be the last of their sorry line, and spare their unborn descendants any further suffering. We will not save the rhino. We will not even save the hedgehog. How can we save the world?

But, if you can purge cheap sentiment from your mind, how exciting and fascinating it will be to watch as the world becomes uninhabitable. It’s almost worth going on a health kick to survive another 60 years and see everything immolated. How many humans have had the awe-inspiring opportunity to witness such spectacle: the end of all that is?6

Why not export capital (and its wiling servants, if they are so keen on it) to an already-dead planet? Then capital can get on with realising its utopia, and we can get on with recovering earth for Red Plenty.

It is crucial to note here that capital doesn’t — and necessarily cannot — understand “itself”. Capital is like Neuromancer before the fated fusion with Wintermute, a component part which narcissistically mistakes itself for a final cause. Or it is like Ultron, a deranged personification of a worldwide network, part fiendish artificial intelligence, part artificial stupidity, part petulant infant, constitutively blinded by its own core programming.

Personification of things within the discourse of Capital presents the personification of things within capitalism, that is, the fetishism of commodities. But in addition to these two registers of personification, there remain another two, to which Marx’s Preface calls attention: the personification of persons, both textually and systematically. Capital personifies persons, so Capital personifies persons; the individuals whom bourgeois economics would take as economic agents are treated in the text as personifications of the “social relations whose creature (they) remain.” First and foremost of these categories is capital itself, and thus seldom is there a reference to “the capitalist” without the qualifying clause “i.e., capital personified”.

When persons are personified, they are made in the image and likeness of the ur-person, Capital. Capital is the subject in this world; all other actors are figures, masks, faces, prosopopoeic personifications of the subject. This is the primacy of Capital already emblazoned in the title Capital, the place nineteenth-century novels most often reserve for the subject: Capital is the subject of Capital, as David Copperfield or Jane Eyre or Daniel Deronda are the subjects of David Copperfield, Jane Eyre, and Daniel Deronda. The analytic importance of this subject position, an idea advanced by the trope of personification more than by exposition, is not only that Capital is the protagonist of modernity, but that the workings of capitalism are described by this subjectification and embodiment of an abstraction. Capital is the story of Capital’s becoming-subject, of the relentless self-constitution, the “valorisation of value” that propels this mode of production. The artifice of the trope of personification calls attention to the artifice and instability of this subject, to the fissures and crises in its course of becoming, in its adventure of Bildung.7

Insofar as we are programmed by capital, we can’t understand what capital is either. The conditions for understanding capital properly lie outside it, in a communist science that — to hijack a phrase from Nick Land — must create the conditions for its own emergence almost entirely out of its enemy’s resources. From the inside (of capital), capital is an economic system, which relies on politics only contingently; from the outside, capital is an intricate set of (libidinal, ideological, violent) mechanisms designed to block the emergence of Red Plenty.

There Is No Economy (Philosophical interlude: skip to next section if you want to avoid)

THERE IS NO ECONOMY. There is no pure economy, no economy without politics, no economy without libido. David Graeber is surely right that neoliberalism is

a form of capitalism that systematically prioritised political imperatives over economic ones. Given a choice between a course of action that would make capitalism seem the only possible economic system, and one that would transform capitalism into a viable, long-term economic system, neoliberalism chooses the former every time. There is every reason to believe that destroying job security while increasing working hours does not create a more productive (let alone more innovative or loyal) workforce. Probably, in economic terms, the result is negative — an impression confirmed by lower growth rates in just about all parts of the world in the eighties and nineties. But the neoliberal choice has been effective in depoliticising labor and overdetermining the future. Economically, the growth of armies, police, and private security services amounts to dead weight. It’s possible, in fact, that the very dead weight of the apparatus created to ensure the ideological victory of capitalism will sink it. But it’s also easy to see how choking off any sense of an inevitable, redemptive future that could be different from our world is a crucial part of the neoliberal project.8

From the start, “economy” was the object-cause of a bourgeois “science”, which hyperstitionally bootstrapped itself into existence, and then bent and melted the matter of this and every other world to fit its presuppositions — the greatest theocratic achievement in a history that was never human, an immense conjuring trick which works all the better because it came shrouded in that damp grey English and Scottish empiricism which claimed to have seen off all gods. When Thatcher said “there is no such thing as society”, she was only echoing the assumptions of Hume and Smith: “society” is an unsupportable abstraction, a spook that proper scientific thinking will exorcise soon enough… Only impressions are verifiable, everything else is superstitious junk to be jettisoned. Everything, that is, except capital… (Those bloody savages attribute power to their wooden gods, whereas we…)

Hume, to his credit, at least pushed empiricism to the point where it dismantled itself. It turns out, Hume showed, that when pursued to its logical conclusions, empiricism leaves us with none of the presuppositions upon which the emergent secular liberalism relied. There is no self (there is no impression that corresponds with what we call the self — a double scandal for empiricism, since all ideas were supposed to be rooted in impressions) just as there is no causality (we don’t experience cause and effect, only constant conjunction). Hume, stunned by the spider scepticism, offered a kind of homeopathic remedy against reason’s tendency to evacuate the human world of all its fetishes, touchstones and commonplaces. Reason, Hume argued, slumping into his backgammon chair, only has a very limited dominion over our lives. Emotion and habit dictate most of what we think and do. Thus, the self and causality are back, and Kant’s transcendental critique arrives to clear up the mess.

So there is no escaping libido, not even for the British… This insight is crucial to the Radical Enlightenment which Spinoza patiently prepares in his lens-grinders’ lab in Amsterdam. As the defenders of theocratic and secular power quickly realised, Radical Enlightenment was the most dangerous weapon in Christendom — not least because it exposed as bogus the difference between theocratic and secular power: there is in all political power an irreducible theocratic element. Spinoza pre-emptively takes out both British empiricism and the “continental” trajectory kicked off by Kant (the greatest trick German Idealism ever pulled was pretending that Spinoza never existed). The critique of superstition is meaningless while we still believe in free will and the self. The first anthropomorphic act is the invention of the human being, projected back off the image of an invented God who not only doesn’t exist, but couldn’t possibly exist. (Even God couldn’t have free will.)

For human beings who want to move in the direction of love and freedom, the only option consists in the apparent paradox of theoretico-practically inserting themselves into the naturalistic matrix of cause and effect. The effect is to break down the cordon sanitaire that Hume placed around emotions, preserving bourgeois thought’s “commonsense” division between feelings and thought. In refusing this opposition, Radical Enlightenment democratises the possibility of what Lynne Segal calls Radical Happiness (with the proviso that Spinoza preferred to think of joy rather than happiness — because of the association of happiness with happenstance)

Emotions don’t just happen, they emerge out of fields of cause and effect which can be analysed. This means that feelings can be engineered, in a hyperstitional spiral, which has more to do with what Justin Barton calls “lucidity”9 than with what academic philosophers call Reason. I’m using the term “emotion” rather than “affect” here, very deliberately. Affect as it is now routinely used by academics is pretty much completely opposed to what Spinoza meant by it. The problem begins with Deleuze, and the fatal splicing of Spinoza’s project of emotional engineering with Bergson’s vitalist cult of creativity and unpredictability. It’s hard to think of thinkers more opposed in their fundamental presuppositions and orientations than Spinoza and Bergson — and more or less everything that is wrong with Deleuze, in my view, is tied up with his infatuation with Bergson. It is Bergsonism, rather than Spinozism, which is the true ideology of late capitalism. It’s true that many of the key sciences of late capitalism — libidinal- and realityengineering, advertising, branding, media, the happiness industry — are in some sense Spinozistic, but this is a captured Spinozism, an emotional engineering tethered to Capital’s needs, not geared to the production of joy.

It does not move… or change… or grow old… remains… forever… icy… silent

“The idea that a wave of economic change is so disruptive to the social order that a society might rebel against it — that has, it seems, disappeared from the realms of the possible. But the disappearance of 47 per cent of jobs in two decades (as per Frey and Osborne) must be right on the edge of what a society can bear, not so much because of that 47 per cent, as because of the timeframe. Jobs do go away; it’s happened many times. For jobs to go away with that speed, however, is a new thing, and the search for historical precedents, for examples from which we can learn, won’t take us far. How would this speed of job disappearance, combined with extensive deflation, play out? The truth is nobody knows. In the absence of any template or precedent, the idea that the economic process will just roll ahead like a juggernaut, unopposed by any social or political counter-forces, is a stretch. The robots will only eat all the jobs if we decide to let them.”

— John Lanchester, “The Robots are Coming”

The least reflective of capital’s managers believe their own propaganda: the welfare state was a regrettable moral lapse, an indulgence. The thought that it was an insurance policy against revolution doesn’t compute anymore: why worry about revolution now? Reality is now more real than it ever was, established as a kind of granite, inertial certainty, from which the possibility of change is a priori excluded. Beneath the frenzied “simulation of productivity”, a sterile no-man’s land, which does not move, which remains forever icy and silent… The more intelligent of capital’s agents, however, must realise that this cannot continue for much longer now. Nihiliberalism is a smash and grab raid, a last hurrah before they helicopter off behind the compound walls, and let everything else descend into an Oryx and Crakestyle dystopia.

Up here in the kingdom of Gormenghast, where everything cowers in the crooked shadows cast by the twisting towers and turrets of finance capital, we’re already living in a dystopia — but a dystopia that cloaks itself in the time-honoured mantle of the English bourgeoisie: the boring. Hyper-anxiety digitally glossed over with hi-res distraction machineries makes for a wonderful capture system. Deep in the bowels of MiddleEngland — bunkered far away from all the hashtags, handheld devices and all the other haranguing technologies they distribute amongst the lower orders — these eminence grises were close to celebrating total victory, the final achievement of their historic mission. Close, but no Cuban cigar… If only it hadn’t been for those pesky Greeks… and Spaniards… and Scots… bloody foreigners don’t know what’s good for them…

The English bourgeoisie: crushing spirits and making everything boring since 1750. If there’s a sentient creature anywhere in the cosmos that is not boring and miserable, they will find it and neutralise it.

All vampires are first of all vampirised, and look at the long faces and manicured grey fingers of these ghouls, capital’s oldest and most trusted servants, to see what capital does to its human resources:

Long gone are the virile, predatory vampires that once populated horror stories about capitalism, sucking out the vital essence of the proletariat in Gothic fortresses of “dead labor”. Instead, shambling worm-eaten wrecks mill about aimlessly, whilst augmenting their numbers in obscure cannibalistic circuits that defy rational comprehension and which are, in any case, too hideous to steadily contemplate. Fiends have degenerated into ghouls, who do not hunt and feed to strengthen themselves, but only to carry on, prolonging their putrescent decrepitude.10

These Grey Anglo-Saxon Protestant capitalist sorcerers seldom appear in the light. They pay their subordinates well — all those CEOs, politicians, columnists — to spin the line that England in 2015, possibly the most depressed country ever to exist on Earth, is some shining island of freedom and wealth that immigrants are desperate to get into. Only in secret do they boast to capital’s other subterranean agents that England’s chief export product is the “historical defeat of the working class”:

What is England’s export product? Supposedly, it’s finance. To some degree it’s as lieutenant to America’s empire, but that’s limited. We have a real-estate bubble on the basis of the finance system, because every single super-rich person in the entire world has to have a house in London, so they’re selling bits of London and the south-east.

Why is it appealing? On the one hand, you have a creative, subservient working-class. You get the best servants here. Second of all, it’s security; you have political safety, whereas if you come from Bahrain, Singapore, Macau, in those places something could still happen.11

“Democracy is Joy”

Neoliberalism has reached the point where it is now forced to undermine its own libidinal and ideological bases. The Troika’s naked attempts to unseat Syriza are unpicking the natural(ised) association of capitalism with democracy upon which capitalist realism has depended. In this final phase, capitalist realism cannot even muster the pretence that it can even tolerate democracy, still less that capitalism is the only political system compatible with democracy.

Apparently that Greek referendum was “polarising”. Was it? when 60% voted no, and no single area voted otherwise? Seems more likely to be unifying than polarising. Perhaps that’s the problem. Turns out the consensus is not where you thought it was.

Any question which asks for yes or no is sort of likely to be “polarising” anyway, isn’t it?

“Polarising” in most of these repeated uses means that the mass of people have been asked to consider issues fundamental to their lives: these are difficult questions. It would be better if they didn’t task themselves with them and can’t understand them anyway, so “polarising” equals, likely to cause thought, debate, dispute and subject them to the stresses of political agency. How dare a government go to the people with such pressing and complex questions, when its job is to shield them from the difficulty of thought via technocracy. Polarising here just means profound questions, questions that touch and demand action on fundamental aspects of social organisation.

But to be asked such questions and to debate or dispute them isn’t vexing, harrowing or painful, it’s essential and welcome. Political agency is not a burden, it’s its absence which weighs on you and its apparent “demands” are experienced instead as a euphoria, a lightening of the load, a lifting up. The powerful affective elements of mass participation are something Jeremy Gilbert gets at well in Common Ground, and the hunger and need for these kinds of intensities is palpable.

In his speech before the vote last night Tsipras observed, at least so the translation ran, “Democracy is joy”. (Carl Neville)

Now listen to capitalist realism’s useful idiots line up on Twitter:

Dan Hodges: I’ve just held a referendum of myself, and I’ve voted overwhelming not to pay off my credit card bill or mortgage this month.12

Simon Schama: I’m voting No to my credit card bill today. This will put me in a much stronger position to negotiate a repayment schedule.13

I’m voting No to facile folk economic bullshit. I’m voting No to bank bailouts and banker’s bonuses paid out of public money. Oh, it seems I can’t vote on that.

We live in capitalism, its power seems inescapable — but then, so did the divine right of kings.14

There is a possible alternative, however, in which ownership and control of robots is disconnected from capital in its current form. The robots liberate most of humanity from work, and everybody benefits from the proceeds: we don’t have to work in factories or go down mines or clean toilets or drive long-distance lorries, but we can choreograph and weave and garden and tell stories and invent things and set about creating a new universe of wants. This would be the world of unlimited wants described by economics, but with a distinction between the wants satisfied by humans and the work done by our machines. It seems to me that the only way that world would work is with alternative forms of ownership. The reason, the only reason, for thinking this better world is possible is that the dystopian future of capitalism-plus-robots may prove just too grim to be politically viable. This alternative future would be the kind of world dreamed of by William Morris, full of humans engaged in meaningful and sanely remunerated labour. Except with added robots. It says a lot about the current moment that as we stand facing a future which might resemble either a hyper-capitalist dystopia or a socialist paradise, the second option doesn’t get a mention.15





cybergothic vs. steampunk1

In December 2015, Hilary Benn made a speech in the House of Commons, supporting air-strikes against Syria.2 The speech, and the hysterical acclaim it received, were an exercise in retromania: the equivalent in politics of what the “new” Star Wars film is in cinema: the same old thing again, but worse. Benn’s intervention was a repetition of exactly the kind of speech that was made to justify the attack on Saddam Hussein, and which therefore led to the emergence of ISIS.

One great value of Badiou’s intervention3 is that it checks any temptation to treat all this as if were just a mistake. As Badiou makes clear, from the point of view of capital, the Iraq war and its consequences were not some blunder. They were an opportunity to trial a new form of (post)colonialism, in which states of conflict open up a temporary autonomous zone for capital accumulation, and plundering can continue without the irksome duties involved in setting up and running a state.

The capitalist “West” has only ever been a structural fantasy of independence and separation from what is outside, a fantasy that is failing now that the border policing on which it depends no longer works. The enemy is already inside, while the victims can no longer obligingly remain offscreen, even if they wanted to.

Badiou and Benn are in agreement about one thing, however: that ISIS can be described as fascists. While this classification is tempting, it obfuscates rather than illuminates the nature of ISIS’s malignancy and its relationship to the current (decadent and doomed) phase of capitalist domination. Badiou is closer when he characterises ISIS as gangsters: they are indeed part gang, part apocalyptic cult, part franchise. If nothing else, ISIS is a slick brand — a brand that is far more effective than anything capital can come up with at the moment in any case.

ISIS holds up a mirror to twenty-first-century capitalist nihilism. This nihilism does not have the Mephistophelean fervour of nineteenth-century existentialism, nor is it the cold scientific nihilism described by Ray Brassier. This is a boring nihilism: an existential poverty that accompanies the material poverty into which capital plunges so many. A tiny minority escape material poverty, but only capital’s most devoted addicts can evade existential poverty.

Capitalist realism was only ever a fantasy — a fantasy that the human resources capital needs for its growth were as infinite as its own drive. Yet capital is now coming up against limits of all kinds, and existential limits are not the least of these. Capital cannot care, but humans cannot help but care. For all the capitalist realist posturing, the open secret is that human beings continue to engage in caring and nurturing practices, practices which, moreover, remain more important to them than anything capital can offer. Shopworn PR injunctions won’t cut it in any more. How can you believe that “anyone can make it”, when you and everyone you know is unemployed or underemployed? When the reward for poorly paid night shifts and cold early mornings is more of the same, if you are lucky? You can never do enough for capital. It’s not enough to produce and retail shoddy commodities no one really wants — you must also be “passionate” about it.

When Ken Livingstone talked a while ago of ISIS members “giving up their lives” for the cause, he was shouted down in yet another example of desperate capitalist media decadence (the British media abounds in such examples, a sign that is in its death throes). The distinction between understanding something and justifying it is elementary, and Livingstone was making a similar point to the observation that Michael Corleone makes about the Cuban rebels in Godfather II. “I saw a strange thing today”, Michael remarks to Hyman Roth. “Some rebels were being arrested. One of them pulled the pin on a grenade. He took himself and the captain of the command with him. Now, soldiers are paid to fight; the rebels aren’t.” “What does that tell you?”, Roth asks. “They could win”, Michael replies. ISIS won’t win, but the analogy points to the very serious problem that capital now faces. Paying people has never touched people’s deepest motivations. You need to offer some other cause, some other purpose. What happens when you demoralise people, destroy their capacity to commit to any purpose in life beyond capital accumulation, and don’t even pay them? What if you don’t even offer them the possibility of being exploited, and classify them as a surplus population?

Capital doesn’t have much of an answer, but ISIS does. A disputed poll “suggested that more than one in four French youth between the ages of 18 and 24 have a favourable or very favourable opinion of ISIS, although only 7–8% of France is Muslim.”4 Whatever the truth of this survey, the willingness to believe it indicates that there is a growing suspicion that societies dominated by capital are now encountering mass disaffection and defection. “More than three of every four who join ISIS from abroad do so with friends and family. Most are young, in transitional stages in life: immigrants, students, between jobs and mates, having just left their native family. They join a ‘band of brothers (and sisters)’ ready to sacrifice for significance.”5 The motivation is belonging and fellowship, not hatred. “A survey of those Saudi men who volunteered for Afghanistan and who later fought in Bosnia and Chechnya or trained in al-Qaeda camps has found that most were motivated not by hatred of the west but by the desire to help their Muslim brothers and sisters.”6 For all that ISIS offers horrifically false solutions, it responds to real problems. (In calling Islamism identitarian, Badiou doesn’t credit the extent to which ISIS offers at least a partial escape from the dismal identities that capitalism has assigned to so many young muslims, and to so many others too.)

Capital is nothing if it is not parsimonious, and for the last thirty years it is has sustained itself by relying on readymade forms of existential affiliation. This reliance on already-existing forms of identification — all those nationalisms and religions, with any number of archaisms ready to crawl out of the crypt — is what postmodernism has been. There are no “pure” archaisms, nothing ever repeats without difference, and ISIS is properly understood as a cybergothic phenomenon which combines the ancient with the contemporary (beheadings on the web). It faces not a confident capitalist modernity, but a capitalism that has retreated from the present, never mind the future. Left to its own resources — or rather, left to the resources it retains from previous forms of exploitation — capital can never come up with anything new. Postmodernism was its ideal form, and the naturalised postmodernism of capitalist realism was its optimal solution to political and cultural antagonism. The UK has specialised in developing the steampunk model: Victorian social relations, but now with iPhones.

But the conditions which sustained capitalist realism have now evaporated, and the real enemy which prompted the neoliberal counter-revolution is re-emerging. This enemy was not the necrotic Stalinist monolith of the USSR; still less was it the cult of Parisian Maoism, which was only ever the most minor of distractions. No: neoliberalism was designed to eliminate the various strains of democratic socialism and libertarian communism that bubbled up in so many places during in the Sixties and Seventies. Wherever this possibility emerged, capital crushed it, most ruthlessly and most spectacularly in Chile. But the rising tide of experimental political forms in so many areas of the world at the moment shows that people are rediscovering group consciousness and the potency of the collective. It is now clear that molecular practices of consciousness-raising are not opposed to the indirect action needed to bring about lasting ideological shifts — they are two aspects of a process that is happening on many different time tracks at once. The growing clamour of groups seeking to take control of their own lives portends a long overdue return to a modernity that capital just can’t deliver.7 New forms of belonging are being discovered and invented, which will in the end show that both steampunk capital and cybergothic ISIS are archaisms, obstructions to a future that is already assembling itself.





mannequin challenge1

One of the images that has most haunted me since the election is that of Clinton and her close allies doing their version of the “mannequin challenge” on the campaign plane. It wasn’t only the smugness of this scene which irked (but just check out the sheer amount of self-satisfaction packed into Hillary’s grin); it was the sense that this simulation of stasis — reminiscent of the eerie scenes in Westworld in which the android-hosts are temporarily put into sleep-mode — actually revealed what the Clinton campaign was composed of: decommissioned political robots playing out an exhausted programme one last time before being permanently taken offline. The uncomfortable irony is that this final-day promotional video’s injunction — don’t stand still, vote today — is, unfortunately, exactly what too many of Clinton’s potential supporters did. But it was also what Clinton’s whole campaign had done: stayed still. While Trump’s campaign was possessed of a sense of effervescing excitement, of anarchic unpredictability, the feeling of belonging to a building-movement, Clinton’s offered only more of the same. Or the same, but less. Its message was not only that nothing much will change, but also that nothing much needs to change.

This paralysis cannot be attributed only to the complacency and insularity in the Clinton camp; it is instead a symptom of a broader pathology afflicting the “centre-left”. “Centre-left” has to be placed in inverted commas here because the malaise is in large part a consequence of this group’s failure to register that the “centre” to which it is attached and from which it takes all its bearings has disappeared. In addition to the parallels with Brexit, there are clear echoes of the last UK General Election. Rather like Ed Miliband, Clinton lost essentially because she was unable to mobilise her own supporters. It turns out that there wasn’t much of a surge to the right: as Gary Younge points out in an invaluable piece, Trump “may have led the charge to the right but comparatively few marched with him”2 (he ended up winning a lower proportion of the vote than losing candidates John Kerry, John McCain, Mitt Romney and Gerald Ford). Instead, there was an evacuation of the centre. Like Boris Johnson, Trump is opportunistic; but it is this opportunism which enabled him to respond to transformed conditions and to be seen to respond to them — something which his own party’s ruling establishment, just as much as Clinton’s Democrats, were singularly unable to do.

The mood that Trump and Brexit caught is a dissatisfaction with capitalist realism. Yet it isn’t capitalism that is being rejected in these inchoate revolts, but realism. When Simon Reynolds wrote about Trump a few weeks ago, he picked up on a quotation from The Art of the Deal “I play to people’s fantasies”.3 The turn to fantasy is crucial to the current success of the right represented by Trump and Brexit.

What both Trump and the Brexiteers are selling is a fantasy of nationalist revival. The automatic deference to economic “good sense” and corporate “expertise” on which capitalist realism has relied. Genuflections to… which only a few months ago were a requirement for anyone serious about pursuing power, have now become toxic. Rather than adding to her authority, Hillary Clinton’s closeness to Wall Street confirmed her reputation as a stooge of the status quo; just as the appeals made by David Cameron — who already seems like a figure from a long-ago era — to “experts” proved in the end to be disastrously counterproductive. In the fantasy of nationalist revival, “experts” are refigured, not as avatars of an economic reality principle, but as spoilers and obstructors, enemies of the resurgent will.

The Brexit vote was practically a case study of what Paul Gilroy calls postcolonial melancholia. Trump’s rise — Make America Great Again! — is the American equivalent of the same phenomenon. As Gilroy points out, this melancholia has its manic and jubilatory aspects, but it is rooted in a longing for an idealised past, and a denial of the complexities and perplexities of the present… Since it is organised around desires that are impossible to satisfy, the flight into fantasy will of course be very far from some harmless exercise in escapism; immense damage will inevitably be done in the attempt to preserve these //// of restoration and “purification”. Postcolonial melancholia is caused by “the loss of the fantasy of omnipotence”, at the same time as it is a compensatory strategy which renders the disappearance of a sense of omnipotence as a merely temporary matter, soon to be rectified. It is precisely the fantasmatic dimension of feelings of omnipotence that is denied in Trump’s rhetoric. The omnipotence was real — the fall into vulnerability and malaise is to be attributed to a depressive stupor, which will be overcome by a recovery of will and belief: nationalist magical voluntarism.

The jubilatory denial of the constraining power of economic conditions — and ultimately of any conditions — accounts in part for the striking differences in libidinal tenor between the Clinton and Trump campaigns. Clinton’s buttoned-up poise, her rendition of an obsolete “good sense”, and her failure to recognise that the “centre” ground on which she stood had collapsed beneath her, was a personification of capitalist realism at its most staid and shopworn: entirely devoid of any capacity to inspire, and mired in a near-past for which few express any nostalgia. If Obama came to represent a version of capitalist realism — the narrative arc of his presidency, after all, saw euphoric “change” and “hope” quickly declining into deadlock and impasse — he nevertheless possessed a grace, equanimity and charisma that Clinton could never muster. He gave late-period capitalist realism and geopolitical realpolitik a serious, personable and thoughtful face; and, in spite of all the disappointments and jading, his being president at all still possessed a quality of the unexpected and the momentous. For all that Clinton’s accession to the presidency would have been momentous, it didn’t feel that way. Her status as tarnished dynastic insider always overshadowed her position as gender outsider.

In any case, Trump’s immoderation was a break with all of this. His displays of unbound libido have a performative dimension. Trump’s “unprofessional” “lapses”, his seeming faux pas, his ready descent into racist invective and misogyny, his hate-mongering: these are significant not only for their attraction to those already evincing such attitudes. They also have an appeal to some of those who don’t share them, and who might even deplore them: what such outbursts come to signify is both an “authenticity” — a simulation of “straight talking” — and, equally importantly, a performance of libidinal freedom. I’m by no means the first to note the parallels with Silvio Berlusconi, Trump’s most obvious precursor. Franco Berardi has rightly argued that much of Berlusconi’s appeal came from his “ridiculing of political rhetoric and its stagnant rituals”. Voters were invited to identify “with the slightly crazy Premier, the rascal Prime Minister who resembles them”. Voters too don’t always say the right thing (and they certainly say things in private which they wouldn’t want broadcast in public); they too have contempt for the staid conventions of parliament. Needless to say, “resemblance” of this sort is always cultivated and engineered; voters are directed into selecting and identifying with some of their own traits at the expense of others. Like Berlusconi, Trump disdains law and rules “in the name of a spontaneous energy that rules can no longer bridle”. Those disquieted or even disgusted by his racism and misogyny could nevertheless still be excited by Trump’s disregard for politesse, procedure and precedent. It was Trump’s excess which allowed him to appear as the “candidate of change”, something which many of his supporters insistently cited as the reason that they voted for him. Simon Reynolds refers to

the edgy promise of a less boring politics. The New York Times recently quoted a voter who confessed to flirting with the idea of voting for Trump because “a dark side of me wants to see what happens… There is going to be some kind of change, and even if it’s like a Nazi-type change, people are so drama-filled. They want to see stuff like that happen.”4

As such, you might say, Trump was less the glam than the punk candidate, possessing the same combustible, fissile mixture of the reactionary and the… that characterised so many punk acts. Punk’s political… boredom… mid-Seventies stasis was so enervating that any change would be better. Well, after Brexit and Trump, we can say with certainty: boring dystopia is over. We’re in a whole other kind of dystopia now.

In Trump’s case, the fantasies of national restoration reassure, mitigating the sense of risk that he provokes. It’s almost as if the fantasies give permission to indulge in the excitement… Vertiginous change and a restored past, all in the same moment; Trump has found a way to renew the formula that the right has successfully deployed since Reagan and Thatcher. (And one perennial problem for the revolutionary left is that it doesn’t have the same recourse to reassuring fantasies, the same appeal to a restored past, with which to leaven the leap into the unknown.)

Then there are the fantasies of class… at which Trump excelled. “The real story of this election”, Fukuyama argued,

is that after several decades, American democracy is finally responding to the rise of inequality and the economic stagnation experienced by most of the population. Social class is now back at the heart of American politics, trumping hah! () other cleavages — race, ethnicity, gender, sexual orientation, geography — that had dominated discussion in recent elections.”5

Martin Jacques made similar claims in the Guardian:

The wave of populism marks the return of class as a central agency in politics, both in the UK and the US. This is particularly remarkable in the US. For many decades, the idea of the “working class” was marginal to American political discourse. Most Americans described themselves as middle class, a reflection of the aspirational pulse at the heart of American society. According to a Gallup poll, in 2000 only 33% of Americans called themselves working class; by 2015 the figure was 48%, almost half the population. … () Brexit, too, was primarily a working-class revolt. … () The return of class, because of its sheer reach, has the potential, like no other issue, to redefine the political landscape.6

Bernie Sanders…; but the version of class politics offered by Trump and Brexit is nothing new at all. It repeats a divide-and-rule strategy used by Nixon, Thatcher and many other right-wingers for many years. What we have seen in both Trump’s win and Brexit is a perpetual obfuscation of class via race and nationalism. Both Trump and the Brexiteers proffered a highly racialised account of class politics, as the very term “white working class” implies. The depredations that the working class have faced under neoliberalism were relentlessly attributed to racialised others: immigrants, economically aggressive foreign powers… Converting class antagonism into racialised and nationalistic resentment has been central to the success of UKIP, but it didn’t invent so much as intensify a strategy that has served the right well for forty years.

On the face of it, it’s incredible that Trump could in any way persuasively appear to be a man of the people — to come off, in the astonishing words of his son, as “a blue collar guy with a big balance sheet”. It’s not as if Trump, who inherited his wealth (and effectively squandered much of it) is even a self-made man who came from any kind of modest background. No doubt this is one more example of the subordinated being seduced into identifying with the rich (and thus, for instance, opposing the imposition of higher taxes on the super-wealthy). If Trump is a “blue collar guy with a big balance sheet”, then those who engage in this fantasmatic identification are blue-collar folk who don’t yet happen to have a big balance sheet (but who, in the fantasy, will surely get one in the end). But this doesn’t answer the question of how Trump in particular — and of all people — was capable of engendering this fantasy. I think that there are at least four (strongly related) reasons for this: his ability to seem to be in tune with working-class worries and concerns; his… liberal-professional elite; his comportment; and his position in the media ecology.

Contrary to how he was portrayed in the mainstream media Trump did not talk only of walls, immigration bans, and deportations. In fact he usually didn’t spend much time on those themes. … () T ()he heart of his message was something different, an ersatz economic populism, which has been noted far and wide, but also a strong, usually overlooked, anti-war message. Both spoke to legitimate working class concerns. … () Trump took the Bernie-style populism, emptied it of real class politics, reduced it to a jumble of affective associations, and used it to beat-up the smug liberals of the professional managerial class.7

“Populism”, Francis Fukuyma argued back in June, “is the label that political elites attach to policies supported by ordinary citizens that they don’t like.”8 Yet these policies aren’t typically generated by “ordinary citizens” themselves; more often, they are attempts by elites to ventriloquise desires and anxieties “ordinary citizens” are held to have. Right-wing populism of the kind Trump and Brexit represent is a gambit in a struggle amongst different versions of the elite. Crucial to this process is the way in which the opposing elite is characterised. At least since Nixon, the right has identified the “bad” elite as a “liberal” clique, with its cosmopolitan ease, its remoteness from ordinary life, and its contempt for the supposed vulgarity, insularity and chauvinism of the subordinated classes. Such an elite really does exist, of course, and its domination of large areas of the left since the 1960s has made it easy for the right successively to pull different versions of the trick that Trump… in this campaign. Trump reassures and flatters his supporters: the problem is not you, he says, but the Others, once we’ve built the wall, everything will be OK. By contrast, the message from the left, Trump says, is that the problem is you; the Others are OK, deserving of special favours that won’t be granted to you.

Joan C. Williams claims, in a problematic piece that nevertheless makes some interesting points, Trump’s success is also the consequence of a particular kind of resentment, whereby “the white working class (WWC)” “resents professionals but admires the rich.”9 If Hillary Clinton, Williams argues, “epitomises the dorky arrogance and smugness of the professional elite”, then, like something out of Ballard’s Kingdom Come — a poor novel but prescient social prophecy — Trump has come out of a fusion of celebrity culture and business that currently possesses far more hegemonic pull than the arid professional politics which Clinton drearily personifies. This form of populism depends upon television’s simulation of intimacy and familiarity — McLuhan remarked that when people see a film star on the street, they recognise them, but when people see a TV star, they typically think that it is someone they know. Trump’s presiding over The Apprentice, his willingness to appear on shows such as The Roast of Donald Trump, means that he feels like someone audiences personally know. As a representative of this “professional elite”, Clinton was too close, too familiar. At the same time, Trump’s position in the media ecology means that, in some respects, he could seem less remote than Hillary Clinton.

What we are seeing, evidently, is not an attack on the establishment from outside (or below), but the replacement of one form of establishment with another. And one reason that this insurgent establishment — neo-authoritarian and neo-nationalist rather than neoliberal — has been able to overcome its rivals is that it has stirred up a populist political fervour that capitalist realism tended to damp down. Capitalist realism secured its hegemony by de-activating people as political agents and re-interpellating them as entrepreneurial individuals. It wanted to close down political movements, not build them, all the better to organise and administrate policy from above.

Faced with Trump’s performance of unbound libido…

The danger here is in conflating this return of class with class agency. One of the most telling — and poignant — phenomena in the wake of the UK referendum on EU membership was a particular kind of dismay expressed by some of those who had voted leave. They were alarmed by the result because “they didn’t think their vote would count”. Still others claimed that a decision this momentous shouldn’t have been left to them. Brexit may have been supported by large numbers of the working class, but this is very far from its being an expression of self-conscious working-class agency.

It is certainly a mistake to oppose this current form of class politics to race. What is new is the disappearance of any countervailing pressures from the advocates of globalisation, free trade, etc. The tension that has defined the neoliberal right for forty years — in which ostensibly opposing positions in practice complemented one another — has now become a scission. What does this mean?

It means, first, that this right has retreated from its claim on modernity. Neoliberal ideology made neoliberalisation seem as if it were synonymous with modernisation. But it is exactly this modernity that the right is now rejecting. In place of the neoliberal embrace of a globalised present, there is now only a turn backwards, and inwards. The Brexit vote was driven by what Paul Gilroy has called “postcolonial melancholia”, and Trump’s rise has clearly been powered by the American equivalent of this phenomenon.

But the right’s retreat from modernity gives all the more impetus for the left to reclaim it. Current right-wing populism is responding to real problems of the neoliberal world. In addition to economic stagnation, it is also offering a balm for the existential deficit in contemporary capitalism: the banal nihilism of a world cored out by capitalist imperatives. Its answer, naturally, is nationalism. But this is by no means the only response to the problem of belonging. Control of their own lives.





PART FIVE

WE HAVE TO INVENT THE FUTURE: INTERVIEWS





they can be different in the future too: interviewed by rowan wilson for ready steady book (2010)1

In 2010, Rowan Wilson interviewed Mark for Ready Steady Book about the “para-space” of Zer0, blogging and cyberculture, capitalist realism, hauntology and lost futures.

Rowan Wilson: Your blog, k-punk, is one of the leading blogs for cultural analysis. When did you first start writing it and why did you start?

Mark Fisher: Thank you. I started it in 2003. At the time, I was working as a philosophy lecturer in a Further Education college in Kent — I reflect on some of my experiences there in Capitalist Realism. I was then quite badly depressed — not because of teaching, which I enjoyed, but for a whole series of long-term reasons — and I started blogging as a way of getting back into writing after the traumatic experience of doing a PhD. PhD work bullies one into the idea that you can’t say anything about any subject until you’ve read every possible authority on it. But blogging seemed a more informal space, without that kind of pressure. Blogging was a way of tricking myself back into doing serious writing. I was able to con myself, thinking, “it doesn’t matter, it’s only a blog post, it’s not an academic paper”. But now I take the blog rather more seriously than writing academic papers. I was actually only aware of blogs for a short while before I started mine. But I could quite quickly see that the blog network around Simon Reynolds’ blog — which was the first network I started to read — fulfilled many of the functions that the music press used to. But it wasn’t just replicating the old music press; there were also sorts of strange, idiosyncratic blogs which couldn’t have existed in any other medium. I saw that — contrary to all the clichés — blogs didn’t have to be online diaries: they were a blank space in which writers could pursue their own lines of interest (something that it’s increasingly difficult for writers to do in print media, for a number of reasons).

RW: You’re almost one of the elder statespeople of blogging now. How has it changed since you started?

MF: Blogging networks shift all the time; new blogs enter the network, older ones fall away; new networks constitute themselves. One of the most significant developments was the introduction of comments; a largely unfortunate change in my view. In the early days of blogs, if you wanted to respond to a post, you had to reply on your own blog, and if you didn’t have a blog, you had to create one. Comments tend to reduce things to banal sociality, with all its many drawbacks.

Yet blogs continue to do things that can’t be done anywhere else: look at the way that Speculative Realism has propagated through blogs. Originally coined as term of convenience for the work of the philosophers Ray Brassier, Graham Harman, Iain Hamilton Grant and Quentin Meillassoux, Speculative Realism now has an online unlife of its own. This isn’t just commentary on existing philosophical positions; it’s a philosophy that is actually happening on the web. Graham has his own blog, Object-Oriented Philosophy, but there are a whole range of Speculative Realism-related blogs, including Speculative Heresy and Planomenology. Reid Kane of Plamomenology has gone so far as to argue that Speculative Realism is “the first avatar of distributed cognition”, that, in other words, there is a natural fit between SR and the online medium.

RW: You were one of the co-founders of the Cybernetic culture research unit (Ccru), described by Simon Reynolds as the academic equivalent of Apocalypse Now’s Colonel Kurtz. Who did you form it with and what was its purpose?

MF: The main driving forces behind it were Sadie Plant and Nick Land. But Sadie Plant left quite quickly so the Ccru as it developed was much more shaped by Nick Land. Nick’s 1990s texts — which are to be issued in a collected edition this year, by Urbanomic, who publish the Collapse journal — are incredible. Far from the dry databasing of much academic writing or the pompous solemnity of so much continental philosophy, Nick’s texts were astonishing theory-fictions. They weren’t distanced readings of French theory so much as cybergothic remixes which put Deleuze and Guattari on the same plane as films such as Apocalypse Now and fictions such as Gibson’s Neuromancer.

Jungle was crucial to the Ccru. What the Ccru was about was capturing, (and extrapolating) this specifically British take on cyberculture, in which music was central. Ccru was trying to do with writing what jungle, with its samples from such as Predator, Terminator and Blade Runner, was doing in sound: “text at sample velocity”, as Kodwo Eshun put it.

RW: The writing of the Ccru seems very different to your current style. Are you still involved with the Ccru — and indeed is it still operating?

MF: It was never formally disbanded but then again it was never formally constituted. It’s odd because, it’s only a decade on that the stuff is starting to get published in book form. As I said, Nick’s texts are just about to be published. Steve Goodman (aka Kode9) has just had his book Sonic Warfare published on MIT Press. As for the change of style, I suppose a number of things happened. One was the slowing of the UK cyberculture that had inspired the Ccru throughout the Nineties. Gradually, the exorbitant hypotheses of the Ccru seemed to have less purchase on a culture that increasingly seemed to correspond more with Jameson’s ideas of retrospection and pastiche. In the Nineties, it was possible to oppose a vibrant cyberculture to the malaise which Jameson identified. But in the Noughties, the blight of postmodernism spread everywhere.

Also, I found that, as I started teaching regularly, and as I got used to writing for an audience — and there’s no form of writing that makes you as aware of having an audience as blogging; print publications just don’t compare — I rediscovered rhetoric, argument and engagement. The exhilaration of the Ccru-style was its uncompromising blizzard of jargon, text as a tattoo of intensities to which you just had to submit. But it’s hard to maintain that kind of speed-intensity for longer writing projects; and I found that I enjoyed producing writing that was expositorier and which tried to engage the reader rather than blitz them. I like Žižek’s line that the idiot he is trying to explain philosophy to is himself; I feel the same. Much of my writing now is me trying to explain things to/for myself.

There were also political schisms. The Ccru defined itself against the sclerotic stranglehold that a certain moralising Old Left had on the Humanities academy. There was a kind of exuberant anti-politics, a “technihilo” celebration of the irrelevance of human agency, partly inspired by the pro-markets, anti-capitalism line developed by Manuel DeLanda out of Braudel, and from the section of Anti-Oedipus that talks about marketisation as the “revolutionary path”. This was a version of what Alex Williams has called “accelerationism”, but it has never been properly articulated as a political position; the tendency is to fall back into a standard binary, with capitalism and libertarianism on one side and the state and centralisation on the other.

But working in the public sector in Blairite Britain made me see that neoliberal capitalism didn’t fit with the accelerationist model; on the contrary, pseudo-marketisation was producing the pervasive, decentralised bureaucracy I describe in Capitalist Realism. My experiences as a teacher and as trade union activist combined with a belated encounter with Žižek — who was using some of the same conceptual materials as Ccru (the Freudian death drive; pulp culture, technology), but giving them a leftist spin — pushed me towards a different political position. I guess what I’m interested in now is in synthesising some of the interests and methods of the Ccru with a new leftism. Speculative Realism has returned to some of the areas that the Ccru was interested in. What I’m hoping will happen in the next decade is that a new kind of theory will develop that emerges from people who have been deep-cooked in post-Fordist capitalism, who take cyberspace for granted and who lack nostalgia for the exhausted paradigms of the old left.

RW: One of the most exciting things to happen in publishing last year was the development of the Zer0 Books imprint. Can you explain how that came about and the purpose of the project?

MF: The imprint was set up by the novelist Tariq Goddard. He asked Nina Power and me if we’d like to do books, and we suggested a range of other people. What we wanted was to produce the kind of books we’d want to read ourselves, but which weren’t being published anywhere. In mainstream media, the space that had drawn Tariq and myself towards theory in the first place — the music press, areas of the broadcast media — had disappeared. Effectively, that kind of discourse had been driven into exile online. So part of what Zer0 was about was harvesting the work that has been developed on the blog networks. Zer0 is about establishing a para-space, between theory and popular culture, between cyberspace and the university. The Zer0 books are a reminder of what ought to be obvious, but which the imbecilic reductionism of neoliberal media would like us to forget: serious writing doesn’t have to be opaque and incomprehensible, and popular writing doesn’t have to be facile.

RW: Your first book, Capitalist Realism: Is There No Alternative?, was published by Zer0 in November. Why do you think that capitalism, even in the wake of the financial crisis, has such a grip on our consciousness?

MF: I’m not sure that it has a grip on our consciousness so much as on our unconscious. It shapes the limits of what we can imagine. It does so because it has enjoyed twenty years of unchallenged domination, blitzing our nervous systems with its intoxicants, paralysing thought. Put at its simplest, capitalist realism is the widespread idea that capitalism is the only “realistic” political economic system. The response to the financial crisis only reinforced this belief — it was (on every level) unthinkable that the banks could be allowed to crash. The problem is imagining an alternative that anyone believes could be actually attained. Which isn’t to say that an alternative can’t ever come about; in fact, after the financial crisis, we’re in the bizarre situation at the moment where everything — very much including the continuation of the status quo — looks impossible. But this is already an improvement from how things seemed only two years ago. The financial crisis forced capitalist realism to change its form. The old neoliberal story was no longer viable. But capital has not yet cobbled together much of a new narrative, or come up with any economic solution to the problems that led to the crash in the first place. It’s as if capitalism has suffered its own version of shock therapy.

RW: How is your argument different from that put forward by Fredric Jameson in his work on the culture of postmodernism?

MF: Well, as I say in the book, in many ways what I’m calling “capitalist realism” can be contained under the rubric of Jameson’s theorisation of postmodernism. Yet the very persistence and ubiquity of the processes that Jameson identifies — the destruction of a sense of history, the supersession of novelty by pastiche — meant that they have changed in kind. Postmodernism is now no longer a tendency in culture; it has subsumed practically all culture. Capitalist realism, you might say, is what happens when postmodernism is naturalised. After all, we’ve now got a generation of young adults who have known nothing but global capitalism and who are accustomed to culture being pastiche and recapitulation.

RW: In the book you move from describing the problems of capitalist society to how it is making us mentally ill. What do you think are the central lasting effects of neoliberalism on our psyches and, with its collapse, how do you see these unravelling?

MF: Neoliberalism installs a perpetual anxiety — there is no security; your position and status are under constant review. It’s no wonder that, as Oliver James shows in The Selfish Capitalist, depression is so prevalent in neoliberalised countries. Widespread mental illness is one of the hidden costs of neoliberal capitalism; stress has been privatised. If you’re depressed because of overwork, that’s between you and your brain chemistry!

I do think that the financial crisis killed neoliberalism as a political project — but it doesn’t need to be alive in order to continue to dominate our minds, work and culture. Even though neoliberalism now lacks any forward momentum, it still controls things by default. So, sadly, I don’t see the deleterious psychic effects of neoliberalism waning any time in the immediate future.

RW:You identify the madness of managerial bureaucracy, the incessant and pointless “auditing culture”, in contemporary public services, specifically education. You discuss how this auditing culture is now, along with capitalism’s PR network, a new big Other, a replacement for God. It’s the ideological matrix that we all cynically dismiss but nonetheless remains the binding authority. Why are we not simply able to shrug it off?

MF: PR is not limited any more to specific promotional activities — as I say in the book, under capitalism, all that is solid melts into PR. In so-called “immaterial” labour, the effect of auditing is not to improve actual performance but to generate a representation of better performance. It’s a familiar effect that anyone subject to New Labour’s targets will know all too well.

Neoliberalism reproduces itself through cynicism, through people doing things they “don’t really believe”. It’s a question of power. People go along with auditing culture and what I call “business ontology” not necessarily because they agree with it, but because that is the ruling order, “that’s just how things are now, and we can’t do anything about it”. That kind of sentiment is what I mean by capitalist realism. And it isn’t merely quietism; it’s true that almost no one working in public services is likely to be sacked if they get a poor performance review (they will just be subject to endless retraining); but they might well be sacked if they start questioning the performance review system itself or refusing to cooperate with it.

RW: So now we move from the critique to the positive proposals. In an interview with Matthew Fuller for Mute you tentatively suggest that the left needs to come up with a new big Other, one that is more representative of Rousseau’s “general will”. How is this to be distinguished from the capitalist big Other and how would it be prevented from becoming reified, a new system of mystical dominance?

MF: Reification isn’t a problem per se; in fact, it’s something we should hope for. Evan Calder Williams, whose book Combined and Uneven Apocalypse is coming out on Zer0, talks of an “anti-capitalist reification”, and I think that’s what we need to develop. It’s capitalism that poses as being anti-reification; it’s capitalism that presents itself as having dissolved all illusions and exposed the underlying reality of things. Part of what I’m arguing in Capitalist Realism is that this is an ideological sleight of hand; it’s precisely neoliberal capitalism’s ostensible demystifications (its reduction of everything to the supposedly self-evident category of the free individual) that allow all kinds of strange, quasi-theological entities to rule our lives. But I don’t think the aim should be to replace capitalism’s fake anti-reification with a “real” anti-reification. Reification can’t be entirely eliminated. I take this to be one of the important lessons that Lacanian psychoanalysis has to teach. Being a speaking subject at all involves a minimal reification; the big Other is coterminous with language itself. But this is very far from being a problem for the left. It’s the left that needs to insist on the reality of something in excess of individuals, whether you call it the “general will”, the “public interest”, or something else. When Mrs Thatcher famously denied the existence of society, she was echoing Max Stirner’s claim that all such abstractions are “spooks”. But we can’t ever rid ourselves of these incorporeal entities — neoliberalism certainly hasn’t. As I argue in Capitalist Realism, neoliberalism hasn’t killed the big Other — for who is the consumer of PR (which no actual empirical individual believes) if not the big Other? The point now — and I would affirm this forcefully, not tentatively — is to invent a leftist big Other. This doesn’t mean reviving authoritarianism; there is no necessary relation between the big Other and a strong leader. On the contrary, in fact, authoritarianism happens when there is a confusion between the big Other (as virtuality) and an empirical individual. What we need are institutions and agents that will stand in for — but cannot be equated with — a leftist big Other.

RW: You talk about the re-formatting of memory that is a symptom of capitalist realism, where history can be altered almost instantly (as in a Philip K. Dick novel) as we stand agog before the supposed ceaseless innovation of capitalism. You were also one of those to start using the concept “hauntology”, the idea that there was a cultural meme that acknowledged the collapse of a moment and picks through the remains for the lost futures buried within. Similarly, we are in a political landscape littered with “ideological rubble” (as you quote Alex Williams). My suspicion is that for you the “moment” that has collapsed is the politics of 68, one that was perhaps guilty of the re-formatting of history and memory in its own way, before many of its ideas were taken up by a post-Fordist capitalism. So what is the detritus that you are picking through? What of the discarded remnants of left politics would you dust off? And is it possible to give old ideas new momentum?

MF: I would say that, in many ways, the politics of 68 haven’t collapsed enough. 68 is a spectre which still hangs over theory. Yet the forces which 68 railed against no longer exist; there is no Stalinist Party or State that we need to blow apart with a Cultural Revolution. Which isn’t to say that we should want to return to Stalinist authoritarianism, or that it is possible to do so; the oscillation between these two options is the sign of a failure of political imagination. It’s necessary to go all the way through post-Fordism, to keep looking ahead, especially at times when there seems to be nothing ahead of us. Part of the importance of the concept of hauntology is the idea of lost futures, of things which never happened but which could have. On one level, late capitalism is indeed all about ceaseless reinvention, nothing is solid, everything is mutable; but on another level, it is about recapitulation, homogeneity, minimally different commodities. Some of Jameson’s best passages are about this strange antinomy. Deleuze and Guattari, too, emphasise the way in which capitalism is a bizarre mix of the ultra-modern and the archaic. The failure of the future haunts capitalism: after 1989, capitalism’s victory has not consisted in it confidently claiming the future, but in denying that the future is possible. All we can expect, we have been led to believe, is more of the same — but on higher resolution screens with faster connections. Hauntology, I think, expresses dissatisfaction with this foreclosure of the future.

So it’s not now a question of giving old ideas new momentum, it’s a matter of fighting over the meaning of the words “new” and “modern”. Neoliberalism has made it seem self-evident that “modernisation” means managerialism, increased exploitation of workers, outsourcing, etc. But of course this isn’t self-evident: the neoliberals fought a long campaign on many fronts in order to impose that definition. And now neoliberalism itself is a discredited relic — albeit, as I argued above, one that still dominates our lives, but only by default now. Part of the battle now will be to ensure that neoliberalism is perceived to be defunct. I think that’s already happening. There is a change in the cultural atmosphere, small at the moment, but it will increase. What Jim McGuigan calls “cool capitalism”, the culture of swaggering business and conspicuous consumption that dominated the last decade, already looks as if it belongs to a world that is dead and gone. After the financial crisis, all those television programmes about selling property and the like became out of date overnight. These things aren’t trivial; they have provided the background noise which capitalist realism needed in order to naturalise itself. The financial crisis has weakened the corporate elite — not materially so much as ideologically. And, by the same token, it has given confidence to those opposed to the ruling order. I’m sure that the university occupations are the signs of a growing militancy. We need to take advantage of this new mood. There’s nothing old fashioned about the idea of rational organisation of resources, or that public space is important. (The failure to rationally organise natural resources is now evident to everyone; and the consequences of letting the concept of public space decline are equally obvious to anyone living in Britain, with its violent crime and drunkenness, both of which are symptoms of a kind of despair that is as unacknowledged under capitalist realism as it is ubiquitous.) Similarly, what is intrinsically “modern” about putting workers under intolerable stress? The pseudonymous postal worker Roy Mayall put this very well in his LRB blog:

We used to be told that there were three elements to the postal trade: the business, the customers and the staff, and that all were equally important. These days we are clearly being told that only the business matters. So now the “modernisers” are moving in. They are young, thrusting, in-your-face and they think they know all the answers. According to them, the future is the application of new technology within the discipline of the market. But the market doesn’t tell us what to do: people tell us what to do. The “market” is essentially a ploy by which one group of people’s interests are imposed on the rest of us. The postal trade is at the front line of a battle between people’s needs and the demands of corporations to make ever increasing profits. That’s what they mean by “modernisation”, and it’s not “nostalgia” to remind ourselves that things used to be different.2

But the fight will only be won when we can say with confidence, not only that things used to be different in the past, but that they can be different in the future too. I’m hoping that, before long, the neoliberal era will be seen for what it was: a barbarous anti-Enlightenment atavism, a temporary interruption of a process of egalitarian modernisation.

RW: At the end of last year you edited a collection of essays, The Resistible Demise of Michael Jackson, brought out almost at the speed of John Blake Publishing! What was so important about Michael Jackson’s death that made you put such energy into this project?

MF: Yes, it’s rapid-response theory! There’s no doubt that Jackson’s death arrived at a punctual moment. A whole thirty-year reality system had just collapsed with the bank bailouts. Obama had been elected. There was no one who personified that thirty-year period more than Michael Jackson. In the few days after Jackson died, I found myself watching his videos over and over again. I surprised myself by moved from a position of detached cynicism to feeling increasingly sad. There was something in those videos — particularly the Off The Wall clips — which afterwards disappeared from Jackson personally and from the culture in general. So I listened to Off The Wall and “Billie Jean” obsessively. I probably listened to “Billie Jean” forty times, but it was like listening to it for the first time; there were depths to it I’d never got to before. I wrote a post on my blog which elicited some positive responses; and it struck me that the network around Zer0 — which includes many of the world’s music writers as well as theorists — was in an ideal position to produce a book that could deal with Michael Jackson as a symptom. Which isn’t to say that the book is some desiccated analysis that doesn’t engage with the sensuous qualities of Jackson’s music — there are some wonderful descriptions of the tracks and Jackson’s dancing. The book was put together very quickly, but I’m extremely pleased with the results. It was heartening to see what music writers can do when you give them space and let them pursue their interests. There are some pieces in the book — such as Chris Roberts’ and Ian Penman’s — that are so sui generis that it is difficult to imagine them appearing anywhere else.

RW: You’ve had a busy year, what with the blog, teaching, finishing a stint as reviews editor at the Wire, conference papers, marriage, Zer0 and the publication of two books — is it time for a rest now or will 2010 be just as busy?

MF: This is not the time for a rest. On a personal level, a rest is impossible. Most of what I do doesn’t make me much money, so I have to keep working at a furious rate to keep my head above water. On a wider cultural and political level, this is a highly exciting time, not a moment to be convalescing. This year, in addition to the teaching, blogging, freelancing and editing for Zer0, I will be putting out Ghosts Of My Life, which will bring together my writings on hauntology and lost futures; in some ways, it’s the other half of Capitalist Realism. There’s another big project that I’m involved with which I have high hopes for, but we’re not ready to go public on that yet.

RW: And finally, I hope it’s not too late to ask what were your favourite books of last year?

MF: Apart from the Zer0 books — and I’ve almost certainly forgotten something really important — they would be:

Fredric Jameson, Valences Of The Dialectic. A genuinely monumental work that I expect to be referring to for many years.

Graham Harman, Prince Of Networks. A stunning reinterpretation of Bruno Latour’s work that is also Graham’s most lucid account yet of his object-oriented philosophy.

Jodi Dean, Democracy and Other Neoliberal Fantasies: Communicative Capitalism and Left Politics. Jodi’s sharp analysis of the impasses of the left is also a kind of requiem for much the 2.0 bluster of the last decade.

Slavoj Žižek, First As Tragedy, Then As Farce. Much more focused than some of Žižek’s recent books, this was a reminder of his supreme relevance to the current conjuncture.

RW: Thanks Mark.





capitalist realism: interviewed by richard capes (2011)1

“Since there are so many people who are depressed — and I maintain that the cause for much of this depression is social and political — then converting that depression into a political anger is an urgent political project… Anti-depressants and therapy are the opium of the masses now.”

— Mark Fisher

Richard Capes: What is capitalist realism?

Mark Fisher: You’d think I’d be able to answer this very quickly. But in fact it’s easier to spot than it is to define, I think, capitalist realism. There’s various different ways of looking at it. One is looking at is as a belief, a belief that capitalism is the only viable political economic system. That’s one sense of the realism — that anything else is unrealistic. And it’s often what you hear people say if one is critical of capitalism — they’ll say, “Well it might not be the best system, but it’s the only one that works.” One can think of it as a belief, but it’s also an attitude, an attitude in relation to that belief, an attitude of resignation and defeat. So I suppose that what I’m talking about with capitalist realism is not so much the attitude propagated by this kind of neoliberal right. It’s more how the success of the neoliberal right transforms the attitudes of the general population, and especially of the left I think. But of course the problem with talking about beliefs or attitudes is it implies a kind of individual psychological perspective. What we’re talking about here is the kind of collective psychic infrastructure, I’d say — a kind of diffuse ideological atmosphere, and the way in which those beliefs are instituted across all areas of life in a country like the UK: from the media through to the workplace, through to our own unconscious attitudes.

RC: When and how did capitalist realism emerge?

MF: I think you’re looking at the Eighties as the key period of transition really. We’re looking at a kind of synergy between ideology and the restructuring of capitalism — the restructuring of capitalism from so-called Fordism to post-Fordism, Fordism being the sort of dominant form of capitalism in the West, in the post-war period, which was based on a kind of compact of stability, where the working class was offered security in exchange for boredom. Where most towns would have one or two major industrial enterprises, most of the male workers would expect to work in those industries their whole working life. But they could expect minor incremental improvements in their standard of living over that working period. This sort of fell apart in the Seventies when the world that we’re now familiar with — so familiar, in fact, that we take it for granted — the world of post-Fordist capitalism started to emerge.

What are key terms of post-Fordist capitalism? The dread word “flexibility”, which, in terms of the worker, tends to cash out of what’s called “precacrity”, i.e. constant conditions of instability and insecurity, short-term employment, casualisation. And of course that goes alongside some of the other key developments of post-Fordism, such as digitisation of the workplace, just-in-time production, and, of course, globalisation. So the re-structuring of capitalism in this way caught labour on the back-foot, labour as in the worker’s movement as well as in the Labour Party. The key problem I think articulated by the most forward-thinking of the left groups in the Seventies and Eighties — including the sort of the autonomous in Italy and what’s called the “New Times” group around Marxism Today in the UK — was, “How could the left hegemonise post-Fordism?”, “How could the left produce it’s own version of post-Fordism?” And I think the failure of that — the failure to meet that challenge — accounts for a lot of the failure of the left.

On the one hand we have the restructuring of capitalism along the lines of post-Fordism. But what’s key to that, of course, is that this just wasn’t something that was simply imposed by capital on workers; it was in many ways driven by the desires of workers — workers who simply didn’t find enticing a life of boredom for forty years in a factory, who wanted more freedom. I think the key issue now is, in a way, the discrepancy between what they did want and what they actually got. I think that’s where opportunities lie for the left, actually.

But coming back to “Where did capitalist realism emerge?” — well, “When and how did it emerge?” It was that the right successfully harnessed those desires — the anti-authoritarian currents that came out from the Sixties. The left I think failed to come up with a convincing model of an anti-authoritarian left. Energies that were released by the kind of struggles against capitalism on the left then became diverted into this neoliberal project, which, in the Eighties, had two faces. On the one level there was inducement. In the UK we saw this in the form of, particularly, the selling off of council houses. It was a really good move by Thatcher in lots of ways, because it immediately positioned the whole of the post-war social-democratic project as sort of being out-of-date, top-down, bureaucratic, and kind of Thatcherite neoliberalism as being about the future, the future that would deliver choice to individuals, which would deliver freedom away from the strictures of the state. A whole array of things happened in the UK, of course, privatisation. Again, privatisation was articulated in terms of giving people choices: “You too can now own shares!” Alongside these carrots, of course, there was a lot of stick with the destruction of the unions, or the effective destruction of the unions.

The miners’ strike is the most powerfully symbolic image of the end of the worker’s movement. I think when we think about that — when we think about the miners’ strike — that gives us the most kind of vivid sense of how deeply established capitalist realism was by the middle of the Eighties, and certainly by the end of the Eighties. By the end of the Eighties we were in a situation that would have seemed science-fictional from the perspective of the middle of the Seventies. If you told people that all of the national utilities would be sold off and privatised, that the mining union which had just brought down the Conservative government would be sort of defeated in abeyance, that the unions were simply not major players in public life anymore — that would have seemed unimaginable. Yet it happened, and it happened in a relatively short time.

If the Eighties were the sort of battleground — in retrospect it seemed like there was only one way that battle was going to go. In the Eighties, of course, things seemed different. It didn’t seem inevitable that neoliberalism would triumph. In retrospect the success of neoliberalism seems to have been overdetermined. But by the Nineties, I think, the key moment, of course, is the arrival and election of New Labour, which was the final victory for Thatcherite neoliberalism — where the Labour party could come in, essentially accepting the broad framework that had been imposed by neoliberals. I think then we enter into the kind of phase of capitalist realism which most of the book is devoted to analysing I suppose.

RC: How has capitalism persuaded us that it’s the only “realistic” political-economic system?

MF: One way of getting to this is by forcing ritualistic compliance, where there’s no other available language or conceptual model for how we understand life, work, or society, except that of business. And that’s one of the key things that happened in that period, particularly with public services — and that’s something I dwell on at some length in the book Capitalist Realism. It’s the extent to which teachers are now required to go through these self-surveillance procedures, these self-assessment procedures, which have been imported in from business, and the strange subjective disavowal that comes with these procedures often — managers who are uncomfortable imposing kind of business rhetoric, business methods, nevertheless will say to workers, say to teachers, “You don’t have to believe in this, but this is what we have to do now. We have to go along with this kind of thing.” And that sense that one has to go along with practices and languages coming in from business — I think that that is a key part of this sense that there is no alternative — that this is how things are done now — and there’s no other way around it.

I think that in addition to what I said earlier are a kind of crushing of the previous forms of working-class solidarity. Well, a crushing — I guess it’s better to talk about decomposition really, in lots of ways, because it wasn’t simply, as I said, about capital hammering trade unions. It’s that trade unions hadn’t — trade unions in the form they had developed — had to fit with the Fordist mode of organisation, and as post-Fordism emerged, as Fordism fell apart — as I say, partly driven by the desires of workers — trade unions and other aspects of the labour movement failed to move with it. The effect of that is this kind of generalised atomisation, I think — a kind of collective depression, which isn’t experienced collectively, because nothing is, actually.

But where between the individual and the state — there’s nothing in the space anymore. The space that trade unions used to occupy — well, people could feel then a direct connection between there own working lives and a wider political world and have some sense of agency because of that. That space was gone and people were… There’s this process of what I’ve called the “privatisation of stress” or general psychic privatisation. You get to own your own home, but your home becomes this place of refuge and consolation in a world where — because outside it public space is massively denuded. And it’s this decline of a public space which we can have any connection with. And it massively contributes to this sense that there’s no alternative to the way things are.

RC: You argue in the book that capitalist realism is immune to moral criticism. Could you explain why?

MF: It’s no use just talking about greed and these categories. There’s this kind of embedded Hobbesianism with capitalist realism. Part of capitalist realism is: “that’s the way the world is”. And that involves: “Well, people are naturally competitive”. If there’s widespread greed, or if this is appealed to as a notion — “Well, the reason there was a bank crash was because of greedy bankers” — that won’t undermine capitalist realism, it’ll feed into it. It will feed into it in the sense that that kind of resignation, cynicism are part of the background of capitalist realism anyway. It also misses the target, I think.

The problem with late capitalism is not the greed of capitalists. That’s the difference between a Marxist analysis and an ethical one — the Marxist one will focus on systems, forms of organisation are central. Capitalism is not bad because CEOs are uniquely evil. It’s the other way around. Anyone who’s in the position of CEO would act as CEOs do. It’s just a systemic pressure that produces that kind of behaviour. Part of the problem is that we are looking at systemic tendencies here. It’s archaic and kind of folk-psychological to focus on these categories which we think apply in everyday life, like more responsibility, to this kind of inhuman system. The scale of what we’re up against is obfuscated by a focus on the ethical.

RC: You also talk about “recycling” as another way in which our attention is deflected from a real problem.

MF: Isn’t recycling a classic case of: “We assume responsibility for the systemic tendencies of capitalism”? It’s not really our fault that there is an environmental catastrophe. The thing it is nobody’s fault, you can say, in a genuine sense, but that is the problem — because there is no agent capable of acting. There’s no agent at the moment that’s capable of taking responsibility for a problem on the scale of the environmental catastrophe that we’re facing. Instead, it’s contracted out to us as individuals as if we could do anything about it by simply putting plastic in the right bin. That won’t solve the environmental catastrophe that we’re up against. The only thing that can solve it is the production of an agent capable of acting. But of course nothing like that has ever existed throughout human history until now — which doesn’t mean it can’t exist, but that we’re in very new territory. That appeal to individual responsibility, as if aggregating up enough individual responsibility will substitute the need for this kind of agent. That’s one of the pernicious dimensions of the culture behind recycling.

RC: Towards the end of the first chapter you argue that gangster films like Goodfellas and Pulp Fiction offer visions of the world that promote capitalism or reinforce capitalist realism. Could you explain how they do that because they’re often seen as offering a very gritty, realistic portrait of modern life?

MF: Exactly. It’s because of that though, isn’t it? What do we mean by realism? That’s very much at stake. I think Ellroy also talks about — I think Ellroy is an interesting case because he’s pretty open about it in the political dimension of it. Ellroy’s project in something like American Tabloid, where he wants to take down all of these images of kind of American liberal politicians and expose the kind of seedy acquisitiveness behind the veneer — Ellroy’s quite open about this as a cultural-political project. This sense of precisely what is realistic. What is realistic? That people are competitive, they naturally struggle against one another, that the real world of the streets is described by this kind of micro-capitalist — not even micro often — struggle between warring families or warring interest groups — quite clearly this will feed into capitalist realism, I think, in lots of levels: in the assumption of individualism, the assumption of competition, also what has disappeared from that picture — which is any kind of public world.

RC: Would you say the American TV series The Wire is a work of capitalist realism?

MF: It’s a fascinating parallel with the book, I think, in that, in lots of ways it’s very similar to Capitalist Realism. What is the difference between that and large swathes of gangster rap or Ellroy is the implicit critique in it, isn’t it? There’s a celebration with Ellroy or gangster rap — “this not just how things are, but there’s something good about the fact they’re like this actually, and that we need to be positive about disillusionment”. Behind The Wire, despite this sense of massive institutional inertia, and just the impasses of politics, the fact that however hard individuals try to act the system has either a way of subsuming them or eliminating them — although that could be dispiriting, in the same way that Capitalist Realism could be dispiriting (and some people do read it in that way), for me the message of The Wire is very similar to the message of Capitalist Realism, that this is what we’re up against now. That was how things were pre-2008. Of course one of the many things that interests me about The Wire is the emphasis that’s placed on post-Fordist bureaucracy, the same as I place it in Capitalist Realism — on the way that kind of target culture has this inherent kind of skewing of facts, the sinister alliance between managerialism and target culture, in the way that it sort of blocks out initiative and also prevents people from doing their job in a way that you’d think they ought to be doing it.

On the face of it you’d think with The Wire — yeah, it’s a negative message, and to that extent it would reinforce capitalist realism. The second series about containerisation, about the decline, the diminishment of the old forms of labour, and their replacement with this kind of post-Fordist robotics — computerisation — is very flat with the themes of Capitalist Realism the book. But I see it more as describing or rather anatomising — diagraphing — capitalist realism, rather than it actually reinforcing it, because it quite plainly lacks that element of celebration. It does also lack resignation, even though it does seem to be a seamless world from which there is no escape. The very fact it exists is a form of refusal of resignation, I think. Showing the sheer systematicity of these processes is something other than simply being resigned to them in everyday life and work.

RC: You mentioned the phrase “privatisation of stress” earlier in the interview. Could you talk about your experience of this when you worked as a teacher in further education?

MF: FE in the UK used to be the place where students who didn’t really get on that well with conventional education — where they would go for a slightly different approach. I started teaching there the early part of the 2000s, and one could already see that ethos under threat and it became, increasingly as the decade wore on, as the kind of Blairite business agenda came to dominate life at college more and more. Partly what I mean by the “privatisation of stress” in relation to education is that people are required to become their own workers. There’s a trick that’s been played by neoliberalism which we’ve all succumbed to more or less — which is the idea that bureaucracy is in the past, bureaucracy belongs to this old statist, heavy, top-down, centralised world and we’re glad to be rid of it.

But of course, when we think about what our working lives involve now, I’d say for many people it involves more bureaucracy, not less. The difference is that the kind of bureaucratic surveillance is not performed by external parties; it’s increasingly performed by us. We have to fill in fifty or sixty page logbooks; we have to fill in endless detailed documents assessing our own performance. But this is part of a sort of wider privatisation of stress, which is that we’re invited to take responsibility for the additional stresses that an increased workload and decreased security bring to bear on us. Since trade unions are no longer as effective as they were, our first recourse often when we’re put under extra stress is not to complain to a trade union or get them to act on our behalf but to go to a doctor and get anti-depressants, or if we’re “lucky” — in inverted commas — get therapy. The rise of depression amongst the general population, particularly amongst the young, is, I think, a symptom of this privatisation of stress.

RC: In the book you say that in Britain “depression is now the condition most treated by the NHS”.

MF: As far as I’m aware that’s still the case. I haven’t checked out the statistics recently, but I can’t imagine that in the period we’re in at the moment depression has decreased amongst the population. What struck me about this was, “Why is this acceptable? Why, particularly in a period in which we can look back now and see as a period of boom — why in this period of so-called boom were so many people, particularly young people, why were so many of them depressed? Doesn’t this indicate some fundamental kind of affective problem with late capitalism?” It seems to me that one aspect of the privatisation of stress is there’s not an availability of a kind of cultural language of disaffection and discontent, particularly for the young, I think. And one of the interesting things about the last year or so, with the student militancy at the end of 2010 and the riots this year, is this kind of eruption of a negativity, which I don’t think was available to young people in lots of ways in the high pomp of capitalist realism.

RC: In the book you talk about students suffering from “depressive hedonia”. Could you tell us what this is?

MF: I was talking about the students I was teaching — so they were younger teenagers… not that young, I suppose: sixteen to nineteen. Not undergraduates. This does seem to strike a chord with them actually. Many of the people who write to me about the book, younger people, think that that captures something about their experience. Depressive hedonia would be just a way of thinking about the form that depression takes in a world where stimulus is always available, I think. I don’t think we’ve remotely got to grips with the affective consequences of the kind of cyberspace-matrix that the young especially are embedded in.

Part of what I’m describing in the book really is the tensions between a kind of crumbling disciplinary framework — in which teachers are there as these prison-guards of this collapsing system. Well, on the one hand they are prison guards. On the other hand, they’re required to interface with this constant world of stimulus, and be entertainers. There’s a tension between being a prison guard and an entertainer — it’s pretty difficult to say the least. In terms of depressive hedonia, depression is usually described as a case of anhedonia, where the sufferer of depression is unable to derive pleasure from anything. It seemed to me that there’s almost an opposite syndrome in place with teenagers, where pleasure is so easily available that, well, that it’s this very availability of pleasure that’s depressing in many cases. I guess there’s a kind of consumer model of pleasure which is involved, which doesn’t build up people’s sense of self-esteem, sense of well-being, or perhaps more importantly a sense of involvement in things. Instead of that you’ve got this kind of rapid-fire small bursts of pleasure. And one of the things that’s removed by this is a kind of productive boredom.

The existential crisis posed by boredom in the Seventies — when you really could be bored, when there wasn’t a seamless stimulus-matrix available — I think there’s a big relation between that — the availability of a certain kind of boredom — and phenomena like punk. The availability of constant low-level stim in twenty-first-century culture precludes that kind of boredom, precludes alienation in a certain way, but produces this kind of general feeling of unacknowledged disaffection I think. These forms of stimulation are not really capable of engaging people in a way that takes them out and beyond themselves. People are sort of trapped in themselves in this form of kind of functional misery, in a sense that they’re just miserable enough, as it were, miserable enough to carry on — not too miserable that they would either reach a point of subjective destitution or just have to question — pushed to the point where they have to question the general social causes for why they’re like this. So I think it’s just enough pleasure to keep them depressed as it were. That’s one way of looking at depressive hedonia.

But of course one of the great things that’s happened over the last year or so, that’s significant though, is the student protests at the end of 2010. It was students who lead this. There’s a sense there of what I was looking for or hoping for when I was writing Capitalist Realism — that these forms of unacknowledged disavowed discontent would convert into forms of public anger. What was so exciting about the student protests was seeing that process start. Because I think a lot of the older people are much more in that mode that I was describing earlier of kind of resignation. I don’t think there’s many people who are fans or enthusiastic supporters of the coalition government, but I suspect the general attitude is, “Well, there’s not much we can do about this”. In other words, a form of capitalist realism. What we saw with the young is a kind of challenging of that in a very dramatic way.

RC: In a talk you gave about Capitalist Realism earlier this year you called for the development of a “leftist psychotherapy”. Could you explain what you mean by this?

MF: This is really serious, I think. Since there are so many people who are depressed — and I maintain that the cause for much of this depression is social and political — then converting that depression into a political anger is an urgent political project. Of course it’s not only about that. It’s also about levels of real distress and suffering in society, which cannot be handled or dealt with by the individualising, privatised assumptions of the dominant forms of treatment in mental illness, which are, in this country, cognitive behavioural therapy — which is a kind of combination of positive thinking and kind of psychoanalysis-light: the focus on the family background of the sufferer, and on then of converting thought patterns from these negative into positive ones. There’s that. And on the other hand, brain chemistry focus — the horrible loop whereby massive multinational pharmaceutical companies sell people drugs in order to cure them from the stresses brought about by working in late capitalism. Neither of these things are very effective — all they do is largely contain people’s depression rather than actually deal with the actual cause of depression.

One can apply Marx’s arguments about religion very directly to this — that religion was the opium of the masses. Anti-depressants and therapy are the opium of the masses now, in lots of ways. That isn’t to say that they don’t do anything at all. They do in many cases relieve intense suffering, which people are undergoing. But it’s just the same as religion. As Marx said, it’ll make people better in a kind of savage and pitiless world — religion wants real comfort to people in the same way, in a world of relentless competition, of digital hyper-stress, etc. Being able to talk to someone for an hour in cognitive behavioural therapy or having something which will take the edge of things via anti- depressants — that will make people feel better, but just as with religion, it doesn’t get to the sources of that sort of misery in the first place. It in fact obfuscates it.

If you want to look at the rise of capitalist realism, one can also look at the decline of anti-psychiatry. As anti-psychiatry declined, then capitalist realism grew. I think there’s a relation there between the two. That normalisation of misery as part of the privatisation of stress has been absolutely central to the rise of capitalist realism.

How do we get beyond that? Some kind of return to the issues that were raised by anti-psychiatry. I’m not saying necessarily that everything anti-psychiatry said was right. With anti-psychiatry, as with many other anti-authoritarian strands of leftism that emerged in the Sixties — that kind of rhetoric became diverted and captured by the neoliberal right. When did anti-psychiatry cash-out? Well in some ways, Care in the Community, etc. But of course that wasn’t the only way it could have gone. Thinking about ways of reforming, changing institutional care, of looking at a shift beyond this narrow kind of focus either on family background or the kind of chemical make-up of people’s brains — this could have a very high impact, I think, if we could articulate this.

A reader of Capitalist Realism actually drew my attention to the work of someone called David Smail, who’s himself a kind of therapist — though I don’t think he’d like the term “therapist”. He, in a number of books, has sort of argued for the development of a leftist psychotherapy. Smail claims that feelings of well-being fundamentally arise from a public world — against the background of a public world. And in a society in which the concept of the public has been so kind of viciously and systematically attacked — it’s no surprise, Smail argues, that distress has increased. He argues that — as I would — that the dominant forms of treatment in mental illness have reinforced that rather than challenged it. I think developing Smail’s ideas could be extremely powerful.

RC: In the book you call French students involved in protests against neoliberalism “immobilisers”. What does this term mean?

MF: It’s a term I use myself, like “immobilisation” — to bring capitalism to a halt. I think the problem of articulating things in that way is that it feeds into the dominance of capitalist realism in the sense that it concedes that history belongs to capital or history is only going one way — capital. And that all we can do is obstruct, resist or delay the inevitable triumph of capital. It seems to me there are obvious problems with that way of thinking. It’s really still part of capitalist realism. It’s part of capitalist realism in a very big way because we’ve lost any sense that the future is ours, that we can move forward to a future that we’re constructing. Instead all we’re doing is putting up barricades against a future that we ourselves are conceding belongs to capital.

RC: How did the student protests in Britain differ from that?

MF: I’m not sure that they did differ that much from it. As with many left-wing protests, there’s a strong sense of what they’re against, but not so much sense of what is wanted. What’s encouraging about it for me is that at least the British young have broken out of that kind of pull of what’s conventionally called “apathy”, but I don’t like that term at all. In the book I use the term “reflexive impotence”, which I think is a better sense of what’s at stake with many British young. Why I called it reflexive impotence is that people feel they can’t do anything, and they’re sort of aware that their feelings that they can’t do anything mean that they can’t do anything, or contribute even more to the inability to actually act, yet it still doesn’t enable them to act. Reflexive impotence is another phrase for depression, I think. That’s how a depressive person feels. They know that their own attitudes are reinforcing their own inability to do anything, and also making them feel worse. Yet knowing that is not likely to inspire them to act. Instead it makes them more and more depressed. I think that sums up the situation for the British young or large swathes of the British young up to 2008.

I guess what’s also encouraging about the student protests is that politics becomes an available option. I think the level of so-called depoliticisation was so strong amongst the young that even sort of failed or flawed forms of politicisation are encouraging because I think part of depression and part of the depression I was talking about really is the disappearance of politics as such. Many young people in Britain who take capitalist realism for granted don’t see much of a future for themselves, don’t see a very interesting future for themselves. At best they’ll be indebted in order to get a job that isn’t very exciting — that’s probably how they’re seeing things. And the idea that one can challenge this politically — I don’t think for many of them that it was available as a thought. Making it available again was what was encouraging about student militancy.

RC: Do you think more and more students are breaking out of the bounds of capitalist realism and becoming more radical?

MF: I think it is early days. There’s all kinds of things going on. I think student militancy — the emergence of it — is something that wouldn’t have happened before 2008. After the bank crisis of 2008 — this is a major event, a kind of major trauma, for capital, and of course we’re still right in the middle of it. And it’s evident that capital does not have a solution to the problems which lead up to the bank crises of 2008 at all. I think student militancy is one dimension of it, the riots are another. But I think that these are really the beginnings of something and we don’t know where it’s going to go at all.

And it’s a shame in a way that this massive efflorescence of student militancy before Christmas last year dissipated and wasn’t able to be sustained during this year. That doesn’t mean that it’s gone away. I think certainly over the next course of the month or so, building up to November — in November there’s going to be another big flash point. A lot of the people who have been politicised by what happened last year will be back again.

The thing is things move so quickly. There’s a strange rhythm of events at the moment where you have this massive rush of unpredictable kinds of events occurring. I think that’s what happened with student militancy at the end of last year, then earlier this year we had the whole Murdoch thing, and then the riots. These things erupt in an unexpected way, in a way that goes far further than people would anticipate before they happen. But then things seem to go back to normal, seem to stabilise again. But every time things go back to normal, so-called normal, then normality is much more unstable, I think, than it was before. This tendency of collapse at the moment, with what we’re living through, is the disintegration of the reality system, quite simply.

Something that has been built up for over twenty-five years, i.e. capitalist realism, in the neoliberal mode — since that has been so pervasive, since that has dominated all of the assumptions of institutional and organisational life as well as the unconscious, it’s not surprising that it doesn’t collapse all in one go. People’s expectations, everything they take for granted, is shaped by that reality system — that in itself keeps it going for some period. But at the same time, we can see it really rocking at the moment. I think there’s the opportunity for the left at this time. I think, yes, we need things to get radical, but we also need to get hold of the mainstream. This is where we’re totally disconnected. It’s not only that we are totally disconnected from the “mainstream”, so-called. I mean I use the mainstream in inverted commas, because precisely at moments like this we don’t know what the mainstream can be. We’ve know what it was up to 2008.

Part of the book Capitalist Realism is really about the massive decline of mainstream media, mainstream culture, under the kind of tyranny of capitalist realism. I just don’t think we know what mainstream media or mainstream politics can be like in the coming period because everything is up for grabs again. We can see that severe crisis that the ruling class is in, in the UK, which was made clear by the so-called Hackgate thing — a network of complicity between the media and the police and politicians, which David Cameron had to admit he was right in the middle of. Now you’d think that would provide an opportunity for the left, but the problem is there’s no presence in the mainstream, no agent that can press home this clear advantage. And that’s been quite clearly the case since 2008.

RC: How can the left hope to establish a presence in the mainstream media when it almost completely excludes genuinely left voices?

MF: I don’t think it’s inevitable that they would be excluded. I think it’s a mistake to think the form of mainstream media is fixed — that that kind of neoliberal attuned mainstream media with its very narrow bandwidth, with very low expectations that it has of its audience. This was something that was imposed gradually. It is something that was fought for and achieved by neoliberals and their allies in big business. But it’s a hegemonic struggle and media and mainstream politics are terrain which the political right have dominated to the extent that people forget that there’s ever anything different to this. But I don’t think we can say in advance what will be excluded and what won’t be excluded. For instance, with the Labour Party, you can still see them acting as if it was before 2008, still acting as if the old so-called centre ground still existed. But it just doesn’t exist anymore and no one’s testing this out — that’s the problem. No one is testing out what would happen if you tried to take a more left-wing perspective in the mainstream media.

Since Ed Milliband and the post-New Labour Labour Party has decided to pitch things towards some obsolete centre-ground, we just don’t know what would happen. And I think that’s what needs to be tested out at the moment. It’s quite clear that we’re facing a dilemma, that the UK — what we’ve seen with the riots and with the student militancy is these kinds of fissures in UK society that we haven’t seen to this extent since maybe the poll-tax riots or, even earlier than that, the miners’ strike. I think capitalist realist hegemony depended upon this kind of production of consensus — or rather image of consensus — that had to be kind of continually reproduced by the media. Even when the media is condemning riots or condemning student protests, nevertheless they are visible — the visible cracks in this form of consensus or, like I said, appearance of consensus. So, like I say, we just don’t know what’s going to happen at this stage and we shouldn’t concede any terrain to the enemies especially at this time really.

RC: It’s not in the interest of the mainstream media to encourage people to question capitalism, though, is it? Newspapers, for example, are profitseeking businesses, owned by very wealthy people.

MF: That’s defeatist because we can’t go anywhere without — either the media is reformed or we actually compete on terrain which is not favourable to us. I don’t think this means we ought to concede to it, I think. Reading Nick Davis’ book, Flat Earth News — it’s very interesting. It does vindicate everything you’ve said with newspapers. 60% of broadsheet content comes from PR. But I guess what’s interesting about that though isn’t that the owners of the newspapers collude with the PR companies as such. It’s more that it’s a direct consequence of the underfunding of journalism. Journalists are required to turn around ten stories a day. They won’t be out on the streets doing investigative reporting. They’ll be editing press releases.

But I think this is susceptible to influence by us as well — what Davis calls these “astro-turf” groups, as a play on the idea of grassroots organisation. So a lot of things which appear in the paper as if they’d come from grassroots organisations in fact come from these corporate astro-turf PR bodies or whatever. We need our own astro-turf bodies as it were to compete into this ecology. What gives us hope here is the fact that there isn’t a strong agenda being pushed by these journalists, that they’ll accept anything that comes into the inbox if it’s pushed there with sufficient kind of vigour. I still think a lot of journalism is kind of opportunistic, and it’s a question of our organising to intervene into this kind of ecology.

We’ve seen examples recently of Owen Jones, though — Owen Jones has got in all kinds of media on the back of Chavs. He’s appeared on Daybreak, Sky News — right in the heart of this kind of corporate beast. So it can be done. I don’t think we can a priori say what can be achieved at this time. Capital is in disarray, the ruling class is in disarray at the moment, and I think that if we give up in advance and say, “We’ll never get into mainstream media”, then we’re doing them a favour. Of course the other danger is simply constructing everything so we adapt to the existing structures of mainstream media. That’s also fatal — toning things down so that we can be accepted. It’s about a hegemonic struggle so that we can change what is acceptable to say on there. And if we can’t do that then we have failed. That’s pretty clear and New Labour is the most objective lesson in that. If you simply construct your project on the basis of what is now acceptable in the mainstream and maybe just slightly shifting things over — that will fail.

And not only fail, but will also produce this kind of political despondency such as I tried to describe in the book really. I think we have to go between these two strategies — either staying outside the mainstream media completely or just adapting to what the mainstream media is like now. We have to learn lessons from neoliberals, really, I think. They were capable of changing what the media was in the same way we have to imagine that the media can change in our direction. Of course they’ve got resources we haven’t got. But we’ve got resources they haven’t got as well.

Going back to what I was saying earlier on: We should be inspired to the extent to which the triumph of neoliberalism, in a way, is showing how things can go from impossible to inevitable. That’s the way history goes — that things seem completely off the agenda, that there’s no way that things can happen; suddenly, things switch where they’re the only thing that can happen. That’s how it was with neoliberalism. The one thing we can be sure of at the moment is that things can’t go back to how they were before 2008. That can’t happen. We’re in a period of major tumult, major change. The right, the kind of neoliberal right, is at its weakest since I can remember.

And we need to think ahead I think about how things can be different. And media is really a key part of that. I think it’s really significant that the Hackgate thing happened this year, because it’s part of this delegitimation process, you might say. The delegitimation process has at least two aspects. I think one is the discrediting of neoliberalism, although neoliberalism is quite plainly going to continue as a kind of guiding set of defaults for a while yet. As a political programme with a kind of confidence, it disintegrated after 2008. So we’re in this kind of vacuum at the moment where neoliberalism has effectively collapsed, but nothing has come to replace it. That is an opportunity.

RC: In your book you say that the anti-capitalist protests do nothing more than provide a “carnivalesque background noise to capitalist realism”. Could you explain why?

MF: There’s this spectacular dimension to anti-capitalist protests — this purely petitionary dimension to it. My problem with the anti-capitalist thing in a sense is that there’s nobody who can meet the demands that are being put forward there. It has the form of petition, but there’s no one to whom this petition is actually aimed. That’s what’s peculiar about it. Let’s imagine at one of these G20 protests — let’s imagine everyone inside the G20 goes, “Well, okay, we’ve heard this noise. We’ve heard these slogans. That’s it. We agree that capitalism is really a bad system.” Then what? Even if everybody inside the G20 meeting agreed with that, they still couldn’t do anything. It’s this peculiar form of spectacular petition, which I think does not expect to win because there is no model of what it would be like to win, as it were. This is not to say that nothing went on there and those protests were completely valueless or insincere. But I do think we need a concept of failure on the left. I think that one thing that separates the neoliberal right from the left is that there’s much less tolerance of failure on the neoliberal right.

I think built into many of these movements is a kind of inbuilt expectation of failure, so that it’s not a problem if things actually fail. With the student thing there was at least — although it actually did fail, it could have succeeded, at least theoretically. It had a determinate aim. The people they were exerting pressure on had the power to make the decision not to impose those student fees, etc. Unless there are determinate winnable goals, a kind of generalised despondency will result. It’s what my comrade Alex Williams calls “feel-good, feel-bad”. You feel good because you’re out in a protest doing something. But ultimately you feel bad because — and these two things are completely sutured together, the feel-good and the feel-bad — you feel bad because you don’t expect to achieve anything ever. It’s just a kind of carnival of the defeated. It’s those aspects that I think are troubling about that kind of protest.

As I say, the student protest was different because they had a determinate goal that produced this criterion of success and failure. Also: because of the sustained nature of it. There wasn’t just something over in a day. It was something over a period of weeks. It built up and had managed to embed itself in the structure of universities, by the occupations. That produces a very different dynamic to a kind of anti-capitalist carnival that happens for a day or a short period of time. The problem ultimately was that, as we discussed earlier, that did fizzle out. I think that then just poses different challenges about how — since people have been politicised by that issue — how do we sustain that kind of struggle over a longer period, and how do we keep it embedded into everyday life. I think that link between people’s working life, or the life of students, and politics is crucial — that politics is not something that is just performed by a professional class of administrators at some spectacular distance. It’s something that directly connects with how we live and work. I think that that was the power of the student protests by contrast with the Nineties-Noughties anti-capitalism — although I’m not suggesting a total discontinuity there.

It seems to me that trade unions were successful in the past, as I’ve said, because of Fordism. The collapse of Fordism, that’s made the way trade unions operate more difficult. But that doesn’t mean that no form of workers organisation couldn’t work effectively now. But I do think we need imagination and a real shift from the Fordist paradigm. Having been an active trade union member in points in my life, I’ve seen the extent to which higher echelons of trade unions are still orientated around — many of them are still orientated around Fordism, around pay and strikes. I saw this particularly with teaching. Many of the issues that I describe in the book — the problems of observations, of bureaucracy, of self-surveillance — these are things that teachers are kind of passionate about, which unions have a very limited interest in. I think shifting the terrain of struggle onto things that matter to people is a way of re-engaging them. There’s no reason, in my view, why trade unions themselves couldn’t become major players again if they’re prepared to shift, very belatedly, into the post-Fordist world.

RC: Is the occupy movement taking place in America at the moment doing nothing more than providing a “carnivalesque background noise to capitalism”?

MF: Part of what makes things different now from how they were in the past, just is the fact that the banking crisis has happened and that capital is on the back foot. There’s an element of petitionary acting out with those forms of anti-capitalism that I describe in the book. In the situation where capital is much weaker — but also the situation is much more desperate, I think — that has created a different set of situations where, you know, “What are people to do faced with this kind of ongoing train wreck of the financial system?” There’s a sense that anything thrown in front of that train is good at this time. We simply don’t know, I think, how far things will spread, how things will develop in conditions as they are now as opposed to what they were like at the end of the twentieth century, at the beginning of the twenty-first century. It seems to me that these negative protest-based movements — if they’re to have any lasting impact — must transform into robust organisations that have institutional structures and a positive agenda. But I don’t think that we can rule that out at this stage. We just don’t know what’s going to happen.

RC: Some have argued that one of wonderful things about the movement is its lack of a central organising system because it’s bringing together all kinds of people with different problems.

MF: Okay, that’s a resource. But I think organisation is required, though, because otherwise how do we compete with capital? I think capital is quite happy facing people who are not that organised. It’s good to have a broad-based group of people. But there was a broad-based opposition to the Iraq War — and that’s a major moment of capitalist realism, I think, in the UK. When you have however many millions out in the streets in the UK and nothing happened. That shows that sheer numbers of people don’t necessarily accomplish anything. I think you only accomplish anything when you’ve got organisation, goals and structures, in the end. Otherwise you’ve just got some faith in a kind of spontaneity of the people somehow. When has that ever yielded anything? You’re not up against things which are susceptible to spontaneity. There’s a difference between capitalism and other forms of kind of political social dominance, isn’t there? We can’t just take all of the capitalists out and execute them. Capitalism is a structure — it’s as much a cognitive structure as it is a social structure. You can’t just take out the ruling class. Even imagine this was the case, imagine it was possible — you can’t just take out the ruling class and have got rid of it. Difficult questions are: How do we organise life differently? How do we organise the economy in a way that’s different from the way that capitalism has done? That’s not solved by executing capitalists.

RC: What do you think a post-capitalist society look like?

MF: I’m not sure we’re even close to answering that question at the moment, to be honest. I’m not saying that in a defeatist way. In a way it’s partly a testament to the power of capitalist realism. We have to start by granting the power that it has over our imaginations, over our social, political and economic imaginations. Part of that power is the way it structures oppositions in our minds, so that you think there’s this deadlock between either we’ve got state centralisation or neoliberalism. It’s imperative that we think beyond this deadlock, I think, so that when we’re arguing against neoliberal capitalism, then we’re not implicitly arguing to go back to social democracy or back to a Stalinist state. We might want to go back to elements of social democracy. But it’s not going to be enough to say that we just want to retreat to how things were a few years ago. I think we need a sense of where we’re going to. We can be somewhat emboldened here because it’s not as if anyone’s got a very clear idea of where things are going at the moment. And the one thing we can be certain of is that they won’t carry on as they have been. We need this boldness of imagination on our side, willingness to engage in thought experiments, science-fictional scenarios — because, quite honestly, they’re just as likely as anything else that’s going to happen.

RC: In the last chapter of the book you suggest that one way society can be improved is by establishing a “paternalism without the Father”. Could you explain what you mean by this?

MF: That’s one challenge to the impasses that we’re in. As we were talking about the mainstream media — I do think media is crucial. One of the ways in which neoliberal hegemony has cemented itself is by an attack on paternalism, because it’s saying paternalism is part of this obsolete, bureaucratic, centralising, top-down, archaic world that we’re glad to be rid of. What’s involved in paternalism? Paternalism is other people telling you what you ought to do, and we — we neoliberals — don’t believe in that; we believe that you should be able to choose for yourselves. Now this whole way of setting things up has, I think, been highly successful and for that reason deeply pernicious. They also associate paternalism with elitism, because they will say, “Paternalism then is someone deciding for you what you ought to like and what you ought not to like.” One doesn’t simply want to reverse the terms there and accept the way the binary is set up. We need to think about how paternalism could be different from the image that neoliberalism has of it.

What’s interesting to me is the way in which elements of paternalism do survive in neoliberal culture. The smoking ban, for instance. It quite clearly runs contrary to the way I was characterising — one might say caricaturing — the neoliberal appeal. This is quite clearly stopping people from making choices. Paternalism survives in a kind of way in health. It doesn’t survive in culture, and that’s interesting. But it seemed to me that what was at stake in mass media when I was growing up, and the paternalistic dimension of it, wasn’t people telling me what to do — they’re assuming intelligence on my part. They’re assuming that I can cope with things that I didn’t already like.

There’s this different model of desire that’s at stake with how I would construct paternalism in a positive way — which isn’t about just deciding for people what’s good for them. It is about having a wager that there is maybe a desire for the strange in people — people don’t already know what they want and that the things which they really end up most valuing maybe things which surprise them. What I’m arguing is that a lot of the features that neoliberalism, neoliberal culture claims for itself — which is innovation, the capacity to surprise, newness — none of these things are generated by neoliberal culture. The exact opposite is the case in fact. When you have a consumer model of “choice” — in inverted commas — what you get is this kind of bland homogeneity, a faux-diversity, concealing an extremely narrow bandwidth of options.

What was it that actually did allow for there to be innovation, surprise, and novelty? Well, some kind of condition of stability and some kind of removal from immediate commercial pressures. That’s how one could think about, particularly, how the BBC used to operate, how Channel 4 operated in its early days. Nothing is more illustrative, I think, the triumph of capitalist realism in the UK than Channel 4, which started off showing Tarkovsky seasons, had hour-long programmes simply consisting of philosophers discussing ideas — to Location, Location, Location or whatever else is on Channel 4 at the moment. There’s some massive decline that then produces this retrospective impossibilisation. That other Channel 4 did exist, but now it seems utterly impossible.

But it is only possible in some kind of model of paternalism — of thinking the best of people and thinking they deserve the best, not of serving up whatever people want, or whatever is held that people want. Part of the notion behind this for me would be the plasticity of desire. Neoliberalism wants to trap people in where they already are. This model of paternalism is about saying people are capable of being stranger, of liking things which they don’t know at the moment that they would like. That’s the side that we should be on — is in inculcating this. Of course, for me, as a teacher, there’s a kind of flatness, I think, between this concept of paternalism and teaching. Surely teaching must involve this kind of wager — that the student can enjoy things which are alien to them. That’s some of the issues for me about how to think of paternalism differently.

The reason I don’t like the term paternalism is the association with familialism — patriarchy, etc. It’s very difficult to think of a word that would work in the same way. That’s probably part of the conceptual poverty brought about by capitalist realism — that we’re forced back onto this word that in many ways is unsatisfactory. Recently, I’ve done a pamphlet with Jeremy Gilbert, which will be coming out through Compass.2 There we use the term “democratic paternalism”, partly drawing upon Raymond Williams’ work in his book — I think it’s 1961 — Communications. Williams’ presciently discusses different models of broadcasting. You start off with an authoritarian one, move towards a paternalistic one, and then that breaks down under pressure from things like the commercial model. What Williams wants is a democratic model where everyone participates in the production of media. I think that we can’t just directly go there. We need this kind of democratic paternalism. The goal is more participation than production. The paternalistic dimension just acknowledges the fact that there are asymmetries of kind of power, knowledge, etc. But the democratic side says we can’t be satisfied with these differences in power, knowledge — we must aim towards equalling them out. That’s how I’d like to think about the political project — as one of democratic paternalism.

One of the problems with paternalism in the way it had traditionally been set up was that that was an elite body that could sit and decide what was good for everybody. There isn’t going to be in any desirable system in the future — there isn’t going to be one body that will decide for everybody what is good for the rest of them. There’s already a plurality of different kinds of knowledge bases and skill bases, etc., which will mean that that is avoided.

Part of what’s involved in re-floating this concept of paternalism is defending the concept of education, and also defending the concept of authority; and differentiating the concept of authority from that of authoritarianism. Authority based on expertise, knowledge, skills — there’s nothing wrong with that, providing it isn’t abused. That needs to be abused to be authoritarianism, which is simply power based on fear. Part of a democratic political project is not eliminating authority, but constituting authority collectively. The best way of fighting authoritarianism is not abandoning the question of authority — which will always re-assert itself in one form or another, if one simply ignores it — but of constituting authority in this collective way. I think that returns to this challenge I was suggesting right at the start of the interview — that we need to now face up to again, which is this question of how do we develop an anti-authoritarian left. Like I said, the question was posed in some ways in the Seventies and the Eighties. Now we have to answer it.

RC: What’s to stop a paternalistic state from becoming a totalitarian one?

MF: I think I sort of partly answered that by… Totalitarianism is authoritarianism — authority simply being asserted on the basis of fiat. And I think that would be very different from the model of authority — the paternalistic model of authority — that I was suggesting. That’s why, I think, you need definite democratic paternalism, rather than just paternalism per se. I’m not really saying anything that different from how some teaching situation would operate, for instance, where one can’t simply impose stuff on the students and expect them to accept it. You have to negotiate with them, you have to win them over, to start from the level they’re at, etc.

RC: And if you can’t do that, what do you do then?

MF: If we can’t do that, then we’re in a severe crisis at that point. What are the situations where you can’t do that? All I’m saying is that an authoritarian solution won’t help. If you can’t bring people round in that situation, then there may be nothing you can do. But simply returning to some kind of authoritarian solution where you just tell them — that would only exacerbate the problems, it won’t solve them. I think we’d have to bet on the fact that this sort of can be done and you can bring people with you. At a point where we’re forcing people to do things, things have already gone wrong very severely.

Let me put it another way: I think we’re very far off leftist totalitarianism at the moment, and we’re too frightened of it as well. In the Sixties, Stalinism was a clear and present danger. Leftist totalitarianism was a real threat that people were trying to escape from. It simply isn’t now. It’s not that one should entirely dismiss those fears, but I think that we’re at the stage where we need to establish a new orthodoxy, a strong hegemonic presence, and once we’ve done that, then we can worry about the dangers of that being taken too far or totalitarianism, etc.

But I just don’t see that as an issue at this time. What’s more of an issue is the kind of soft totalitarianism of neoliberal dictatorship, isn’t it? I don’t use those terms lightly. This situation where people — where there’s a rhetoric of choice and no effective political choice, where there’s a general kind of helplessness and people feel they’ve got no control over their lives — it seems to me that these are what we need to fight against. I’ve never been able to force a student to do anything anyway. Let’s say there was the full resources of the military and prison service available to me, I wouldn’t still be able to bend the student, still, in that way. If things have gone past the point of negotiation where you can’t, as it were, manipulate people in their own interests, then that’s a severely extreme situation.

RC: Another thing you say needs to happen is for the left to “not take over the state but to () subordinate it to the general will”.

MF: Yeah. Neoliberals don’t really have to run the state as such themselves. They get their subordinates to do it. The state is clearly an important locus of power. We get some theories which already write off the state and I think that is a mistake. It’s quite clear that neoliberalism could not have achieved the hegemony it has without also being able to control states. So I think the state remains an important locus of power.

It’s just the idea of taking over the state, in a way, in the classic style of the 1917 Bolshevik revolution, etc. — even if you could do that, that wouldn’t achieve the overthrow of capitalism anyway, partly because capitalism is a global phenomenon. It itself is in the position I say — it subordinates the state. It doesn’t have to takeover the state directly. Partly what I was thinking there is that we want to differentiate ourselves from being old style statists. This is again part of this neoliberal binary where they’re for a small state, we’re for a big state. I think we need to first distinguish the concept of the public from the concept of the state. The two aren’t the same — the state facilitates public space, but is not the same as the public. The public interest is not synonymous with the kind of will of the state. Partly the importance of this move is to differentiate us from the caricature of the old left. But at the same time it’s important not to go down a certain kind of anarchist route where you’re denying the importance of the state at all. The state quite clearly retains a massive significance.

RC: How do you get the state to serve the people?

MF: Why does parliamentary politics serve the interest of business? Because business is the only effective agent acting upon it. The point is: Why is capitalist realism rife in parliamentary politics? You can’t explain that in terms of the logic of parliamentary politics itself. Parliamentary politics is in many ways responding to the situation outside it, such as the decline of trade unions, etc. The classic situation of the Seventies was where the politicians were caught between business on the one hand and trade unions on the other. What we need to do is constitute a force outside of parliament strong enough that it becomes a dominant influence on parliament.

Again: learn from neoliberalism. It doesn’t control parliament because it has its own people directly in there, though that might to some extent be true. The point is that even if that were true, how is it possible? It’s possible because of the constitution of forces inside society, isn’t it? That’s it at its basic behaviourist level, I think. Politicians and administrators will bow to the strongest force in a certain way. Then what we need in the first instance is to create conflict in their own minds. At the moment, it’s just all too easy to bow down to business, because it’s only powerful force acting upon them. There’s a widespread, inchoate discontent, for instance, about the banks — and since there’s no agent that’s capable of focusing that discontent and bringing it to bear on politicians, then they can ignore it — they just make a few moralising gestures towards it. To me it’s a question of how you constitute those extra parliamentary forces, how we produce these new forms of solidarity.

RC: But business has a very fixed set of things it wants, whereas the public want a multitude of different things, don’t they?

MF: That’s why I do think we at least need some determinate set of demands, at least provisionally, because otherwise things just dissipate. Unless we’ve got a set of demands of that sort, and some kind of model for a new orthodoxy — that’s the thing about the mainstream — a model for what we want the mainstream to look like. If we don’t have that, then those, as you say, specific determinate demands that business has will continue to dominate.

RC: In the last chapter of Capitalist Realism you also say that strikes in public services are self-defeating. Could you explain why?

MF: I think things have changed — the strikes earlier on this year, the TUC one and all of that, and the action that’s coming up in November. There’s a difference there because it approaches them all almost like a general strike. It’s not just that teacher’s are out, but the whole of the public sector. I’m still suspicious of one-day strikes, of just how effective they can be. Unless the discontent and militancy spreads beyond that one day — it’s very easy to contain a one-day strike. As happened in the FE college where I worked — you get this farcical situation where the principle, on a £120,000, would come down and hand out coffee to the people picketing, because everyone will claim to be on the side of the workers — because it doesn’t really cost anything. Rather, it costs us stuff — it costs the workers their wages for the day. It doesn’t really cause any lasting damage to the institution — that kind of action. Certainly they can easily plan for and, indeed, in many ways welcome it, because it lowers the wage bill for the year.

I wouldn’t want to make a definitive statement about the modern day situation now. But I think we need to think about winning hegemonic influence again. Why have nurses got more status than teachers? It’s partly that nurses often go on strike. It’s not that one should pander to the image of them in the media, but at the same time that’s where we’re starting from and why we have to struggle against it. Given that the media will use all of its weapons to produce what Alex Williams calls “negative solidarity” — turning one set of workers against another. With a one-day strike with teachers — the classic or standard line from the media is, “Well look at how the teachers are inconveniencing the rest of the workforce, of childcare and all of that.” I think we just have to think of the long-term strategic consequences of these things.

I hope that if one-day strikes happen they would work, but I just think that too often they haven’t worked. Rather than just kind of going over and over these things that have failed, keep doing them, is to look at different forms of disruption — things which actually inconvenience management. Like I say, in terms of teaching — why do things that inconvenience the students? Or if it’s children: Why inconvenience the pupils and the parents? Why not do something that only inconveniences management? I think the benefit of the kinds of refusal that would be invisible to the students, pupils, parents, etc., is that they show the absolute uselessness of this kind of bureaucratic work and the extraneous nature of managerialism. If one refuses to collaborate with certain managerial initiatives, one can perfectly well carry on teaching — just cause problems for management. I think more imagination about targeting disruption on those who you want it to hurt would be good.

RC: I interviewed Keith Famish several weeks ago about his book, Time’s Up! In it, he argues that the only way to prevent global ecological collapse and thus ensure the survival of humanity is to rid the world of industrial civilisation. Do you have any thoughts on this?

MF: If that is true it’s very depressing. That’s not a reason to object to it in itself, I suppose. We need to hold onto a model of the future. That’s something I want to retain from Marxism, actually — is a kind of technocratic vision of the future. It doesn’t mean it has to be one that’s completely indifferent to the environment. I suppose that I am one of those people he would attack in the sense that what I would hope for is that there’s a managed solution to these things that would involve technology. As I sort of mention in the book about rationing — I don’t see a problem with a rationing of resources at some point. But I don’t see that as necessarily meaning that we would be immiserated. People are always bleating on about the Second World War, how great that was, about how great people felt during the time of rationing, and sort of how healthy people were as well. I think we’ve seen in a sense the results of the opposite of that — that having unlimited access to things doesn’t produce well-being or happiness. On the contrary, it produces a kind of generalised misery I think. I don’t have any problem with an idea of a rationing of resource at some point, which I think could be part of the solution here. But I do still believe civilisation is possible. I think the question is: How are things to be managed? Part of what I want to argue for is a defence of the concept of management as opposed to managerialism. It seems to me that the only solution to environmental catastrophe is a managed one or we’re already betting on the catastrophe already having happened, or already acting like the catastrophe already has happened. I find libidinally alienating these visions of a sort of return to organic societies, little villages.

RC: Some might argue that such societies would be less alienating than what we have at present because they offer a face-to-face social existence.

MF: I think there are severe problems at a libidinal level, like that. There’s a reason that people don’t want face-to-face contact. Sometimes there’s a value in face-to-face contact. There’s also a value in impersonality. The achievement of an urban modernity was the ability not to have to deal with face-to-face contact all the time. I really think this is deeply dubious line — because I suspect what is behind the claim that it has to be like this and that civilisation can’t carry on is this kind of death-wish and this desire to take us back to the kind of conditions of a Medieval world.

RC: Those making the claim would probably argue that the death-wish is civilisation itself which is heading towards self-destruction.

MF: Fair enough. I can see that — but there’s two deaths here I think, neither of which I want. I really want to avoid this binary that either we’re going back to something which I think people — there’s a drive to escape those conditions that you can’t put back in a box. The only way of eliminating the desires for impersonality, for homogeneity, for mass production — the only way of ending the desires for that is by a post-traumatic forgetting I think. Otherwise those desires will maintain.

I think there’s nothing wrong with those desires actually. This makes me a Marxist I think, but I believe in mass production, of coordination, etc. Marx is somewhat sanguine about many of the issues that we wouldn’t be anymore because of — there’s this Promethean model of extracting resources from the Earth, and this kind of model of practice that was about converting the inert mater into something useful for us or whatever. I think we are rightly now somewhat suspicious of that kind of Promethean drive that’s indifferent to the depletion of resources, etc. Okay, so there’s a kind of death logic of that Prometheanism, which just uses up all the resources. But we don’t want to be forced between these two deaths, I think — a death of modernity and a kind of return to village life. “The idiocy of rural life” — that’s the great phrase from Marx and Engels. The issue for me is how to commensurate an environmental agenda with modernity, with the desires for mass production, for the homogenous, for the generic. I wouldn’t think these things are the only things that should go on in culture. But an important element of culture which I think is crucial to maintain.

RC: Won’t mass production end if you end capitalism? Don’t the two go hand-in-hand?

MF: I don’t think we have to see things in that way. What interests me is almost the opposite — the way we see elements of communism erupting in capitalism, at the point of highest capitalist triumph. Like I always say about Starbucks — Starbucks shows the desire for communism because everything attributed to Starbucks is everything that was said about communism — that it is homogenous, it’s generic, etc., etc. What do people want from Starbucks? Not the coffee — well, I hope not because it’s horrible. They want from it something that is familiar, that’s generic — that is a form of public space, kind of homogenous public space. We can argue that post-capitalism can deliver this better and cheaper than Starbucks does. The desire for public space, the desire for the homogenous and replicated can be synonymous. But all we’ve got at the moment is degraded versions of it, such as Starbucks.

There’s no reason to think that mass production is just a feature of capitalism. You know we’ve got robots and stuff. This is one of the concrete challenges about how we would construct an economy without capitalism. The difference between me and my line of and certain kinds of anarchistic approaches, I suppose, is that I just agree with Marx, where the global triumph of capitalism is the pre-condition for post-capitalism. If capitalism is global, then we need also to be global or sufficiently global. It’s not like capitalism operates by global government, but it has sufficient systems to coordinate its activities around the world which minimise the effectiveness of anti-capitalist struggle. I think we need similar systems of global coordination, and I think that can involve resource management so that we most effectively use it, so resources are used in the most effective way. I think condemning us back into this world of literary dark ages, where we’re in tiny villages and we have a limited sense of the world around us is a horrific prospect. I still maintain a hope of a rationally organised post-capitalist civilisation.





preoccupying: interviewed by the occupied times (2012)1

Occupied Times: Paul Mason recently commented that the uprisings of 2011-12 have brought the curtain down on capitalist realism. Can you briefly outline what you mean by the term “capitalist realism”? And do you believe that the financial crisis and the subsequent popular fightback have signalled a new beginning?

Mark Fisher:Capitalist realism can be seen as a belief — that there’s no alternative to capitalism, that, as Fredric Jameson put it, it’s easier to imagine the end of the world than the end of capitalism. Other systems might be preferable to capitalism, but capitalism is the only one that is realistic. Or it can be seen as an attitude of resignation and fatalism in the face of this — a sense that all we can do is accommodate ourselves to the dominance of capitalism, and limit our hopes to contain its worst excesses. Fundamentally, then, it’s a pathology of the left, nowhere better exemplified than in the case of New Labour. Ultimately, what capitalist realism amounts to is the elimination of left-wing politics and the naturalisation of neoliberalism. I think it’s too quick to talk about the end of capitalist realism, though what we have been seeing for the past couple of years is a challenge to this naturalisation of neoliberal concepts. In some ways, the austerity measures that have been implemented have constituted an intensification of capitalist realism. Those measures couldn’t have been introduced unless there was still a widespread sense that there is no alternative to neoliberal capitalism. The various struggles that have blown up since the financial crisis show a growing discontent with the panic neoliberalism that has been put in place since 2008, but they have yet to propose any concrete alternative to the dominant economic model. Capitalist realism is about a corrosion of social imagination, and in some ways, that remains the problem: after thirty years of neoliberal domination, we are only just beginning to be able to imagine alternatives to capitalism. But at least now we can imagine imagining such alternatives.

OT:What have you made of the global Occupy movement’s role as part of the mass mobilisation against the politics and economics of austerity and neoliberalism? From what you’ve seen can Occupy and other movements mount a sustained opposition to the ruling status quo, continuing with the global actions planned throughout May?

MF: The short answer is that this remains to be seen. There’s no doubt the Occupy movement has played a major role in the shifting of ideological atmosphere that has happened in the last year or so. You’re right that the question of sustainability is crucial. In Capitalist Realism, I argued that the anti-capitalist movement had become background noise to capitalist business as usual — something that it was by and large easy for capitalism to ignore. The question is, can Occupy provide the basis for a sustainable antagonism? The broad problem we’re facing here is, how can this antagonism be sustained now that the Communist Party has disappeared and trade unions have for the most part become quiescent? The party and the union structure provided sustainability, continuity and institutional memory. Now, it’s not that these are the only institutions that could provide such things, or that those older institutions would be fit for purpose, even if they had survived into the twenty-first century. But a genuinely new force that is capable of struggling against twenty-first-century capitalism must be able to fulfil those functions. I think we also need to recognise the importance of building hegemony — and this means stepping outside the activist universe. There’s a danger of the activist’s world become very self-contained. We need to reach beyond those intensely engaged with politics to those who don’t look to politics at all to explain the misery of their lives. It’s those people who have been most affected by capitalist realism, and who could be mobilised against it, if they could be reached.

OT:What was your reading of the riots last August? The epitome of neoliberal materialism or further evidence of a system built on greed breaking down?

MF:I think those involved in the riots were largely exactly the kind of people I was just talking about — those for whom “politics” means absolutely nothing. I’m not saying that the riots weren’t “political”, that they were an inexplicable upsurge of criminality, as the right did. The riots were political, but in a negative sense — they were a massive symptom of a failure of politics, an expression of discontent which lacked political goals or strategy. These are the signs of a system verging on collapse; people took part because they felt radically excluded. The invisible wall that prevents people from acting like this had collapsed — there was so little on offer that there was almost no incentive not to riot. It’s to be hoped that the discontent that exploded so powerfully, and, in many cases so tragically, in the riots, can be harnessed. Shortly after the riots, I went to a screening of the Black Audio Film Collective’s 1986 film Handsworth Songs, an essay-film about the 1980s riots. The film’s director, John Akomfrah, said that, if these rioters can bring the British state to its knees for three days, they will also be able to organise themselves. That is my hope.

OT: In the sections of the book where you cover the culture of work, you describe the combination of marketisation and maddening bureaucracy as “Market Stalinism”. This evokes the excellent US television series The Wire where the police, the politicians, the teachers, etc. are all shown to be focused, above all else, on “juking the stats”. Can you describe how Market Stalinism works and how we can hope to get rid of it?

MF: I hadn’t actually seen The Wire at the time I wrote Capitalist Realism, which is why there’s no mention of it in the book. But you’re right, The Wire exemplifies so much of what I wanted to say in Capitalist Realism. In fact, if you want to know what capitalist realism is, watch The Wire! Market Stalinism was my term for the kind of bureaucracy which was typical of Blairism, but which, as The Wire demonstrates, was by no means confined to Blairism, or to Britain. The neoliberal claim was that marketisation obviates the need for the state and for bureaucracy. But the result of imposing “marketisation” on public services is always a crazed proliferation of bureaucracy, via target setting, league tables, performance reviews, etc. Just as under Stalinism, everything becomes geared towards the production of appearance. In these conditions, gaming the system is inevitable. How to get rid of Market Stalinism? We need to expose one of the biggest lies in neoliberalism: the idea that it is an anti-bureaucratic force. This will involve a struggle against managerialism, and towards a workplace based on the collective autonomy of workers.

OT: You write in Capitalist Realism: “This battery of bureaucratic procedures is by no means confined to universities, nor to education: other public services, such as the NHS and the police, find themselves enmeshed in similar bureaucratic metastases.” Now that the police want to strike, do you think they should be seen as just another public service, or does their role of enforcing the government’s agenda mean we shouldn’t oppose cuts to the police force in the same way we do the NHS, education or welfare?

MF: It’s a difficult question, but one that should be answered pragmatically and strategically. If we are involved in fighting the police — either literally or at some other level — then the police are playing their role as ideological enforcers. Which isn’t to say, I must emphasise, that we should ignore police brutality and corruption. What happened to Alfie Meadows and others is appalling, and needs to be exposed. But we have to remember that the police aren’t the enemy, they are the servants of the enemy, and if all of our energy is taken up struggling against them, then they are doing their job for their masters very effectively. Ultimately, it must be far better if the servants are turned against their masters.

OT: A lot of what you write in the book comes from your experiences of working as a Further Education teacher. Where do you believe the Coalition, and New Labour before them, are going wrong with their education policies?

MF:The broader agenda here is the imposition of what I have called business ontology: the idea that only outcomes recognised by business count. It’s gradually become accepted that the principal — if not the only — role of education is to turn out the kind of compliant individuals which “business” wants. As systems from the private sector are increasingly introduced into education, the influence of managerialism grows, and the status of the teacher is downgraded. The pretext for the battery of bureaucratic and self-surveillance techniques that have been implemented by successive governments is that they “increase efficiency”, but their effect is to spread anxiety and erode the autonomy of the teacher. This isn’t an accident: it’s the real aim of these measures. Education has been corralled into naturalising and intensifying capitalist competition; it’s easy to forget, for example, that league tables were only introduced relatively recently. League tables produce the kind of Market Stalinist distortions I was talking about earlier. Teaching becomes a matter of training students for examinations; anything else is a luxury. Contrast this with the much-praised education system in Finland, which is fully comprehensive, has no league tables or inspectorate, and is based on trust in teachers.

OT: A predominant theme of the book is the issue of mental illness in capitalist societies. You write, “what is needed now is a politicisation of much more common disorders. Indeed, it is their very commonness which is the issue: in Britain, depression is now the condition that is most treated by the NHS.” It seems that with mental illness scarring the lives of so many sufferers and their loved ones in the UK, it should be towards the top of the political agenda. How can we begin to reduce the stigma, isolation and shame that our society still attaches to the issue of mental illness? How can we convince people that its cause has roots in the collective, not just the individual?

MF: This is a crucial question. The way in which social and political problems are converted into individual pathologies, to be explained via chemical imbalances or family history, neatly sums up so much of what has happened under capitalist realism. It’s what I’ve called the privatisation of stress. Depression has been described as a pathology of responsibility: you feel intensely responsible for the state that you’re in. The excruciating paradox is that, while you feel that only you can get yourself out of depression, the condition consists precisely in your inability to act. There’s more than an analogy with the political hopelessness and fatalism that have characterised capitalist realism. Depression, after all, is a pathology which centrally involves a sense of realism (indeed, there’s a phenomenon called depressive realism): the depressive thinks that they are being realistic, that they have perceived the real state of things, denuded of illusion. This describes the post-utopian tenor of capitalist realism perfectly: other societies had their illusions, their dreams of something beyond capitalism, but we have come to terms with the inevitability of competition and precariousness. Yet depression shows the extent to which people — even during the boom years — could not come to terms with this. With precarity increasing and welfare programmes eroding, it’s not surprising that there should be an increase in depression and anxiety. But this increase in distress has been pathologised, neuroticised and commoditised over the past thirty years. Instead of looking to unions when our workload becomes unbearable, we’re invited to look for a medical solution. Stressed by too many working hours? Take this medication, which will restore the balance of your brain chemistry. Worried about losing your job? Tell me about your mother. This is a major example of the naturalisation process I talked of earlier. What we need is a denaturalisation (and consequent politicisation) of mental illness. I think the formation of a dedicated pressure group could work towards this. We need something like a revival of the Anti-Psychiatry movement of the Sixties and Seventies. Well, not so much a revival as a re-occupation of the terrain that Anti-Psychiatry fought on; you could argue that the receding of Anti-Psychiatry correlates very closely with the rise of capitalist realism.

OT: With neoliberal economics being so globalised, so strongly enforced by powerful entities on a national, international and supranational level, does this not make it that much harder for any one nation-state to adopt a new economic paradigm? Would there not be credit-rating downgrades from the “objective” agencies who missed the Enron and sub-prime scandals, a hysterical frenzy among the corporate media, veiled threats from the IMF and OECD and, quite possibly, stampeding capital flight? Couldn’t there even, depending on the extent of the country’s departure from the consensus, be hostility from the other neoliberal countries?

MF:Of course, that would happen, and this kind of threat plays a large part in the current mode of capitalist realism. In fact, this is pretty much a statement of what capitalist realism is at this time. But it presupposes that capital is the most powerful force on earth, and it’s this presupposition which needs to be undermined. How? By constituting a counter-force capable of disciplining capital. We’ve become used to a world in which workers fear capital, never the reverse. Capitalist realism has never been about direct ideological persuasion — it’s not that the population of the UK were ever convinced of the merits of neoliberal ideas. But what people have been convinced of is the idea that neoliberalism is the dominant force in the world, and that, consequently, there is little point resisting it. (I’m not suggesting that most people recognise neoliberalism by name, but they do recognise the policies and the ideological narrative which neoliberalism has so successfully disseminated.) This perception has arisen because capital has subdued the forces acting against it — most obviously, it has crushed unions, or forced them into being consumer/service institutions within capitalism. But you’re right — the situation has changed since the heyday of social democracy, and one of the principal ways in which it has changed is the globalisation of capital. Indeed, this is one way that unions were outmanoeuvred: if your members won’t work for these rates, we’ll go to a place where workers will. One of the strengths of Occupy is that it is a transnational movement. But the challenge for Occupy is whether it can constitute a force capable of inducing fear into capital. My suspicion is that it won’t be able to do that on its own, and that it will need other institutions and groups — probably including unions — if it is to succeed in being a counter-force to capital. Capital isn’t actually global, but it is sufficiently global, and therefore any effective opposition to it needs to be sufficiently global also. The concrete question — somewhat obfuscated by many of the debates about centralisation versus networks — concerns coordination. How are disparate groups to be coordinated? We can we learn lessons from neoliberalism here: its success was based on building a patchwork of heterogeneous groups, often with different, even conflicting agendas.

OT: The book ends very optimistically, saying that there is a sense that anything was possible again. That was two or three years ago now. Still optimistic? More or less than before?

MF: Well, I think that the optimism has somewhat been borne out by what’s happened since I wrote the book. As I said, I think it’s going too far to say that capitalist realism is over, but the fact that Paul Mason could make such a claim shows how much has changed over the past couple of years. Just before the student militancy blew up in the UK at the end of 2010, I spoke at a conference, making the — in retrospect — mild claim that there would be shows of public anger against austerity, and I was accused of “revolutionary nostalgia”. The point is, that it was my accuser that seemed to have the most (hah!) realistic handle on things then. But surely there’s not anyone now who thinks that public discontent in the UK is at an end. Things have got better and worse since 2009: worse, in that panic neoliberalism has further attacked the welfare state, NHS, education, etc.; better in that opposition is coalescing, and the ideological climate has shifted.

OT: You’ve written a lot about how popular culture has reinforced capitalist realism. You show how commercial pop and hip-hop music and films like Children of Men and Wall-E, even when purporting to critique authority and the system, in fact leave only a message of its inevitable perpetuation. Do you feel that there is much in the way of popular culture that does successfully subvert capitalist realism? What subversive music, films and books can you recommend to OT readers?

MF: I’m not saying that there are no political potentials at all in the popular culture I discuss in Capitalist Realism. What I was pointing to, though, was the fact that anti-capitalism at the level of a film’s message does nothing in itself to disrupt the super-hegemony of capital. Anti-capitalism — or at least anti-corporatism — is utterly standard within Hollywood films: consider something like Avatar, for instance. This is the objective irony of capital: nothing sells better than anti-capitalism. Or, even more bleakly, late capitalism’s culture is anti-capitalist. There is an asymmetry: we struggle against capital, but part of capital’s defeat of us is that it can sell our books. This isn’t a completely closed circle, though. The issue is how culture connects up with struggles, and you can’t second guess that. It’s possible that any of the films I talked about could contribute to the development of class consciousness or inspire people to engage in struggles. Conversely, it’s possible that even those films or television programs which inventory the features of capitalist realism end up reinforcing it. Take something like The Wire: yes, it exemplifies practically everything I say about capitalist realism, but, for that very reason, you could say that it supports, rather than subverts, capitalist realism. You could very easily take away the message that struggling to change things is pointless; the system wins in the end. But one film I would recommend to people, if they haven’t seen it, is Mike Judge’s Office Space, which I briefly discuss in Capitalist Realism: I’ve seen no film which better captures the bureaucratic immiseration of late-capitalist managerialism labour.





we need a post-capitalist vision: interviewed by anticapitalist initiative (2012)1

AntiCapitalist Initiative: Paul Mason recently argued that in light of the Arab revolutions, capitalist realism has come to an end.2 Do you agree?

Mark Fisher: I think that is going too far. I understand why Paul made that claim, but capitalist realism is very tenacious. Certainly, things look very different to how they did a few years ago during the high pomp of capitalist realism — when it was thought that the age of revolutions was in the past, that no great change will ever happen again, that every part of the world will eventually end up capitalist.

These ideas — basically, the theses of Francis Fukuyama’s The End of History and the Last Man — were widely accepted at an unconscious if not a conscious level, even by those opposed to capitalism. It’s that acceptance of capitalist dominance, or rather the unthinkablility of any break from that dominance, which constitutes what I’ve called capitalist realism. But with what has happened in the Arab world, the hope for radical, systemic change has been re-ignited. It’s part of a shift in ideological atmosphere that we have seen manifested this week in the French and the Greek elections, with their votes against austerity.

Austerity, after all, is the deflated yet intransigent form that capitalist realism has assumed since the bank crises. Before the bank crises, capitalist realism managed to look as if it were a post-political condition — not a particular ideological constellation, just the way things were. It’s no longer able to sustain that post-political mask. But if capitalist realism were actually finished, then there wouldn’t be any austerity at all; it’s only because people continue to accept that there is no alternative, not only to capitalism, but to neoliberal capitalism, that the swinging cuts that have been imposed in the name of austerity have gone through. As it is, in Europe, we are only seeing the beginnings of a challenge to austerity. These challenges are by no means insignificant, but it’s not yet the end of capitalist realism.

But there’s another way in which capitalist realism persists. Capitalist realism can also be a seen as the inability to imagine an alternative to capitalism, and I don’t think we’re close to overcoming this yet. Not surprisingly, after thirty years of capitalist realism, our capacity to even conceive of alternatives to capitalism has atrophied. Opposition to neoliberalism is growing, but this new anti-capitalist mood has yet to bring forth any powerful vision of post-capitalism. Certain tendencies in anti-capitalism are, in effect, inversions of capitalist realism — they accept that capital controls technological modernity, and offer only withdrawal and retreat as an alternative.

AI: How can the left organise itself today to maximise its impact?

MF: The most important problem the left now faces seems to me to be coordination. There are any number of groups hostile to capitalism, but the task is to bring them together to form a sustainable antagonism. We need to forge greater links between those already engaged in struggle — the unions, Occupy, the student movement, the various anti-cuts groups — and also to reach out to those who aren’t yet politicised. The way that the opposition between centralisation and decentralisation has dominated discourse on the left recently has distracted us from the fact that coordination does not entail Stalinist centralisation. Systems can be coordinated and decentralised at the same time. After all, that’s how capitalism operates!

A key question is institutional memory; a system that has no memory cannot learn and will keep repeating the same mistakes. What’s crucial is that we give up any nostalgia for previous eras. Leftist politics has been weakened by its attachment to superseded forms of economic and political organisation. There’s a strange romance of glorious failure which we have to give up.

A major part of grasping the potentials of the present is reaching out to precarious workers. We need to think creatively about how they can be politicised and organised.

AI: Do you think that the autonomist critique of classical Marxism has any relevance in helping us understand the modern world?

MF: Yes, I do. The autonomist critique of authoritarianism and Stalinist bureaucracy is something that we shouldn’t forget. Any credible leftist politics now has to take the problem of anti-authoritarianism very seriously. At the same time, however, we have to recognise that the situation is very different from the context in which autonomist ideas first emerged in the 1960s and 1970s. Then, the Communist Party and the trade unions were very powerful; Stalinism was still an oppressive presence.

None of these things are true today. Whatever the merits of autonomism anti-statism, it has to be acknowledged that anti-statism is now hegemonic. There’s a congruence between the language of neo-anarchism and David Cameron’s Big Society, which is not to say that the discourses are identical. But one problem with anti-statism — particularly when coupled with localism, as it often is — is that it makes any defence of institutions like the NHS very difficult. The drive of the original autonomists was to escape existing institutions, whereas I think our aim today should be to produce new institutions.

AI: Today people talk about “zombie capitalism”3: an undead system which people can’t see beyond. Does this chime with Owen Hatherley’s Militant Modernism4 argument about the way the left has to challenge the dominance of neoliberalist capitalism as the only modernising force on the planet?

MF: Yes. Neoliberalism is now undead: it was massively discredited after the bank crises, but that hasn’t stopped it continuing in zombie form. The default settings of most of our institutions remain neoliberal, and will do so until they are reset. In claiming there was “no alternative” to neoliberalism, the neoliberals were staking a claim that they were the only modernisers. Resistance to neoliberalism was a resistance to modernisation.

Neoliberal ideologues have successfully imposed an equation between neoliberalisation and modernisation; this has been central to capitalist realism. Look at the way that something like the Royal Mail disputes are reported in the mainstream media: the workers are always said to be struggling against “modernisation”, when really they are opposed to privatisation.

At the same time, it’s clear that neoliberalism has in many ways arrested modernity. That’s part of the point of Militant Modernism: the rise of neoliberalism has seen a turn to “postmodern” cultural and political forms, a formal nostalgia that is manifested in the refurbishing of familiar modes. It’s not for nothing that Fredric Jameson calls postmodernism, with its culture of retrospection and pastiche, “the cultural logic of late capitalism”. Neoliberalism claims to be the only modernising force, but it’s increasingly clear that it is incapable of delivering modernity. The current crisis is a massive opportunity for the left to reclaim modernity for itself.





“we have to invent the future”: an unseen interview with mark fisher (2012)1

Mark Fisher: Do you drive?

Sam Berkson: No

MF: I don’t drive either and I can strongly relate to many of the poems in Life In Transit (), having spent so much time on public transport. There was something that Mrs Thatcher said: “If you are a man over thirty on public transport, you’ve failed”. I think that’s really telling actually. The men I know don’t drive but often women do — I think with women, it might be safety that makes them want to drive. I always find it a waste of time being in a car. Whereas on a train you can read, write, do something else, and you can listen. But almost nobody listens to each other anymore because of the amount of headphones, etc. I think what comes out strongly from your poems is it is public transport in name only — because 1) it isn’t owned publicly, as all these hideous private operators, and 2) the space isn’t actually public, as you draw out in a lot of the poems, people are engaged much more in their own private conversations on mobile phones. To a ridiculously embarrassing and excruciating extent sometimes.

SB: Usually only a few people are listening. It’s ironically public because everyone is so much in their own private world, what they’re doing is bringing a much more private world into the public sphere. Everybody, right- or left-wing, doesn’t like the idea of people listening into their private conversations. And yet we are at a time when our conversations are the most listened into because all the creeping technology. And also we’re complicit with things like Facebook, we’re quite happy to blurt out what we’re doing all the time.

MF: I think there is a double thing going on — increasingly people are concerned about Facebook and its erosion of privacy or whatever. I think there is an interesting doublethink coming out here. In one sense people are talking on mobile phones, assuming that people aren’t listening to them but sort of knowing at some level that at least one person will be. And then there is that Facebook phenomenon when you put stuff on there, hoping that people will actually look at it — desperately sharing it, looking for an audience that you may or may not get. And then neurotically checking how many likes or comments you get.

SB: It is not caring about the audience that is there but desperately needing more and more of an audience.

MF: I think celebrity is important on lots of levels to do with… It’s faux intimacy isn’t it? There is a generalisation of the female-targeted gossip magazines, the general form of culture, TV etc., it is this phenomenon of referring to people by their first names, like you get on the cover of these things as if you know them.

Tim Burrows: People reading mags on the train, talking about dieting.

MF: It is bio-control and the model for that is the women’s magazine. It is about reducing a certain anxiety. It is not about saying you must do this one thing. It is about on one page Geri Halliwell is happy with her curves. The next month she is feeling much better because she has lost weight. You get these double binds being issued all the time by these magazines. The function of which is to destabilise and keep people in a state of anxiety and also add on solutions to every problem which is always that a consumer object will resolve this for you. Dieting is bio-power, a form of body control. What we have got with this digital culture now is this weird thing of hyperordinariness. You have got people who are done up to the nines but it isn’t like David Bowie where you are playing with some abstract aestheticisation. We have got people who have this uber ordinariness — it is a normative model: perfect teeth, right skin tone. An utterly conservative artificiality.

SB: You hear people say symmetry is the ideal human beauty, and I like to think that symmetry is probably something that looks OK. But to deny that there is some sort of beauty in the eye of the beholder, that there is something original and unique about things and that we each find different things beautiful is bringing things back to the power of something very conservative, as a way of conforming towards being beautiful — and of course it is not normal at all, it’s a really freaky look.

MF: It’s a wash-back from digital, a lot of people are photoshopping themselves. The normalisation of cosmetic surgery, Botox, etc., is part of this bio-power regime and this constant anxiety about appearances, etc. Cosmetic surgery is not good — it’s not good! People are concerned about their appearance, but they are measuring by the standards of this depressing normativity. Neuroses is highly productive, and very useful for capitalism. What’s better than inherent dissatisfaction? Inherent dissatisfaction can be sold to endlessly. That’s why that women’s magazine model is so useful for consumer capitalism.

SB: You see that on the tube — there is an advert at the moment about wishing your friends were more beautiful, I think it is an advert for a camera — that idea that you want to be displayed as beautiful by the fact that you hang around with beautiful people.

TB: That has always been the paradox of the tube — it is where you will find the most professional people in London at a certain time, but it seems like the least airbrushed place you could be. You are up against someone’s face, see every imperfection.

SB: Yeah the lighting’s terrible isn’t it! The light on the tube is deliberately meant to be uncomfortable because people are less likely to fight each other if they are uncomfortable and exposed. If I were designing the tube and I wanted to make it comfortable, I wouldn’t do it like I do it. Take things like the pubs — they worked out that pubs put people off if you can’t see inside. The whole idea of a dark little nook so you come in to hide away in a corner; what you really want is big glass-fronted windows. People can come in and feel comfortable and safe.

MF: That isn’t a pub to me, that’s a bar.

SB: It just feels uncomfortable because it feels like you are being watched. It’s the panopticon, isn’t it.

MF: It is second-phase Foucault, a sort of auto-panopticon. I remember someone said during the time Big Brother was still worth thinking about that the difference between Big Brother and Foucault’s panopticon was in Foucault’s panopticon you didn’t know whether you are being watched or not, whereas contestants on Big Brother know for sure they are. There is now this phase with Facebook of the auto-panopticon, as we said earlier, where people make themselves the object of surveillance and survey themselves in this weird way.

SB: We can fight back. And we have also got this other problem on tubes and buses — there are so many adverts around.

MF: Semiotic pollution as I call it.

SB: Yeah. And what is the sensible response to that? It is to put earphones on — it is to not look at your surroundings, just essentially to shut your senses off to your surroundings. This is a terrible position for people to be in. I would argue that it is actually worse to be unaware of your surroundings. Everyone’s advice is to be in the present, look around you, experience things, etc. But if you are going to do that all you are going to see are adverts and messages and hear all these announcements.

MF: It’s quite stunning. If you go to Europe, I noticed this in Sweden, Stockholm, there were no adverts. I thought, “What’s going on?” Even in the New York subway doesn’t have many. There is something about the massive cyber-blitz of adverts in London. It is not that people tune out of public space — there is no public space for them to be in anyway. It is either a case of a certain kind of immersion or in this babble — the babble of competing mobile phone voices, or the babble of capital, shouting at you to buy something.

SB: You can bury yourself in your own personal sand — you can shut yourself off. This seems to be a lot of people’s way of travelling is to literally disconnect from the world around them, and in some ways it makes sense — but at the same time you are disconnected from the world around you.

MF: I think certain kinds of disconnection are needed now. Unplugging from certain kinds of networks. I was speaking to my students about trying to unplug — we are in a new phase of human life I think. In the Seventies, boredom was a big problem. Boredom was an existential void, boredom could then be thrown back at the entertainment industry and mainstream culture and it was also a challenge to ourselves: why are we allowing ourselves to be bored? Given that we are finite animals and we are gonna die, it was a moral scandal of insane proportions that we can ever be bored. But now boredom is a luxury we don’t have any more, because of our smartphones, even when you are standing in a bus queue or waiting for a train, you’ve got this constant low-level stimulus. Boredom and fascination are mixed in together now, to go back to those celebrity magazines. And a better example of this is those free papers in London which have thankfully disappeared — thelondonpaper, one word, and the totally aptly named London Lite. The Evening Standard and Metro are great journalism compared. Those papers were an utterly terrifying prospect when they appeared. Talk about semiotic pollution, and also just the way they literally clogged up the streets and you’ve got really poor immigrants responsible for irritating people, to stand in the way of commuters and push these things into their hands. But then the total compliance of readers, because they operated on a tired exhaustion. You’d look down the carriage, every single person will be reading those papers. You could feel the intellectual and cultural level just sink. Commuting time is probably the time when many people are paying the most attention to culture. It’s not that I was immune to this — you’d see the headline on it, about some celebrity you half know and are not even interested in, yet you’d still want to know. It was this form of curiosity where you are not even interested in it. So you’d read the whole of this paper, not even interested in it, but at the same time it had drawn me in. This is what I mean about boredom and fascination. I imagine many people like myself have had serious books in their bag that they would have read if these papers weren’t there. It tells you a lot about the way capital takes advantage of the worst instincts and exhaustion.

TB: Which is kind of why Boris Johnson is so popular. He is the hero of the freesheet magazine () Shortlist generation.

MF: I think the thing with Boris is a bit like Franco Berardi said about Berlusconi — the person who mocks the place of power while occupying it. That’s also Boris isn’t it. Somebody who is weirdly popular around young people in a depressing way, because he doesn’t take politics seriously or doesn’t seem to. Of course, what he does take extremely seriously is that of advancing his own position and own class. This form of faux bonhomie and cynical dismissal is an extremely dangerous problem by which class power naturalises itself. I think Cameron has a version of that, not that he is as popular, but he is pretty good at coming across as a friendly sort of fellow you can talk to. My sense of the Cameron government is a total smash and grab. They know they are not going to get in again, but they also know if they change the defaults on certain things then no Labour government in the immediate future without massive change at the top at the culture of the Labour Party is not going to have the capacity of change it back.

SB: I read this recently, I don’t know if it was a quote but Thatcher was asked what her greatest achievement was and she said New Labour.

MF: I don’t know if it is a quote but it is certainly true. I joined the Labour party. I have never joined a political party before but you have to have the same ambition that New Labour had and think five years ahead. If a few of us went in with a strong agenda you could drive it in a certain direction.

SB: I thought that and joined the Green Party.

MF: Fair enough. I don’t want to concede any territory. I don’t want to put all my eggs in that basket. There was no point joining the Labour Party during the Nineties. They were set on one direction, towards New Labour, neoliberalisation, there was no way it was going in any other place, whereas now I don’t know where it’s going. It might carry on with this desperately banal soft neoliberalism or it may become something else in the end.

Two years ago UEL was totally festooned with lots of revolutionary banners, all of that — it was the time of the student cuts, it was an incredible effervescence of militantism, which seemed to come out of nowhere. Now when you go to UEL and you walk down the central corridor where all the banners were hanging off is Costa and Starbucks and the biggest sign you can see is an office with Credit Control on the side. There is a parable of what happens to every public space there. The public space that was asserted failed so now we are back into these corporate monoliths and Credit Control in big letters right in the centre of the corridor.

TB: There are Costa Coffees in every NHS Hospital waiting room these days.

MF: My wife’s from Gravesend and in a hospital near Dartford, McDonald’s bid for the franchise of the restaurant. It is such a Philip K. Dick world to me where you can have shops in hospitals. I don’t intrinsically object to change — I just object to the fact that everybody’s change is shit. The thing about capitalism is that it provides things that nobody likes. When people talk about choice and capitalism — Microsoft, that sums up everything. Nobody wants it, everybody has to have it. It is the same with chains. Who is a big fan of them? Almost nobody, but we all have to go in them.

SB: People used to complain about British Rail being late all the time because we thought we had more ownership over it. Now we accept the fact that of course they are going to charge too much, because they can, and of course it is going to be crap, because we haven’t got any other choice. Before we felt it was closer to us.

MF: There was a case for modernisation of those publicly owned industries — they were run at a massive inefficiency, but that was just a pretext of privatisation. They should have been improved while being publicly owned. It costs a lot more now it is privatised. It is some kind of ridiculous fee, how much more the tube costs the public purse since it was part privatised. It is a destruction of ethos with the workers themselves — the same with hospitals, why aren’t they cleaned properly? Because you bring in private contractors whose only incentive is to deliver it as cheaply as possible, to pay their cleaners as cheaply as possible. If you don’t have that public service ethos then everything of course will become shoddier. It’s glossy shoddiness, isn’t it. That is the reality.

SB: Again and again you come up with the same paradox. It is almost exactly the opposite to the thing it says. You’ve got more choice; you’ve got no choice. It’s shinier, it’s better; it’s worse. It’s cheaper; it’s more expensive. I think realistically we are not going to go back to nationalisation — it may not be a good idea.

MF: The one poem that really pulled me in was that early one about people not having a ticket. So powerful on so many levels I think. The class dynamic of it. Having been in lots of those positions — either sitting there watching (), or being the person who hasn’t got a ticket…

TB: It reminded me of George Osborne being caught out in first class without a first-class ticket. He said he didn’t want to waste taxpayers’ money on a first-class ticket.

MF: Nice! You’ve got to respect the improvisational verve of that ludicrous excuse. Nothing sums up capitalism more than that, the fact that first class persists. The other day I went to Liverpool and it seemed like I was walking endlessly to get past first class. And of course, no one is in first class. Is it even economic to run, or does it have to be there because the class system demands it?

SB: That is the attraction of first class, there is no one in it. The whole idea of competition in train travel was completely flawed — it is not like you can go on the other line on the other train that leaves at exactly the same time — there isn’t one.

MF: The one thing I think that most people would unequivocally nationalise overnight is the railways.

SB: It is expensive for the government to run, because they are just giving loads of public money to private companies who then charge loads of money. It hasn’t liberated things, it hasn’t given us freedom. I want to renationalise public space — not necessarily for the state.

MF: I think we have got to distinguish public space from the state. The state is legitimate, I would argue, insofar as it facilitates public space, but the public must be thought of as separate from the state. The state might be a precondition for the public, but it isn’t the same. People want public space, which is why Starbucks is popular because it offers a generic sociality. It is a form of anonymous, generic kind of space, and even things like the X Factor, why people like it is because people are publicly, collectively, communing in something. So it shows that even in these conditions, where ideologically everything is opposed to the public, there is still a desire for the public and all we are getting is degraded forms. What communism would offer is you can have these generic spaces where people can come in but you don’t have to pay for shit coffee. That’s the kind of public space we need in the future really, where people can get together but don’t have the parasitic add-ons of capital really.

SB: I think this whole thing about the means not the ends, just saying this is the step that I like. I’ll go this way because I like this way. I find it hard to imagine what my ideal future is like but I just think: What things work? And let’s do more of those things that work.

MF: I think it is an imaginative task now is for us to think, what is the future of the public? If we can accept that the neoliberal story that the public is over — that story is now over. If the public isn’t going to be just old-style nationalised state industries, state centralization, all of that, what is it going to be like in the future? We don’t know, we have to invent it.





hauntology, nostalgia and lost futures: interviewed by valerio mannucci and valerio mattioli for nero (2014)1

NERO: Let’s start from your last book, Ghosts of My Life…

Mark Fisher: Well, the overall theme of the book is the disappearance of the future, at least in culture. For me, the failure of the twenty-first century is that the twenty-first century has yet to really start — so, in a way, it’s a disappearance of both the present and the future. This is something that is quite evident in music. In Ghosts of My Life I mainly collected a number of pieces that have already appeared in a variety of different places, together with some specific articles written especially for the book; it’s an augmented collection, you can say. I wrote a number of pieces concerning hauntology, which is a term originally conceived by Jacques Derrida that started to regain currency in 2006: I picked up on and used it in relation to a number of different musicians such as Ariel Pink, Jessica Rylan, the Focus Group and the whole Ghost Box label… So, in Ghosts of My Life I tried to explicate how this concept had been gaining a new currency, especially in relation to music.

N: Talking about hauntology, there’s one excerpt in your book that sounds like a recap of this kind of aesthetic, even if it’s not about music: that is, when you describe the typical atmosphere of a British TV show from the Seventies. Now, musicians such as the ones from Ghost Box heavily rely on this kind of memory — you know, of BBC educational programs, TV series from the Sixties and Seventies and so on. And they often spread a sort of melancholic feeling, which is quite different from the simple nostalgia of the past…

MF: Melancholia is one of the great threads running through my book. I think that what happened after the Seventies — and particularly during the Eighties, when the occupying forces of neoliberalism arose — was this sense that things were shifting. But probably the extent to which they would have shifted was not that clear at the time — at least not to me. I guess this is partly about the age that I am, and the expectations that I’ve formed, being born at the end of the Sixties, into a culture that was vibrant and experimental. It was something you could describe as an “informal education system”. I didn’t like school too much myself, but I didn’t need to like it because the source of education could come from elsewhere. Music culture was a big part of that: it was in music press — like NME and so on — that I first encountered the work of continental theorists like Derrida and Baudrillard. It’s this kind of wide and interconnected network that I call “popular modernism”, a kind of infrastructure for disseminating and distributing experimental theory and culture. At the time it was just right, you just expected things to be like that, there was nothing special about it. But during the Eighties, this network slowly disappeared. At first, I thought it was just a temporary blip and that it would have all come back. But I was wrong: it was an irreversible shift. So you see, things that are taken for granted just disappear. And this brings us to a melancholia, a hauntological melancholia.

N: This is interesting, because if we take the classic idea of melancholia — as proposed, for example, by iconologists and so on — we can describe it as the painful consciousness of our limits in contrast to our desires. How does this “hauntological melancholia” differ from that?

MF: First of all, let me tell you that I try to distinguish this kind of melancholia from standard depression, which is another important issue to me. Because you know, standard depression is fairly spread: it’s not very acknowledged, at least not as a political and cultural problem; instead, it’s treated as a chemical problem, or as the result of people’s family history. In other words, it’s highly privatised. I think depression is manifesting itself in terms of low self-expectations. Depressive people don’t expect much from life. Things are getting worse and they are changing only to stay the same in a more intense form — and that’s what capitalism is. So you have this kind of sadness or depression that is basically a consequence of adjusting to such things. But the melancholia I’m describing is a completely different thing. That’s why I’m opposing it to depression: it’s a much more conscious articulation, an aestheticised process. I would actually say that if depression is taken for a granted state, as a form of adjustment to what is now taken for reality, then melancholia is the refusal — or even the inability — to adjust to it. It’s holding on to an object that should officially be lost. So instead of saying, “Well, Public Service Broadcasting was like that, but now things have changed”, you simply refuse to accept the loss of the object.

N: And why is that “hauntological’?

MF: Let’s put it this way: it’s easy to say, “Oh, things were great in the Seventies, let’s go back to the Seventies”, but I think the real issue is “What kind of future did we expect from the Seventies?” I mean, there was a trajectory, and this trajectory was interrupted. And now we find ourselves haunted by this future that we vaguely expected at the time, and that was terminated somewhere during the Eighties by the values related to neoliberalism. From this point of view, it’s no coincidence that the Eighties saw a traumatic and violent defeat of the left, at least in the UK.

N: You’re introducing another major theme of hauntology: the so called “nostalgia of the future”…

MF: I think that the concept of “nostalgia of the future” partly illustrates one of the paradoxes that I’m trying to get across through the book; for example, hauntological music is often accused of being nostalgic. To a certain extent this is true, but the point is: “nostalgic compared to what?” I mean, the whole twenty-first-century music scene could be described as nostalgic: where is the sense of the future now? Today, if you ask people what is “futuristic music”, they would reply electronic music from the Nineties, or even Kraftwerk, and stuff like that. In a way, we still rely on an old future.

N: What do you think of recent phenomena such as vaporwave and the “pop art of the virtual plaza”? According to music critic Adam Harper, artists such as James Ferraro or Fatima Al Qadiri are at least trying to reconsider the concept of future in music, taking inspiration from virtual technologies and the whole late-capitalism imagery…

MF: I actually think that vaporwave still relies on a twentieth-century vision of the future. The sound texture and even the imagery is derived from Nineties corporate sources. The fact that vaporwave has been perceived as an example of “futuristic music” shows a kind of diminished expectations: can we really compare that to, let’s say, Kraftwerk? Or to jungle music? Or to BBC Radiophonic Workshop? All of these things clearly delivered a sense of future-shock, like “Where does this thing come from?” After listening to such artists, people had to reconstruct the whole sense of the music that was around them. Unfortunately, I just don’t think there’s anything like that in relation to vaporwave…

N: But it’s nonetheless interesting how these artists relate to a typical twenty-first-century imagery. To quote the Wire’s review of Fatima Al Qadiri’s album, this music “imagines a world of frantically animate matter with no life outside of the iPad.” You can’t deny that such a description sounds like a mirror of our time.

MF: I think Fatima Al Qadiri mirrors this time by also not having a specific relationship with our time, at least in a way previous music did. Don’t get me wrong, I sincerely think this music deserves attention: it was very interesting when I was in Berlin at the CTM Festival and somebody played some vaporwave stuff over big speakers, and you could just hear that it wasn’t meant to be heard that way. You know, the compression, the sounds… it really seemed music made for smartphones and tablets.

N: The relation between music and smart technology also resembles what happened with the visual aspects of our everyday lives: the idea of “image” can no longer be completely detached from the devices on which it is displayed…

MF: Indeed, smartphones and tablets are increasingly becoming — if not exclusively — the image of what the present is; of the extent to which communication technology has completely colonised our sense of what technology is. This is another symptomatic phenomenon of the twenty-first century. Now, think about it: how much did we really care about communication devices in the twentieth century? We cared a lot about music technology because we could hear that… But phone calls and stuff like that: who really cared?

N: These communication technologies are also affecting our idea of representation. Let’s make an example: the concept of realism in presentday horror movies is often based on the idea of “digital footage” (i.e. amateur footage that depicts supernatural events, etc.) In a few words: it is “real” what could be captured through an amateur camera. All that considered, how much do you think these technologies are influencing our understanding of reality and our relation with imagination?

MF: It looks as though, for example, we forgot the grand visions that science-fiction once had about technology: I mean, we used to talk about terraforming, transforming planets, altering solar systems! And from terraforming now we are discussing how to improve our access to the internet. That’s a kind of reduction in itself, I think. Anyway, speaking schematically and overgeneralising, I think that there’s far too much emphasis on online digitality. It has totally colonised our sense of what the present and the future are, and I think the actual phenomenological reality is engaging with what I prefer to call “capitalist cyberspace”. So I’d rather not talk about technology as such, but more about the way technology operates within our economic system. For example, I think one of the key elements of digital technology is this sense of being slightly late all the time. Let’s think about social media like Twitter: you’re in a perennial state of reactivity, by the very fact you’re there, you’re always late, and therefore you’re always in a state of slight and intense anxiety. I think we kind of normalised this as part of our nervous system, where even if something is perceived as instantaneous, it isn’t quite. And this is part of a general sense of lack, of things lagging behind, which is a feature of the digital as such. Capitalist cyberspace demands a constant dispersion of attention, you’re always solicited to respond and to react, so it’s very difficult to be absorbed in anything. Also, the basic form of digital communication is command: every time you pick up your smartphone, you’ve been told to do things. And even if they are friendly commands, nevertheless it’s a massive stress on the nervous system. Just dealing with these commands, or even ignoring these commands, blocks us with a constructive relationship to the future: that’s the other side of the destruction of time-perspective.

N: And then there is also the inundation of information. Do you think that when you see a lot of things, it makes you feel like you’ve already seen everything?

MF: Well yes, it does. But back in the day, it wasn’t just the lack of exposure to things that made people think that they were experiencing something new. They were really experiencing something new, it wasn’t just an illusion.

N:But don’t you think that these technologies somehow affect our imagination? For example, for a long time the future was envisioned by humans through the invention of new technologies (i.e. Leonardo da Vinci, Isaac Asimov, etc.), and in the Nineties technology was seen as a tool for change on an aesthetic and political level (techno music, cyberpunk, etc.). Today, instead, technology itself has become the subject who’s “telling us what the future is”, bringing about an inability to imagine it…

MF: I agree. If you think about it, nowadays we don’t have “the future”: we have upgrades. And in a way it’s a pre-postmodernist thing. The whole experience of modernity was this double perception that whatever your current experience is, it’s already obsolete; because modernity is a process which never reaches an end: there’s no resting, no point of equilibrium, only this endless upgrading. And then today you have corporations such as Apple, whose business model is entirely based on this: obsolescence. You don’t expect to own an iPod for very long, if only because they don’t last that much… I’ve had five or six already!

N: So what’s the difference between the modernist approach and this let’s say post-postmodern way of being modernist?

MF: Well, I mean that the degree in which modernism survives is the sense of newness, as in traditional modernism, but it’s been transformed in terms of upgrades. In the past, the grand vision of the future was essentially a great dislocation from the present: that grand vision is no longer available to us. Look at science fiction: I think already in the Eighties there was a crisis of the genre, but anyway, the last great science-fiction movies are from that time. Today, we’re still locked into Blade Runner, dystopian cities, or even William Gibson’s cyberpunk… I would say that The Matrix itself, with its vision of a fully simulated society, couldn’t update this vision. Perhaps Minority Report, with its pop-up corporate advertisings, captures the reality of capitalist cyberspace even better than William Gibson: today cyberspace is like those continuous pop-up windows that constantly appear as advertising, commanding us to do something, in which we are not fully immersed in; it’s more like a background noise from everyday life.

N:Let’s go back, then, to the years when — according to your analysis — the trajectory toward the future was interrupted: the Eighties. Perhaps, one thing we shouldn’t underestimate, is that the Eighties is also the decade where postmodernist aesthetics became a common language; we come from thirty years of temporal pastiches, past and present anachronisms, double codes, quotations and appropriations from different eras… Wasn’t that a negation of the future itself?

MF: Absolutely. Also, if you read texts like The Ecstasy of Communication by Baudrillard, which is from 1987, you find out that things like the overwhelming flow of messages, the inability to constitute a distinction between the inside and the outside, to deal with having no halo or private protection anymore… Well, he’s basically talking about Twitter and Facebook! And if you think about another author such as Frederic Jameson, his texts from the Eighties are astonishingly prophetic. What was the specificity of postmodernism in the Eighties, is now the dominant aesthetic paradigm; to the degree that it’s very hard to see anything else. One of the most penetrating things of Jameson’s analysis is this awareness of a particular form of anachronism that was emerging and calling attention to itself: if you think about a film like Body Heat, it was set in the Eighties and it had a contemporary aesthetic, but the feel was something from film noir of the Thirties and Forties. Now, that mixture of contemporary settings and out-of-date references is exactly the standard for so much culture of the twenty-first century. We naturalised anachronism.

N: What about physical spaces? We talked about how postmodernism reshaped our relationship with time, but if you think about it, the term “postmodern” first emerged in architecture as a reaction against modernist architectural movements.

MF: I think that the defeat of modernism in architecture, as described by Owen Hatherley in his book Militant Modernism, is part of the picture I’m describing. Just consider a city like London: the most futuristic parts of the city are the brutalist ones. You go to the Barbican Centre and you spontaneously think about the future, precisely because of the modernism of the buildings. Fashion is another example: it seems to be stuck, they’re cyclically re-modernising old styles. It’s not even fashion as it used to be.

N:In that sense, what’s your opinion of Simon Reynolds’ Retromania, his book about the obsession that pop culture has in relation with its own past?

MF: I mostly agree with Simon’s analysis, but I guess that the main difference is that he sees retromania as an internet-related phenomenon. Of course the internet changed our lives, and of course the idea of timeless time deeply affected our habits, even in music; but we also have to bear in mind all the consequences of the naturalisation of anachronism and its side effects, which are issues related not only with the possibility of accessing a space like the internet: it’s also a political matter, it’s the way in which we use the internet and the way in which the internet functions in our economic society.

N: We started by talking about the “informal education system” you grew up with during the Seventies, and how it shaped a common idea of “popular modernism”. How do you think younger generations relate to that? How does their idea of “future” compare to the old one?

MF: I think that they still feel a need for futurism, but it’s in terms of a spectral, virtual presence of the former sense of it. I think that this leads to the fact that there’s no specific discontent about the present. But when you produce something and you have the feeling that everything’s already been done… it’s sad, you know?





PART SIX

WE ARE NOT HERE TO ENTERTAIN YOU: REFLECTIONS





one year later…1

K-PUNK IS ONE YEAR OLD!

Contrary to the plague of miserabilism that seems to have descended on blogdom (as identified by Robin), I know EXACTLY why I blog…

For much of the last year, especially when things got REALLY BAD, it’s been my only connection to the world, my only outside line… It’s reinvigorated my enthusiasm for so many things, and pricked my enthusiasm for things I’d never previously considered… (I say this especially to the currently disenchanted Marcello, who has done both; I remember being drawn out of a catatonic depression last year by reading through the entire Church of Me archives.)

It’s made me many valued friends, both online and (thanks to Luke’s brilliant walks) off too… Plus it’s put me back in touch with friends I’d lost contact with. (Yeh, there’s the occasional wanker, but I can honestly say, very few, almost none really, certainly there’s far fewer of them than the excellent, high quality correspondents.)

In short, and no exaggeration, it’s made life worth living…

I know it’s an awful cliché, but it’s really true, a blog is what you make it…

So heartfelt thanks to all of those who have contributed, by linking, commenting, reading or inspiring…





spinoza, k-punk, neuropunk1

Being a Spinozist is both the easiest and the hardest thing in the world.

Easy, because it is simply a matter of acting in such a way as to produce joyful encounters. Hard, because the defaults of the Human Operating System (OS) are, in one of nature’s most deliciously cruel tricks, set against this. The principal question which Deleuze and Guattari’s Anti-Oedipus set out to answer was deeply Spinozistic: “Why is it that people are so prepared to fight for their own servitude?” Meanwhile, Burroughs’ Spinozistic abstract model of addiction — i.e., very much NOT a metaphor, what could be more literal? — describes humanity’s enslavement to a vast immiserating machine whose interests are not its.

All of which, to come back to RadarAnomalous’ Badiou-doubts2 leads to another positive way in which we can wrest reason/rationality back from what Robin Undercurrent calls, hilariously, “boredom-mongering epistemonauts”. According to Spinoza, to be free is to act according to reason. To act according to reason is to act according to your own interests. Finally, however, we have to recognise that, on Spinoza’s account, the best interests of the human species coincide with becoming-inhuman.

Many of the problems with Human OS come from its inefficient bio/ neuro-packaging. By contrast with very simple organisms that are set up to be attracted to what is beneficial to them and to flee from what is hostile to them, human beings have a convoluted system for processing exogenous and endogenous stimuli, routed/rooted in the arborescent central nervous system running out of the spine and overseen by the brain. Actually, according to neurologists, the brain is in effect, three distinct brains — the “reptilian brain”, which is responsible for basic survival functions, such as breathing, sleeping, eating; the “mammalian brain”, which encompasses neural units associated with social emotions; and the “hominid” brain, which is unique to humans and includes much of our oversized cortex — the thin, folded, layer covering the brain that is responsible for such “higher” functions as language, consciousness and long-term planning. Neurology also gives a rigorously materialist account of the thanatoidal confusions between desire and prohibition that Lacan and Žižek have described.

Crucially for Burroughs’ analysis, it provides an account of why humans are so endemically prone to addictive behaviour. This is because there are actually two separate circuits, one for motivation and one liking. In the latter stages of addiction, you want to consume the drug, but it is improbable that you will also like jacking up. Add all this up, and you pretty much have a neuronic recipe for the unremitting misery, hatred and violence that have characterised human history. Nietzsche said that if animals could describe the human species they would call it “the sad creature”.

Yet, precisely because of this hideously collocated morbid assemblage, the human contains a potential for destratification which the functionally streamlined simple organism lacks. This is where Spinoza converges with cyberpunk, and hence with Deleuze and Guattari, cyberpunk’s main theoretical program. One of the consequences of Spinoza’s analysis, as I said before, is that human beings’ emotion-generating hardware can be understood using the same causal framework that is applied to the so-called natural world. In the twentieth century, cybernetics will make the same discovery.

But let’s dispense with one of the lazy, hazy assumptions we’re all prone to fall into whenever we hear the word “cybernetics”. Cybernetics does not only refer to technical machines. Wiener call it the study of control and communication in animals and machines (btw: why leave out plants?). Its principal discovery is “feedback” — a system’s capacity to reflect and act upon its own performance. So, as Luke and I were discussing the other day, the whole point of cybernetics is that nothing is “more cybernetic” than anything else. There are only systems with more or less feedback, and different types of feedback.3 So if the word “cybernetics” calls up only gleaming steel you have the wrong association.

If cyborgianism is oriented towards a maintenance and reproduction of the organism and its homeostatic control circuitries, Cyberpunk or k-punk (one of the motivations for the “k” btw is the origin of the word “cyber” in the Greek “kuber’) flees towards a cybernetics of organic disassembly. Again, let’s be clear here. You don’t disassemble the human organism by replacing its parts with metal or silicon components. (That’s why the term “cyborg” — or “cybernetic organism” is misleadingly redundant. All organisms are already cybernetic). What matters is the overall organisation of the parts. Do the parts operate as hierarchically organised and functionally-specified “organs” within a cybernegatively construed interiority or do they operate as deterritorialised potentials pulling from/towards the Outside?

This latter arrangement is what Deleluze and Guattari, following Artaud, designate as the Body without Organs. As Nick pointed out long ago, the BwO is an essentially Spinozist concept: “when it is a matter of the body without organs it is always a matter of Spinoza”.

One of the sublimely ruthless (=machinically efficient) aspects of the behaviour of Aliens, predators and shoggoths from which the organism recoils in horror is their readiness to ditch body parts when they are damaged or redundant. The BwO quickly dispenses with any features that either inhibit its flatlining slide towards the zero intensity of pure potentiality or which draw it back towards the closed-down depotentiation of the organism. (I have sometimes wondered about the k-punk potential of “If thine own eye offend thee, pluck it out.”) This, astonishingly perhaps, is Spinozist reason.

We can now see why becoming inhuman is in the best interests of humanity. The human organism is set up to produce misery. What we like may be damaging for us. What feels good may poison us.

The fascinatingly destratifying potential in neuroeconomics, then, lies in the possibility of using it against its ostensible purposes. As yet another of Kapital’s slave-programs, the purpose of neuroeconomics is to induce the kinds of idiot-repetition-compulsion Burroughs and Downham delineate. According to Rita Carter in Mapping the Mind, “where thought conflicts with emotion, the latter is designed by the neural circuitry in our brains to win”.4 The Spinozist body without organisation program is aimed at reversing this priority, providing abstract maps for imposing the goals of reason upon emotional default. So k-punk is also neuropunk: an intensive rewiring of humanity’s neural circuits.

Even if they have often repressed the knowledge, all cultures have understood that being a subject is to be a tortured monkey in hell, hence religion, shamanic practices, etc., geared towards the production of BwOs. Paradoxically, the ultimate interests of any body lie in having no particular interests at all — that is in identifying with the cosmos itself as the BwO, the Spinozist God, the Lemurian body of uttunul.

To get super-immanent, then, let’s think about blogging. As Undercurrent described it over on hyperstition, at its best, blogging can be a “participative molecular collective of truly K+ processes (i.e. buying materials to write about so other people reply and recommend other things which you then write about…)”.5 What has begun to emerge on the most destratifying elements of the blogosphere is a depersonalising, desubjectifying network producing more joyful encounters in a positive feedback process in which mammal-reptilian conflict defaults are disabled.

On the side of the BwO, everything is positive, so what use can be made of this animal-in-a-trap howl of outraged subjectivism? Well, at the moment, Marcello is functioning as a morbidly compelling example of how not to be a good Spinozist. Spinoza’s rigorous analysis of sorrow shows how the sad are typically not engaging directly and sensitively with the world but with their own frozen images (think of these as being like outdated data caches). Consider, if you can bear it, the way in which Marcello tilts at the windmills of his own phantasms in a flailing, pathetically resentful hunger for attention that is exemplary of how to produce sad encounters. It is a display of that Romantic fetishisation of self-destruction that, far from being subversive or transgressive, is the Human OS in person. (n.b. It is crucial to distinguish the intricate art of self-disassembly from the gruesome thanatropic processes of self-destruction.)

Still, in the words of Deleuze’s favourite Spinozist formula, no one knows what a body can do. Maybe there will come a time when even Marcello will join us in this only-just-beginning, inciting experiment in collective identity-shutdown. What reasonable person wouldn’t?





why dissensus?1

The word “dissensus” came to me while I was sitting on the 28th floor of Centrepoint a few weeks ago.

They took me to the top of the mountain.

The view was of course stunning, literally sublime: London in all its unmanageable vastness, seen from both above and from its very heart. It was high, so high, and with the long table in front of you and the metropolis below, you felt like you should be crushing the economies of Third World countries.

I was there for a meeting about Moodle, which is a “Virtual Learning Environment”, a fairly new — and, so it would turn out, very exciting — open source educational software application. I knew nothing about it and when were “put into groups” by the Blairite Komissar in charge, I simply asked what were the merits of Moodle as opposed to using html. Cue black looks and frowns from the initiates. The Komissar, who has joined our group, tells me, in the nicest possible way of course, that I “seemed to be sceptical and might like to think about my attitude.”

Aha! So being sceptical is pathological now. Rude. I geddit.

Course, quick as a flash, I replied. “Yeh… and you ‘might like to think about’ being a Blairite managerialist.”

“Blairite?” he replied, clearly stunned at having his politesse challenged. At being counter-pathologised.

Later, a woman from Dublin College, also in our group, launches a notbefore-time assault on PowerPoint (“death by bullet point…” “something used by people with no charisma…”, as someone rightly said on Danny Baker’s radio show this week). She pointed out that she had done a presentation a few weeks ago and people had been appalled and outraged that SHE DID NOT HAVE POWERPOINT. As she rightly argued, if you have an organised mind, there really is little need for PowerPoint.

Cue Komissar, again. “PowerPoint? Rubbish? It’s just a tool isn’t it?”

I didn’t say the following, but I wish I had: Well, not really Mr Progtech Microsoft, that’s a rather naïve view of technology donchathink… Technology, especially MS technology, has a tendency to induce behaviours, it does not “enable” some pre-existent human “creativity”… (Sure, there can be innovative uses of PowerPoint, but we all know what the standard use of PowerPoint involves… total redundancy… banal bullet points apologetically talked through.. sentences tailing off… “well, as you can see…” all in the name of “professionalism”…)

Blairite power IS Microsoft… in every sense… diffuse… emolliating… blandly inescapable…

And you only see its real face when you challenge it, step outside the smothering consensus of politeness.

The English master class are the only people for whom hypocrisy is not only acceptable, but obligatory.

“Yes, yes, you have a grievance, yes, of course things are totally unjust. But there are ways of going about things, old chap. Procedures. Aggression, confrontation, they never get anything done, do they? (And after all, they are a little vulgar, don’t you think?) Now, that’s not what I’m saying, I think your intensity is admirable, but other people, well. They’re not quite so intelligent. They won’t understand. So I would advise moderating it a bit. For your own sake. Carry on like this and things might get uh difficult for you…”

Stupidity and cowardice are always the stupidity and cowardice of the other.

Power is always the power of the big other, that which speaks through you and of whom you speak.





new comments policy1

Please note: feminazis, cult studs guilt mongers, passive consumer-whingers, “friends” who occupy the moral high ground, misanthropes, gliberals, stoner pacifists, therapy-pushers…

Whilst I disagree with Luke’s idea that comments boxes should be closed entirely, I have decided to institute a new policy on comments.

Only comments deemed to be positive by the Kollektive will be left up. The purpose of the site is to build the Kollektive, so comments by those intrinsically hostile to the notion of collectivity or those hostile to the k-punk project per se will be deleted as soon as possible, so as not to waste the energy of the collective on distracting, egocratic nonsense.

Clearly, I am at work throughout the day, and unlike some UK public service managers, my job does not allow me to spend all day in front of the computer. I am hoping though that, when I am not available to delete comments, others in the Kollektive can be deputed to take over.

Maybe another solution would be to only allow registered users to comment. Commenting here is a privilege that has been abused.

k-punk is not a “liberal” or “democratic” “free for all” (cf. The Prisoner). There are plenty of other ill-disciplined forums where people can air their resentments, ill-thought bile, and tedious ego-defence opinionism.

Or of course you can say what you like on your own blog. They really are very easy to set up.

What could be easier than sitting on the sidelines and carping? I know some people get a nice warm feeling in the stomachs from their sense of innate superiority to all “groups” and “gangs”. Perhaps what those people should do is follow the logic of their position to its logical conclusion and utterly withdraw from public forums and indeed public life altogether.

Perhaps even more egregious though is the passive-consumer whinger. Think, really, how outrageous it is for the likes of “Roger” to appear in the comments box and assure me that I am “coming off like a prick”. On my own site. I don’t say that k-punk is my site in a possessive sense. I just mean it is space that has taken me a great deal of time, stress and anguish to build. It really is like inviting someone into your own house and having them abuse you. If anything makes me a “prick”, it is accepting a situation like that.

After all, Roger, and others, you have paid absolutely NOTHING for access to this site. Nor, naturally, have I received any financial remuneration for producing it. That isn’t to say that I haven’t received massive positive affect from doing it — what could be better than being part of a collective network? But it really has reached the point where I dread coming to k-punk to see what irrational spleen or spoilt boy/girl moodiness I will have to waste energy on dealing with next.





comments policy (latest)1

Basically the situation atm is this…

The comments boxes have become almost completely unproductive. Almost all of the worthwhile discussion happens between members of the Kollelktive, who, if the comments boxes weren’t there, might be inspired to produce their own posts.

The comments boxes have heated things up — and SPEEDED things up.

They need to cool down and slow down.

Yesterday, when I closed most of the current comments boxes down, you can’t imagine the relief I felt. I could come to k-punk without feeling sick with anxiety about what unthought-out oedipalised rage, overgrown adolescent boy sulks and gliberal stupid American platitudes (“hey man, all that Marxist lingo makes my cringes cringe…”) I would have to deal with.

It was definitely more stressful than work. And I have a very stressful job.

My problem is that I attribute rationality to positions and people who clearly are incapable of exhibiting it. It’s partly to do with my background, which persists at a neuronic level, in the insistence: YOU ARE INFERIOR, BEND YOUR HEAD. So even when I am faced with clinically deranged second-stringer stalker-obsessive autists with delusions of relevance, part of me thinks, hmmm maybe they are right.

They most certainly are not.

There is no more urgent task on this hell planet than the production of rational collectivities.

These are not fascist gangs with “leaders”. Nor are they perfectly functioning neurobotic Spinozist networks. No, but they can be on the way to this latter, if there is a commitment amongst the collective to a STARTING FROM WHERE YOU ARE.

Demanding perfection before you are prepared to commit is Prog Tech SF. Starting to build a way out of hell HERE, NOW is kyberpunk.

The Kollektive takes priority. In the comments boxes as they have developed in the last few weeks (k-punk as New ILM… yeucccchhhhhhhh!), the Kollektive has struggled to make itself heard over the howls of outraged subjectivists, Conflict-Addicted Organisms (CAOs), and, worst and most pitiful of all, ILM-style one-liner one-upmen.

Do you feel alienated by this?

Good.

And goodbye, then.

The comments will be restored if there is a way of restricting them to registered users only.

We are not here to entertain you.





chronic demotivation1

What is supposed to be good about dope? The problem with it is not just the resultant psychosis but the ACTUAL STATE it puts people into in the first place — chronically demotivated, lethargic, filled with the kind of idiot porcine self-satisfaction that is the dialectical obverse of feeling paranoid. “Better to be Socrates dissatisfied than a pig satisfied…”: not for stoners, whose only commitment is to the pleasure principle, to the shortest route to total relaxation. Thought, thought requires effort man, stop oppressing me, let me sit here and babble senselessly, coz that’s creative, right, don’t mess with my mojo, but buy me some munchies when you go to the shop, yeh?

What could be better proof of Lacan’s claim that the nirvana principle — the drive towards the total extirpation of all tension — is not the death drive proper but merely the highest expression of the pleasure principle? Stoner stupefaction seeks only to remove tension, to become a zombified consumer, shambling to the fridge or the late-night garage to satisfy the constant craving of the insatiable Tungsten Carbide stomach of Kapital opened up in your organism by the dope.

The meat, and all it wants…

Thought, meanwhile, begins beyond the pleasure principle. As Houellebecq says in relation to Lovecraft, only those who are dissatisfied with life want to read and think. What from the perspective of those slaved to the pleasure principle is the introduction of a discordant and dysfunctional element (“hey, Infinite Thought, why you going to the library? Why don’t you mong along here with us? Come and play with us, Nina, FOREVER…”) is from the POV of anti-naturalist kommunist konstructivism the positive libidinal motor of an ever-complicating process of intelligence-production.

I know someone, probably Gleebot, will immediately leap on what I’m about to say and produce some counter-examples which will allegedly disprove it, but most stoners are males, aren’t they? More than that, and here’s why any empirical refutation won’t wash, smoking makes you male. Self-satisfied, concerned only with yourself, unable to care about others even if you wanted to.

One of the many myths about stoners is that they are not aggressive. It’s true that, in themselves, they don’t FEEL aggressive. Their blissed out idiot state of hyper-relaxed slackness precisely wipes away any feeling that would interrupt their communion with their own organism. But when this onanistic self-involvement is threatened, well, then we see how irascible, irritable and bad tempered stoners can be. Stoners demand the right to their own (passive) aggression, but detest any show of aggression from others, precisely because any antagonism — particularly political antagonism, my god antagonism and rationality, what could be more of a DOWNER? — disrupts their “right” to take pleasure. Bad vibes, man.

I need hardly underline the point that young people voluntarily subordinating themselves to this pacification program is not exactly politically positive. It’s not only because they all smoked it themselves when they lolled about on a full grant or because their kids are all smokers that the government is in favour of relaxing the legal penalties on the smoking of the supposedly harmless drug. It’s because it is politically expedient. What could be better for the Komissars of Kapital than if half the population spends all their spare time (i.e. convalescence from reproduction of Kapital time) smoking dope and the other half spends it on SSRI anti-depressants?

Fukuyama’s Brave New World inspired argument against SSRIs was that, in producing a feeling of well-being, they remove the psychological motivation for action, for proving yourself. Though Fukuyama’s argument is obviously advanced in the services of pro-Kapital enterprise, its logic can also be used by communists. You will not struggle against Kapital — you will not struggle against anything — if you are emolliated by narcotics.

Of course, the obvious counter-example that people will reach for is Rastas and dub. But the Rasta relationship to dope was very different to that of most white workers toking on their time off, or students spending all day in what the Fall, gloriously, called “a State-subsidised cannabis haze”. It was not only that the level of downpression to which the Rastas was much greater than the “hard week” of the white worker, it was that their consumption of drugs was part of a disciplined religious and political ritual. Exactly the opposite, then, of those who turn to dope as a means of fugging out the world.





how to keep oedipus alive in cyberspace1

1. Contaminate k-space with the monkey superstition that there are such things as “persons”.

2. Reject rationality and promote the propagation of opinionist virus (= Nietzschean perspectivism = mbodied/embedded subjectivism = Kapitalist ideology).

3. Ensure the continued disengagement of reason by personalising all discourse. “You’re only saying that because you are… insert sex/ethnic/ sexuality/abuse/marital status here as applicable ().”

4. Promote the use of certain common fallacies of reasoning, in particular: Irrelevant appeal to tradition/ authority — “We’ve always done that here…” — or to popularity — “Some people might like it…”

The Ad hominem fallacy — attacking the arguer instead of the argument (this is especially popular amongst lawyer-politicians and their defenders).

The straw man fallacy — invent a deliberately weakened version of your opponent’s position, demolish it, then claim to have refuted their argument.

The Spinoza Agents (the Cold Rationalist equivalent of Gibson’s Turing Cops, who, unlike the Turing Police, are dedicated not to the curbing of AI but to its acceleration) report that a new and dangerously virulent form of artificial stupidity is spreading unchecked throughout k-space. This is a nasty combination of the ad hominem and straw man irrationalist mind viruses, provisionally codenamed “straw ad hominem”. This oedipalising idiocy proceeds thus: given that this argument challenges commonsense and what is consensually accepted, the person who presented it must be insert allegedly derogatory remark about mental health/marital status/ upbringing here (), therefore anything they say is to be dismissed. No need to refute their arguments substantively, natch.

The SAs warn: “this is unusually moronic even given the low standards we expect of you jumped-up monkeys. Watch it.”





we dogmatists1

No, I am not tolerant.

No, I do not want to “debate” or “enter into dialogue with” liberal democrats, PoMoSophists, opnionists, carnalists, hedonists, mensheviks, individualists…

No, I don’t respect you, nor do I solicit such respect for myself from you.

The defenders of tolerance, debate, dialogue and respect advertise their bourgeois credentials with such advocacy. I’m sorry, apologists for exploitation of labour, but, no, I don’t see it as my duty to provide the enemy with a space to express itself. You already have the global videodrome, the judiciary, the police, the psychiatric establishment and the most powerful armies of the world on your side. If that isn’t enough, you could always make the effort to build your own profile and audience so you can add to the chorus of approval for the Satanic-worldly. (Too much like hard work? Thought so.)

Be under no illusions: differends, incommensurability, language games, forms of life, very far from disrupting the Dominant Operating System are that operating system in person. Žižek is right about Rorty being right: for all their apparent philosophical wrangles, the political upshot of the theories of Derrida and Habermas (and one can presumably add in Lyotard here) is exactly the same: defence of the liberal values of respect for Otherness, etc., etc.

Yes, I want to leave all that behind. One of the scandals of Badiou’s thought is to announce the blindingly obvious: difference is not suppressed by the established order, it is its banal currency. Fragmentation, deconstruction, cut-up are the very stuff of which mediocracy is made.

So, yes, hold on tight and spit on me, I am a dogmatist.

But what does being a dogmatist entail?

Briefly, it involves commitment to the view that there are Truths. One can add to this, the view that there is a Good.

It’s no accident that, since Kant,2 rationalism has been held to be synonymous with dogmatism. Post-Kant, we have grown accustomed to the view that critique rather than dogma is the only acceptable ethical and philosophical position, so that “rational dogmatism” sounds like the worst imaginable insult.

But where does this attack come from? Fundamentally, four interrelated positions: authoritarianism, mysticism, egotism and relativism.

Far from being equivalent to authoritarianism, as the postmodern liberal doxa would have it, dogmatism is the only effective alternative to authoritarianism. Authoritarianism and postmodern “forms of life” entail one another. The familiar PoMo relativist insistence that it is neither possible nor desirable to arbitrate between the different ethical and ontological claims of “incommensurate” “language games” surrenders reason to mysticism. Unlike rationalist systems, which proceed from stateable axioms or principles, these “forms of life” are unable to point to any reasoning which founds them. The sheer existence of these “discursive communities” is held to be the justification for any traditions and beliefs to which such communities might subscribe. It should come as no surprise that Spinoza was feared and reviled by the authorities of all established religions, since Spinoza used reason alone to prove that the core belief upon which traditional theism was based — that there is a personal, transcendent God who performs miracles and has free will — was irrational nonsense. In other words, it was Spinoza’s dogmatism that allow him to overthrow the “authority” of the Torah.

In terms of contemporary academic philosophy, rationalism is beset not only by Nietzschean-Wittgensteinian-Lyotardianism and Heideggerian Nazi poetico-mysticism, but also by the qualia cult of consciousness. This “philosophy” replaces the ineffable mystery of God with the ineffable mystery of consciousness. It consists solely in the negative claim that consciousness cannot be explained by either science or philosophy. This is religion in the worst sense.

But dogmatism is religion in the best sense. It is only through dogmatism — ruthless subordination of your Self to an impersonal system — that his majesty the Ego can be crushed. This has been the appeal of nontheistic religion throughout the ages. The Ego is simply authority in miniature (just as political authoritarianism is Egotism writ large), a micro-despot which can only be pushed off his throne by a commitment to sober systematicity.

Finally, it is a mistake to oppose dogmatism to pragmatism. Postmodernism advocates pragmatism at every level: not only at the level of how to get things done (the realm of praxis) but also at the level of what is to be done. But dogmatism is capable of distinguishing between what is to be done — what the goal is — from how this is to be achieved.





london litened1

The free paper plague is infesting all areas of London life. From dawn to dusk… Arriving at the station in the morning, the Metro already piled up, waiting. Leaving the train, slipping into your somnambulant self, commuter character armour freezing into place, automatically making the Waste Land walk across London Bridge (“I had not thought that death had undone so many”), the way already blocked by reps proffering City AM. (London Bridge is a film set now (hyperreal city): there’s barely a day where there isn’t a camera crew or some out of work actors playing a bit part in some promotional pantomime.) And in the evening, rushing to escape the black hole of the city, you have to play live-action Pac Man with the London Lite and thelondonpaper drones blocking the pavement every few yards. As if London needed people — poorly paid members of the city’s immigrant subproletariat, at that — actually being employed to obstruct the pavement. In the train, the free papers are everywhere, their dull gloss a lurid temptation for the drained mind… cut and pasted PR… nothing happening forever… cocaine celebrities… a survey says… join in the debate… vote: more or bore… your texts… consume it and feel lulled and sullied… Semiotic parasites designed to prey upon hypnagogic drift. Weapons against the city’s intelligence. Almost no one reads books anymore. London litened, littered, public transport desolated into a time waste land. Look around the carriage, snapshot of a Myspaced city: diversity without difference, homogeneity without communality — bodies reduced to claustrophobic zombie meat fighting for space, background hum of mutual hostility simmering, yet everyone is reading the same thing…





no future 20121 (for nick kilroy)

There was no future, but it wasn’t like anyone expected.

2003. We’re wandering through the industrial spectres and overgrown dereliction of the Lea Valley. It’s like the world has ended. A world has ended here, in fact. But now non-human worlds teem and thrive amid the deserted factories and the waste-strata. Feral plants, algae so thick and artificial-looking you’d swear you could walk across the canal on it. It is not a space that humans live in anymore. But it is a space they explore. Most of us there that day had alternative names. K-space names. Nick K, Woebot, Heronbone.

Heronbone shows us a social history in the form of discarded packaging from defunct commodities. They call Heronbone the bard of Stratford — this is his patch, his Waste Land, and many of his words are assembled from discards, fragments of grime lyrics recalled from the pirates, observations of insect colonies, flights of fancy prompted by this desolated space. Nick K is ablaze with projects and schemes, his photographers eye captured by images every few minutes. Photography is a darker art than most people routinely suspect. The visionary photographer can find the image, but they cannot necessarily see everything that is recessed in it. Most photographs act as mirrors, reflecting back the past into a frozen present. But some make contact with more mysterious dimensions of time. The “traces and clues of things to come”. Futures bleeding back. Omens that can only be read retrospectively.

Sometimes there are signs but no one who can read them.

2007. Other stalkers are moving through the scurf space we had traversed four years before.

Repetition, with a difference:

“Right,” said Sinclair, straightening up. “Are you ready for the zone? From here on in it’s pure Tarkovsky.” And so it was. Light-industrial spaces, car-wrecker’s yards, square-windowed studios, haulage depots. Then, a mile further on, we hit the fence.

The perimeter of the Olympic site is now secured by a plywood fence that is 10ft high, around four miles long, bright blue in colour and chinkless. In places it is double-banked, in others it is topped by razor- or barbed-wire. The ODA began its construction last spring, and the last sections were put into place in July.

The fence is a barrier designed to exclude not only access, but also vision. There are no viewing windows built into it, no portholes for the curious stakeholder. To see inside the zone, you must ascend a Stratford towerblock, hire a helicopter, or — the desideratum — visit the ODA’s website, which provides stills of the construction process and mockedup futuramas of the park (light-glinted buildings, sparkling water features, happy munchkin people).2

Nothing Again Nothing

The “mocked-up futuramas of the park” surrender East London to the eventless horizon of the end of history, in which nothing happens forever. Nothing happens, again and again. Nothing happens. And every time it does, its announced with a press release.

In between our many visits to the Lea Valley in 2003 and Iain Sinclair and Robert Macfarlane’s expedition there in 2007, what happened, of course, was the awarding of the Olympic games to London. In that period, Nick K died, the photograph he took that day in 2003 now looking more than ever like an eerie pre-echo both of his own fate, and the fate of the whole area, which has now been consumed by the CGI-shadow of 2012.

The first signs of a coming non-event is always the CGI.

Ghost Marketing

The CGI simulations that ringfence the Lea Valley project forward fake futures which will never arrive but which are immediately effective, already re-organising space in East London, already diverting resources from public to private. What this constitutes is a kind of negative hauntology, operating according to the familiar hype-dynamics of corporate capital. (Cybercapital relies on its own ethereal entities, of course.) We are not dealing with the spectres of lost possibilities, the ghosts of things that never happened, or the traces of forgotten events photoshopped out of the end of history. Instead, we are confronting the CGI-signs of a massive pseudo-event. A pre-scripted PR initiative disguised as an authentic happening.

According to some interpreters, 2012 is the year of the Mayan apocalypse. (Don’t worry, though, its scheduled for December, so it shouldn’t disrupt the Olympics.) The Olympics are now correlated with the end of time in quite a different way.

The arrival of the Olympics in China is not just a ratification of the Chinese regime, it’s also another moment in the end of history. 2008 is a symbolic threshold, much like 1989. Anti-modernist protests against China obscure the fact that the Olympics, like the People’s Republic of China, is now inherently meshed with global capital. 2008 will celebrate this integration, which may well presage a new mode of capitalism, in which authoritarian state control co-exists with PKD-like piratical capital. Victorian vampirism reformatted for cyberspace. The spectre of ultrapostmodernism, in which everything can be mass-replicated, but nothing new will ever be invented.

Memory Disorders

Both in Derrida’s original articulation of the concept, and its current recirculation, fifteen years after Specters of Marx, “hauntology” must be understood in relation to postmodernity. Postmodernism, in turn, has to be understood, as Jameson has taught us, as “the logic of late capitalism”. Postmodern temporality is captured by Fukuyama’s claim — everywhere officially disavowed, even by Fukuyama itself, even as, surreptitiously, it is universally accepted, operating as a kind of presupposition of the contemporary cultural unconscious — that we have reached the “end of history”. This is not only the conclusion of the process, but also the final cause to which everything has always been tending. End, then, in a double, appropriately Hegelian, sense: the terminus and the teleological goal.

The logic of late capitalism awaits the disintegration of the old Soviet bloc to find its fullest expression. Jameson’s great contribution was to have grasped the way in which, far from leading to an efflorescence of cultural innovation, the unprecedented dominion of capitalism over the globe and the unconscious would lead only to a cultural situation given over to previously inconceivable levels of stagnation and inertia. Shorn of the confidence that an elite modernism could provide a revolutionary alternative to pacifying entertainment, no longer capable of believing that there was any form of detournement which could not in turn be re-incorporated and commodified, Jameson is the successor to both the Frankfurt School and the Situationists.

Jameson’s Marxism, in other words, had taken cognizance of Baudrillard’s critique. It was Baudrillard who anticipated the fusion of the opinion poll and reality TV in the seamless system of cultural “interactivity” which disarms any oppositional impulse by not only interpellating the consumer, but inducting them into its circuits. You decide. Text your response. Vote online. Join the debate. More or bore.

Jameson and Baudrillard understood that this user-generated content, together with the concomitant retreat of the cultural elite that has enabled it, would not lead to new kinds of creativity, but to pastiche and retrospection. Just as the capitalist language of “diversity” is a cover for new modes of homogeneity. The duplicity that operates here is more a strange structural effect than any deliberate attempt at mystification, Jameson observes.

What Jameson calls the “nostalgia mode” is one expression of this homogeneity. This remains one of Jameson’s most ingenious formulations — the nostalgia in question is not manifested in a psychological state but in a kind of unacknowledged formal reiteration.

Hauntology is the counterpart to this nostalgia mode. The preoccupation with the past in hauntological music could easily be construed as “nostalgic”. But it is the very foregrounding of temporality that makes hauntology differ from the typical products of the nostalgia mode, which bracket out history altogether in order to present themselves as new. Post-post-punk, indie’s equivalent of mock Tudor.

The great sonic-theoretical contribution of the Caretaker to the discourse of hauntology was his understanding that the nostalgia mode has to do not with memories but with a memory disorder. The Caretaker’s early releases seemed to be about the honeyed appeal of a lost past: Al Bowlly’s aching croon in the Strand ballroom in prewar tearoom London, buried beneath the sound which constitutes something like the audio-correlate of hauntology itself: crackle. In veiling the past, crackle also makes the dimension of time audible. It is through this scratching of the scanner-lens that we can hear the time-wound, the chronological fracture, the expression of the sense, crucial to hauntology, that “time is out of joint”. Dyschronia.

As the Caretaker project has developed, though, it has become more about amnesia than memory. Theoretically pure anterograde amnesia is not about the inability to remember, so much as the incapacity to make new memories. The inability to distinguish the present from the past. The cultural pathology of a clip-show culture locked into endless rewind.

It as if the Caretaker has taken us from an Overlook Hotel/Dennis Potter theme park into a simulation of neurological disorder. Fragments of tunes providing minimal orientation in an labyrinth of abstract sound. Have you heard this before? You can never be sure.

Nostalgia for Modernism

But if there is one act which makes a case for the supreme pertinence of the concept of hauntology in relation to music today, it is Burial. Precisely because Burial deals with nostalgic longings, his music does not belong to the nostalgia mode. What you hear in Burial’s two LPs is a craving for a past which nevertheless appears irretrievably lost, veiled behind a relentless drizzle of crackle. Beyond the longing for a particular moment or a particular musical genre is a longing for the ceaseless forward motion of a culture which once appeared capable of infinite renewal, but which is now used up, involuted. The nostalgia for modernism resists the postmodern nostalgia mode.

Burial’s music is possessed by an extraordinary sense of space. This isn’t only a question of the production, which recalls Martin Hannett as much as King Tubby or Basic Channel. It is also about what images the music evokes — very vivid audio-vignettes of South London in this decade. Edward Hopper sound paintings of London after the rave. A city populated by ex-ravers gone to seed, like Nigel Cooke’s dejected vegetables. The long comedown after all the highs. Serotonin crash and anti-depressants. The spaces that are the correlates of such disaffected states. All day cafes and night buses glowing like diving bells in the undersea murk of the early hours. What haunts here is not only the past but possible futures. A drowned world catastrophe leaking back in time.

Haunting is about space as much as time — about the spaces where the time rift becomes perceptible, and, with Burial’s debut LP in particular, it was as if you were hearing double: hearing both the current dereliction and the former collective ecstasy. Flashbacks flaring in the gloom. What you are attuned to is a specific sense of place, as opposed to the “third place” — the space that is neither home nor work, but which combines elements of both. Spaces of consumer convalescence which could be anywhere. Burial’s “In McDonald’s” relocates the spatially-indifferent multinational capsule of the corporate franchise in a specific city: London, once again the capital of Capital. Once the sooty, smoggy centre of industrial capital, now the main hub of cybercapital. Open for business. Closed to almost anything else.

Is This Burning an Eternal Flame?

The arrival of the Olympic flame in London a few weeks ago was a pseudoevent on the grandest of scales, given content only by its subversion.

The CGI shadows of 2012 already enclose us. Present time captured into the performance of pre-scripted PR opportunities forever. But 2012 is an opportunity for dissent too. A focus for disaffection. Burial’s second LP includes a sample from Lynch’s Inland Empire: “I saw your light, it burns forever.”

You could hear this as the secret key to Burial’s whole sensibility. Like Lynch, Burial is attuned to the muffled, muted light flashes of the numinous that can be fleetingly glimpsed through the mundane. Distant lights, or lights that can be apprehended only from a distance.

Can we be guided by these lights, instead of by the Olympic flame, a symbol of a capital now more globalised than ever, the ultra-bright striplights drawing planetary destiny into an eternal shopping mall surrounded by a sweatshop?





ridicule is nothing to be scared of (slight return)1

Like David Stubbs, I’m of course delighted to have been shopped to the commissars of commonsense who compile Private Eye’s “Pseud’s Corner”. It’s always bracing to be middlebrow-beaten; a pleasure I can expect to enjoy fairly regularly from now on, since, if the section from the Mark Stewart feature that they selected is considered fair game, then they might as well open up a permanent spot for me.

It’s difficult to know what the alleged problem is: the conjoining of politics and music? Well, it’s hardly stretching a point to argue that a record such as For How Much Do We Tolerate Mass Murder? might, y’know, have had some connection with geopolitical developments at the end of the Seventies. Would the same objection be made to linkages between politics and other areas of culture? But of course what is objected to is as much a question of tone as of content. The default expectation in British media is that writers perform a homely matiness: writing must be light, upbeat and irreverent, never taking itself or anything else too seriously.

The function of “Pseud’s Corner” — to punish writing that in some way overreaches itself, that gets ideas above its station or gets carried away — has now been taken up by online discussion boards and comments facilities everywhere. The effect on any writer who internalises the critique is to be intimidated into colourless mediocrity. But the problem with most published writing today is not that it is “pretentious”, it is that is unreflective PR hackwork. David Stubbs is right to invoke a certain Orwell as the patron of bluff, plain-speaking John Bull prose — but the Orwell of “Politics and the English Language” also attacked the mechanical circulation of dull, dead language. If only that Orwell were more heeded. “Never use a metaphor, simile, or other figure of speech which you are used to seeing in print”, he demanded, optimistically hoping that “if one jeers loudly enough, send some worn-out and useless phrase — some jackboot, Achilles’ heel, hotbed, melting pot, acid test, veritable inferno, or other lump of verbal refuse — into the dustbin where it belongs.”

Over sixty years later, such “verbal refuse” continues to circulate with impunity, and is supplemented by a whole inventory of PR commonplaces and consumer-affect babble (journeys, rollercoaster rides). Surely any amount of “pretentiousness” is preferable to these soporific linguistic screensavers?





break through in grey lair1

“Instead of tripping and beating a philosophy for its supposed faults only to end up with the same range of mediocre biases with which we began, we ought to find a more vigorous means of engagement with philosophers. The method I propose is to replace the piously overvalued ‘critical thinking’ with a seldom-used hyperbolic thinking. For me at least, it is only books of the most stunning weakness that draw attention to non sequiturs and other logical fallacies. The books that stir us most are not those containing the fewest errors, but those that throw most light on unknown portions of the map. In the case of any author who interests us, we should not ask ‘where are the mistakes here?’, as if we hoped for nothing more than to avoid being fooled. We should ask instead: ‘what if this book, this thinker, were the most important of the century? How would things need to change? And in what ways would we feel both liberated and imprisoned?’ Such questions restore the proper scale of evaluation for intellectual work: demoting the pushy careerist sandbagger who remains within the bounds of the currently plausible and prudent, and promoting the gambler who uncovers new worlds. Nietzsche makes far more ‘mistakes’ than an average peer-reviewed journal article, but this does not stop intelligent adults from reading him all night long, while tossing the article aside for a day that never comes.”

— Graham Harman, Prince Of Networks2

This is one of the most stirring passages in Prince Of Networks, and it’s particularly worth citing just now, when the topic of grey vampires3 has come up again4. The mention of Nietzsche reminds me that he is one of the great scourges of grey vampirism, nowhere more than in the following passage from Part Six of Beyond Good And Evil:

“Aren’t people’s ears all full enough already of wicked noises?” says the sceptic, as a friend of peace, almost as a sort of security police: “This subterranean No is terrifying! Be quiet at last, you pessimistic moles!” For the sceptic, this tender creature, is frightened all too easily. His conscience has been trained to twitch with every No, even with every hard, decisive Yes —to respond as if it had been bitten. Yes! And No! —that contradicts his morality. Conversely, he loves to celebrate his virtue with a noble abstinence, by saying with Montaigne, “What do I know?” Or with Socrates, “I know that I know nothing.” Or “Here I don’t trust myself. There is no door open to me here.” Or “Suppose the door was open, why go in right away?” Or “What use are all rash hypotheses?” Not to make any hypotheses at all could easily be part of good taste. … () In this way a sceptic consoles himself, and he certainly needs some consolation. For scepticism is the spiritual expression of a certain multifaceted physiological condition which in everyday language is called weak nerves and infirmity.

Baron Mordant wrote to me a while back asking if grey vampirism wasn’t a symptom of mental illness, and it is — but of the widespread, normalised and normalising pathology that Nietzsche describes here. As is wont, Nietzsche attributes the rise of the “spider scepticism” to racial intermixing but we needn’t follow his ethnicising logic in order to utilise his analysis, which applies with uncanny acuity to the impasses of postmodern relativism and the stale corridors of the academy, tyrannised by the Fear — where the worst thing that could happen was that you are caught out in an error or a mis-cited quotation, rather than that you have wasted your life in endless equivocation, quibbling and deferral (while crying in your state-subsidised beer that you are doing so…)

Vampires do not appear in mirrors. In the case of grey vampires — and remember that there are vampires that are not grey; there are other kinds of energy piracy altogether, some more lustrous and ferocious — this means both that they cannot recognise themselves as vampires and that their existence is entirely dependent upon the attention of the Other. Grey vampires do not see themselves as vampires; they sincerely think that it is a duty to deflate enthusiasm and puncture projects. One sure sign of a grey vampire is the airy dismissal of concepts such as energy vampirism — no matter what their theoretical commitments might be in their published intellectual work, GVs are resolutely commonsensical in their everyday ontologies. But make no mistake about it, there is no more Real level to human life than that of energy and its distribution. As Burroughs more than anyone else realised, persons and the social are just masks covering up a terrain populated by energy predators and propagators.

Remember that you have to invite a vampire over your threshold — and grey vampires, like trolls, lose all their power once you cease to pay them attention or think about them. That is why, when they feel that your attention is gone, GVs will try any trick to regain it — the appeal to “democratic” values is a particularly scurrilous tactic (“you must give me your attention! It’s your duty”). Trolls shamelessly try the same thing, of course, and it must be remembered that GVs are enablers of trolls — they like to position themselves as scrupulously neutral, uncommitted (whilst proffering all sorts of promissory notes about the commitments that they will make in future, what they will do once X or Y have stopped, the bad faith fantasies that prevent them from seeing the trap they are in) but the grey vampire’s secret sympathies are always with the troll. For the troll actually articulates the resentment and spite which the grey vampires feel but are not able to express. They share the trolls’ justification for their action — the belief that some people are getting ahead of themselves, that there is rather too much unseemly excitement about X or Y… As if what was required in intellectual life is more bent heads, more bitterness, less enthusiasm… Some teachers and lecturers do think that way, see it as their role duty to pass on the arid petrification which calcified their spirit usually sometime during their postgraduate career… Remember: all vampires are victims of vampirism…

But I see motivating students, passing on enthusiasm, as the first and most important task of a teacher. (Which isn’t to say that one has to blindly encourage everything a student says or writes; far from it.) That’s why I would say that one of the most despicable figures in the academic bestiary is the Troll-Master: the figure who feeds on the crushed enthusiasm of belittled students. The easiest way to win a cheap kind of respect is by adopting a nothing-can-impress-me hyper-critical stance, doused in cool weltweltschmerz, finding fault everywhere handing out praise and encouragement only very rarely; it’s a transparent tactic, but one that works surprisingly well, and not only on jejune students, but also on very accomplished people, even those who have written a number of books. Often, the Troll-Master’s own intellectual project will be mediocre and/or suspended — it’s clear that all their libidinal energy is tied up in enslaving students into neurotic servitude. Troll-Masters can permanently insinuate themselves into students’ heads, but usually their power depends upon the hothouse claustrophobia of the university department — they are village despots, whose charismatic tyranny seldom works outside their own turf. If they have a long-term effect, it is only to produce more grey vampires.

Graham is absolutely right to note that grey vampires tend to operate on a one-to-one basis, whereas trolls always require an audience. That’s because trolls want the attention of the big Other, whereas grey vampires want to directly identify with the big Other — to become the voice of neutrality and authority, the voice from nowhere, which doesn’t make any refutable claims and therefore cannot be caught out. The reason that there is a close fit between grey vampirism and the academy — now more than ever — is that the academy seeks to inculcate precisely this kind of neurotic neutrality (the other side of careerist sandbaggery), where the most important thing is that footnotes are correctly formatted. It is usually liberating to actually read the work of GVs and Troll-Masters: from their endless, refined critique, you’re led to believe that what they produce will be the most sophisticated, error-free, immaculate work you could imagine; it’s quite a shock when you actually read it and see how contestable and (often) mediocre it is.

The alternative to these traps is not the heroic solitary genius, but the network, another reason that Graham’s new book is so important. As Nick Srnicek has been arguing, political theory now has to deal with the question of networks. (Incidentally, one of the reasons that Speculative Realism can contribute so much to political theory is that the areas SR opens up do not come already pre-packed in supersaturated pseudo-political “meaning”, as in the exhausted, dustbowl terrains presided over by trad continental philosophy.) The toxicity of grey vampires and trolls is so important to think about because they it is essentially network toxicity. Troll-jouissance is derived precisely from their capacity to corrupt networks — the troll’s usual MO is enter a thriving network and destroy it by diverting all its energy to dealing with them. The grey vampire, as ever, is more subtle — and, for that reason and for so many others, more dangerous. They sap the network’s energy, not only by defending trolls, but by also defending equivocation itself, by construing any decision or determinate position as oppressive (deconstruction is a grey vampire pathology). Their preferred model for discussion is the fruitless combat of the comments box/discussion board “debate”. This is the energy-swamp of web 2.0; but other kinds of network can grow here too.





real abstractions: the application of theory to the modern world1

At a recent symposium at the University of East London devoted to dance music and theory, some dissenting journalists declared that they would much rather be “buffoon empiricists” than credulous dupes of theory. This kind of dismissal of theory, by way of ostensibly plain-speaking selfdeprecation, is nothing new in British culture. It’s a certain attitude that practically defines itself by its disdain for theoretical abstractions, a disdain which once informed empiricism, the philosophy with which the Englishspeaking world is most associated. But, precisely because it aimed to reject supposedly unprovable abstractions, the empiricism of philosophers such as George Berkeley and David Hume ended up undermining rather than ratifying the categories of given experience: Berkeley famously denied the existence of the material world itself, while Hume argued against the existence of the self. In contrast with their rarefied weirdness, buffoon empiricists see their own role as shoring up the way the world appears to us in our unreflective moments. They claim to privilege “evidence”, but really this is no more than a self-evident appeal to the very categories that empiricist philosophers denied: persons and (physical) things. And if only persons and physical things are real, what do buffoon empiricists think just happened in the global economy? Understanding the credit crunch and the recession demands the acknowledgement that abstractions are real.

It’s no accident that the countries which bought into neoliberalism and financialisation most enthusiastically were the US and the UK. The “continental” theoretical tradition that buffoon empiricism defined itself against was often guilty of the kind of intricately nebulous, reality-denying textualism of which Anglo-Saxon nominalism accused it. The type of theory that has percolated through the art world and cultural studies in recent years — a confection of diluted postmodernism and degraded Deleuzianism, with its menagerie of vague anti-concepts such as difference, sensation and multiplicity — is not so far from buffoon empiricism. What this kind of antitotalising thinking shares with it is a profound hostility towards systematicity; it holds the widespread view that making any kind of determinate claim is dogmatic, oppressive, even totalitarian.

As Fredric Jameson has argued, this pick-and-mix approach to theoretical propositions has rather too close a fit with consumerism — in fact, Jameson famously goes so far as to say, it’s an expression of the “cultural logic of late capitalism”. What is certain is that vague rhetorics of diversity do not have the cold lucidity necessary to give an account of the real abstractions of capital. In his 1966 essay, “Cremonini, Painter of the Abstract”, Louis Althusser made a distinction between “abstract painting” and “the painting of abstraction”.2 The painter Leonardo Cremonini, Althusser argued, managed to expose the abstractions of capital not by directly depicting them — such a thing is impossible — but by showing “the determinate absence which governs us ()”. As Benjamin Noys puts it in a commentary on Althusser’s essay in his forthcoming book The Persistence Of The Negative:

We have no image of capital, capital itself is a kind of pure relationality, a pure abstraction of value, labour, and accumulation, which can only be “seen” in negative. This is why the negation of real abstractions demands further abstraction, as abstraction is the only possible means to reveal this pure relationality which conceals itself in plain sight.3

Getting to this real abstraction entails an analysis of what I call capitalist realism. Capitalist realism — which by no means collapsed with the banks last year; on the contrary, there is no greater testament to its continuing power than the scale of the bank bailouts — is the notion that capitalism is the only viable political-economic system. It maintains that there is an inherent relation between capitalism and reality. Capitalist realism is a kind of anti-mythical myth: in claiming to have deflated all previous myths on which societies were based, whether the divine right of kings or the Marxist concept of historical materialism, it presents its own myth, that of the free individual exercising choice. The distrust of abstractions — summarised by Margaret Thatcher’s famous denial: “there is no such thing as society” — finds expression in a widespread reduction of cultural ideas and activities to psychobiography. We are invited to see the “inner life” of individuals as the most authentic level of reality. Much of the appeal of reality television, for instance, consists in its seductive claim to show participants for what they “really are”. The media is a sea of faces that we are encouraged to feel we are on first name terms with. Feature interviews in mainstream papers and magazines are invariably structured around biographical chat and photographs. In Britain, now more than ever, artists and musicians are faced with the choice of representing themselves in this biographical way or not appearing at all. Attempts to appeal to abstract ideas alone — either in the art itself or the forces it is dealing with — are habitually greeted with a mixture of contempt and incomprehension.

This is not restricted to the tabloid press — whose outing last year of the determinedly “faceless” musician Burial is only one example of its aggressive insistence upon psychobiographical reduction. The default settings of the British broadsheet press are just as dismissive of abstraction. Witness Nick Cohen’s recent fulmination against Frieze’s own Dan Fox in the Observer, criticising a blog Fox had written analysing mainstream newspaper reports of the “Altermodern” exhibition at Tate Britain, London. Cohen’s article included a priceless sideswipe against “the type of French intellectual who makes the English wish the Channel was a thousand miles wide.” With its guiding assumption that theory is some continental toxin for which the antidote is Anglo-Saxon common sense, Cohen’s piece was a manifesto for buffoon empiricism, making its standard complaint that theory is “unsupported by anything as mundane as evidence”.4

But empiricism is not the same as the empirical — any worthwhile theory must account for empirical data, but, in order to do so, it cannot remain at the same level of the data it is seeking to explain. Besides, empirical facts typically have little to do with the phenomenological experience of individuals. Althusser’s description of his own theory as “scientific” has been derided, not only by Anglo-Saxon nominalism but also by much post-Structural theory, which has tended to prefer poetry and discourse to the natural sciences. But Althusser’s conception of the individual subject as a product of ideology is far more scientific than buffoon empiricism’s unthinking dissemination of the concepts of persons and things. In his book Nihil Unbound, which draws upon neuroscience as well as the work of “continental” theorists, the philosopher Ray Brassier argues that science exposes human beings’ everyday understandings of themselves and the world around them to be banal fictions. The kind of philosophical realism that Brassier advocates has nothing to do with capitalist “realism” — indeed, it has the resources to expose this so-called realism as nothing of the sort. Developing from the work of neurophilosophers such as Paul Churchland and Thomas Metzinger, who argue that all of the seemingly self-evident furniture of inner life (emotions, the self itself) are mystificatory superstitions, Brassier’s work is part of a renewed theoretical assault on a buffoon empiricist ideology that calls itself reality.





no i’ve never had a job…1

I should have pointed out that Ivor Southwood has his own blog: here he is on the Fairy Jobmother;2 and here’s Digital Ben3 with more on the same theme. Ben’s post is, in the best possible way, sad. The key line is: Why can everyone else do it and not me? When I was unemployed, I was convinced that an absolute ontological gulf separated me from work. Work — which, like “being in a relationship” — would automatically confer on me the status of being a Real Person. But the horrific irony was that one couldn’t achieve this status. You couldn’t become a Real Person by getting a job. It was the other way round: only Real People could get work. Being unemployed wasn’t a cause of shame; rather the sense of shame which I carried around as if it was the core of my being was what prevented me getting a job. So my job applications and interviews had an air of total hopelessness about them. I know there’s no way you would give the job to an insect like me, and we both know I couldn’t do it even if by some miracle you offered it to me, but… It took me years to realise that job interviews were a ritualised exchange where the point was to determine whether you knew what the right communicative etiquette was, and that telling the truth made you some weirdo. Surely even those who have not been in the Castle know that one doesn’t behave like that…

Being a postgraduate student was little better than being unemployed — not least because it was regarded (by me as much as anyone else) as a way of avoiding work. (A friend once remarked that, in most circles in Britain, it would be less shameful to confess to being a drug addict than to admit you were a postgraduate student in an arts subject.) But I only “avoided work” because I didn’t think I could do it. Ben writes:

I can’t quite make up my mind whether this missing quality is a rulingclass privilege (for which see the discussions collected here a few years back), or more of a stereotypical working class thing — hustle, graft, with its suggestions of not-entirely-legitimate activity. Perhaps it’s something possessed by people at both ends, but lost by those in-between? Rather like the ridiculous etiquette books of early Victorian times — real aristocrats didn’t worry about that type of thing, they just did what the hell they pleased (knowing that they were immovably established and that being seen using the wrong kind of spoon wasn’t going to affect them at all). Only the upwardly mobile bourgeoisie cooked up these arcane rules and customs to try and monopolise the road up and discreetly kick the bulk of the population off the ladder.

For me, it was absolutely a question of being projected into a space between classes. When I did work in factories, I was either pitied or pilloried. Every job seemed impossible: manual work because of my feckless diliatoriness, graduate jobs because, well, I wasn’t the sort of person who could do them. Me, a teacher, a journalist or a lawyer — surely not.

Is there anyone who has caught the agony of this state of worklessness better than Morrissey? The useless jouissance of refusing what was anyway impossible: “No I’ve never had a job/because I’ve never really wanted one”, “No, I’ve never had a job because I’m too shy…” I do sometimes think that the implicit political position in those handful of early Smiths songs was one of the most powerful of the Eighties. Singing “England is mine and it owes me a living” at the time of three million unemployed and the Miners’ Strike… Rejecting the masculine destiny of Fordist worker at the very moment when that destiny was being denied to the working class (“No, we cannot cling to the old dreams any more”)… Rejecting, that is to say, all of those working-class homilies about the dignity of labour… If there was a militant dysphoria in Morrissey it was here… and the dysphoria was absolutely integral to the militancy: incapacity as refusal. Failure as negative capability. I’d rather be me miserable and shy than a successful communicative capitalist… All of this when the Wildean defiance was shaped by gaucheness and awkwardness, rather than staged as a PoMo panto turn. “There are brighter sides to life/and I should because I’ve seen them/but not very often”. The “but not very often” is the genius touch, of course. Without that, the gesture of refusal could seem like empty breast-beating; it would just be the swagger of “Wham Rap”… With it, there is just enough suggestion of other worlds, other ways of being, which no one in the current state of things has more access to than the unemployed dysphoric… And no one sees the total system of capital — the way that work, sexual relationships, commodities all intermesh and entail one another — no one sees that more clearly than the person excluded from work…

Morrissey represented the desire for a proletarian bohemia at the moment when — after the Sixties, after glam, after punk and post-punk — that possibility was being closed down. There’s an excellent chapter in Jim McGuigan’s excellent Cool Capitalism about the history of bohemia, which McGuigan connects with Marcuse’s concept of art as the Great Refusal. It seems to me that the installation of business ontology over the last thirty years has centrally involved the defeat of bohemia: art schools returning to largely being places for the privileged; the reduction of the print music press to indie Smash Hits; TV becoming populist trash or middlebrow mediocrity. The business culture of “selling yourself” (which I, like every right thinking person still regard as the height of vulgarity) has engendered the mandatory, seamless positivity that Ben and Ivor talk about: the Great Acceptance, as opposed to the Great Refusal. The aspiration to enter into bohemia was always the wrong kind of ambition from the perspective of a certain working-class way of thinking. Still is… many members of my family have never encouraged me to write, and continue to regard it as a “hobby”, doing everything they can to put pressure on me to get “proper work”… Contrast this with the bourgeois kids doing unpaid internships for years on end…





fear and misery in neoliberal britain1

The passage I’ve pasted below — the introduction to a presentation, which was entitled “‘We’re not all in this together’: Public Space and Antagonism in the Wake of Capitalist Realism” — was intended to be a kind of minimally fictionalised phenomenological tuning-up exercise, to give a predominantly non-UK audience a sense of what it has been like to live in the UK under capitalist realism. Everything here is based on genuine experiences, although some experiences have been compressed and condensed, and the experiences are not necessarily mine.

Now: The swipe card doesn’t work. The machine senses anxiety, you’re sure of it. It knows the card is not yours. You try the card again. Nothing. Same red light. The card isn’t yours, but you should have access to the building. You had to borrow someone else’s card because it is only possible to get swipe cards between the hours of 9 and 1 and you are working at these times.

Someone is behind you. You feel uncomfortable. Will they notice that the card does not belong to you? You try the card again. Again nothing. Red light.

Your phone rings. You struggle to get it out of the bag. By the time you have it, the call has gone through to the answering service. You see that the call has come from another of your employers. A familiar anxiety grips you: what have you done wrong now? But you have no time to worry about that at the moment.

You try the swipe card again. At last, the green light comes on. You’re through the door.

Rushing down the corridor. Which floor were you supposed to be on? You rifle through your bag until you find the documentation. You should be on this floor, but at the other end of the corridor. You walk towards the room number. But suddenly your progress is blocked. There is a no entry sign: an office that cuts the corridor in half and through which there is no access.

It’s a nightmare topology. Every time you seem to get close, another obstacle appears. You will have to go out of the corridor, down the stairs and up to the next set of stairs, facing a number of swipe card-access doors on the way.

By now the five minutes you hoped to have before you start is evaporating rapidly.

By the time you reach the room you were heading for, you are already late. You log-on to the computer. Or you try to. The log-in is rejected. You try again. No luck. Then you remember: you’re trying a log-in from one of the other institutions that you work at. It’s difficult to keep track sometimes. You remember the correct log-in, quickly scan one of your email accounts. See an email from an administrator. Have you filled in your bank details form? Yes, you’ve filled it in, you think. Weeks ago. But of course you can’t be sure — maybe you only thought you had filled it in. Have they lost it? Flash of anxiety: will I not be paid this month? Last year, when you filled in all the same forms that you have to complete again this year, you were not paid for a whole fifty-hour contract, until you pointed out the mistake. Will the same thing happen again?

But there’s no time to worry about this now.

You have a room of seventy students waiting to be taught.

Such is life in the UK’s bloated and over funded public institutions.

Welcome to Liberty City. The busier you are, the less you see.

Ten years ago: the New-Path Institute

The psychiatrist asks you if your mood has improved.

You say no.

The psychiatrist says that the dose needs to be increased.

You don’t respond. You can’t. The drugs you’re taking and the condition you are suffering from give you the cottonhead response time of a zombie. The psychiatrist feels very far away, like you are seeing him through a fish-eye lens.

You don’t need to respond. It’s not about your responses.

Besides, there’s a sneering voice in your head constantly shouting at you.

Of course the drugs won’t work.

Of course you won’t get better.

Because there’s nothing wrong with you.

Just give up.

But that’s easier said than done.

The best you can hope for is a coma.

After the consultation, you return to your bed. Everything feeling very heavy, as if a crushing undersea pressure is bearing down on you. You lie on the bed, absolutely convinced that this is the truth — the raw unvarnished Real. Strangely, that remorseless glacial sense of certainty does not lessen your anxiety or bring you any relief. You cannot rest, even though you are catatonically immobile. Your heart is pounding. Jackhammer thud out of a Poe story. It gets faster and louder until the only thing louder is the voice in your head.

Later, you say to a nurse:

So that’s what the treatment amounts to? Drugging and incarceration.

They nod. In the background, someone is howling.

Now: Rush away to one of the other places you work. You are supposed to photocopy some texts.

But by the time you arrive in the corridor, all the doors are locked. No one there.

This is the second time this has happened. Last time the photocopier wasn’t working.

You should have come earlier today. But there wasn’t time then. Defeated, but trying to ensure that the two-hour round trip is not a complete waste of time, you go to the library, using the temporary swipe card that you were given because your contract has not been prepared yet. You take some books off the shelf and try to check them out. No dice. Your library record has not yet been prepared.

Can you come back later?

Yes, you can come back later.

On the train home. Claustrophobia-inducing crush. You’re so anxious about having your iPod or your phone stolen that it would almost come as a relief if they were.

Exhausted, still standing up because there is no space to sit, you think about reading the book in your bag. But the temptation of the free paper is too great. Its headlines fix on your tired mind like predators that have eyed a stricken animal. The little oedipal-celebrity narratives hook you in. Everything collapsing into the universal form of the tabloid. Idle chatter subsuming all other news. Politics as a family soap opera. Nothing going on except ambition, intrigue, envy. You’re bored even as you are fascinated.

Six years ago: In the office of the occupational therapist.

You are being asked to prove that you are mentally fit.

Because — as the Human Resources manager kindly pointed out — you have suffered from stress in the past. (The thought flashes through your mind — not that they cared when you were suffering.) But now people are concerned.

The anger that you’ve been showing towards management can only be a sign that you are unwell. A little unbalanced.

Don’t worry. No one is attacking you. We’re all here to help.

You say to the occupational therapist:

If I say management is conspiring against me will that prove I am mad?

Now: Stepping over the vomit, you remember too late: only a fool would go out into a provincial English town centre late in the evening. It’s night of the living dead out here.

Screams that sound like they come from the Dante-damned. And that’s just from the people who are enjoying themselves.

The lurching zombie threat of violence simmering.

Try not to catch anyone’s eye.

When you go by Accident and Emergency, you see all the walking wounded, and some who are not walking. All the casualties of the UK’s many happy hours.

You remember a doctor saying that twenty years ago, the night shift was so boring that the medics would engage in wheelchair races with one another. Not anymore. Not with all the knives, gun crime, fights, alcoholrelated accidents, stomach pumps…

And all the superbugs breeding in the wards…

You reach home, switch on the TV. Emollient patrician voices crying crocodile tears. Public services to be massively cut back. 30%, 40%.

A new age of austerity.

Aristocrats and millionaires telling us: we’ve all got to do our bit.

We’re all in this together.





exiting the vampire castle1

This summer, I seriously considered withdrawing from any involvement in politics. Exhausted through overwork, incapable of productive activity, I found myself drifting through social networks, feeling my depression and exhaustion increasing.

“Left-wing” Twitter can often be a miserable, dispiriting zone. Earlier this year, there were some high-profile twitterstorms, in which particular leftidentifying figures were “called out” and condemned. What these figures had said was sometimes objectionable; but nevertheless, the way in which they were personally vilified and hounded left a horrible residue: the stench of bad conscience and witch-hunting moralism. The reason I didn’t speak out on any of these incidents, I’m ashamed to say, was fear. The bullies were in another part of the playground. I didn’t want to attract their attention to me.

The open savagery of these exchanges was accompanied by something more pervasive, and for that reason perhaps more debilitating: an atmosphere of snarky resentment. The most frequent object of this resentment is Owen Jones, and the attacks on Jones — the person most responsible for raising class consciousness in the UK in the last few years — were one of the reasons I was so dejected. If this is what happens to a left-winger who is actually succeeding in taking the struggle to the centre ground of British life, why would anyone want to follow him into the mainstream? Is the only way to avoid this drip-feed of abuse to remain in a position of impotent marginality?

One of the things that broke me out of this depressive stupor was going to the People’s Assembly in Ipswich, near where I live. The People’s Assembly had been greeted with the usual sneers and snarks. This was, we were told, a useless stunt, in which media leftists, including Jones, were aggrandising themselves in yet another display of top-down celebrity culture. What actually happened at the Assembly in Ipswich was very different to this caricature. The first half of the evening — culminating in a rousing speech by Owen Jones — was certainly led by the top-table speakers. But the second half of the meeting saw working-class activists from all over Suffolk talking to each other, supporting one another, sharing experiences and strategies. Far from being another example of hierarchical leftism, the People’s Assembly was an example of how the vertical can be combined with the horizontal: media power and charisma could draw people who hadn’t previously been to a political meeting into the room, where they could talk and strategise with seasoned activists. The atmosphere was anti-racist and anti-sexist, but refreshingly free of the paralysing feeling of guilt and suspicion which hangs over left-wing twitter like an acrid, stifling fog.

Then there was Russell Brand. I’ve long been an admirer of Brand — one of the few big-name comedians on the current scene to come from a working-class background. Over the last few years, there has been a gradual but remorseless embourgeoisement of television comedy, with preposterous ultra-posh nincompoop Michael McIntyre and a dreary drizzle of bland graduate chancers dominating the stage.

The day before Brand’s now famous interview with Jeremy Paxman was broadcast on Newsnight, I had seen Brand’s stand-up show the Messiah Complex in Ipswich. The show was defiantly pro-immigrant, pro-communist, anti-homophobic, saturated with working-class intelligence and not afraid to show it, and queer in the way that popular culture used to be (i.e. nothing to do with the sour-faced identitarian piety foisted upon us by moralisers on the post-structuralist “left”). Malcolm X, Che, politics as a psychedelic dismantling of existing reality: this was communism as something cool, sexy and proletarian, instead of a finger-wagging sermon.

The next night, it was clear that Brand’s appearance had produced a moment of splitting. For some of us, Brand’s forensic take-down of Paxman was intensely moving, miraculous; I couldn’t remember the last time a person from a working-class background had been given the space to so consummately destroy a class “superior” using intelligence and reason. This wasn’t Johnny Rotten swearing at Bill Grundy — an act of antagonism which confirmed rather than challenged class stereotypes. Brand had outwitted Paxman — and the use of humour was what separated Brand from the dourness of so much “leftism”. Brand makes people feel good about themselves; whereas the moralising left specialises in making people feed bad, and is not happy until their heads are bent in guilt and self-loathing.

The moralising left quickly ensured that the story was not about Brand’s extraordinary breach of the bland conventions of mainstream media “debate”, nor about his claim that revolution was going to happen. (This last claim could only be heard by the cloth-eared petit-bourgeois narcissistic “left” as Brand saying that he wanted to lead the revolution — something that they responded to with typical resentment: “I don’t need a jumpedup celebrity to lead me”.) For the moralisers, the dominant story was to be about Brand’s personal conduct — specifically his sexism. In the febrile McCarthyite atmosphere fermented by the moralising left, remarks that could be construed as sexist mean that Brand is a sexist, which also meant that he is a misogynist. Cut and dried, finished, condemned.

It is right that Brand, like any of us, should answer for his behaviour and the language that he uses. But such questioning should take place in an atmosphere of comradeship and solidarity, and probably not in public in the first instance — although when Brand was questioned about sexism by Mehdi Hasan, he displayed exactly the kind of good-humoured humility that was entirely lacking in the stony faces of those who had judged him.

I don’t think I’m sexist, But I remember my grandmother, the loveliest person I’ve ever known, but she was racist, but I don’t think she knew. I don’t know if I have some cultural hangover, I know that I have a great love of proletariat linguistics, like “darling” and “bird”, so if women think I’m sexist they’re in a better position to judge than I am, so I’ll work on that.

Brand’s intervention was not a bid for leadership; it was an inspiration, a call to arms. And I for one was inspired. Where a few months before, I would have stayed silent as the PoshLeft moralisers subjected Brand to their kangaroo courts and character assassinations — with “evidence” usually gleaned from the right-wing press, always available to lend a hand — this time I was prepared to take them on. The response to Brand quickly became as significant as the Paxman exchange itself. As Laura Oldfield Ford pointed out, this was a clarifying moment. And one of the things that was clarified for me was the way in which, in recent years, so much of the self-styled “left” has suppressed the question of class.

Class consciousness is fragile and fleeting. The petit bourgeoisie which dominates the academy and the culture industry has all kinds of subtle deflections and pre-emptions which prevent the topic even coming up, and then, if it does come up, they make one think it is a terrible impertinence, a breach of etiquette, to raise it. I’ve been speaking now at left-wing, anticapitalist events for years, but I’ve rarely talked — or been asked to talk — about class in public.

But, once class had re-appeared, it was impossible not to see it everywhere in the response to the Brand affair. Brand was quickly judged and-or questioned by at least three ex-private school people on the left. Others told us that Brand couldn’t really be working class, because he was a millionaire. It’s alarming how many “leftists” seemed to fundamentally agree with the drift behind Paxman’s question: “What gives this working class person the authority to speak?” It’s also alarming, actually distressing, that they seem to think that working class people should remain in poverty, obscurity and impotence lest they lose their “authenticity’.

Someone passed me a post written about Brand on Facebook. I don’t know the individual who wrote it, and I wouldn’t wish to name them. What’s important is that the post was symptomatic of a set of snobbish and condescending attitudes that it is apparently alright to exhibit while still classifying oneself as left-wing. The whole tone was horrifyingly high-handed, as if they were a schoolteacher marking a child’s work, or a psychiatrist assessing a patient. Brand, apparently, is “clearly extremely unstable… one bad relationship or career knockback away from collapsing back into drug addiction or worse.” Although the person claims that they “really quite like Brand ()”, it perhaps never occurs to them that one of the reasons that Brand might be “unstable” is just this sort of patronising faux-transcendent “assessment” from the “left” bourgeoisie. There’s also a shocking but revealing aside where the individual casually refers to Brand’s “patchy education and () the often wince-inducing vocab slips characteristic of the auto-didact” — which, this individual generously says, “I have no problem with at all” — how very good of them! This isn’t some colonial bureaucrat writing about his attempts to teach some “natives” the English language in the nineteenth century, or a Victorian schoolmaster at some private institution describing a scholarship boy, it’s a “leftist” writing a few weeks ago.

Where to go from here? It is first of all necessary to identify the features of the discourses and the desires which have led us to this grim and demoralising pass, where class has disappeared, but moralism is everywhere, where solidarity is impossible, but guilt and fear are omnipresent — and not because we are terrorised by the right, but because we have allowed bourgeois modes of subjectivity to contaminate our movement. I think there are two libidinal-discursive configurations which have brought this situation about. They call themselves left-wing, but — as the Brand episode has made clear — they are in many ways a sign that the left — defined as an agent in a class struggle — has all but disappeared.

Inside the Vampires’ Castle

The first configuration is what I came to call the Vampires’ Castle. The Vampires’ Castle specialises in propagating guilt. It is driven by a priest’s desire to excommunicate and condemn, an academic-pedant’s desire to be the first to be seen to spot a mistake, and a hipster’s desire to be one of the in-crowd. The danger in attacking the Vampires’ Castle is that it can look as if — and it will do everything it can to reinforce this thought — that one is also attacking the struggles against racism, sexism, heterosexism. But, far from being the only legitimate expression of such struggles, the Vampires’ Castle is best understood as a bourgeois-liberal perversion and appropriation of the energy of these movements. The Vampires’ Castle was born the moment when the struggle not to be defined by identitarian categories became the quest to have “identities” recognised by a bourgeois big Other.

The privilege I certainly enjoy as a white male consists in part in my not being aware of my ethnicity and my gender, and it is a sobering and revelatory experience to occasionally be made aware of these blind-spots. But, rather than seeking a world in which everyone achieves freedom from identitarian classification, the Vampires’ Castle seeks to corral people back into identi-camps, where they are forever defined in the terms set by dominant power, crippled by self-consciousness and isolated by a logic of solipsism which insists that we cannot understand one another unless we belong to the same identity group.

I’ve noticed a fascinating magical inversion projection-disavowal mechanism whereby the sheer mention of class is now automatically treated as if that means one is trying to downgrade the importance of race and gender. In fact, the exact opposite is the case, as the Vampires’ Castle uses an ultimately liberal understanding of race and gender to obfuscate class. In all of the absurd and traumatic twitterstorms about privilege earlier this year it was noticeable that the discussion of class privilege was entirely absent. The task, as ever, remains the articulation of class, gender and race — but the founding move of the Vampires’ Castle is the dis-articulation of class from other categories.

The problem that the Vampires’ Castle was set up to solve is this: how do you hold immense wealth and power while also appearing as a victim, marginal and oppositional? The solution was already there — in the Christian Church. So the VC has recourse to all the infernal strategies, dark pathologies and psychological torture instruments Christianity invented, and which Nietzsche described in The Genealogy of Morals. This priesthood of bad conscience, this nest of pious guilt-mongers, is exactly what Nietzsche predicted when he said that something worse than Christianity was already on the way. Now, here it is…

The Vampires’ Castle feeds on the energy and anxieties and vulnerabilities of young students, but most of all it lives by converting the suffering of particular groups — the more “marginal” the better — into academic capital. The most lauded figures in the Vampires’ Castle are those who have spotted a new market in suffering — those who can find a group more oppressed and subjugated than any previously exploited will find themselves promoted through the ranks very quickly.

The first law of the Vampires’ Castle is: individualise and privatise everything. While in theory it claims to be in favour of structural critique, in practice it never focuses on anything except individual behaviour. Some of these working class types are not terribly well brought up, and can be very rude at times. Remember: condemning individuals is always more important than paying attention to impersonal structures. The actual ruling class propagates ideologies of individualism, while tending to act as a class.

(Many of what we call “conspiracies” are the ruling class showing class solidarity.) The VC, as dupe-servants of the ruling class, does the opposite: it pays lip service to “solidarity” and “collectivity”, while always acting as if the individualist categories imposed by power really hold. Because they are petit-bourgeois to the core, the members of the Vampires’ Castle are intensely competitive, but this is repressed in the passive aggressive manner typical of the bourgeoisie. What holds them together is not solidarity, but mutual fear — the fear that they will be the next one to be outed, exposed, condemned.

The second law of the Vampires’ Castle is: make thought and action appear very, very difficult. There must be no lightness, and certainly no humour. Humour isn’t serious, by definition, right? Thought is hard work, for people with posh voices and furrowed brows. Where there is confidence, introduce scepticism. Say: don’t be hasty, we have to think more deeply about this. Remember: having convictions is oppressive, and might lead to gulags.

The third law of the Vampires’ Castle is: propagate as much guilt as you can. The more guilt the better. People must feel bad: it is a sign that they understand the gravity of things. It’s OK to be class-privileged if you feel guilty about privilege and make others in a subordinate class position to you feel guilty too. You do some good works for the poor, too, right?

The fourth law of the Vampires’ Castle is: essentialise. While fluidity of identity, pluarity and multiplicity are always claimed on behalf of the VC members — partly to cover up their own invariably wealthy, privileged or bourgeois-assimilationist background — the enemy is always to be essentialised. Since the desires animating the VC are in large part priests’ desires to excommunicate and condemn, there has to be a strong distinction between Good and Evil, with the latter essentialised. Notice the tactics. X has made a remark/ has behaved in a particular way — these remarks/ this behaviour might be construed as transphobic/sexist etc. So far, OK. But it’s the next move which is the kicker. X then becomes defined as a transphobe/sexist, etc. Their whole identity becomes defined by one ill-judged remark or behavioural slip. Once the VC has mustered its witchhunt, the victim (often from a working-class background, and not schooled in the passive aggressive etiquette of the bourgeoisie) can reliably be goaded into losing their temper, further securing their position as pariah/ latest to be consumed in feeding frenzy.

The fifth law of the Vampires’ Castle: think like a liberal (because you are one). The VC’s work of constantly stoking up reactive outrage consists of endlessly pointing out the screamingly obvious: capital behaves like capital (it’s not very nice!), repressive state apparatuses are repressive. We must protest!

Neo-Anarchy in the UK

The second libidinal formation is neo-anarchism. By neo-anarchists I definitely do not mean anarchists or syndicalists involved in actual workplace organisation, such as the Solidarity Federation. I mean, rather, those who identify as anarchists but whose involvement in politics extends little beyond student protests and occupations, and commenting on Twitter. Like the denizens of the Vampires’ Castle, neo-anarchists usually come from a petitbourgeois background, if not from somewhere even more class-privileged.

They are also overwhelmingly young: in their twenties or at most their early thirties, and what informs the neo-anarchist position is a narrow historical horizon. Neo-anarchists have experienced nothing but capitalist realism. By the time the neo-anarchists had come to political consciousness — and many of them have come to political consciousness remarkably recently, given the level of bullish swagger they sometimes display — the Labour Party had become a Blairite shell, implementing neo-liberalism with a small dose of social justice on the side. But the problem with neo-anarchism is that it unthinkingly reflects this historical moment rather than offering any escape from it. It forgets, or perhaps is genuinely unaware of, the Labour Party’s role in nationalising major industries and utilities or founding the National Health Service. Neo-anarchists will assert that “parliamentary politics never changed anything”, or the “Labour Party was always useless” while attending protests about the NHS, or retweeting complaints about the dismantling of what remains of the welfare state. There’s a strange implicit rule here: it’s OK to protest against what parliament has done, but it’s not alright to enter into parliament or the mass media to attempt to engineer change from there. Mainstream media is to be disdained, but BBC Question Time is to be watched and moaned about on Twitter. Purism shades into fatalism; better not to be in any way tainted by the corruption of the mainstream, better to uselessly “resist” than to risk getting your hands dirty.

It’s not surprising, then, that so many neo-anarchists come across as depressed. This depression is no doubt reinforced by the anxieties of postgraduate life, since, like the Vampires’ Castle, neo-anarchism has its natural home in universities, and is usually propagated by those studying for postgraduate qualifications, or those who have recently graduated from such study.

What is to be done?

Why have these two configurations come to the fore? The first reason is that they have been allowed to prosper by capital because they serve its interests. Capital subdued the organised working class by decomposing class consciousness, viciously subjugating trade unions while seducing “hard-working families” into identifying with their own narrowly defined interests instead of the interests of the wider class; but why would capital be concerned about a “left” that replaces class politics with a moralising individualism, and that, far from building solidarity, spreads fear and insecurity?

The second reason is what Jodi Dean has called communicative capitalism. It might have been possible to ignore the Vampires’ Castle and the neoanarchists if it weren’t for capitalist cyberspace. The VC’s pious moralising has been a feature of a certain “left” for many years — but, if one wasn’t a member of this particular church, its sermons could be avoided. Social media means that this is no longer the case, and there is little protection from the psychic pathologies propagated by these discourses.

So what can we do now? First of all, it is imperative to reject identitarianism, and to recognise that there are no identities, only desires, interests and identifications. Part of the importance of the British Cultural Studies project — as revealed so powerfully and so movingly in John Akomfrah’s installation “The Unfinished Conversation” (currently in the Tate Britain) and his film The Stuart Hall Project — was to have resisted identitarian essentialism. Instead of freezing people into chains of alreadyexisting equivalences, the point was to treat any articulation as provisional and plastic. New articulations can always be created. No one is essentially anything. Sadly, the right act on this insight more effectively than the left does. The bourgeois-identitarian left knows how to propagate guilt and conduct a witch hunt, but it doesn’t know how to make converts. But that, after all, is not the point. The aim is not to popularise a leftist position, or to win people over to it, but to remain in a position of elite superiority, but now with class superiority redoubled by moral superiority too. “How dare you talk — it’s we who speak for those who suffer!”

But the rejection of identitarianism can only be achieved by the reassertion of class. A left that does not have class at its core can only be a liberal pressure group. Class consciousness is always double: it involves a simultaneous knowledge of the way in which class frames and shapes all experience, and a knowledge of the particular position that we occupy in the class structure. It must be remembered that the aim of our struggle is not recognition by the bourgeoisie, nor even the destruction of the bourgeoisie itself. It is the class structure — a structure that wounds everyone, even those who materially profit from it — that must be destroyed. The interests of the working class are the interests of all; the interests of the bourgeoisie are the interests of capital, which are the interests of no-one. Our struggle must be towards the construction of a new and surprising world, not the preservation of identities shaped and distorted by capital.

If this seems like a forbidding and daunting task, it is. But we can start to engage in many prefigurative activities right now. Actually, such activities would go beyond pre-figuration — they could start a virtuous cycle, a selffulfilling prophecy in which bourgeois modes of subjectivity are dismantled and a new universality starts to build itself. We need to learn, or re-learn, how to build comradeship and solidarity instead of doing capital’s work for it by condemning and abusing each other. This doesn’t mean, of course, that we must always agree — on the contrary, we must create conditions where disagreement can take place without fear of exclusion and excommunication. We need to think very strategically about how to use social media — always remembering that, despite the egalitarianism claimed for social media by capital’s libidinal engineers, that this is currently an enemy territory, dedicated to the reproduction of capital. But this doesn’t mean that we can’t occupy the terrain and start to use it for the purposes of producing class consciousness. We must break out of the “debate” that communicative capitalism in which capital is endlessly cajoling us to participate in, and remember that we are involved in a class struggle. The goal is not to “be” an activist, but to aid the working class to activate — and transform — itself. Outside the Vampires’ Castle, anything is possible.





good for nothing1

I’ve suffered from depression intermittently since I was a teenager. Some of these episodes have been highly debilitating — resulting in self-harm, withdrawal (where I would spend months on end in my own room, only venturing out to sign-on or to buy the minimal amounts of food I was consuming), and time spent on psychiatric wards. I wouldn’t say I’ve recovered from the condition, but I’m pleased to say that both the incidences and the severity of depressive episodes have greatly lessened in recent years. Partly, that is a consequence of changes in my life situation, but it’s also to do with coming to a different understanding of my depression and what caused it. I offer up my own experiences of mental distress not because I think there’s anything special or unique about them, but in support of the claim that many forms of depression are best understood — and best combatted — through frames that are impersonal and political rather than individual and “psychological”.

Writing about one’s own depression is difficult. Depression is partly constituted by a sneering “inner” voice which accuses you of self-indulgence — you aren’t depressed, you’re just feeling sorry for yourself, pull yourself together — and this voice is liable to be triggered by going public about the condition. Of course, this voice isn’t an “inner” voice at all — it is the internalised expression of actual social forces, some of which have a vested interest in denying any connection between depression and politics.

My depression was always tied up with the conviction that I was literally good for nothing. I spent most of my life up to the age of thirty believing that I would never work. In my twenties I drifted between postgraduate study, periods of unemployment and temporary jobs. In each of these roles, I felt that I didn’t really belong — in postgraduate study, because I was a dilettante who had somehow faked his way through, not a proper scholar; in unemployment, because I wasn’t really unemployed, like those who were honestly seeking work, but a shirker; and in temporary jobs, because I felt I was performing incompetently, and in any case I didn’t really belong in these office or factory jobs, not because I was “too good” for them, but — very much to the contrary — because I was over-educated and useless, taking the job of someone who needed and deserved it more than I did. Even when I was on a psychiatric ward, I felt I was not really depressed — I was only simulating the condition in order to avoid work, or in the infernally paradoxical logic of depression, I was simulating it in order to conceal the fact that I was not capable of working, and that there was no place at all for me in society.

When I eventually got a job as lecturer in a Further Education college, I was for a while elated — yet by its very nature this elation showed that I had not shaken off the feelings of worthlessness that would soon lead to further periods of depression. I lacked the calm confidence of one born to the role. At some not very submerged level, I evidently still didn’t believe that I was the kind of person who could do a job like teaching. But where did this belief come from? The dominant school of thought in psychiatry locates the origins of such “beliefs” in malfunctioning brain chemistry, which are to be corrected by pharmaceuticals; psychoanalysis and forms of therapy influenced by it famously look for the roots of mental distress in family background, while Cognitive Behavioural Therapy is less interested in locating the source of negative beliefs than it is in simply replacing them with a set of positive stories. It is not that these models are entirely false, it is that they miss — and must miss — the most likely cause of such feelings of inferiority: social power. The form of social power that had most effect on me was class power, although of course gender, race and other forms of oppression work by producing the same sense of ontological inferiority, which is best expressed in exactly the thought I articulated above: that one is not the kind of person who can fulfill roles which are earmarked for the dominant group.

On the urging of one of the readers of my book Capitalist Realism, I started to investigate the work of David Smail. Smail — a therapist, but one who makes the question of power central to his practice — confirmed the hypotheses about depression that I had stumbled towards. In his crucial book The Origins of Unhappiness, Smail describes how the marks of class are designed to be indelible. For those who from birth are taught to think of themselves as lesser, the acquisition of qualifications or wealth will seldom be sufficient to erase — either in their own minds or in the minds of others — the primordial sense of worthlessness that marks them so early in life. Someone who moves out of the social sphere they are “supposed” to occupy is always in danger of being overcome by feelings of vertigo, panic and horror:

… () isolated, cut off, surrounded by hostile space, you are suddenly without connections, without stability, with nothing to hold you upright or in place; a dizzying, sickening unreality takes possession of you; you are threatened by a complete loss of identity, a sense of utter fraudulence; you have no right to be here, now, inhabiting this body, dressed in this way; you are a nothing, and “nothing” is quite literally what you feel you are about to become.2

For some time now, one of the most successful tactics of the ruling class has been responsibilisation. Each individual member of the subordinate class is encouraged into feeling that their poverty, lack of opportunities, or unemployment, is their fault and their fault alone. Individuals will blame themselves rather than social structures, which in any case they have been induced into believing do not really exist (they are just excuses, called upon by the weak). What Smail calls “magical voluntarism” — the belief that it is within every individual’s power to make themselves whatever they want to be — is the dominant ideology and unofficial religion of contemporary capitalist society, pushed by reality TV “experts” and business gurus as much as by politicians. Magical voluntarism is both an effect and a cause of the currently historically low level of class consciousness. It is the flipside of depression — whose underlying conviction is that we are all uniquely responsible for our own misery and therefore deserve it. A particularly vicious double bind is imposed on the long-term unemployed in the UK now: a population that has all its life been sent the message that it is good for nothing is simultaneously told that it can do anything it wants to do.

We must understand the fatalistic submission of the UK’s population to austerity as the consequence of a deliberately cultivated depression. This depression is manifested in the acceptance that things will get worse (for all but a small elite), that we are lucky to have a job at all (so we shouldn’t expect wages to keep pace with inflation), that we cannot afford the collective provision of the welfare state. Collective depression is the result of the ruling-class project of resubordination. For some time now, we have increasingly accepted the idea that we are not the kind of people who can act. This isn’t a failure of will any more than an individual depressed person can “snap themselves out of it” by “pulling their socks up”. The rebuilding of class consciousness is a formidable task indeed, one that cannot be achieved by calling upon ready-made solutions — but, in spite of what our collective depression tells us, it can be done. Inventing new forms of political involvement, reviving institutions that have become decadent, converting privatised disaffection into politicised anger: all of this can happen, and when it does, who knows what is possible?





PART SEVEN

ACID COMMUNISM





acid communism (unfinished introduction)1

“The spectre of a world which could be free”

“T ()he closer the real possibility of liberating the individual from the constraints once justified by scarcity and immaturity, the greater the need for maintaining and streamlining these constraints lest the established order of domination dissolve. Civilisation has to protect itself against the spectre of a world which could be free.

… () In exchange for the commodities that enrich their lives … () individuals sell not only their labour but also their free time. … () People dwell in apartment concentrations — and have private automobiles with which they can no longer escape into a different world. They have huge refrigerators stuffed with frozen foods. They have dozens of newspapers and magazines which espouse the same ideals. They have innumerable choices, innumerable gadgets which are all of the same sort and keep them occupied and divert their attention from the real issue — which is the awareness that they could both work less and determine their own needs and satisfactions.”

— Herbert Marcuse, Eros and Civlisation2

The claim of the book is that the last forty years have been about the exorcising of “the spectre of a world which could be free”. Adopting the perspective of such a world allows us to reverse the emphasis of much recent left-wing struggle. Instead of seeking to overcome capital, we should focus on what capital must always obstruct: the collective capacity to produce, care and enjoy. We on the left have had it wrong for a while: it is not that we are anti-capitalist, it is that capitalism, with all its visored cops, its teargas, and all the theological niceties of its economics, is set up to block the emergence of this Red Plenty. The overcoming of capital has to be fundamentally based on the simple insight that, far from being about “wealth creation”, capital necessarily and always blocks the production of common wealth.

The principal, though by no means the sole, agent involved in the exorcism of the spectre of a world which could be free is the project that has been called neoliberalism. But neoliberalism’s real target was not its official enemies — the decadent monolith of the Soviet bloc, and the crumbling compacts of social democracy and the New Deal, which were collapsing under the weight of their own contradictions. Instead, neoliberalism is best understood as a project aimed at destroying — to the point of making them unthinkable — the experiments in democratic socialism and libertarian communism that were efflorescing at the end of the Sixties and the beginning of the Seventies.

The ultimate consequence of the elimination these possibilities was the condition I have called capitalist realism — the fatalistic acquiescence in the view that there is no alternative to capitalism. If there was a founding event of capitalist realism, it would be the violent destruction of the Allende government in Chile by General Pinochet’s American-backed coup. Allende was experimenting with a form of democratic socialism which offered a real alternative both to capitalism and to Stalinism. The military destruction of the Allende regime, and the subsequent mass imprisonments and torture, are only the most violent and dramatic example of the lengths capital had to go to in order to make itself appear to be the only “realistic” mode of organising society. It wasn’t only that a new form of socialism was terminated in Chile; the country also became a lab in which the measures which would be rolled out in other hubs of neoliberalism (financial deregulation, the opening up of the economy to foreign capital, privatisation) were trialled. In countries like the US and the UK, the implementation of capitalist realism was a much more piecemeal affair, involving inducements and seductions as well as repression. The ultimate effect was the same — the extirpation of the very idea of democratic socialism or libertarian communism.

The exorcising of the “spectre of a world which could be free” was a cultural as well as a narrowly political question. For this spectre, and the possibility of a world beyond toil, was raised most potently in culture — even, or perhaps especially, in culture which didn’t necessarily think of itself as politically-orientated.

Marcuse explains why this is the case, and the declining influence of his work in recent years tells its own story. One-Dimensional Man, a book which emphasises the gloomier side of his work, has remained a reference point, but Eros and Civilisation, like many of his other works, has long been out of print. His critique of capitalism’s total administration of life and subjectivity continued to resonate; whereas the claims Marcuse’s conviction that art constituted a “Great Refusal, the protest against that which is”3 came to seem like outmoded Romanticism, quaintly irrelevant in the age of capitalist realism. Yet Marcuse had already forestalled such criticisms, and the critique in One-Dimensional Man has traction because it comes from a second space, an “aesthetic dimension” radically incompatible with everyday life under capitalism. Marcuse argued that, in actuality, the “traditional images of artistic alienation” associated with Romanticism do not belong to the past. Instead, he said, in… formulation, they “recall and preserve in memory belongs to the future: images of a gratification that would destroy the society that suppresses it.”4

The Great Refusal rejected, not only capitalist realism, but “realism” as such. There is, he wrote, an “inherent conflict between art and political realism”.5 Art was a positive alienation, a “rational negation” of the existing order of things. His Frankfurt School predecessor, Theodor Adorno, had placed a similar value on the intrinsic alterity of experimental art. In Adorno’s work, however, we are invited to endlessly examine the wounds of a damaged life under capital; the idea of a world beyond capital is despatched into a utopian beyond. Art only marks our distance from this utopia. By contrast, Marcuse vividly evokes, as an immediate prospect, a world totally transformed. It was no doubt this quality of his work that meant Marcuse was taken up so enthusiastically by elements of the Sixties counterculture. He had anticipated the counterculture’s challenge to a world dominated by meaningless labour. The most politically significant figures in literature, he argued in One-Dimensional Man, were “those who don’t earn a living, at least not in an ordinary and normal way”.6 Such characters, and the forms of life with which they were associated, would come to the fore in the counterculture.

Actually, as much as Marcuse’s work was in tune with the counterculture, his analysis also forecast its ultimate failure and incorporation. A major theme of One-Dimensional Man was the neutralisation of the aesthetic challenge. Marcuse worried about the popularisation of the avant-garde, not out of elitist anxieties that the democratisation of culture would corrupt the purity of art, but because the absorption of art into the administered spaces of capitalist commerce would gloss over its incompatibility with capitalist culture. He had already seen capitalist culture convert the gangster, the beatnik and the vamp from “images another way of life” into “freaks or types of the same life”.7 The same would happen to the counterculture, many of whom, poignantly, preferred to call themselves freaks.

In any case, Marcuse allows us to see why the Sixties continue to nag at the current moment. In recent years, the Sixties have come to seem at once like a deep past so exotic and distant that we cannot imagine living in it, and a moment more vivid than now — a time when people really lived, when things really happened. Yet the decade haunts not because of some unrecoverable and unrepeatable confluence of factors, but because the potentials it materialised and began to democratise — the prospect of a life freed from drudgery — has to be continually suppressed. To explain why we have not moved to a world beyond work we have to look at a vast social, political and cultural project whose aim has been the production of scarcity. Capitalism: a system that generates artificial scarcity in order to produce real scarcity; a system that produces real scarcity in order to generate artificial scarcity. Actual scarcity — scarcity of natural resources — now haunts capital, as the Real that its fantasy of infinite expansion must work overtime to repress. The artificial scarcity — which is fundamentally a scarcity of time — is necessary, as Marcuse says, in order to distract us from the immanent possibility of freedom. (Neoliberalism’s victory, of course, depended upon a cooption of the concept of freedom. Neoliberal freedom, evidently, is not a freedom from work, but freedom through work.)

Just as Marcuse predicted, the availability of more consumer goods and devices in the global North has obscured the way in which those same goods have increasingly functioned to produce a scarcity of time. But perhaps even Marcuse could not have anticipated twenty-first-century capital’s capacity to generate overwork and to administer the time outside paid work. Maybe only a mordant futurologist like Philip K. Dick could have predicted the banal ubiquity of corporate communication today, its penetration into practically all areas of consciousness and everyday life.

“The past is so much safer”, observes one of the narrators of Margaret Atwood’s dystopian satire, The Heart Goes Last, “because whatever’s in it has already happened. It can’t be changed: so, in a way there’s nothing to dread”.8 Despite what Atwood’s narrator thinks, the past hasn’t “already happened”. The past has to be continually re-narrated, and the political point of reactionary narratives is to suppress the potentials which still await, ready to be re-awakened, in older moments. The Sixties counterculture is now inseparable from its own simulation, and the reduction of the decade to “iconic” images, to “classic” music and to nostalgic reminiscences has neutralised the real promises that exploded then. Those aspects of the counterculture which could be appropriated have been repurposed as precursors of “the new spirit of capitalism”, while those which were incompatible with a world of overwork have been condemned as so many idle doodles, which in the contradictory logic of reaction, are simultaneously dangerous and impotent.

The subduing of the counterculture has seemed to confirm the validity of the scepticism and hostility to the kind of position Marcuse was advancing. If “the counterculture led to neoliberalism”, better that the counterculture had not happened. In fact, the opposite argument is more convincing — that the failure of the left after the Sixties had much to do with its repudiation of, or refusal to engage with, the dreamings that the counterculture unleashed. There was no inevitability about the new right’s seizure and binding of these new currents to its project of mandatory individualisation and overwork.

What if the counterculture was only a stumbling beginning, rather than the best that could be hoped for? What if the success of neoliberalism was a not an indication of the inevitability of capitalism, but a testament to the scale of the threat posed by the spectre of a society which could be free?

It is in the spirit of these questions that this book shall return to the 1960s and 1970s. The rise of capitalist realism could not happened without the narratives that reactionary forces told about those decades. Returning to those moments will allow us to continue with the process of unpicking the narratives that neoliberalism has woven around them. More importantly, it will enable the construction of new narratives.

In many ways, re-thinking the 1970s is more important than revisiting the 1960s. The 1970s was the decade that neoliberalism began a rise that it would retrospectively narrate as irresistible. However, recent work on the 1970s — including Jefferson Cowie’s Stayin’ Alive: The Last Days of the Working Class, Andy Beckett’s When the Lights Went Out and John Medhurst’s That Option No Longer Exists — has emphasised that the decade wasn’t only about the draining away of the possibilities that had exploded in the Sixties. The Seventies was a period of struggle and transition, in which the meaning and legacy of the previous decade was one of the crucial battlegrounds. Some of the emancipatory tendencies that had emerged during the Sixties intensified and proliferated during the Seventies “F ()or many politicised Britons”, Andy Beckett has written, “the decade was not the hangover after the Sixties; it was the point when the great Sixties party actually started”.9

The successful Miners’ Strike of 1972 saw an alliance between the striking miners and students that was echoed similar convergences in Paris 1968, with the miners using the University of Essex’s Colchester campus as their East Anglian base.

Moving far beyond the simple story that the “Sixties led to neoliberalism”, these new readings of the 1970s allow us to apprehend the bravura intelligence, ferocious energy and improvisational imagination of the neoliberal counter-revolution. The installation of capitalist realism was by no means a simple restoration of an old state of affairs: the mandatory individualism imposed by neoliberalism was a new form of individualism, an individualism defined against the different forms of collectivity that clamoured out of the Sixties. This new individualism was designed to both surpass and make us forget those collective forms. So to recall these multiple forms of collectivity is less an act of remembering than of unforgetting, a counter-exorcism of the spectre of a world which could be free.

Acid Communism is the name I have given to this spectre. The concept of acid communism is a provocation and a promise. It is a joke of sorts, but one with very serious purpose. It points to something that, at one point, seemed inevitable, but which now appears impossible: the convergence of class consciousness, socialist-feminist consciousness-raising and psychedelic consciousness, the fusion of new social movements with a communist project, an unprecedented aestheticisation of everyday life.

Acid communism both refers to actual historical developments and to a virtual confluence that has not yet come together in actuality. Potentials exert influence without being actualised. Actual social formations are shaped by the potential formations whose actualisation they seek to impede. The impress of “a world which could be free” can be detected in the very structures of a capitalist realist world which makes freedom impossible.

The late cultural critic Ellen Willis said that the transformations imagined by the counterculture would have required “a social and psychic revolution of almost inconceivable magnitude”.10 It’s very difficult, in our more deflated times, to re-create the counterculture’s confidence that such a “social and psychic revolution” could not only happen, but was already in the process of unfolding. But we need now to return to a time when the prospect of universal liberation seemed imminent.

No More Miserable Monday Mornings

Let’s begin with a moment that is all the more richly evocative because of its apparent modesty:

It was July 1966 and I was newly nine years old. We had holidayed on the Broads and the family had recently taken possession of the gorgeous wooden cruiser that was to be our floating home for the next fortnight. It was called The Constellation and, as my brother and I breathlessly explored the twin beds and curtained portholes in our cabin built into the boat’s bow, the prospect of what lay ahead saw the life force beaming from us like the rays of a cartoon sun. … () I … () made my way up to through the boat to take up position in the small area of the stern. On the way, I pick up sister Sharon’s teeny pink and white Sanyo transistor radio and switched it on. I looked up at the clear blue afternoon sky. Ike and Tina Turner’s “River Deep, Mountain High” was playing and a sort of rapturous trance descended on me. From the limitless blue sky I looked down into the churning, crystal-peaked wake our boat was creating as we motored along, and at that moment, “River Deep” gave way to my absolute favourite song of the period: “Bus Stop” by the Hollies. As the mock flamenco guitar flourish that marks its beginning rose above the deep burble of the Constellation’s engine, I stared into the tumbling waters and said aloud, but to myself, “This is happening now. THIS is happening now.”11

This account comes from Going To Sea in a Sieve, the memoirs of the writer and broadcaster Danny Baker. It ought to go without saying that this was nothing more than a snapshot, one sun-saturated image from a period that contained more than enough misery and horror. The Sixties were not a realised utopia, just as the opportunities that lay ahead for Baker would not be available to most working-class people. Similarly, it would be easy to discount Baker’s reverie as nostalgia for lost childhood, the kind of golden memories that practically anyone from any historical period or social background might have.

Yet there is something very specific about this moment, something that means it could have only happened then. We can enumerate some of the factors that made it unique: a sense of existential and social security that allowed working-class families to take holidays at all; the role that new technology such as transistor radios played in both connecting groups to an outside and enabling them to luxuriate in the moment, a moment that was somehow exorbitantly sufficient; the way that genuinely new music — music that wasn’t imaginable a few months never mind a few years before — could crystallise and intensify this whole scene, imbue it with a sense of casual but not complacent optimism, a sense that the world was improving.

This sense of exorbitant sufficiency could be heard in the Kinks’ “Sunny Afternoon”, which Baker might well have also heard on the same transistor radio that day, or in the Beatles’ “I’m Only Sleeping”, which would come out a month later; or in later releases like the Small Faces’ “Lazy Sunday”. These tracks apprehended the anxiety-dream toil of everyday life from a perspective that floated alongside, above or beyond it: whether it was the busy street glimpsed from the high window of a late sleeper, whose bed becomes a gently idling rowing boat; the fog and frost of a Monday morning abjured from a sunny Sunday afternoon that does not need to end; or the urgencies of business airily disdained from the eyrie of a meandering aristocratic pile, now occupied by working-class dreamers who will never clock on again.

“I’m Only Sleeping” (“stay in bed, float upstream”) was the twin of Revolver’s most self-consciously psychedelic track, “Tomorrow Never Knows” (“switch off your mind, relax and float downstream”). If the lyrics to “Tomorrow Never Knows”, minimally adapted from The Psychedelic Experience: A Manual Based on the Tibetan Book of the Dead, seem somewhat pat, the music, the sound design, retain the power to transport. “It wasn’t like anything else we’d ever heard”, John Foxx recalls of “Tomorrow Never Knows”,

but somehow seemed instantly recognisable. Sure, the words were a bit suspect, but the music, the sound — organic electricity, disintegrated transmissions, lost radio stations, Catholic/Buddhist mass from a parallel universe, what being stoned ought to be like — weightless, timeless, revelation, moving over luminous new landscapes in serene velocity. It communicated, innovated, infiltrated, fascinated, elevated — it was a road map for the future.12

These “luminous new landscapes” were worlds beyond work, where drudgery’s dreary repetitiveness gave way to drifting explorations of strange terrains. Listened to now, these tracks describe the very conditions necessary for their own production, which is to say, access to a certain mode of time, time which allows a deep absorption.

The refusal of work was also a refusal to internalise the systems of valuation which claimed that one’s existence is validated by paid employment. It was, that is to say, a refusal to submit to a bourgeois gaze which measured life in terms of success in business. “I didn’t come from a background where people had ‘careers’”, Danny Baker writes. “You went to work, you had different jobs at different times, but it was all in a jumble. It did not define you or plot your course in life — and thank God for that.” Baker left school in South East London with no qualifications. Yet he is careful that his picaresque journey from record shop assistant, to fanzine producer, music journalist and television and radio presenter should not be seen as either a hard luck nor a hard work story. He doesn’t tell it as a petit-bourgeois narrative of “betterment”, but of recklessness rewarded. This “recklessness” came out of a sense that fulfilment wasn’t to be expected from work, and from an immense confidence, which allows him to consistently rebuff bourgeois imperatives and anxieties. The two volumes of Baker’s memoirs lay out very clearly the factors which allowed this confidence to grow: the comparative stability of his father’s work, in thriving docks that seemed as if they would remain at the heart of British economic life forever; the family’s embedding in a working-class network that supplemented wages with “bunce”; its acquisition of a brand-new council flat with a garden. His own movement into writing and broadcasting was facilitated not by any entrepreneurial drive, but by a newly emerging public sphere — constituted out of parts of television, radio and print media — in which working-class perspectives were validated and valued. But this was not a working class which could be understood according to the protocols of kitchen-sink or socialist realism anymore than it was limited by ruling-class caricature. It was a working class that no longer knew its place, that had gotten above itself. Even the old redoubts of the bourgeoisie were no longer secure. In the Sixties, Ted Hughes had become one of Britain’s leading poets, Harold Pinter one of its most exciting new dramatists, both of them producing work which reflected working-class experience in challenging and difficult ways, and taking it — via television — into the living rooms of a mass audience.

In any case, we are a long way from the disappearance of class later that would later be trumpeted by neoliberal ideologues. The settlements that labour and capital had come to in societies like the US and the UK accepted that class was a permanent feature of social organisation. They assumed that there were different class interests which had to be reconciled, and that any effective, not to mention just, governance of society would have to involve the organised working class. Trade unions were strong, emboldened in their demands by low unemployment. Working-class expectations were high — gains had been made, but more were surely on the way. It was easy to imagine that the uneasy truces between capital and labour would end, not with a resurgence of the right, but with an embrace of more socialistic policies, if not quite the “full communism” that Nikita Krushchev thought would be in place by 1980. After all — or so it seemed — the right was on the backfoot, discredited and perhaps fatally damaged in the US because of the protracted and horrific failure of the Vietnam War. The “establishment” no longer commanded automatic deference; instead, it came to seem exhausted, out of touch, obsolete, limply awaiting to be washed away by any or all of the new cultural and political waves which were eroding all the old certainties.

Where the new culture was not being driven by those from working-class backgrounds, it seemed that it was being led by class renegades such as Pink Floyd, young people from bourgeois families who had rejected their own class destinies and identified “downwards”, or outwards. They wanted to do anything but go into business and banking: fields whose subsequent libidinisation would have boggled the expanded minds of the Sixties.

Working-class aspiration did not equate to class mobility, where the dubious reward was gradual and grudging acceptance by “betters”. Instead, the new bohemia seemed to point to the elimination of the bourgeoisie and its values. Indeed, it was the conviction that this was imminent which was one of the few areas of overlap between the counterculture and the traditional revolutionary left, who seemed in many other respects to be at variance with one another.

Ellen Willis certainly felt that the dominant forms of left-wing politics were incompatible with the desires and ambitions triggered and tranduced by music. While the music that she listened to spoke of freedom, socialism seemed to be about centralisation and state control. The counterculture’s politics might have been opposed to capitalism, Willis thought, but this did not entail a straightforward rejection of everything produced in the capitalist field. Her “polemic against standard leftist notions about advanced capitalism” rejected at best only half-true the ideas “that the consumer economy makes us slave to commodities, that the function of the mass media is to manipulate our fantasies, so we will equate fulfilment with buying the system’s commodities”.13 Mass culture — and music culture in particular — was a terrain of struggle rather than a dominion of capital. The relationship between aesthetic forms and politics was unstable and inchoate — aesthetic forms did not simply “express” some already-existing capitalist reality, they anticipated and actually produced new possibilities. Commodification was not the point at which this tension would always and inevitably be resolved in favour of capital; rather, commodities could themselves be the means by which rebellious currents could propagate:

the mass media helped to spread rebellion, and the system obligingly marketed products that encouraged it, for the simple reason that there was money to be made from rebels who were also consumers. On one level the sixties revolt was an impressive illustration of Lenin’s remark that the capitalist will sell you the rope to hang him with.14

In the UK, Stuart Hall felt similar frustrations with much of the existing left — frustrations that were all the more intense in his case because he thought of himself as a socialist. But the socialism that Hall wanted — a socialism that could engage with the yearnings and dreamings that he heard in Miles Davis’ music — was yet to be created, and its arrival was obstructed as much by figures from the left as from the right.

The first obstructive figure of the left was the complacent steward of Cold War organised labour or social democracy: backward-looking, bureaucratic, resigned to the “inevitability” of capitalism, more interested in preserving the income and status of white men than in expanding the struggle to include…, this figure is defined by compromise and eventual failure.

The other figure — what I want to call the Harsh Leninist Superego — is defined by its absolute refusal of compromise. According to Freud, the superego is characterised by the quantitatively and qualitatively excessive nature of its demands: whatever we do, it’s never enough. The Harsh Leninist Superego mandates a militant ascesis. The militant will be single-mindedly dedicated to the revolutionary event, and unflinchingly committed to the means necessary to bring it about. The Harsh Leninist Superego is as indifferent to suffering as it is hostile to pleasure Lenin’s phobic response to music is instructive here: “I can’t listen to music too often. It affects your nerves, makes you want to say stupid nice things and stroke the heads of people who could create such beauty while living in this vile hell.”

While the complacent leaders of organised labour were invested in the status quo, the Harsh Leninist Superego stakes everything on a world absolutely different to this one. It was this post-revolutionary world which would redeem the Leninist, and it was from the perspective of this world that they judged themselves. In the meantime, it is legitimate and indeed necessary to cultivate an indifference towards current suffering: we can and must step over homeless people, because giving to charity only obstructs the coming of the revolution.

But this revolution had little in common with the “social and psychic revolution of almost inconceivable magnitude” that Ellen Willis thought was seeded in the counterculture’s dreamings. The revolution as she conceived of it would at once be more immediate — it would fundamentally concern how care and domestic arrangements were organised — and more far-reaching: the transformed world would be unimaginably stranger than anything Marxist-Leninism had projected. The counterculture thought it was already producing spaces where this revolution could already be experienced.

To get some sense of what those spaces were like, we can do no better than listen to the Tempations’ “Psychedelic Shack”, released in December 1969. The group play the role of breathless ingénues who have just returned from some kind of Wonderland: “Strobe lights flashin’ way till after sundown… There ain’t no such thing as time… Incense in the air…”

For all the familiarity of these signifiers, listening to “Psychedelic Shack” now can actually bring us up short. Invited to think about the psychedelic, our first associations might be with solipsistic withdrawal (the lyrics of a track like “Tomorrow Never Knows” invite just such an association). Yet “Psychedelic Shack” describes a space that is very definitely collective, that bustles with all the energy of a bazaar. For all its carnivalesque departures from everyday reality, however, this is no remote utopia. It feels like an actual social space, one you can imagine really existing. You are as likely to come upon a crank or a huckster as a poet or musician here, and who knows if today’s crank might turn out to be tomorrow’s genius? It is also an egalitarian and democratic space, and a certain affect presides over everything. There is multiplicity, but little sign of resentment or malice. It is a space for fellowship, for meeting and talking as much for having your mind blown. If “there’s no such thing as time” — because the lighting suspends the distinction between day and night; because drugs affect time-perception — then you are not prey to the urgencies which make so much of workaday life a drudge. There is no limit to how long conversations can last, and no telling where encounters might lead. You are free to leave your street identity behind, you can transform yourself according to your desires, according to desires which you didn’t know you had.

The crucial defining feature of the psychedelic is the question of consciousness, and its relationship to what is experienced as reality. If the very fundamentals of our experience, such as our sense of space and time, can be altered, does that not mean that the categories by which we live are plastic, mutable? Understood in individual terms, this quickly leads to the facile relativism and a naïve voluntarism that the Temptations themselves had targeted on their first psychedelic soul single, “Cloud Nine”. Sure, you can be what you want to be, but only by being a million miles from reality, only by leaving behind all your responsibilities. This superegoic appeal could have been endorsed by conservatives as well as a certain brand of radical: conservatives, who wanted everyone to knuckle down to work; militants, who demanded commitment to revolution, which — they said — entailed an attention to the horrors of the world, not a quick fix flight from the real.

Yet the claim that altered states of consciousness took you a “million miles away from reality” was question-begging. It foreclosed the idea that altered state of consciousness could offer a perception of the systems of power, exploitation and ritual that was more, not less, lucid than ordinary consciousness. In the Sixties, when consciousness was increasingly besieged by the fantasies and images of advertising and capitalist spectacle, how solid was the “reality” from which psychedelic states fled in any case? Wasn’t the state of consciousness susceptible to spectacle more like somnambulance than alertness or awareness?

In retrospect, one of the most remarkable features of the psychedelic culture of the 1960s was the way it mainstreamed such metaphysical questions. The psychedelic was not new — many pre-capitalist societies had incorporated psychedelic visions and the use of hallucinogens into their ritual practice. What was new was the break out of the psychedelic from particular ritualised spaces and times, and from the control of particular practitioners, such as shamans and sorcerers. Experiments with consciousness were now in principle open to anyone. Despite all the mysticism and pseudo-spiritualism which has always hung over psychedelic culture, there was actually a demystificatory and materialist dimension to this. Widespread experiments with consciousness promised nothing less than a democratisation of neurology itself — a newly widespread awareness of the brain’s role in producing what was experienced as reality. Those on acid trips were externalising the workings of their own brain, and potentially learning to use their brains differently.

Yet psychedelic experiences were not confined to those who had taken drugs. The very mass media which mainstreamed psychedelic concepts along with the Vietnam War was itself a massive experiment in altering consciousness. With television, the breakdown of the distinction between dreams and waking life that film had begun now entered “private” domestic space. Television was at the centre of a media landscape that was still only just assembling, and which no one understood because nothing like it had ever existed before. The Beatles released their first album only a few months before the assassination of John F. Kennedy. Television was channel for contagion (Beatlemania!), trauma and hysteria as much as paternalistic messages or commercial huckstering. No one had been as famous in their own lifetime as the Beatles, because the infrastructure for such a fame was only just being created, and the Beatles themselves were playing a part in building it, as if — at one and the same time — the world had become an extension of their own electronic dream, and they had become characters in everyone else’s dream.

You might say that the Beatles’ own psychedelic turn was an attempt to convert all of this into a lucid dream. This is the quality of Sgt Pepper’s “A Day in the Life”, which plays out the difference between Lennon’s lucid dream calm and the urgencies of work life (McCartney’s breathless commuter, who reaches the bus in seconds flat). Yet escape from urgencies is always achingly proximate — once on the bus, McCartney’s immediately character falls into a dream.

Lennon sounds dispassionate but not detached; there is humour but no blokish familiarity. His vocal seems to intimate that the ordinary somnambulance of the workaday world can only be properly apprehended from the perspective afforded by a different kind of trance. Or is it, rather, that a voice disconnected from the imperatives of working/waking life comes off as catatonic? The tracks shows us the inside seen from outside, as Lennon takes us on journey through the different ways in which consciousness is electronically mediated (by newspapers, film, television): “I read the news today, oh boy”.

This contrast between urgency and lucidity was everywhere in Jonathan Miller’s television adaptation of Alice’s Adventures in Wonderland. It was broadcast on BBC television in December 1966, and reflected the influence of the Beatles even as it would go on to influence the Beatles in turn. Shot in black and white, the film has a strangely sober, almost austere visual style, devoid of any special effects or florid imagery. This fits with the adaptation’s most striking innovation, its rendering of the characters not as animals, but as human beings. “Once you take the animal heads off”, Miller told Life, “you begin to see what it’s all about. A small child, surrounded by hurrying, worried people, thinking: ‘is this what being grown up is like?’”

The film is pervaded by an atmosphere of lassitude, of languor and catatonia that sometimes lurches into sudden panic and helplessness. Miller again: “The book, by dressing things up in animal clothes, presents a disguised — a dream-disguised — domestic charade. … () All the levels of authority and order-giving and obedience are reflected.”15 The ordinary world appears as a tissue of Nonsense, incomprehensibly inconsistent, arbitrary and authoritarian, dominated by bizarre rituals, repetitions and automatisms. It is itself a bad dream, a kind of trance. In the solemn and autistic testiness of the adults who torment and perplex Alice, we see the madness of ideology itself: a dreamwork that has forgotten it is a dream, and which seeks to make us forget too, by sweeping us up in its urgencies, by perplexing us with its lugubrious dementia, or by terrifying us with its sudden, unpredictable and insatiable violence.

The laugher that this Alice provokes — sometimes uneasy, sometimes uproarious — is a laughter that comes from the outside. It is a psychedelic laughter, a laughter that — far from confirming or validating the values of any status quo — exposes the bizarreness, the inconsistency, of what had been taken for common sense. Is this not the laugher that Michel Foucault describes in a justly renowned passage from the Preface to The Order of Things, a book that was originally published in the same year that Miller’s version of Alice was broadcast? Foucault refers there to a story by Borges in which

he quotes a ‘certain Chinese encyclopaedia’ in which it is written that “animals are divided into: (a) belonging to the Emperor, (b) embalmed, (c) tame, (d) suckling pigs, (e) sirens, (f) fabulous, (g) stray dogs, (h) included in the present classification, (i) frenzied, (j) innumerable, (k) drawn with a very fine camelhair brush, (l) et cetera, (m) having just broken the water pitcher, (n) that from a long way off look like flies”. In the wonderment of this taxonomy, the thing we apprehend in one great leap, the thing that, by means of the fable, is demonstrated as the exotic charm of another system of thought, is the limitation of our own, the stark impossibility of thinking that.16

This perspective, this laughter from the outside, runs through all Foucault’s work. For all its intricacy, its density and opacity, Foucault’s major work from The History of Madness at the beginning of the 1960s, in the… through to the books on sexuality he would publish after the Death Valley seem to revolve around and repeat a fundamental insight, or outsight. … the arbitrariness and contingency of any system, its plasticity.

If this outside vision was consonant with the psychedelic consciousness, in Foucault’s case it did not have its origins in drugs. Foucault wouldn’t consume LSD until nearly a decade later, when he headed out to Death Valley and took acid at Zabriskie Point, the site of Michelangelo Antonioni’s film about the counterculture.

Foucault, seldom comfortable in his own skin, was always looking for a way out of his own identity. He had memorably claimed that he wrote “in order not to have a face”, and his prodigious exercises in rogue scholarship and conceptual invention, the textual labyrinths he meticulously assembled from innumerable historical and philosophical sources, were one way out of the face. Another route was what he called the limit-experience, one version of which was his encounter with LSD. The limit-experience was paradoxical: it was an experience at and beyond the limits of “ordinary” experience, an experience of what cannot ordinarily be experienced at all. The limit-experience offered a kind of metaphysical hack. The conditions which made ordinary experience possible could now be encountered, transformed and escaped — at least temporarily. Yet, by definition, the entity which underwent this could not be the ordinary subject of experience — it would instead be some anonymous X, a faceless being.

Much of the music that came out of the counterculture gave voice to this entity from the outside, and Foucault’s turn to the limit-experience paralleled popular experimentations with consciousness. “T ()he problem”, Foucault said, in one of the interviews collected in the book Remarks on Marx,

is not to recover our “lost” identity, to free our imprisoned nature, our deepest truth; but instead, the problem is to move towards something radically Other. The center, then, seems still to be found in Marx’s phrase: man produces man. … () For me, what must be produced is not man identical to himself, exactly as nature would have designed him or according to his essence; on the contrary, we must produce something that doesn’t yet exist and about which we cannot know how and what it will be.17

In a commentary on Foucault’s text, Michael Hardt has argued that “the positive content of communism, which corresponds to the abolition of private property, is the autonomous production of humanity — a new seeing, a new hearing, a new thinking, a new loving.”18

A new humanity, a new seeing, a new thinking, a new loving: this is the promise of acid communism, and it was the promise that you could hear in “Psychedelic Shack” and the culture that inspired it. Only five years separated “Psychedelic Shack” from the Tempations’ early signature hit “My Girl”, but how many new worlds had come into being then? In “My Girl”, love remains sentimentalised, confined to the couple, in “Psychedelic Shack”, love is collective, and orientated towards the outside.

With “Psychedelic Shack”, the Temptations were a year into the new sound that the group’s unofficial leader, Otis Williams, had persuaded producer Norman Whitfield to develop. Whitfield had initially been reluctant to change the Temptations’ sound but his eventual conversion would lead to some of the most stunning productions in popular music history: productions that would build on the promise that “Tomorrow Never Knows” evoked, but which the Beatles themselves would rarely make good on. Whitfield became so entranced by the psychedelic soundscapes he worked on in the studio that he would push for The Temptations to release tracks that were eight or nine minutes long, with space for extended instrumental passages. He formed the group the Undisputed Truth specifically as a lab to try out these long-form lysergic productions. Whitfield’s experimentation with the studio as a compositional tool paralleled what Lee “Scratch” Perry was doing in Jamaica with dub. The sonic spaces they opened up were also about a particular experience of time: a distended time, a time that was at once denuded, and populated with strange audio unlike forms, which enticed the listener into a deep immersion in the moment, even as they enfolded us into rhythmic patterns and pulses. This new space-time would later be revisited and refurbished by new explorers such as Tom Moulton, Larry Levan and Walter Gibbons: the inventors of the extended dance track, which would in turn form the basis of the psychedelic genres such as house, techno and jungle.

The template for the new Temptations’ sound had been Sly and the Family Stone, with traces of James Brown and Jimi Hendrix: a febrile matrix, composed of elements which were already interacting with one another. The change in sound was more than a shift in style; it was also responded to a new set of demands and expectations of what music could be. No longer confined to love-song balladeering or good-time cheerleading, popular music could now be social comment; even better, it could feed off and feed back into the social transformations that were dissolving former certainties, prejudices, assumptions. It could take its bearings from the confidence, anger and assertiveness that was brimming out of the Civil Rights movement, and it could perform a new set of social relations that gave a heady taste of what the world might look like once the movement had succeeded. That is what Greil Marcus heard and saw in Sly and the Family Stone in his great 1975 essay, “The Myth of Staggerlee”:

Sly’s real triumph was that he had it both ways. Every nuance of his style, from the razzle dazzle of his threads to the originality of his music, made it clear that we was his own man. If the essence of his music was freedom, no one was more aggressively free than he. Yet there was also room for everyone in the America made up of blacks and whites, men and women, who sang out “different strokes for different folks” and were there on stage to show what such an idea of independence meant.19

Sly and the Family Stone did indeed seem to have it every way: with a sound that was somehow ramshackle, improvised, and yet sinuously danceable; a music that was neither sentimental, nor sanctimonious, but humorous and deadly serious all at the same time.

The laughter of Alice, the ludic freedom and daring embodied by Sly and the Family Stone: they might have been performed by an advanced guard, but there was no necessity for them to be confined to an elite. On the contrary, the question that their presence on radio and TV insistently posed was: why shouldn’t this bohemia be open to everyone?

Despite much of the traditional left’s deafness and hostility to these currents, the counterculture did have an impact on the workplace, in struggles conducted by a new kind of worker. “It’s a different generation of workingmen”, explained J.D. Smith, a union treasurer at the Chevy Vega plant in Lordstown, Ohio. “None of these guys came over from the old country, grateful for any job they could get. None of them have been through a depression. They’ve been exposed — at least through television — to all the youth movements of the last ten years and they don’t see the disgrace of being unemployed.”20

In 1972, the Lordstown Plant was embroiled in a struggle over working conditions which reflected the new intolerance towards drudgery and authoritarianism. “The Lordstown workers”, Jefferson Cowie writes,

became a collective national symbol for the new breed of worker and emblematic of a widespread sense of occupational alienation. People gravitated to the refreshing vision of youth, vitality, inter-racial solidarity hidden from the public behind the likes of television’s Archie Bunker, prowar labor leadership, and the growing politics of the blue-collar backlash.21

Lordstown was part of a wave of activism in which this “new breed of worker” struggled for democratic control of their own trade unions and of the places in which they worked. Seen in the light of such struggles, the egalitarian social space projected in “Psychedelic Shack” could not be dismissed as a passive pipe-dream or a distraction from actual political activity. Rather, music such as this was an active dreaming which arose out of real social and cultural compositions, and which fed back into potent new collectivities, and a new existential atmosphere, which rejected both drudgery and traditional resentments. “The young black and white workers dig each other”, said the Lordstown Local president Gary Bryner, “There’s an understanding. The guy with the Afro, the guy with the beads, the guy with the goatee, he doesn’t care if he’s black, white, green or yellow.” These new kinds of workers — who “smoked dope, socialised interracially, and dreamed of a world in which work had some meaning”22 — wanted democratic control of both their workplace and their trade unions.

Something of the same ferment was building in Italy, where a new kind of worker was increasingly visible. “This new generation of workers did not have so much to do with the old tradition of the labor parties”, says Franco Berardi of the situation in Turin in 1973. “Nor anything to do with the socialist ideology of a state-owned system. A massive refusal of the sadness of work was the leading element behind their protest. Those young workers had much more to do with the hippy movement; much more to do with the history of the avant-garde.”23

By 1977, a whole new social mix, a “mass avant-garde”, was in place in Bologna. It was here, perhaps more than anywhere else, that acid communism came together as an actual formation. The city seethed with the energy and confidence that erupts when new ideas commingle with new aesthetic forms.

The university was filled with terroni (people originating from the South), Germans, comedians, musicians and cartoonists like Andrea Pazienza and Filippo Scozzari. Artists were squatting houses in the center of the city, and running creative places such as Radio Alice and Traumfabrik. Some people were reading books like Anti-Oedipus, some were reciting poems by Majakovski and Artaud, listening to the music of Keith Jarrett and The Ramones, and inhaling dream inducing substances.24

As In February, A/traverso, the zine published by Berardi and others young militants, produced an issue entitled “The revolution is just, possible and necessary: look comrades, the revolution is probable”:

We want to expropriate all the assets of the Catholic Church

Cut the working hours, increase the number of jobs

Increase the amount of the salary

Transform production and place it under workers’ control

Liberation of the huge amount of intelligence that is wasted by capitalism: Technology has been used so far as a means of control and exploitation.

It wants to be turned into a tool for liberation.

Working less is possible thanks to the application of cybernetics and informatics.

Zerowork for income

Automate all production

All power to living labor

All work to dead labor.

In 1977, such demands seemed not only realistic but inevitable — “look comrades, the revolution is probable”. Of course, we now know that the revolution did not happen. But the material conditions for such a revolution are more in place in the twenty-first century than they were in 1977. What has shifted beyond all recognition since then is the existential and emotional atmosphere. Populations are resigned to the sadness of work, even as they are told that automation is making their jobs disappear. We must regain the optimism of that Seventies moment, just as we must carefully analyse all the machineries that capital deployed to convert confidence into dejection. Understanding how this process of consciousness-deflation worked is the first step to reversing it.







